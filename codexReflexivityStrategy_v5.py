# Copyright (c) 2025 浙江环目信息技术有限公司
# Author: 孔穆清 / pb_2n^
# All rights reserved. Proprietary and confidential.
# -*- coding: utf-8 -*-
"""
ReflexivityStrategyTriMA · Quiet 版（稀疏化/节流 + 震荡过滤 + 冷静期）
版本号：v2025.12.03-r39（教学稿 / 宵禁 + 超时落袋版 / 实盘前灾难体检 + 优先级联检版 + 科学验证方案 + review_state 导出 + 多机器人分目录导出 + 空单时效守卫 + 入场体检监控 + 灾难性资金体检总览 + 功能巡检总览 + WebUI 截图复盘模板 + SOL/ETH/DOGE 精细化覆写 + 1m 主节奏与模板互锁 + 旧功能速查清单 + 反手接力与 0.25R 优先级回收 + 实时仓位基准防抖）
====================================================================
新手友好教学速览（建议部署前先读完这一屏）：
--------------------------------------------------------------------
◎ 快速上手五步：
  1) **确认环境** —— 策略按 1m 时框、逐仓、双向合约设计；OKX/Gate/Binance USDT 永续通用，启动前请确认 config 开启 futures、REST/WebSocket/API-Key、`position_adjustment_enable`，并同步更新所选交易所模板（含 Binance v3）。
  2) **加载配置** —— 复用旧版 `config.json` 即可；要调试护栏或仓位治理，只需在 `strategy_parameters` / `pair_overrides` 中覆写单个字段即可生效，谨慎避免整段复制导致后续版本差异被覆盖。
  3) **观察全链路日志** —— WebUI 实时打印候选 / 终审 / 加仓 / 离场判定及中文分数拆解，`[止损地板]` 会标注旧版 0.5R≈0.338R 的锁盈细节；`_log_decision` 会按机器人标签增量生成日更复盘 Markdown，并在仓位详情中同步名义价值、杠杆、守卫状态、组合风险与会话上限。
  4) **模板自检（可选）** —— 如需批量核对配置，可运行 `python tools/validate_freqtrade_templates.py` 对照 freqtrade 2024.12 文档检查模板键名与取值；日常部署只需策略文件与配置即可跳过。
  5) **复盘与回归（可选）** —— 若想额外做工程审计，可在有空时运行 `python manual_expectation_guard_check.py` / `tools/future_leak_scan.py` / `tools/strategy_feature_sanity.py` / `tools/preflight_guard_matrix.py`；这些脚本仅为诊断辅助，正常实盘只需关注 WebUI 日志里的 `[止损地板]`、`floor clamp`、`guard_hold` 关键字即可。
  6) **盘前心理体检（可选）** —— `docs/operator_psych_state_checklist_cn.md` 提供客观量表，按“警觉/亢奋/疲劳/麻木”四象限勾选当下状态，再决定是继续、降频或暂停，避免“喝醉的人说自己没醉”。

◎ 核心功能全景（按模块快速记忆）：
  - **进场**：三锚聚合（方向/广度/冲击）+ channel pivot 冷静期 + 暗面/极端护栏，候选闸门确保只有对齐、空间、宏观都满足的信号才交给终审；`_entry_quality_score` 拆解权重，首单前置倍率、暗面降权、结构稀疏化全部记录在案。
  - **仓位**：账户画像、余额 tier、首腿/尾腿/防守腿协同；浮盈金字塔、防守均价腿、金字塔冷却、组合回撤限速共同决定加仓节奏。
  - **离场**：弹性止盈评分（大/中/小事件）、Strict Giveback、Measured Move、Micro/Small target、EMA 硬阈、量能衰竭、结构台阶等多层守卫协作；旧版 0.5R≈0.338R expectation guard 地板与 Strict Giveback 组合，让盈利单优先落袋，逆风单快速止损。
  - **止损/锁盈**：动态兜底止损、Keltner 缓冲、情境倍数、0.338R release-stop、组合锁盈、会话上限与 crowd guard 共同控制风险。
  - **组合治理**：风格自动驾驶、亏损压力调度、session ceiling 与 crowd sensing 控制再入频次，避免在回撤或拥挤行情中继续放大敞口。
  - **数据与复盘**：多时框 informative、全指标快照、WebUI 绘图三档、每日 Markdown 复盘、`tools/` 系列校验脚本串起教学与审计闭环。
  - **配置覆写**：`pair_overrides`/`strategy_parameters` 支持逐币种调节 ATR 门槛、scale-out、守卫阈值、杠杆上限；所有可调参数旁均附中文注释，方便按波动段微调。

◎ 工程化数据治理速览（freqtrade 2024.12+ 键名对齐）：
  - **数据鲜度与来源**：`_ensure_data_fresh` / `DATA_FRESH_MAX_AGE_MIN` 记录行情延迟，`DATA_BACKFILL_MIN_BARS`+`startup_candle_count` 防止指标漂移；日志按 freqtrade 最新模板标记 key/取值，便于对照官方文档。
  - **目录与导出**：`_review_report_flush` 将 Markdown/JSON/review_state/CSV 按机器人分目录落盘，缺口会在 `_preflight_disaster_guard` 高亮；`tools/validate_freqtrade_templates.py` / `tools/future_leak_scan.py` / `tools/preflight_guard_matrix.py` 复用官方键名校验与未来函数扫描，实盘前可一键巡检。
  - **参数治理**：`_compile_feature_registry`/`_audit_feature_conflicts` 输出开启状态、依赖与互斥关系；`pair_overrides` 注释标明必填字段、推荐范围与“禁用/默认”值，避免复制旧配置后新功能未生效。

◎ 运行骨架与节奏（速记版）：
  - **候选 → 终审**：质量链路先做 multi_tf + volume/盘口/exit-cluster 权重，再执行 channel/暗面/宏观/价格锚闸门；终审结合宏观标签与会话上限决定是否放行，并记录 `entry_quality_breakdown`。
  - **建仓 → 加仓**：首腿按余额 tier 与风险偏好决定，后续加仓遵循 ATR/回撤/浮盈/冷却守卫，并受 `pyramiding.max_add_amount/max_add_pct` 与 `max_position_pct` 限制；实时仓位/价格缺失会打 `add_size_basis_missing` 保护并跳过加仓。
  - **锁盈 → 兜底**：`custom_stoploss` 接管三段反向落袋、结构守卫与兜底地板；`custom_exit` 负责弹性止盈与回吐控制，`use_exit_signal=False` 时离场依然由 stoploss/ROI 路径触发，避免 exit 关闭后守卫失效。

◎ 新策略完整架构总览（复习用）：
  - **输入层**：行情/盘口/资金流 + 多时框 informative + WebUI 绘图通道；
  - **信号层**：三锚聚合 + multi_tf + 盘口/volume/exit-cluster 质量加权 + channel/暗面/宏观护栏；
  - **执行层**：候选闸门 → 终审闸门 → 冷却/会话/余额/宵禁守卫 → 下单路由（市价）→ 加仓/防守腿动态调整；
  - **风险层**：期望守卫、Strict Giveback、Keltner 缓冲、结构守卫、panic/mania 极端护栏、金字塔/总仓上限、日盈利封顶、空头配额；
  - **复盘层**：entry/exit/stoploss snapshot + review_state/Markdown/JSON/CSV 导出 + feature/冲突/灾难体检 + 科学验证作业指导书。

◎ 版本亮点（v2025.12.03-r39，全功能复盘）：
  0) **实盘灾难巡检 + exit-cluster 默认开启 + 加仓基准防抖**：缺失实时价格/仓位时跳过加仓并标注 live/stake 基准，防止 stake_amount=0 时把
     已有仓位当成空仓；反向 exit-cluster 观察加分默认开启且空密度不降权，stoploss 接管结构守卫，exit 关闭时仍能落袋；对照 freqtrade 最新键名
     补充“实盘前灾难巡检”速查（见文末），帮助确认新旧参数兼容与开关默认。
  1) **三阶段反向信号减仓 + 2R/超时全平**：反向终审命中后按 R 分三段减仓（~0.30R 小幅降仓、~1R 大幅锁盈、~2R 或超时全平），每笔交易记录阶段状态并标注 `opp_stage*_trim/exit`，持仓超时会直接释放尾仓，避免 1R/2R 回吐。
  2) **上海宵禁/时区审计强化**：`session_timezone_offset_hours` 默认 8，preflight 会打印本地窗口与封禁档；curfew 阶段日志标注本地时间、原因与 add/entry 拒单，确保夜间封禁与 config_v4 同步。
  3) **止损单位澄清 + Keltner 上限对齐**：stoploss/兜底以价格百分比小数表示（0.303=30.3%），Keltner 缓冲与兜底放宽上限统一为 0.369，注释同步更新以便体检与调参；0.20R 优先放行、小目标 4%/40 分钟与 10%/12% 硬 TP 配置已与 config_v4 对齐。
  4) **分层仓位再平衡**：高余额 tier 首腿降至 31%（硬顶 48%），尾腿与防守腿重新分配；ATR 回踩、浮盈加仓、补亏腿门槛同步放宽，支持大资金轻仓打底、顺势逐步放大；`scale_out_near/exhaust_frac`、`runner_min_frac` 具备 per-pair 覆盖与静态体检，确保减仓/尾仓逻辑一致。
  5) **多交易所预设齐步走**：Gate/OKX/Binance v3 模板共享名义敞口、严格回吐、Measured Move、martingale、期望守卫、撮合步进配置，并新增 `tools/validate_freqtrade_templates.py` 校验 stake、order types、仓位模式与合约可用性，切换交易所时只需细调 `pair_overrides`。
  6) **教学/复盘与工具链**：策略内置“复习+审计”笔记、参数中文注释、名义敞口快照、日更 Markdown 报告、WebUI 绘图档位与 `tools/*` 脚本（模拟守卫、模板校验、未来函数扫描、指标体检）构成调参闭环。
  7) **会话天花板 + 群体感知**：12 小时滚动会话追踪实际盈利上限并回写 `profit_ceiling_r`，`_crowd_flow_adjustment` 结合 `cluster_same/opp` 及时下调目标 R、锁盈地板与回撤阈值，让“队友落袋、对手止损”的情境提前兑现利润。
  8) **反手/暗面体检 + 全景冲突巡检 + 2R 超级趋势**：开机即运行 `_entry_mode_health_check` 确认 channel pivot 与暗面配置未被误关，`_audit_feature_conflicts`/`_audit_directional_parity` 将结构化写入复盘总控（含启用状态、冲突列表、优先级缺口）；`_preflight_disaster_guard` 汇总 config、自检与冲突体检结果，必要时自动关闭未准备好的高级逻辑，并在快车道+驱动+高对齐时把 Measured Move 目标提升至 ~2R，同步保留 panic/mania 极端区的保守落袋。
  9) **科学验证作业指导书**：新增可程序化导出的 `SCIENTIFIC_VALIDATION_PLAYBOOK`，把 preflight 体检、样本构建、因子分层、显著性检验、尾部风险评估与在线监控串成六步流程，并给出与代码因子映射的论文/研报索引，确保每次策略升级都能基于可复现实验验证客观概率优势。
  10) **review_state 结构化导出 + 多机器人分目录**：`_review_report_flush` 会在 JSON analytics 中写入体检/冲突/科研检查摘要，并自动生成 `review_state/` 子目录保存同名快照；启用 `REVIEW_REPORT_SPLIT_BY_BOT=True` 后，复盘 Markdown/JSON/review_state 会按机器人标签分别落到 `bot1/`、`bot2/` 等子目录，方便多机器人并行部署。默认 `REVIEW_REPORT_LIVE_UPDATE=True`，每遇到新事件 ~90 秒内就会增量写入，可通过日志里的“复盘 Markdown/JSON/CSV/ review_state 已写入”提示确认导出是否成功，无需等到当日结束；同时启动阶段会自动创建复盘/analytics/review_state 目录并在日志中提示实际路径，并可选在配置里声明宿主机 `user_data` 根目录（可在 config 的 `review_export.host_dir`、策略参数 `REVIEW_REPORT_HOST_ROOT`，或直接设置环境变量 `HOST_USER_DATA_DIR=/Users/.../user_data` / `FREQTRADE_HOST_USER_DATA_DIR`），日志会同步打印容器→宿主机的映射，避免因未触发事件或路径混淆而误以为未生成。
11) **空单数量守卫回归 + 自检强化**：新增 `DIRECTIONAL_SHORT_OPEN_ENABLE` / `DIRECTIONAL_SHORT_MAX_OPEN` 配置，默认限制同一时间仅保留 1 笔空单；守卫直接读取组合登记 `_portfolio_traces`，并把当前空单数量、触发原因与持仓列表写入终审快照，确保在 mania 反身区也不会无限放大空头敞口。多空对称体检新增空单比例/数量/mania 覆盖的自检提示，当 `short_max_ratio`/`short_max_open`/`short_price_override_floor` 等配置缺失或越界时会在复盘 JSON 与日志中给出警示，可在 `pair_overrides.directional_guard.short_max_open` 覆写为 0 以恢复无限放行，或按币种自定义阈值；当前版本将全局 `short_max_ratio` 再收紧到 0.05，并把 mania 覆盖触发价抬升至 0.86，只有当过去窗口的多单累计足够后才重新放行空单，杜绝 BTC 大跌时的空头滥发。
  12) **入场体检 + 数据/保证金冷却可视化**：`_ensure_data_fresh` 与 `_ensure_min_stake_balance` 现在会把触发原因、预计恢复时间与关键细节写入“入场体检”日志，首次触发用 warning 提醒，恢复时自动输出 info；结构化结果同步记录在 `_review_state.entry_readiness` 并随复盘 JSON / review_state 快照落盘，确保 WebUI 亮灯但未能下单时能立即判断是数据延迟、保证金冷却还是其它守卫所致。新增“候选信号心跳”会在 `enter_long/short` 点亮但 freqtrade 因 pairlock / max_open_trades / balance guard 未能调用终审时主动告警，避免“图上有影子、日志无原因”的盲区。
  13) **灾难性资金体检总览**：新增 `_final_pretrade_bug_sweep` 汇总 preflight、自检、入场体检、目录就绪与资金守卫状态，启动与 `bot_start` 阶段都会自动执行，并把结果写入 `_review_state.catastrophic_sweep`；若发现致命风险或待恢复守卫，将在日志中高亮提醒，指导优先排查路径后再实盘。
  14) **功能巡检总览**：`_compile_feature_registry` 会把频道反手、暗面、Strict Giveback、Expectation Guard、Measured Move/2R 超级趋势、闪电插针守卫、Quiet Mode、复盘导出、灾难体检等新旧模块逐项列出启用状态、关键参数与推荐值，日志与 `_review_state.feature_registry` 会同步标记缺失/异常，确保没有“伪功能”或被误关的守卫悄悄留在代码里。
  15) **空单时效守卫 + 持仓龄体检**：新增 `SHORT_STALE_EXIT_*` 参数族会在空单进入 24~40 分钟仍未跑出（盈利 ≤0.4% 或亏损 ≤1.2%）时主动落袋或平仓，避开“10~20 分钟定胜负”后的拖延亏损；守卫会参考宏观对齐、快/慢车道与 panic/mania 标签，避免在强趋势或极端行情误杀顺势单。科学验证作业指导书增补“持仓龄 vs. 盈亏”步骤，复盘可直接对照多单 ~17 分钟、亏损空单 ~65 分钟的均值样本；r18 进一步把 SOL/ETH 的 `SHORT_STALE_MIN_AGE_MIN`/`FORCE_EXIT_MIN` 收紧到 20/31 分钟，并把 `SHORT_STALE_PROFIT_CEIL` 压到 0.3%，确保亏损空头不会再拖到 4% 止损。
  16) **WebUI 截图复盘模板 + 心理雷达**：`docs/review_reports/2025-11-18-sol-eth-holdtime-review.md` 给出 40 笔交易的 win/loss 持仓龄对比、与 branch-187 的功能差异与 48 小时行动计划；`docs/operator_psych_state_checklist_cn.md` 新增“五分制心态雷达”，提醒操作员在盘前自检，避免“喝醉了还说没醉”的情绪误判。
  17) **SOL/ETH/DOGE 精细化覆写**：`pair_overrides` 现在像 BNB 一样对 SOL/ETH/DOGE 单独声明止盈地板、scale-out、预期守卫、名义资金与空头配额，实盘只需复制对应片段即可同步风控；日志会直接打印“来自 pair_override”的具体字段，方便核对是否落地。
  18) **多会话价格锚 + 回调闸门 + Channel follow 冷静**：`populate_indicators` 会同步生成 20/60/240 根 `price_position` 与 `session_vwap_premium`，`entry_price_guard` 新增多层上限/下限与 VWAP 溢价阈值；`entry_quality` 额外扣分 `price_anchor_weight`，候选阶段也会在 `pullback_gate_long/short` 为真时强制等待 `pullback_ready_*`（MACD 弱化≥2 或出现 ≥25% 下影线）再试；`_channel_pivot_guard` 记录 `channel_last_break`/`channel_pivot_age`/`channel_pullback_taken`，并按 `channel_pivot.follow_up` 中的 `up_wait/down_wait` 与 `up_retrace/down_retrace`、`up_pos/down_pos` 阈值要求跟随单必须先回踩或等待指定根数，默认 DOGE 已演示覆写，防止多头行情里连续抄底/追涨。
    19) **宵禁 + 守卫超时审计**：session bias 支持 block_entries/block_adds（或 add_mult=0）形式的夜间宵禁，策略在候选与加仓闸门直接拒绝并记 `curfew_reason=session_curfew`；小目标命中后记录 hit_ts，超过 `small_target_max_hold_minutes` 仍未破位则触发 `tp_small_target_timeout` 强制落袋。预上线体检输出宵禁/超时快照，便于核对 config 与策略参数的同步。
    20) **性能碎片化治理**：入场/离场影子列改为批量 `assign` 初始化，减少 pandas DataFrame 碎片与性能警告；可视化信号同样采用批量写入，兼顾 WebUI 观察与回测速度，在不改变信号逻辑的前提下减轻多机器人并行时的卡顿。
    21) **反向接力 + 0.25R 优先级落袋**：持仓内出现反向终审信号时可按收益/亏损门限触发 handoff 强平并暂时提高反向灵敏度；profit guard 提供 `FORCE_EXIT_MIN_R` 默认 0.25R 的优先级地板，避免低端锁盈因优先级低被延迟，日志会标注 handoff 方向与锁盈来源便于复核。

◎ 科学验证方案（量化论文映射）：
  1) **环境与守卫体检** —— 读取 `_preflight_disaster_guard`、`_entry_mode_health` 与 `_review_state.feature_audit`，确认执行环境、进场守卫、功能冲突均在健康状态；对应 Lopez de Prado《Advances in Financial Machine Learning》的“假设检验前的流程控制”。
  2) **样本构建与数据留痕** —— 通过回测导出的成交/指标快照，结合 `_resolve_trade_risk_basis`、`_review_report_flush` 与 `tools/` 诊断脚本生成以 R 倍数标注的事件数据；与 A. Moreira & T. Muir (2017) “Volatility-Managed Portfolios” 对齐，确保波动缩放与仓位调度可检验。
  3) **动量与趋势验证** —— 将 `tri_dir/tri_breadth/tri_shock`、`HTF_align` 等特征按 Moskowitz, Ooi & Pedersen (2012) “Time Series Momentum” 的方法做分层，检验多周期动量对齐下的命中率和 R 分布。
  4) **成交量与极端行情检验** —— 利用 `panic_tail_guard`、`blowoff_tail_guard`、`FLASH_VOL_GUARD` 标记，参照 Lo & MacKinlay (1990) “When are contrarian profits due to stock market overreaction?” 和 Bouchaud et al. (2018) 对成交量冲击的分析，验证极端行情守卫对回撤的贡献。
  5) **风险守卫与止损效率** —— 基于 `_expectation_guard_state`、Strict Giveback 与 0.338R release floor 的执行日志，对照 Lopez de Prado 三重障碍模型与期望守卫理论，评估锁盈/止损守卫的 hit ratio 与 tail risk 改善。
  6) **在线监控与滚动显著性** —— 将 `_review_state.scientific_validation`、日更 Markdown、`manual_expectation_guard_check.py` 输出纳入周度/季度复盘，针对每个因子和守卫执行滚动 t 检验或 Mann-Whitney U 检验，持续验证客观优势并回写注释。

◎ 新策略功能与因子审计总结（部署前快速复核）：
  - **进场因子**：`tri_dir/breadth/shock`、multi_tf、volume/盘口/exit-cluster 权重、channel/暗面/宏观护栏；确认 `signal_filters.*` 默认开启、
    阈值与 pair overrides 是否匹配标的波动。
  - **仓位/加仓**：余额 tier、ATR/回撤/浮盈冷却、pyramiding `max_add_amount`/`max_add_pct`/`max_position_pct` 三层上限；实时量价缺失
    会跳过加仓，日志含 `add_size_basis` 说明。
  - **离场/止损**：`custom_exit` 弹性止盈 + Strict Giveback + Measured Move + 小/中/大事件评分，`custom_stoploss` 兜底 + 三段反向落袋 + 结构
    守卫（exit 关闭也生效）；Keltner 缓冲与 panic/mania 极端护栏可在 `pair_overrides` 精调。
  - **组合/日维度守卫**：daily_profit_cap 默认开启（tz_offset_hours=8），session ceiling、crowd guard、short 配额与宵禁联动；若某守卫需关闭，
    在 pair_overrides 显式设为 False/0 避免隐式继承。
  - **数据/模板**：确认 data provider 延迟、模板键名（futures/isolated/net、order_types=market、unfilledtimeout）与交易所实际一致；`tools/*`
    校验脚本与 `_preflight_disaster_guard` 输出若有告警，请先修复再实盘。

◎ 工程化数据治理速览：
  1) **多源数据管线**：`informative_timeframes` 自动拼接 1m/3m/5m/15m 微观与 1h/4h 宏观数据，形成可追踪的指标矩阵。
  2) **特征工程矩阵**：`tri_dir/tri_breadth/tri_shock`、`kel_width_*`、`vol_accel` 等特征统一留痕，支撑后续统计回放与调参。
  3) **事件标签挖掘**：`panic_tail_guard`、`blowoff_tail_guard`、`channel_mode_*` 等护栏输出 bool 标记，可快速筛选极端行情样本。
  4) **决策可解释化**：`_log_decision` 写入候选/终审放行或拒绝理由，包含权重、阈值与实际值，可一键定位异常。
  5) **WebUI 减负**：`WEBUI_PLOT_PROFILE` 提供 lite/balanced/full 三档，按需裁剪图层避免卡顿。
  6) **参数治理基线**：注释标注统计含义，可沿“成交量-波动-通道-动能”四维度系统调参。
  7) **宏观数据闭环**：`_session_context` + `_macro_event_guard` 把主市场时区、人工事件标签写入日志，协助量化事件冲击。

◎ 运行骨架与节奏：
  - 主时框 1m；多空双向；OKX U 本位逐仓净持；同一根 K 线先平后开。参数全部按 5m 基线标注，改回慢周期时 `TIMEFRAME_SCALED_PARAMS` 会自动放宽，确保“旧功能=原始分钟数”这条铁律不变。
  - 三锚聚合（方向/广度/冲击）配合 EMA200(1h) 距离硬闸、ATR 窗口、QuietMode 震荡过滤与冷静期，形成“候选→终审”双闸。
  - 分批顺序：锁盈减仓（scale-out）→ 浮盈金字塔 → 防守均价小腿，确保仓位有章可循。
  - 离场优先级：硬 TP（可选）> 紧急事件≥3 > 小回调/拖尾释放 > near-exit > EMA 硬阈 > 量能衰竭 > 结构台阶 > 峰值回撤/时效。
  - 进场/止盈增强：ATR 加仓/防守回踩 + 自适应锁盈地板（ATR × 动能），浮盈越大锁得越紧。

◎ 新策略完整架构总览（复习用）：
  1) **信号采集层** —— `populate_indicators` 汇聚多时框指标矩阵，写入 `dataframe` 与 `informative` 侧写，确保方向/动量/通道/成交量一
    致性。
  2) **候选闸门层** —— `_candidate_entry_filter` 依赖三锚聚合、QuietMode、channel & macro 守卫筛选潜在信号，输出候选得分表。
  3) **终审决策层** —— `_confirm_trade_entry` 结合暗面减刑、质量拆解、仓位惩罚得出最终入场指令，并写入自解释日志。
  4) **仓位调度层** —— `_position_sizing`、`_adjust_position` 管理首腿/尾腿/防守腿、ATR 加仓与组合风控，记录动态敞口轨迹。
  5) **离场执行层** —— `custom_exit` / `custom_stoploss` 协同 Strict Giveback、期望守卫、Measured Move、2R 超级趋势与锁盈地板。
  6) **复盘审计层** —— `_log_decision`、`_review_report_flush`、`tools/` 辅助脚本提供日更 Markdown、参数快照、守卫回放与模板体检。

◎ 新策略功能与因子审计总结（部署前快速复核）：
  - **参数快照**：启动后检查 `parameter_baseline_*.md` 是否生成，确认自定义覆写与策略基线一致。
  - **进场守卫**：核对 `_entry_mode_health_check` 与 `_preflight_disaster_guard` 日志，确保 channel pivot / 暗面 / QuietMode 均为预期状态。
  - **入场体检**：当 WebUI 出现候选却未下单时，优先查看日志中的 `[入场体检]` 提示与 `_review_state.entry_readiness` 区块，确认是否因为数据延迟或保证金冷静期导致拦截；该体检会给出恢复时间、缺口与 reserve_tap 详情，可据此调整 data provider 或账户预留资金。
  - **仓位治理**：确认 `position_adjustment_enable=True` 且 `DEFAULT_LEVERAGE` 与账户杠杆一致，ATR/组合限速是否贴合账户体量。
  - **离场守卫**：通过仿真或回测确认 0.338R 锁盈地板、Strict Giveback、Measured Move/超级趋势目标按风险基线触发。
  - **风控极限**：检查 `_stoploss_context_profile`、Keltner 缓冲与 panic/mania 极端护栏参数，防止兜底与加仓逻辑冲突。
  - **复盘链路**：确保 `tools/` 工具脚本可正常运行，WebUI / Markdown 报告能追踪信号与守卫细节；多机器人并行时，建议启用 `REVIEW_REPORT_SPLIT_BY_BOT=True` 让复盘 Markdown、analytics JSON、review_state 快照自动分流到 `bot1/`、`bot2/` 等子目录，便于逐一排查。
  - **旧功能速查**：若记不清 r21 是否还保留某守卫，可先打开 `docs/code_inventory.md` 和 `SCIENTIFIC_VALIDATION_PLAYBOOK` 清单，对照“教学 banner & 心理提示”与每个模块的守卫编号逐条勾选；若缺项，复查对应段落的 diff 或回放日志，确认配置是否误删。

◎ 实盘前灾难巡检（r37 增补，参考 freqtrade 2024.12+ 文档键名）：
  - **订单/模式对齐**：确认 `trading_mode=futures`、`margin_mode=isolated`、`position_mode=net` 与交易所侧一致；`order_types.entry/exit/stoploss=market`、`unfilledtimeout.entry/exit` 保持当前数值以避免挂单残留。
  - **加仓基准**：在 WebUI/日志确认持仓行的 `amount` 与最新价格可用；若日志出现 `add_size_basis_missing`，表示实时量价缺失或 stake 由名义上限反推，策略会跳过加仓以避免重仓。
  - **风险开关默认值**：当前 config 默认已开启 `signal_filters`、`pyramiding` 上限、`daily_profit_cap`，请按账户体量检查 `max_add_amount/max_add_pct/max_position_pct` 与 `target_pct/target_abs` 是否合适，必要时在 `pair_overrides` 或全局调节。
  - **时间与时区**：`daily_profit_cap.tz_offset_hours=8`，`session_timezone_offset_hours` 亦为 8；若交易所/服务器使用其他时区，请同步调整以免日界与宵禁错位。
  - **复盘/导出目录**：确认宿主机 `user_data` 映射正常，`review_state/` 与 Markdown 是否落盘；多机器人模式建议启用 `REVIEW_REPORT_SPLIT_BY_BOT=True`。
"""

from typing import Optional, List, Tuple, Dict, Any, Callable, Set, Sequence, Mapping, cast
from collections import defaultdict, deque, OrderedDict
import copy
import csv
import json
import os
import numpy as np
import pandas as pd
from pandas import DataFrame
from datetime import datetime, timezone, date as _date, timedelta
import logging
import math
import time
from decimal import Decimal, InvalidOperation, ROUND_DOWN, ROUND_CEILING
from pathlib import Path
import re

import talib.abstract as ta
from freqtrade.strategy import IStrategy, merge_informative_pair, stoploss_from_open
from freqtrade.persistence import Order, Trade  # 类型提示

_LOGGER_BASE = "freqtrade.strategy"
try:
    _stem = Path(__file__).stem  # type: ignore[name-defined]
    if _stem:
        _safe_stem = re.sub(r"[^0-9A-Za-z_.]+", "_", _stem)
        _LOGGER_BASE = f"{_LOGGER_BASE}.{_safe_stem}" if _safe_stem else _LOGGER_BASE
except Exception:
    pass

logger = logging.getLogger(_LOGGER_BASE)

try:
    _STRATEGY_ROOT = Path(__file__).resolve().parent
except Exception:
    _STRATEGY_ROOT = Path(os.getcwd())


class ReflexivityStrategy(IStrategy):
    """
    Tri-Anchor（方向/广度/冲击） + Quiet 稀疏化（震荡过滤 + 冷静期 + 限次）
    - 时框：1m（参数基线按 5m 记载，守卫自动换算到 1m 根数）
    - 交易：多空双向 / 市价优先
    """

    # [CODEX-ORIG] Tri-Anchor / QuietMode / 冰山分批等主骨架沿用 r20 原版，便于对照旧版复盘与日志。

    INTERFACE_VERSION: int = 3
    STRATEGY_VERSION: str = "v2025.12.03-r39"

    DEFAULT_LEVERAGE: float = 20.0          # 新手：默认按照 5x 杠杆估算名义风险，可与实际 config 对齐
    MAX_LEVERAGE_CAP: float = 20.0          # 新手：策略内置杠杆上限，避免意外启用高倍杠杆

    # === 基础时框 & 启动历史（与 config 保持一致） ===
    timeframe = "1m"
    startup_candle_count = 360
    BASE_TIMEFRAME_MINUTES = 5.0  # 新手：参数基线仍以 5m 标注；运行 1m/15m/30m 时，TIMEFRAME_SCALED_PARAMS 自动换算成等价分钟数。
    TIMEFRAME_SCALED_PARAMS: Tuple[str, ...] = (
        # 教学：以下参数原本以 5m 根数衡量 → 自动按新时框换算实际需要的根数/窗口长度。
        "ICEBERG_COOLDOWN_BARS",
        "SIGNAL_CLUSTER_LOOKBACK_BARS",
        "DIR_GUARD_BARS",
        "EXIT_CONFIRM_BARS",
        "EMERGENCY_OPP_BARS",
        "STOPLOSS_REVIEW_HINT_BARS",
        "STOPLOSS_REVIEW_DEFEND_EXTRA_BARS",
        "SMALL_TARGET_FORCE_BARS",
        "ADDS_LIFETIME_MAX_BARS",
        "PANIC_GUARD_BARS",
        "PANIC_SLOPE_GUARD_BARS",
        "PANIC_SLOPE_LOOKBACK",
        "BLOWOFF_GUARD_BARS",
        "REFLEXIVE_GUARD_BARS",
        "REFLEXIVE_WINDOW",
        "ENTRY_COOLDOWN_BARS",
        "VOL_EXH_DECAY_BARS",
        "ICEBERG_FASTLANE_COOLOFF",
        "ICEBERG_SLOWLANE_COOLOFF",
        "REENTRY_LOOKBACK",
        "PB_LOOKBACK_SHADOW",
        "CHANNEL_PIVOT_LOOKBACK_BARS",
        "CHANNEL_PIVOT_CLEAR_BARS",
        "CHANNEL_PIVOT_PULLBACK_COOLDOWN",
        "ENTRY_PULLBACK_RECENT_WINDOW",
    )
    can_short = True
    process_only_new_candles = True

    # === 实盘特性（职责分离：离场走 custom_exit；止损地板走 custom_stoploss） ===
    use_custom_stoploss = True
    use_exit_signal = False           # 新手：WebUI “Exit” 列展示的是自定义离场动作；策略不依赖 freqtrade 默认 exit 信号。
                                      # 离场由 `custom_exit`/`custom_stoploss` 触发的弹性止盈与锁盈事件完成。
    minimal_roi = {"0": 0.99}         # 兜底，不使用 ROI 抢跑
    STOPLOSS_FALLBACK = 0.303         # 新手：兜底止损默认 30.3%（0.303=30.3% 价格跌幅，小数按百分比表述），动态地板会在此基础上再行收紧/放宽。
    stoploss = -STOPLOSS_FALLBACK     # 兜底绝对止损（freqtrade stoploss 也以价格百分比表示，动态地板会接管，并始终同步至 STOPLOSS_FALLBACK）。
    EXPECTATION_OVERRIDE_BASE_STOPLOSS = 0.303        # 与 STOPLOSS_FALLBACK 保持一致（单位同上），便于自动审计覆写。
                                                      # 说明：本策略所有 stoploss 相关数值均按价格百分比小数表示（例：0.303=30.3% 跌幅），期望守卫/Strict Giveback 的 R 基线即为
                                                      # STOPLOSS_FALLBACK，对应 risk_basis_pct，便于在日志与体检中统一解释风险单位。
    STOPLOSS_KEL_BUFFER_ENABLE: bool = True           # 亏损阶段可选把止损藏到 Keltner 边界外，降低被针探穿的概率。
    STOPLOSS_KEL_BUFFER_SHARE: float = 0.18           # Keltner 宽度的缓冲比例（18% ≈ 上下沿之外再多 18%），满足后才触发止损。
    STOPLOSS_KEL_BUFFER_CAP: float = 0.369            # 止损隐藏后的最大百分比上限（0.369=36.9%），可与兜底止损搭配，自动放宽不会超过此值。
    STOPLOSS_KEL_BUFFER_MIN_WIDTH: float = 0.0        # 仅当通道宽度达到该值（默认不限）才启用隐藏逻辑。
    STOPLOSS_KEL_BUFFER_EXPAND_FALLBACK: bool = True  # 若隐藏止损需要超出兜底 4%，允许自动放宽兜底止损，避免还未触及缓冲就被兜底扫出。
    STOPLOSS_FALLBACK_EXPAND_CAP: float = 0.369       # 放宽兜底止损的上限（0.369=36.9%，默认与 Keltner 缓冲上限一致），防止无限放大亏损空间。
    STOPLOSS_CONTEXT_ENABLE: bool = True              # 新手：根据窄/宽/趋势情境自动缩放兜底，避免震荡仓位仍承受 4% 满额亏损。
    STOPLOSS_CONTEXT_MULTIPLIERS: Dict[str, float] = {
        "default": 0.92,
        "balance": 0.86,
        "range": 0.74,
        "decay": 0.68,
        "narrow": 0.58,
        "trend": 1.02,
    }                                                # 新手：若 SOL/ETH 等震荡币想把兜底压到 ~3%，可在 pair_overrides.stoploss_context_multipliers 中把
                                                     # range/decay/narrow 再各减 0.04~0.06，并结合 stoploss_context_entry_min per-pair 覆盖来设置最小保留风险。
    STOPLOSS_CONTEXT_MIN_MULT: float = 0.52          # 安全下限：收紧倍数不低于 0.52，防止过度收窄。
    STOPLOSS_CONTEXT_MAX_MULT: float = 1.10          # 安全上限：趋势强劲时最多放宽至原兜底的 110%。
    STOPLOSS_CONTEXT_ALIGN_NEED: float = 0.34        # 多周期同向 ≥0.34 且处于快/慢/高周车道时，可少量放宽收紧倍率。
    STOPLOSS_CONTEXT_ALIGN_BONUS: float = 0.05       # 每满足一条趋势车道增加的放宽量，避免强势趋势被过度收紧。
    STOPLOSS_CONTEXT_ENTRY_MIN: float = 0.78         # 收紧后仍需保留 ≥ 初始风险×0.78，确保亏损缓冲与加仓兼容。

    # === 闪电波动守卫（应对插针 + 突发成交量） ===
    FLASH_VOL_GUARD_ENABLE: bool = True              # 启用后监测 wick + 成交量插针，提供快速止损/放宽兜底/防守加仓提示。
    FLASH_VOL_GUARD_LOOKBACK_MIN: int = 2            # 判断插针时至少参考的历史根数。
    FLASH_VOL_GUARD_LOOKBACK_MAX: int = 6            # 判断插针时最多参考的历史根数。
    FLASH_VOL_GUARD_WICK_SHARE: float = 0.48         # 认定“大尾巴”的最小占比（0~1，越大越严格）。
    FLASH_VOL_GUARD_VOLUME_MULT: float = 2.2         # 当前成交量需达到的放量倍数（相对于慢速均量）。
    FLASH_VOL_GUARD_MOVE_PCT: float = 0.012          # 与上一根收盘相比的最小瞬时变动幅度。
    FLASH_VOL_GUARD_EXIT_LOSS: float = -0.012        # 插针后浮亏达到该值（含）会优先考虑闪电止损。
    FLASH_VOL_GUARD_EXIT_PROFIT_CAP: float = 0.003   # 插针后即便仍有少量利润，也会在该值以内允许提前落袋。
    FLASH_VOL_GUARD_EXIT_COOLDOWN_MIN: float = 20.0  # 两次闪电止损之间的最小冷却时间（分钟）。
    FLASH_VOL_GUARD_EXIT_SCHEDULE: Sequence[Mapping[str, Any]] = (
        {
            "label": "age_30m_lock",
            "age_min": 30,
            "exit_loss": -0.008,
            "profit_cap": 0.0025,
        },
        {
            "label": "locked_half_r",
            "locked_r_min": 0.5,
            "exit_loss": -0.004,
            "profit_cap": 0.0015,
        },
    )  # 可选：按持仓龄/锁盈 R 调整闪电止损阈值。
    FLASH_VOL_GUARD_STOP_LOCK: float = 0.009         # 插针遇险时，动态止损会被压缩到该损失上限（含 Keltner 缓冲前）。
    FLASH_VOL_GUARD_RELAX_ENABLE: bool = True        # 插针出现在 panic/mania 防守区时是否允许自动放宽兜底止损。
    FLASH_VOL_GUARD_RELAX_MULT: float = 1.08         # 放宽兜底的乘数（在 STOPLOSS_FALLBACK 基础上乘以该值）。
    FLASH_VOL_GUARD_RELAX_CAP: float = 0.24          # 放宽兜底时的绝对上限（若 0 则跟随 fallback cap）。
    FLASH_VOL_GUARD_DEF_ADD_MULT: float = 0.82       # 触发防守信号后，防守腿所需回撤 ATR 的缩放倍率（<1 表示放宽要求）。

    FLASH_VOL_REVERSE_ENABLE: bool = True            # 启用后可在闪电止损后排队反手仓位。
    FLASH_VOL_REVERSE_DELAY_MIN: float = 0.75        # 反手下单前的最短等待时间（分钟）。
    FLASH_VOL_REVERSE_WINDOW_MIN: float = 9.0        # 反手机会在该时间窗后过期（分钟）。
    FLASH_VOL_REVERSE_MAX_ATTEMPTS: int = 2          # 单个方向最多排队的反手次数，0 表示不限制。
    FLASH_VOL_REVERSE_MIN_PORT_NET: float = -0.05    # 组合净值低于该值时不再尝试反手。
    FLASH_VOL_REVERSE_MAX_LOSS_PRESSURE: float = 0.28  # 组合亏损压力超过该值时不再尝试反手。
    FLASH_VOL_REVERSE_MAX_SIGNALS: int = 3           # 反手候选在窗口内最多重复触发的次数。
    FLASH_VOL_REVERSE_EARLY_AGE_MAX: float = 10.0    # 进场 ≤10 分钟仍未跑出、且轻微亏盈时允许快触发反手窗口。
    FLASH_VOL_REVERSE_EARLY_DELAY_MIN: float = 0.35  # 快速反手的最短等待时间（分钟）。
    FLASH_VOL_REVERSE_EARLY_WINDOW_MIN: float = 6.5  # 快速反手的最小存活窗口（分钟），确保 5~10 分钟内有机会翻向。
    FLASH_VOL_REVERSE_EARLY_PROFIT_CEIL: float = 0.002  # 仅当利润低于该值（含亏损）时才启用快速反手。

    # === 结构守卫（exit 影子移交 stoploss） ===
    STRUCT_GUARD_STOPLOSS_ENABLE: bool = True       # 结构破位 + DI 反转（原 exit_shadow）改由 stoploss 直接执行，避免 use_exit_signal=False 时失效。
    STRUCT_GUARD_REQUIRE_DI_FLIP: bool = True       # 默认要求 DI 反转确认结构破位方向；可按币种放宽。
    STRUCT_GUARD_BLOCK_STOPRUN: bool = True         # 默认跳过伴随长影线的 stoprun，避免假突破误杀。
    STRUCT_GUARD_MIN_PROFIT: float = -0.004         # 允许在小幅亏损（≈-0.4%）内落袋，防止等到兜底止损；设为 0 可只在非亏损时触发。
    STRUCT_GUARD_ALIGN_CAP: float = 0.28            # 结构破位时若多空对齐绝对值低于该阈值（默认弱对齐）则允许触发；设为 1 跳过对齐检查。

    # === 空单时效离场守卫 ===
    SHORT_STALE_EXIT_ENABLE: bool = True             # 启用后，空单在时间/对齐/利润条件满足时会主动收口。
    SHORT_STALE_MIN_AGE_MIN: float = 12.0            # 达到该持仓龄（分钟）且无进展，会开始评估是否平仓。
    SHORT_STALE_FORCE_EXIT_MIN: float = 20.0         # 达到该持仓龄后，无论对齐好坏都倾向平仓，避免拖延。
    SHORT_STALE_PROFIT_CEIL: float = 0.0040          # 盈利低于该值（≈0.4%）仍视为“未跑出”。
    SHORT_STALE_LOSS_FLOOR: float = -0.0100          # 亏损不超过该值（≈-1.2%）时允许小亏出局，避免打到 4% 止损。
    SHORT_STALE_ALIGN_FLOOR: float = -0.06           # HTF 对齐低于该值（偏多）时判定为空单逆风。
    SHORT_STALE_RELEASE_BUFFER: float = 0.0012       # 守卫触发时记录的释放 buffer，方便回放日志。
    SHORT_STALE_SKIP_EXTREMES: bool = False          # panic/mania 区域默认跳过守卫，留给极端行情自行发展，False高波动双杀期也允许守卫介入，防止被流动性掠夺拖到兜底止损。 
    SHORT_STALE_ALLOW_FASTLANE: bool = False         # 快/慢车道顺势时是否仍允许守卫提前平仓。
    SHORT_STALE_SLOW_BLEED_MIN_AGE: float = 26.0     # 持仓达到该龄且持续下滑会触发慢性亏损提前平仓。
    SHORT_STALE_SLOW_BLEED_LOSS: float = -0.0260     # 慢性亏损触发阈值（≈-2.6%），避免拖到兜底止损。
    SHORT_STALE_SLOW_BLEED_ADX_CAP: float = 18.0     # ADX 低于该值视为弱趋势磨损，更倾向收口。
    SHORT_STALE_SLOW_BLEED_ALIGN_CAP: float = 0.22   # 多空对齐绝对值低于该值视为趋势不够强，可提前止损。

    # === 风险预测（ATR / EWMA / HAR / 混合） ===
    RISK_FORECAST_MODE: str = "har"                 #  risk 基准默认读取 ATR，可改为 ewma/har/mix 以引入高频波动预测。
    RISK_FORECAST_EWMA_ALPHA: float = 0.35          #  EWMA 平滑系数（0~1），值越大越强调最新收益波动。
    RISK_FORECAST_EWMA_SOURCE: str = "both"           #  ewma 来源：5m / 3m / both。
    RISK_FORECAST_HAR_WINDOWS: Tuple[int, int, int] = (6, 24, 72)  # HAR 预测窗口（以主时框根数计）。
    RISK_FORECAST_MIX_ATR_SHARE: float = 0.5        #  mix 模式下 ATR 占比。
    RISK_FORECAST_MIX_EWMA_SHARE: float = 0.3       #  mix 模式下 EWMA 占比。
    RISK_FORECAST_MIX_HAR_SHARE: float = 0.2        #  mix 模式下 HAR 占比。
    RISK_FORECAST_SCALE: float = 1.0                #  风险预测整体缩放系数，可按账户波动率统一放大/缩小。
    RISK_FORECAST_MIN_PCT: float = 0.0              #  最低风险百分比地板（0=不强制），避免预测过小导致锁盈过窄。
    RISK_FORECAST_MAX_PCT: float = 0.0              #  最高风险百分比上限（0=不强制），防止预测异常放大。

    # === 科学验证作业指导书（与论文/研报映射） ===
    SCIENTIFIC_VALIDATION_VERSION: str = "2025.11.24-r31"
    SCIENTIFIC_VALIDATION_PLAYBOOK: Tuple[Dict[str, Any], ...] = (
        {
            "id": "preflight",
            "title": "环境体检与守卫健康检查",
            "objective": "确保交易模式、仓位模式与守卫启用状态符合策略假设，避免把执行缺陷误判为策略失效。",
            "actions": (
                "读取 `_preflight_disaster_guard`、`_entry_mode_health` 与 `_review_state.feature_audit` 生成的日志",
                "确认 futures/isolated/hedge 组合、channel pivot、暗面减刑、冲突审计均通过体检",
                "若存在警告则在复盘笔记中标注并关闭高风险模块后再进行回测或实盘",
            ),
            "evidence": (
                "`_preflight_disaster_guard` 报告",
                "`_entry_mode_health_check` 摘要",
                "`_review_state.feature_audit`、`directional_audit` 结构化数据",
            ),
            "references": (
                {
                    "citation": "Lopez de Prado (2018), Advances in Financial Machine Learning",
                    "topic": "流程控制与体检",
                    "mapping": "策略体检阶段对应其 Chapter 2 提出的研究管线自检。",
                },
            ),
        },
        {
            "id": "dataset",
            "title": "样本构建与数据留痕",
            "objective": "生成包含 R 倍数、守卫状态与指标特征的结构化样本，支撑后续显著性检验。",
            "actions": (
                "运行回测或仿真导出成交与 `_log_decision` 快照",
                "调用 `_resolve_trade_risk_basis` 输出的风险刻度整合到交易记录",
                "使用 `tools/manual_expectation_guard_check.py`、`tools/strategy_feature_sanity.py`、`tools/preflight_guard_matrix.py` 做一致性审计",
            ),
            "evidence": (
                "回测 trades.csv / dataframe_with_indicators.csv",
                "`_review_report_flush` 生成的 Markdown 与 JSON 快照",
                "工具脚本的差异报告",
            ),
            "references": (
                {
                    "citation": "Moreira & Muir (2017), Volatility-Managed Portfolios",
                    "topic": "波动缩放",
                    "mapping": "风险单位与仓位缩放与论文的波动调节框架一致。",
                },
            ),
        },
        {
            "id": "momentum",
            "title": "多周期动量与趋势分层检验",
            "objective": "验证 tri-anchor 组合在不同动量/对齐状态下的胜率与盈亏分布。",
            "actions": (
                "基于 `tri_dir`、`tri_breadth`、`tri_shock`、`HTF_align` 等特征进行分层",
                "统计每个分层下的交易数量、平均 R、胜率、最大回撤",
                "对比动量强/弱组的收益差异并执行 t 检验或 Mann-Whitney U 检验",
            ),
            "evidence": (
                "特征分层统计表",
                "显著性检验结果",
                "动量因子剥离后的残差分析",
            ),
            "references": (
                {
                    "citation": "Moskowitz, Ooi & Pedersen (2012), Time Series Momentum",
                    "topic": "时间序列动量",
                    "mapping": "多时框动量对齐即对应该论文的趋势信号构造。",
                },
            ),
        },
        {
            "id": "liquidity_extremes",
            "title": "成交量与极端行情守卫效果",
            "objective": "衡量 panic/blowoff 与闪电波动守卫在尾部风险上的贡献。",
            "actions": (
                "提取 `panic_tail_guard`、`blowoff_tail_guard`、`FLASH_VOL_GUARD` 标记的交易子样本",
                "评估守卫触发前后的盈亏分布与最大回撤",
                "对照未触发守卫的基准样本，使用 KS 检验检查分布差异",
            ),
            "evidence": (
                "触发 vs 未触发守卫的 R 分布对比",
                "尾部损失与 CVaR 度量",
                "事件窗口内的成交量/价格剖面",
            ),
            "references": (
                {
                    "citation": "Lo & MacKinlay (1990), When are contrarian profits due to stock market overreaction?",
                    "topic": "成交量冲击与反转",
                    "mapping": "插针/放量标记用于验证极端事件后的回撤控制。",
                },
                {
                    "citation": "Bouchaud et al. (2018), Trades, Quotes and Prices",
                    "topic": "流动性与冲击",
                    "mapping": "成交量加速度与防守逻辑对应流动性冲击模型。",
                },
            ),
        },
        {
            "id": "holding_time",
            "title": "持仓龄 vs. 盈亏体检",
            "objective": "验证“短空 10~20 分钟定胜负”经验是否稳健，并量化空单时效守卫对回撤的改善。",
            "actions": (
                "统计多/空、止损/拖尾样本的平均持仓时间并与复盘 trades.csv / analytics JSON 对表",
                "回测启用/关闭 `SHORT_STALE_EXIT_*` 守卫时的胜率、平均 R、尾部亏损",
                "在 `_log_decision` 抓取 `sl_short_stale_release` 样本，评估是否成功避免 4% 止损",
            ),
            "evidence": (
                "持仓龄箱线图与均值（如多单 ~17 分钟、亏损空单 ~65 分钟）",
                "守卫前后盈亏/回撤/命中率对比表",
                "短空日志摘录（守卫触发原因、对齐/行情标签）",
            ),
            "references": (
                {
                    "citation": "Acar & Lequeux (1995), A Nonlinear Analysis of High-Frequency Foreign Exchange Rate Returns",
                    "topic": "持仓时效与噪声交易",
                    "mapping": "空头若长时间拖延更接近噪声区，需用时间守卫约束。",
                },
            ),
        },
        {
            "id": "risk_guards",
            "title": "期望守卫与止损效率评估",
            "objective": "检验 Strict Giveback、0.338R release floor、期望守卫对收益分布的改善。",
            "actions": (
                "利用 `_expectation_guard_state` 记录追踪守卫触发节点",
                "对比守卫开启/关闭的模拟结果，计算平均 R、盈亏比、tail loss",
                "执行 Kaplan-Meier 或三重障碍命中率统计，衡量守卫对时间维度的影响",
            ),
            "evidence": (
                "守卫触发日志",
                "命中率与回撤统计",
                "尾部风险对比图",
            ),
            "references": (
                {
                    "citation": "Lopez de Prado (2018), Advances in Financial Machine Learning",
                    "topic": "三重障碍/期望守卫",
                    "mapping": "守卫逻辑与三重障碍、期望值守卫框架一致。",
                },
            ),
        },
        {
            "id": "monitoring",
            "title": "在线监控与滚动显著性回归",
            "objective": "把科学方案嵌入日常复盘，确保策略在实盘期间持续满足统计优势。",
            "actions": (
                "在 `_review_state` 中记录科学验证概要并随日更报告发布",
                "按周执行滚动 t 检验或 Mann-Whitney U 检验，按季度更新显著性摘要",
                "把验证结果回写到配置与注释，必要时调整权重/阈值并保留对照实验",
            ),
            "evidence": (
                "`_review_state.scientific_validation` 快照",
                "周度/季度复盘 Markdown",
                "显著性检验历史记录",
            ),
            "references": (
                {
                    "citation": "Chan, Chan & Karceski (2006), Stock price clustering and discreteness",
                    "topic": "滚动显著性检验",
                    "mapping": "滚动检验思想用于监控因子稳定性。",
                },
            ),
        },
    )

    # === Expected Shortfall（尾部风险守卫） ===
    EXPECTED_SHORTFALL_ENABLE: bool = True          #  默认启用尾部风险处罚，可在 exit_tuning 里按币对关闭。
    EXPECTED_SHORTFALL_ALPHA: float = 0.15          #  ES 计算的左侧分位（α），常见 0.10~0.20。
    EXPECTED_SHORTFALL_WINDOW: int = 20             #  滚动窗口（天数），用于聚合每日 R 倍数收益。
    EXPECTED_SHORTFALL_TRIGGER_R: float = -1.20     #  当 CVaR 低于该阈值（更深负值）即触发处罚逻辑。
    EXPECTED_SHORTFALL_PENALTY: float = 0.35        #  惩罚倍数，severity∈[0,1]，最终处罚=penalty×severity。
    EXPECTED_SHORTFALL_MIN_COUNT: int = 8           #  计算 ES 至少需要的成交样本数，避免样本过少误判。

    # === Keltner 突破节奏调速（避免刚突破就反手、回调见底仍乱追空） ===
    CHANNEL_PIVOT_ENABLE = True             # 新手：True=启用节奏拆分；False=沿用旧版“突破立即可反手”的宽松逻辑。
    CHANNEL_PIVOT_LOOKBACK_BARS = 9          # 突破后至少等待 N 根再视为“完成一个节奏”
    CHANNEL_PIVOT_CLEAR_BARS = 3             # 回到区间中线附近累积 N 根即视作节奏重置
    CHANNEL_PIVOT_CLEAR_POS_LOW = 0.36       # price_position 回到 [low, high] 区间才计入重置计数
    CHANNEL_PIVOT_CLEAR_POS_HIGH = 0.64      # 新手：回到 price_position≥0.64 视为重新靠近上边界，用于判定节奏是否洗牌。
    CHANNEL_PIVOT_PULLBACK_COOLDOWN = 4      # 同一突破节奏内，放过一次反手后至少冷静 N 根
    CHANNEL_PIVOT_UP_REVERT_POS = 0.58       # 上沿突破后要做空，至少跌回 price_position≤该值
    CHANNEL_PIVOT_DOWN_REVERT_POS = 0.42     # 下沿突破后要做多，至少抬回 price_position≥该值
    CHANNEL_PIVOT_UP_ALIGN_NEED = 0.34       # 上沿突破后反手做空需达到的对齐强度（绝对值）
    CHANNEL_PIVOT_DOWN_ALIGN_NEED = 0.34     # 下沿突破后反手做多需达到的对齐强度
    CHANNEL_PIVOT_UP_MID_FRAC = 0.14         # 上沿突破后，至少跌破中轨 14% 通道宽度才算有效回落
    CHANNEL_PIVOT_DOWN_MID_FRAC = 0.14       # 下沿突破后，至少重返中轨 14% 通道宽度才算有效反弹
    CHANNEL_PIVOT_UP_FOLLOW_WAIT = 3         # 新手：突破上沿后新增多单需至少等待 3 根或回踩中轨。
    CHANNEL_PIVOT_UP_FOLLOW_RETRACE = 0.18   # 新手：或等待 ≥18% 通道宽度的回踩才准许继续加多。
    CHANNEL_PIVOT_UP_FOLLOW_POS = 0.66       # 新手：或等 price_position 回到 66% 以下。
    CHANNEL_PIVOT_DOWN_FOLLOW_WAIT = 3       # 新手：跌破下沿后新增空单需至少等待 3 根或反弹。
    CHANNEL_PIVOT_DOWN_FOLLOW_RETRACE = 0.18 # 新手：或等待 ≥18% 通道宽度的反弹才准许继续加空。
    CHANNEL_PIVOT_DOWN_FOLLOW_POS = 0.34     # 新手：或等 price_position 回到 34% 以上。

    # === 弹性止盈评分（事件权重叠加以防“乱跳车”） ===
    EXIT_SCORE_WEIGHTS: Dict[str, float] = {"major": 1.80, "medium": 0.82, "minor": 0.76}  # 新手：各严重度事件累加的基础权重，可按“重大=1.8/中等=0.82/轻微=0.46”调整。
    EXIT_SCORE_THRESHOLD_BASE: float = 1.05      # 新手：常规行情触发弹性止盈所需的累计分数；调高=更保守，调低=更敏捷。
    EXIT_SCORE_THRESHOLD_TREND: float = 1.55     # 新手：趋势行情（强对齐/ADX）下额外要求的阈值，避免 2R 潜力提早被清。
    EXIT_SCORE_THRESHOLD_SLOW: float = 1.24      # 新手：结构慢车道的目标分数，兼顾尾声小波动。
    EXIT_SCORE_THRESHOLD_WEAK: float = 0.88      # 新手：当动能明显减弱时的紧急阈值，允许更快把盈利落袋。
    EXIT_SCORE_MIN: float = 0.68                 # 新手：最低允许的分数地板，防止被极端放宽拖到过低。
    EXIT_SCORE_MAX: float = 2.40                 # 新手：最高可累计分数，用于抑制异常事件堆叠导致的超调。
    EXIT_SCORE_DECAY_BARS: float = 3.5           # 新手：评分每 3.5 根 5m 自动衰减一次，防止旧事件长时间占据权重。
    EXIT_SCORE_FASTPATH_RATIO: float = 0.92        # 新手：大事件计分已达阈值 92% 时可直接触发，避免“卡在临门一脚”。设为 0 关闭。
    EXIT_SCORE_FASTPATH_LEVELS: Tuple[str, ...] = ("major",)  # 新手：允许走“快捷通道”的事件等级，默认只放行重大事件。
    EXIT_SCORE_STRONG_ALIGN: float = 0.26
    EXIT_SCORE_MODERATE_ALIGN: float = 0.16
    EXIT_SCORE_TREND_PROFIT_GATE: float = 0.022
    EXIT_SCORE_SMALL_PROFIT_RELAX: float = 0.012
    EXIT_SCORE_SMALL_RELAX_MULT: float = 0.82
    EXIT_SCORE_RANGE_RELAX: float = 0.76
    EXIT_SCORE_EXTREME_RELAX: float = 0.84
    EXIT_SCORE_DECAY_RELAX: float = 0.88
    EXIT_SCORE_PRIORITY_RELAX: float = 1.12
    EXIT_SCORE_PERF_GUARD_RELAX: float = 0.90
    EXIT_SCORE_PERF_HOT_TIGHTEN: float = 1.08
    EXIT_SCORE_PRIORITY_TIGHTEN: float = 0.82
    EXIT_PROFIT_GUARD_ENABLE: bool = True            # 新手：止盈触发需先通过“盈亏平衡守卫”，避免刚回本就被事件组合赶下车。
    EXIT_PROFIT_GUARD_STATIC: float = 0.0032         # 至少要留住 0.32% 左右的浮盈才允许执行弹性止盈；可按币种波动调节。
    EXIT_PROFIT_GUARD_PEAK_SHARE: float = 0.28       # 若已记录峰值浮盈，则至少保留该峰值的 28% 再止盈，确保趋势单不被提前清仓。
    EXIT_PROFIT_GUARD_TOLERANCE: float = 0.0005      # 容差（8bp）；小幅波动不会卡死释放。
    EXIT_BOOK_USE_ORDERBOOK: bool = True             # 读取订单簿估算可成交价，辅助 Profit Guard 判断是否因滑点被卡住。
    EXIT_BOOK_DEPTH: int = 3                         # 读取的订单簿深度，默认 3 档，避免单档撮合异常导致误判。
    EXIT_BOOK_SLIPPAGE_SHARE: float = 0.0005         # 对订单簿价格额外预留的滑点比例（5bp），卖出减价、回补加价。
    EXIT_PROFIT_GUARD_BOOK_TOL: float = 0.0005       # 当订单簿利润满足地板时额外允许的容差（5bp），防止因价差过小而延迟放行。
    EXIT_PROFIT_GUARD_RELAX_TAGS: Tuple[str, ...] = (
        "peak_retreat_guard",
        "pb_trail_release",
        "small_target_release",
        "pb_small_release",
        "near_release",
        "range_release",
        "micro_target_release",
    )
    EXIT_PROFIT_GUARD_RELAX_SHARE: float = 0.18       # 新手：重大回吐触发时，放宽需要保留的峰值占比，避免盈利重新被拖成亏损。
    EXIT_PROFIT_GUARD_RELAX_DROP_SHARE: float = 0.52  # 当利润较峰值回吐超过 52% 时触发放宽；可按锁盈偏好调节。
    EXIT_PROFIT_GUARD_RELAX_DROP_ABS: float = 0.008   # 或者绝对回吐 ≥0.8% 也触发放宽，防止短时间大幅回落时迟迟不走。
    EXIT_PROFIT_GUARD_RELAX_CLAMP_TO_PROFIT: bool = True  # 新手：放宽后可把盈亏守卫地板压回当前浮盈附近，避免“锁盈线高于现价”卡死释放。
    EXIT_STAGNATION_ENABLE: bool = True               # 新手：允许检测“浮盈 0~-1% 拉扯”停滞仓位，积累事件后择机退出。
    EXIT_STAGNATION_PROFIT_BAND: float = 0.011        # 认为是“停滞区”的浮盈带宽（默认 ±1.1% 之内视为拉扯）。
    EXIT_STAGNATION_MIN_BARS: float = 6.0             # 至少持有 N 根仍停滞才启动评分；会随时框自动换算分钟。
    EXIT_STAGNATION_MIN_DURATION_MIN: float = 18.0    # 或者直接要求停留 ≥18 分钟（两者取较大者）。
    EXIT_STAGNATION_ALIGN_CAP: float = 0.18           # 多周期同向强度若超过 0.18（趋势足够强），则忽略停滞判定。
    EXIT_STAGNATION_ADX_MAX: float = 22.0             # ADX 高于该值视为仍有动能，停滞逻辑不强制介入。
    EXIT_STAGNATION_LEVEL: str = "major"              # 停滞事件记入弹性止盈评分的严重度等级（minor=轻微）。
    EXIT_STAGNATION_REPEAT_COOLDOWN_MIN: float = 12.0 # 同一笔交易连续触发停滞检测的最小冷却时间（分钟）。
    EXIT_RANGE_ENABLE: bool = True                    # 新手：若行情回到宽区间震荡，可更快释放仓位。
    EXIT_RANGE_ALIGN_MAX: float = 0.18                # 只有多周期对齐不再强势时才视为震荡。
    EXIT_RANGE_ADX_MAX: float = 20.0                  # ADX 低于该值视为动能疲软。
    EXIT_RANGE_PROFIT_FLOOR: float = -0.003           # 允许在略低于盈亏平衡时也判定为震荡离场。
    EXIT_PEAK_RETREAT_ENABLE: bool = True             # 新手：开启“峰值回撤守卫”，防止利润大幅回吐仍迟迟不走。
    EXIT_PEAK_RETREAT_MIN_PROFIT: float = 0.028       # 只有峰值浮盈达到 ≥2.8% 才跟踪峰值回撤，避免过早干扰趋势。
    EXIT_PEAK_RETREAT_DROP_SHARE: float = 0.45        # 当前利润较峰值回撤 ≥45% 时记分，可据需求调高/调低敏感度。
    EXIT_PEAK_RETREAT_DROP_ABS: float = 0.012         # 峰值与当前利润的绝对差额至少达到 1.2% 才会记分。
    EXIT_PEAK_RETREAT_LEVEL: str = "major"            # 峰值回撤事件记为 major，单次加权即可接近阈值，确保快速止盈。
    EXIT_PEAK_RETREAT_COOLDOWN_MIN: float = 4.0       # 同一笔交易的峰值回撤事件至少间隔 4 分钟再度记分，减少刷屏。
    EXIT_RANGE_PROFIT_CEIL: float = 0.034             # 若浮盈超过 3.4%，仍按趋势单观察。
    EXIT_RANGE_HOLD_MIN_BARS: float = 3.0             # 至少观察 N 根确认进入震荡节奏。
    EXIT_RANGE_HOLD_MINUTES: float = 12.0             # 或直接用分钟下限。
    EXIT_RANGE_REPEAT_COOLDOWN_MIN: float = 10.0      # 同一笔交易的震荡事件冷却时间。
    EXIT_RANGE_LEVEL: str = "major"                   # 震荡事件默认计入中等权重。
    LOCK_SENSITIVITY: float = 0.88                    # 新手：<1 提高锁盈敏感度；>1 放宽。统一作用于缓冲、阈值与盈亏守卫。
    MICRO_TARGET_SCORE_LEVEL: str = "medium"          # 新手：微型目标释放默认记为“中等”事件，更快叠加到止盈阈值。
    SMALL_TARGET_SCORE_LEVEL: str = "medium"          # 新手：小目标释放默认计为“中等”事件，避免长时间“卡分”不落袋。
    SMALL_TARGET_PROMOTE_TO_MAJOR: float = 0.045      # 新手：当峰值浮盈≥4.5% 时将小目标释放提升为"major"记分，方便 4-6% 区间
    SMALL_TARGET_PROMOTE_TO_MEDIUM: float = 0.028     # 新手：若默认等级较低，峰值≥2.8% 时提升到"medium"，减少 3% 左右浮盈迟迟不落袋。
    HIGH_TARGET_ENABLE: bool = True                   # 新手：≥8.5% 浮盈进入高目标守卫，动能转弱或大幅回吐时快速记分离场。
    HIGH_TARGET_THRESHOLD: float = 0.085              # 记录高目标的浮盈阈值（约 8.5%）。
    HIGH_TARGET_LOCK_RATIO: float = 0.62              # 高目标命中后锁盈地板保留峰值浮盈的 62% 左右。
    HIGH_TARGET_FLOOR_MIN: float = 0.048              # 至少锁住 4.8% 浮盈，防止利润被拖回盈亏平衡。
    HIGH_TARGET_DROP_SHARE: float = 0.32              # 相对峰值回吐超 32%（配合 LOCK_SENSITIVITY）即触发释放记分。
    HIGH_TARGET_DROP_ABS: float = 0.018               # 或绝对回吐≥1.8% 也视为大幅回撤。
    HIGH_TARGET_USE_PEAK: bool = True                 # 以峰值浮盈为锁盈计算基准；设 False 则固定阈值。
    HIGH_TARGET_SCORE_LEVEL: str = "major"            # 高目标释放默认按重大事件计分，一次命中即可接近放行线。
    EXIT_GIVEBACK_ENABLE: bool = True                 # 新手：额外的峰值回吐守卫，确保 3%+ 浮盈回吐过大时快速叠分离场。
    EXIT_GIVEBACK_MIN_PROFIT: float = 0.032           # 仅当历史浮盈达到 ≥3.2% 才启动该守卫。
    EXIT_GIVEBACK_DROP_SHARE: float = 0.36            # 当前利润相对峰值回吐超过 36%（会随 LOCK_SENSITIVITY 缩放）即记分。
    EXIT_GIVEBACK_DROP_ABS: float = 0.009             # 或绝对回吐 ≥0.9% 也视为显著回撤。
    EXIT_GIVEBACK_LEVEL: str = "major"                # 该守卫默认记为重大事件，便于一次性触发止盈。

    # === 群体止盈/止损流量感知（同向/对向仓位的“队友/对手”影响） ===
    CROWD_FLOW_ENABLE: bool = True                    # 新手：默认开启信号扎堆 → 盈亏比动态调节逻辑。
    CROWD_FLOW_SAME_SOFT: int = 2                     # 最近同向信号达到 2 笔开始提前压低目标 R。
    CROWD_FLOW_SAME_HARD: int = 5                     # ≥5 笔同向信号视为高度拥挤，给予最大惩罚。
    CROWD_FLOW_OPP_SOFT: int = 2                      # 最近对向信号 ≥2 笔视为“对手”压力可望被引爆。
    CROWD_FLOW_OPP_HARD: int = 4                      # ≥4 笔对向信号给予最大补偿，允许多等一点。
    CROWD_FLOW_SAME_PENALTY: float = 0.18             # 同向拥挤时最多削减 0.18R 的目标。
    CROWD_FLOW_RELEASE_PENALTY: float = 0.22          # 同向拥挤时同步压低 release R，以便更快落袋。
    CROWD_FLOW_OPP_BONUS: float = 0.12                # 对向拥挤时的奖励幅度（抵消部分惩罚/抬高 release）。
    CROWD_FLOW_BIAS_BONUS: float = 0.10               # 偏向系数（cluster_bias）触发时额外的惩罚/奖励幅度。
    CROWD_FLOW_MIN_TARGET_R: float = 0.36             # 再怎么拥挤也至少追求 ~0.36R（≈4.5%）的目标。
    CROWD_FLOW_FLOOR_BASE_R: float = 0.18             # 同向拥挤触发后，严格回吐守卫至少锁住约 0.18R。
    CROWD_FLOW_DRAWDOWN_CLAMP_R: float = 0.18         # 同向拥挤时把期望守卫允许的回撤限制在 ≈0.18R。
    CROWD_FLOW_MIN_PROFIT_R: float = 0.14             # 当前浮盈至少达到 0.14R 才会启用群体调节逻辑。
    CROWD_FLOW_BIAS_TRIGGER: float = 1.10             # cluster_bias 绝对值超过此阈值视为偏向明显。
    CROWD_FLOW_BIAS_CAP: float = 1.85                 # 偏向封顶值，对应 SIGNAL_CLUSTER_BIAS_BLOCK。

    # === 分批（策略与 config 同时开启 position_adjustment_enable） ===
    position_adjustment_enable = True
    max_entry_position_adjustment = 5              # 最多 5 次加仓（总 6 段），为中大资金留出更细的补仓台阶。
    ICEBERG_LEGS = (                               # 默认 6 段：保留原版 46% 首腿，同时拆分尾部仓位，便于后续按余额分层再调节。
        0.46,
        0.20,
        0.14,
        0.12,
        0.05,
        0.03,
    )
    ICEBERG_MIN_PULLBACK_ATR = 0.24                # 加同向前需有利端回撤 ≥ 0.24×ATR
    ICEBERG_COOLDOWN_BARS = 2                      # 加仓之间的最小间隔（5m 根数）

    # === 轻去指纹（目前仅对仓位规模做轻微抖动） ===
    AF_ENABLE = True
    AF_STAKE_JITTER = 0   # 原0.02

    # === WebUI 可视化配置（lite/balanced/full 三档，解决“过度拥挤/卡顿/残影”问题） ===
    WEBUI_PLOT_PROFILE = "balanced"   # 新手：默认“balanced”展示常用护栏；如需极简视图可改为 "lite"，要全量层可设 "full"。

    # === 数据源缺失重试节流（避免 1m/1h/4h 重复拉取导致警告刷屏） ===
    INFORMATIVE_MISSING_RETRY_MINUTES = 10.0  # 新手：数据缺失时等待多少分钟再重试，避免日志每根 K 都报错。

    # === 交易所信号校准（解决 OKX/Gate 信号密度差异）===
    EXCHANGE_SIGNAL_PROFILE: Dict[str, Dict[str, Any]] = {
        "default": {
            "vol_surge_mult": 1.0,          # 成交量放量阈值乘数（>1 更挑剔，<1 更宽松）
            "vol_accel_mult": 1.0,          # 成交量加速度阈值乘数
            "tri_need_mult": 1.0,           # 三锚软锁基础需求乘数（>1 收紧，<1 放松）
            "dist_relax_mult": 1.0,         # EMA 距离放松比乘数（>1 更严格，<1 更宽松）
            "extreme_tri_relief": 1.0,      # 极端护栏（panic/mania）触发时对三锚门槛的额外放宽倍率（<1 表示放宽）。
            "extreme_dist_relief": 1.0,     # 极端护栏触发时对 EMA 距离门槛的额外放宽倍率（<1 表示放宽）。
            "panic_align_need": 0.0,        # panic_lane 额外要求的多周期对齐度（0 表示不追加）
            "mania_align_need": 0.0,        # mania_lane 额外要求的多周期对齐度
            "require_vol_on_extreme": False,# 极端护栏（panic/mania）是否必须成交量确认
            "entry_cooldown_mult": 1.0,     # 入场冷静期乘数，>1 表示 Gate 等噪音多时延长冷却
            "portfolio_net_drain_limit": -0.012,   # 教学：组合回撤阈值默认与策略一致，可按交易所放宽。
            "portfolio_drain_relax_limit": -0.024, # 教学：允许在组合回撤扩展至 -2.4% 内，只要满足放宽条件仍可加仓。
            "portfolio_drain_relax_profit": 0.036, # 教学：放宽加仓所需浮盈阈值，可针对波动大的交易所调高。
            "portfolio_drain_relax_align": 0.22,   # 教学：放宽加仓仍需的多周期偏置强度。
            "align_floor_long": 0.10,       # 新手：多头至少需要 0.10 的多周期正偏置才追涨，适度放宽以平衡多空放行密度。
            "align_floor_short": 0.10,      # 新手：空头至少需要 -0.10 的偏置才追跌，保持与多头同等宽松度。
        },
        "okx": {
            # OKX 永续波动与文档基线接近，但账户净值波动略大，适度放宽组合回撤阈值。
            "portfolio_net_drain_limit": -0.032,
            "portfolio_drain_relax_limit": -0.045,
        },
        "gate": {
            # Gate 永续长影线多但同步数据略稀疏：适度放宽成交量/对齐阈值，保持与 OKX 相近的信号密度。
            "vol_surge_mult": 1.04,
            "vol_accel_mult": 1.03,
            "tri_need_mult": 1.02,
            "dist_relax_mult": 1.03,
            "extreme_tri_relief": 0.94,
            "extreme_dist_relief": 0.95,
            "panic_align_need": 0.05,
            # 2025-09 校准：mania 护栏与 OKX 对齐，避免 Gate 档位额外的 -0.05 对齐需求导致顶部诱多迟迟不过关。
            "mania_align_need": 0.0,
            "require_vol_on_extreme": False,
            "entry_cooldown_mult": 1.12,
            "portfolio_net_drain_limit": -0.018,
            "portfolio_drain_relax_limit": -0.032,
            "align_floor_long": 0.10,
            "align_floor_short": 0.10,
        },
        "binance": {
            # Binance USDT 永续深度充足但高频噪声较低：放宽放量/三锚需求，同时要求极端护栏出现时确认成交量扩张。
            "vol_surge_mult": 0.98,
            "vol_accel_mult": 0.99,
            "tri_need_mult": 0.98,
            "dist_relax_mult": 1.01,
            "extreme_tri_relief": 0.96,
            "extreme_dist_relief": 0.97,
            "panic_align_need": 0.02,
            "mania_align_need": 0.02,
            "require_vol_on_extreme": True,
            "entry_cooldown_mult": 1.0,
            "portfolio_net_drain_limit": -0.020,
            "portfolio_drain_relax_limit": -0.034,
            "portfolio_drain_relax_profit": 0.034,
            "portfolio_drain_relax_align": 0.22,
            "align_floor_long": 0.10,
            "align_floor_short": 0.10,
        },
    }

    # === 多空优先级治理（解决“护栏冲突导致止盈缺席 / 交易所间优先级不一致”） ===
    SIDE_PRIORITY_ENABLE = True             # 新手：开启后会根据多周期/护栏信号动态给多空打分，用于 tie-break 与止盈审查。
    SIDE_PRIORITY_BALANCE_TOL = 0.08        # 新手：分数差小于 0.08 视为平衡，允许多空同时存在而不强行阻断。
    SIDE_PRIORITY_ENTRY_BASE = 0.18         # 新手：多空差值 ≥0.18 且与当前方向相反时，入场会被引导到优先方向，避免“护栏互撞”。
    SIDE_PRIORITY_EXIT_BASE = 0.14          # 新手：当持仓方向劣势 ≥0.14 时，离场会倾向保守止盈/止损，不再等待硬触发。
    SIDE_PRIORITY_FASTLANE_OVERRIDE = True  # 新手：快车道 + 成交量确认时可少量突破优先级闸门，确保强趋势不被错失。

    # === 入场多周期偏置地板（解决“爆插后误空 / 大涨后误多”） ===
    ENTRY_ALIGN_FLOOR_LONG = 0.10          # 新手：多头至少需要 0.10 的多周期正偏置，略微放宽以提升多头放行密度。
    ENTRY_ALIGN_FLOOR_SHORT = 0.10         # 新手：空头至少需要 -0.10 的偏置，保持多空对称并提高下单概率。

    # === 入场综合质量评分（提高信号门槛，避免“方向对但拿不住”） ===
    ENTRY_QUALITY_ENABLE = True            # 新手：开启后将多周期/三锚/RFS/优先级综合成分数，低于阈值一律拒单。
    ENTRY_QUALITY_ALIGN_WEIGHT = 0.36      # 新手：多周期对齐占比分（方向感最重要）。
    ENTRY_QUALITY_TRI_WEIGHT = 0.27        # 新手：三锚偏置（结构/动能/位置）权重。
    ENTRY_QUALITY_RFS_WEIGHT = 0.21        # 新手：RFS 动能健康度权重。
    ENTRY_QUALITY_PRIORITY_WEIGHT = 0.16   # 新手：多空优先级信心权重。
    ENTRY_QUALITY_FAST_BONUS = 0.038       # 新手：快车道额外加分，代表节奏契合。
    ENTRY_QUALITY_SLOW_BONUS = 0.024       # 新手：慢车道结构单也给少量加分。
    ENTRY_QUALITY_HTF_BONUS = 0.022        # 新手：1h/4h 驱动共振加分。
    ENTRY_QUALITY_CHANNEL_BONUS = 0.018    # 新手：窄通道推进再加分。
    ENTRY_QUALITY_DECAY_PENALTY = 0.032    # 新手：宽通道衰减时减分，提醒可能是尾声震荡。
    ENTRY_QUALITY_VOL_BONUS = 0.02         # 新手：成交量放量确认再加分。
    ENTRY_QUALITY_PRICE_CEIL = 0.68        # 新手：多头价格位于区间上方 68% 以上开始扣分，进一步抑制追天花板。
    ENTRY_QUALITY_PRICE_FLOOR = 0.32       # 新手：空头价格位于区间下方 32% 以下开始扣分，避免抄地板开空。
    ENTRY_QUALITY_PRICE_WEIGHT = 0.24      # 新手：提高价格极值扣分强度，凸显位置重要性。
    ENTRY_QUALITY_PRICE_ANCHOR_WEIGHT = 0.12  # 新手：多时框价格锚偏离的额外扣分强度。
    ENTRY_QUALITY_PULLBACK_BONUS = 0.012      # 新手：确认回踩后给予质量分奖励，鼓励耐心等吸筹。
    ENTRY_QUALITY_PULLBACK_PENALTY = 0.018    # 新手：缺乏回踩仍想重启进场时额外扣分。
    ENTRY_QUALITY_BASE_NEED = 0.68         # 新手：基础阈值 0.68 分以下直接拒单。
    ENTRY_QUALITY_SLOW_NEED = 0.72         # 新手：结构慢车道略收紧到 0.72 分。
    ENTRY_QUALITY_FAST_NEED = 0.77         # 新手：快车道趋势需 ≥0.77 分才执行。
    ENTRY_QUALITY_DYNAMIC_ADD = 0.034      # 新手：若处于动态热榜惩罚（prefer 模式），再额外加严 0.034。
    ENTRY_QUALITY_FRAGILE_ADD = 0.052      # 新手：组合脆弱期提高 0.052 分阈值。
    ENTRY_QUALITY_EXTREME_ADD = 0.07       # 新手：panic/mania 极端护栏时再加严 0.07。
    ENTRY_QUALITY_DECAY_ADD = 0.034        # 新手：宽通道衰减环境，再额外提高 0.034 分。
    ENTRY_QUALITY_PREFER_RELIEF = 0.008    # 新手：优先级明确偏向本方向时，阈值可放宽 0.008。
    ENTRY_QUALITY_NEED_BUFFER = 0.035      # 新手：质量分需超出阈值的基本缓冲，显著削减擦边球信号。
    ENTRY_QUALITY_NEED_BUFFER_FAST_MULT = 0.45  # 新手：快车道默认减半缓冲，避免错过强趋势。
    ENTRY_QUALITY_NEED_BUFFER_SLOW_MULT = 0.85  # 新手：慢车道保留 85% 缓冲，兼顾区间持仓。
    ENTRY_QUALITY_NEED_BUFFER_EXTREME_MULT = 0.5  # 新手：panic/mania 极端下缓冲减半，保留少量防守机会。
    ENTRY_QUALITY_PASS_RATIO_MIN = 1.06           # 新手：综合评分需达到需求×1.06，过滤擦边球候选。
    ENTRY_QUALITY_PASS_RATIO_FAST_MIN = 1.04      # 新手：快车道略放宽至 1.04，兼顾趋势弹性。
    ENTRY_QUALITY_PASS_RATIO_SLOW_MIN = 1.07      # 新手：慢车道 ≥1.07 倍需求，避免区间里重复试单。
    ENTRY_QUALITY_PASS_RATIO_EXTREME_MIN = 1.06   # 新手：panic/mania 极端护栏下进一步加严。

    # === 信号质量附注与深度过滤（默认开启，配合策略节奏过滤弱信号） ===
    SIGNAL_FILTER_ENABLE = True                   # 默认开启信号质量/盘口治理，以策略自带阈值直接拦截弱信号。
    SIGNAL_STRENGTH_THRESHOLD = 0.35              # 质量分（或综合评分）低于 0.35 直接拒单；可按品种强弱上调/下调。
    SIGNAL_VOLUME_FILTER = 0.9                    # 成交量过滤：近端成交量/均值低于 0.9 拒单，避免冷清盘口误触发。
    SIGNAL_MULTI_TF_ENABLE = True                 # 开启双周期趋势/动量确认（默认开，增强一致性，仍可在配置关闭）。
    SIGNAL_MULTI_TF_WEIGHT = 0.40                 # 多周期确认占综合信号质量权重，默认 0.40（仅在开启时生效）。
    SIGNAL_DEPTH_ENABLE = True                    # 开启盘口买卖盘不平衡/流速过滤，默认与质量阈值协同拦截噪音。
    SIGNAL_DEPTH_WEIGHT = 0.30                    # 盘口过滤质量占比，默认 0.30（开启时才参与）。
    SIGNAL_OB_IMBALANCE_NEED = 0.08               # 盘口买卖不平衡阈值（0~1，正数偏多头、负数偏空头）；默认 0.08 需轻微倾斜才放行。
    SIGNAL_FLOW_RATE_NEED = 0.05                  # 盘口资金流速率阈值（abs，大于则视为通过），默认 0.05 过滤滞缓盘口。
    SIGNAL_EXIT_CLUSTER_ENABLE = True             # 默认开启离场扎堆观察加分，仅在出现密集止损/止盈离场时提升信号质量。
    SIGNAL_EXIT_CLUSTER_WEIGHT = 0.12             # 离场扎堆加分权重，默认 0.12，且无密度时不降权；可在配置调小/关闭。
    SIGNAL_EXIT_CLUSTER_WINDOW = 48               # 统计近 N 根（默认 48 根）stop/exit 事件密度，用于反向观察。
    SIGNAL_EXIT_CLUSTER_MIN = 0.02                # 需要超过的最低密度（默认 0.02≈48 根内≥1 次）才开始加分。

    # === 入场价格带守卫（防止 1m 模式追高 or 半山腰抄底） ===
    ENTRY_PRICE_BAND_GUARD_ENABLE = True      # 新手：开启后会根据 price_position 拦截高位做多/低位做空。
    ENTRY_PRICE_LONG_MAX = 0.70               # 新手：多头默认最多跟到 70% 分位，超出视为追高（与 v3 模板一致）。
    ENTRY_PRICE_SHORT_MIN = 0.34              # 新手：空头默认至少等到 34% 分位以上，避免砸底部开空。
    ENTRY_PRICE_LONG_CORE_MAX = 0.50          # 新手：非趋势多头要求 ≤50% 分位，避免“半山腰抄底”。
    ENTRY_PRICE_SHORT_CORE_MIN = 0.50         # 新手：非趋势空头要求 ≥50% 分位，避免“半山腰做空”。
    ENTRY_PRICE_LONG_MAX_60 = 0.66            # 新手：60 根窗口上沿超过 66% 仍视为追高。
    ENTRY_PRICE_LONG_MAX_240 = 0.62           # 新手：240 根窗口上沿超过 62% 仍视为追高。
    ENTRY_PRICE_SHORT_MIN_60 = 0.38           # 新手：做空至少等到 60 根窗口 ≥38% 分位。
    ENTRY_PRICE_SHORT_MIN_240 = 0.42          # 新手：做空至少等到 240 根窗口 ≥42% 分位。
    ENTRY_PRICE_LONG_CORE_MAX_60 = 0.48       # 新手：60 根窗口半山腰抄底上限 48%。
    ENTRY_PRICE_LONG_CORE_MAX_240 = 0.46      # 新手：240 根窗口半山腰抄底上限 46%。
    ENTRY_PRICE_SHORT_CORE_MIN_60 = 0.52      # 新手：60 根窗口半山腰做空需 ≥52%。
    ENTRY_PRICE_SHORT_CORE_MIN_240 = 0.56     # 新手：240 根窗口半山腰做空需 ≥56%。
    ENTRY_PRICE_TREND_RELIEF = 0.04           # 新手：快车道放行时可追加 4% 的追随空间。
    ENTRY_PRICE_SLOW_RELIEF = 0.02            # 新手：慢车道略放松 2%，兼顾结构趋势。
    ENTRY_PRICE_EXTREME_RELIEF = 0.06         # 新手：panic/mania 极端护栏时额外放宽 6%。
    ENTRY_PRICE_EXTREME_REQUIRE_VOL = True    # 新手：极端护栏要有成交量确认才给予额外追随空间。
    ENTRY_PRICE_RELIEF_CAP = 0.06             # 新手：无论多少豁免，总放宽幅度不超过 6%。
    ENTRY_PRICE_VWAP_WINDOW_BARS = 288        # 新手：24 小时滚动 VWAP 评估“会话溢价”。
    ENTRY_PRICE_LONG_VWAP_MAX = 0.012         # 新手：多单价格高于 VWAP 1.2% 视为追价。
    ENTRY_PRICE_SHORT_VWAP_MIN = 0.008        # 新手：空单至少等到价格高出 VWAP 0.8%。
    ENTRY_PULLBACK_RECENT_WINDOW = 18         # 新手：18 根内出现过同向候选则视为刚试过，需等待回踩。

    # === 空头方向配额与高位限制（避免多空 1:1 对冲） ===
    DIRECTIONAL_SHORT_FORCE_DISABLE: bool = True      # 教学：设为 True 时临时跳过空单比例/数量守卫，用于排障或手动干预。
    DIRECTIONAL_SHORT_RATIO_ENABLE: bool = True       # 新手：开启后统计近 N 分钟多空放行量，限制空单比例。
    DIRECTIONAL_SHORT_MAX_RATIO: float = 0.10         # 新手：空单配额再收紧至 5%，确保多单数量明显领先再开空。
    DIRECTIONAL_SHORT_LOOKBACK_MINUTES: float = 1440.0  # 新手：统计近 24 小时内的放行记录。
    DIRECTIONAL_SHORT_MIN_LONG: int = 10               # 新手：至少放行 10 笔多单后才考虑新空单，维持 10% 配额。
    DIRECTIONAL_SHORT_MANIA_OVERRIDE: bool = False    # 新手：禁用 mania 额外放行，确保空单比例治理生效。
    DIRECTIONAL_SHORT_PRICE_OVERRIDE_FLOOR: float = 0.86  # 新手：如启用放行，需位于价格分位 86% 以上。
    DIRECTIONAL_SHORT_OPEN_ENABLE: bool = True        # 新手：开启后统计当前空单数量，超出上限直接拒绝新空单。
    DIRECTIONAL_SHORT_MAX_OPEN: int = 1               # 新手：默认同一时间仅允许 1 笔空单，可在 config 设为 0 表示不限量。

    # === 暗面进场（极端护栏中的顺势反制入口） ===
    DARKSIDE_ENTRY_ENABLE = True           # 新手：开启后当 panic/mania 极端护栏出现衰竭迹象时，可触发“暗面进场”减缓拒单。
    DARKSIDE_ENTRY_PROFILE: Dict[str, Dict[str, Any]] = {
        "long": {
            "price_trigger": 0.26,       # 价格位于区间下沿 26% 以下视为恐慌区，开始累积分数。
            "price_span": 0.09,          # 价格越接近 0 越加分，9% 以内达到满分。
            "align_base": 0.18,          # 多周期正偏置 ≥0.18 才视为具备反攻动能。
            "align_span": 0.26,
            "tri_relief": 0.07,          # 达标后三锚需求下调 0.07，便于抄底信号放行。
            "tri_span": 0.22,
            "rfs_base": 0.40,
            "rfs_span": 0.24,
            "reflex_base": 1.05,         # 软反身性 Z 分数 ≥1.05 代表恐慌回弹势能。
            "reflex_span": 0.65,
            "quality_bonus": 0.045,      # 通过暗面审查后额外给质量分 0.045。
            "quality_relief": 0.02,      # 并把质量阈值下调 0.02。
            "align_relief": 0.06,        # 对齐地板同步放松 0.06。
            "score_need": 0.63,
            "require_volume": True,
            "weights": {"align": 0.26, "tri": 0.24, "rfs": 0.18, "reflex": 0.20, "price": 0.08, "lane": 0.04},
        },
        "short": {
            "price_trigger": 0.74,       # 价格位于区间上沿 74% 以上视为拉高区，开始累积分数。
            "price_span": 0.09,
            "align_base": 0.18,          # 多周期负偏置 ≥-0.18 才算势力翻转。
            "align_span": 0.26,
            "tri_relief": 0.06,
            "tri_span": 0.20,
            "rfs_base": 0.42,
            "rfs_span": 0.24,
            "reflex_base": 1.00,         # 软反身性 Z 分数 ≤-1.0 显示顶部能量坍塌。
            "reflex_span": 0.60,
            "quality_bonus": 0.040,
            "quality_relief": 0.018,
            "align_relief": 0.05,
            "score_need": 0.64,
            "require_volume": True,
            "weights": {"align": 0.28, "tri": 0.22, "rfs": 0.16, "reflex": 0.22, "price": 0.08, "lane": 0.04},
        },
    }

    # === 组合盈亏上下文（Trade 页浮盈 vs Dashboard 净值差异治理） ===
    PORTFOLIO_CONTEXT_ENABLE = True             # 新手：开启后根据所有持仓的组合盈亏调节入场/止盈，避免黑盒忽略其他亏损单。
    PORTFOLIO_NET_DRAIN_LIMIT = -0.12          # 新手：组合加权浮盈跌破 -1.2% 视为回撤，暂停新仓/加仓、加速收缩风险（可被交易所/币种配置放宽）。
    PORTFOLIO_NET_DRAIN_RELAX_LIMIT = -0.28    # 新手：满足放宽条件时，可在 -2.8% 内继续允许运营加仓，避免强势腿被组合回撤拖累。
    PORTFOLIO_NET_DRAIN_RELAX_PROFIT = 0.16    # 新手：若单笔浮盈 ≥3.6% 且处于强势通道，可在组合回撤中少量放行加仓。
    PORTFOLIO_NET_DRAIN_RELAX_ALIGN = 0.22      # 新手：放宽加仓时仍需 ≥0.22 的多周期同向偏置，确保顺势而为。
    PORTFOLIO_FRAGILE_FLOOR = 0.12             # 新手：组合净值低于 2.2% 仍算脆弱，需用赢家锁盈补亏或加严闸门。
    PORTFOLIO_FRAGILE_ALIGN = 0.28              # 新手：脆弱期多空都需要 ≥0.28 的多周期对齐才准入，防止弱势信号搅局。
    PORTFOLIO_LOCK_SHARE_MIN = 0.55             # 新手：当某单贡献 ≥55% 的正向浮盈时触发组合锁盈机制。
    PORTFOLIO_LOCK_MIN_PROFIT = 0.018           # 新手：组合锁盈至少守住 1.8% 浮盈，避免白忙一场。
    PORTFOLIO_LOCK_RATIO = 0.60                 # 新手：默认锁住当前浮盈的 60%，可按手感调高或调低。
    PORTFOLIO_LOCK_RATIO_MAX = 0.85             # 新手：组合锁盈最多保留 85% 的浮盈，留一点给尾随止损。
    PORTFOLIO_FRAGILE_TRI_MULT = 1.05           # 新手：组合脆弱时三锚需求 ×1.05，逼迫更强共振后才出手。
    PORTFOLIO_FRAGILE_DIST_MULT = 1.04          # 新手：组合脆弱时 EMA 距离 ×1.04，避免太贴线就冲动开单。
    PORTFOLIO_ALLOW_FASTLANE_OVERRIDE = True    # 新手：允许超级强势快车道在脆弱期略微突破组合守护，防止错失大趋势。

    # === 组合脆弱对齐动态阈值（解决“组合脆弱期加仓过于严格”） ===
    PORTFOLIO_FRAGILE_LOSS_PRESSURE = 0.26      # 新手：当亏损敞口占比 ≥10% 才视为真正脆弱，避免轻微回吐就全面收紧。
    PORTFOLIO_FRAGILE_ALIGN_MIN = 0.08          # 新手：组合脆弱期对齐阈值的地板，确保仍需一定多周期共振。
    PORTFOLIO_FRAGILE_ALIGN_FAST_RELIEF = 0.10  # 新手：快车道信号可额外放宽 0.10，对齐要求不过度苛刻。
    PORTFOLIO_FRAGILE_ALIGN_SLOW_RELIEF = 0.05  # 新手：慢车道信号也适度放松 0.05，兼顾结构类机会。
    PORTFOLIO_FRAGILE_ALIGN_DRIVE_RELIEF = 0.04 # 新手：当 1h/4h 驱动通道仍在推进时，允许再放松 0.04。
    PORTFOLIO_FRAGILE_ALIGN_POS_FACTOR = 2.0    # 新手：组合净值每 +1% 可降低 0.02 的对齐需求（2.0×0.01）。
    PORTFOLIO_FRAGILE_LOSS_GRACE = 0.06         # 新手：若亏损敞口 ≤6%，判定为轻度回吐，可给额外宽松。
    PORTFOLIO_FRAGILE_ALIGN_LOSS_RELIEF = 0.04  # 新手：轻度回吐时额外放松 0.04，避免正收益组合被卡住。
    PORTFOLIO_FRAGILE_ALIGN_EXTREME_MIN = 0.0   # 新手：极端护栏（panic/mania）+快车道可降到 0，允许高置信补仓。

    # === 软反身性 & 宏观事件/时区守护（用来应对 FOMC、期权结算、黑天鹅预警等） ===
    REFLEXIVE_EVENT_ENABLE = True       # 新手：开启后会自动读取下方事件窗口/交易时区，对信号进行加减速或暂停。
    MACRO_EVENT_WINDOWS: Tuple[Dict[str, Any], ...] = tuple()  # 新手：在 config 覆盖为元组/列表，元素为 {"label": "FOMC", "start": "2024-09-18T17:30:00Z", "end": "2024-09-18T20:30:00Z", "bias": "flat"}。
    EVENT_PRE_COOLDOWN_MINUTES = 40     # 新手：事件前置冷静期（分钟），用于防范发布前的诱骗波动。
    EVENT_POST_COOLDOWN_MINUTES = 20    # 新手：事件结束后的缓冲期，等待波动消化再恢复正常节奏。
    EVENT_PHASE_DEFAULTS = {            # 教学：不同阶段默认的“软闸门”调节系数，可按需在 config 中覆写。
        "pre":  {"tri_mult": 1.05, "dist_mult": 1.04, "add_mult": 1.08, "block_entry": False, "block_add": True},
        "live": {"tri_mult": 1.10, "dist_mult": 1.06, "add_mult": 1.15, "block_entry": True,  "block_add": True},
        "post": {"tri_mult": 1.03, "dist_mult": 1.02, "add_mult": 1.05, "block_entry": False, "block_add": False},
    }
    SESSION_PROFILE_ENABLE = True       # 新手：按主市场时区（亚/欧/美）切换手感，便于适配不同波动节奏。
    SESSION_TZ_OFFSET_HOURS: float = 8.0        # 教学：将 session_biases 的 start/end 解释为本地时区的小时偏移（相对 UTC），默认按上海时区解读。
    SESSION_BIASES = (                  # start/end 按本地小时，闭区间 [start, end)。
        {"label": "asia",    "start": 7,  "end": 15, "tri_mult": 1.04, "dist_mult": 1.03, "add_mult": 1.08, "bias": "calm", "block_entry": False, "block_add": False},
        {"label": "europe",  "start": 15, "end": 20, "tri_mult": 1.00, "dist_mult": 1.00, "add_mult": 1.00, "bias": "balanced", "block_entry": False, "block_add": False},
        {"label": "us",      "start": 24, "end": 7,  "tri_mult": 0.10, "dist_mult": 0.10, "add_mult": 0.0, "bias": "volatile", "block_entry": True, "block_add": True},
    )
    SESSION_PROFIT_WINDOW_HOURS: float = 12.0   # 新手：按 12 小时滚动窗口统计各时区的实际/峰值收益，用于调节期望守卫与量度目标。
    SESSION_PROFIT_HISTORY_LIMIT: int = 6       # 新手：历史窗口最多保留 6 期（约 3 天），便于平滑近期上限而不过度记忆旧行情。
    SESSION_PROFIT_ROLL_DECAY: float = 0.55     # 新手：跨窗口衰减系数，越低代表旧窗口贡献越小，适合近期波动上限变化较快的市场。
    SESSION_PROFIT_ROLL_ALPHA: float = 0.45     # 新手：窗口内滚动均值的平滑因子，0.45≈当期权重 55%，旧权重 45%。
    SESSION_PROFIT_MIN_CEILING_R: float = 0.44  # 新手：缺少样本时的最低盈亏比地板（约 0.44R），防止无上限时期望守卫被“卡死”。
    SESSION_PROFIT_CEILING_PAD: float = 0.15    # 新手：允许目标比观察到的天花板高出 0.15R 的缓冲，避免刚摸到上限就被迫收手。

    # === 风格预设 ===
    PRESET = "conservative"  # conservative / neutral / aggressive

    STYLE_AUTOPILOT_ENABLE = True  # 新手：自动判定行情强弱/组合状态，动态切换激进或保守手感。
    STYLE_AUTOPILOT_THRESHOLDS = {
        "align_strong": 0.58,             # 多周期对齐 ≥0.58 视为趋势充足，可考虑激进放行。
        "rfs_support": 0.14,              # RFS 动能同向 ≥0.14 代表行情有延续性。
        "drawdown_conservative": -0.020,  # 组合净值跌破 -2.0% 自动切到保守模式。
        "loss_pressure_conservative": 0.09,  # 亏损敞口 ≥9% 视为脆弱，优先走保守。
        "equity_push_aggressive": 0.018,  # 组合净值 ≥1.8% 或热手期才允许激进尝试。
        "price_top": 0.76,                # 价格落在区间上方 76% 以上视为追天花板。
        "price_bottom": 0.24,             # 价格落在区间下方 24% 以下视为砸地板。
        "price_buffer": 0.06,             # 价格需离顶部/底部至少 6% 区间才算安全区。
    }
    STYLE_PRESET_PROFILES = {
        "conservative": {
            "dist_mult": 1.08,
            "tri_mult": 1.05,
            "quality_add": 0.025,
            "frontload_mult": 0.85,
            "cooldown_mult": 1.18,
        },
        "neutral": {
            "dist_mult": 1.0,
            "tri_mult": 1.0,
            "quality_add": 0.0,
            "frontload_mult": 1.0,
            "cooldown_mult": 1.0,
        },
        "aggressive": {
            "dist_mult": 0.94,
            "tri_mult": 0.94,
            "quality_add": -0.02,
            "frontload_mult": 1.12,
            "cooldown_mult": 0.88,
        },
    }

    # === 信号扎堆保护（多空平衡 / 防止假反转） ===
    SIGNAL_CLUSTER_LOOKBACK_BARS = 18             # 新手：回溯 18 根（≈90 分钟）统计最近信号密度。
    SIGNAL_CLUSTER_PLOT_ENABLE: bool = True       # 新手：默认开启 WebUI 信号稀疏化，减少扎堆箭头。
    SIGNAL_CLUSTER_PLOT_COOLDOWN_BARS: int = 3    # 新手：同向信号放行后至少冷却 3 根（按当前时框换算）。
    SIGNAL_CLUSTER_PLOT_COOLDOWN_FAST: int = 1    # 新手：快车道/强趋势放宽为 1 根即可再次提示。
    SIGNAL_CLUSTER_PLOT_WINDOW_BARS: int = 10     # 新手：在 10 根窗口内统计 WebUI 信号数量。
    SIGNAL_CLUSTER_PLOT_MAX_PER_WINDOW: int = 1   # 新手：默认同向在窗口内仅展示 1 次，明显压缩马丁箭头。
    SIGNAL_CLUSTER_PLOT_FAST_ALIGN: float = 0.42  # 新手：快车道且多周期对齐 ≥0.42/≤-0.42 时可突破冷却限制。
    PANIC_LONG_PRICE_CEIL: float = 0.22           # 新手：panic 补多需价格位于下沿 22% 以内才绘制候选。
    MANIA_SHORT_PRICE_FLOOR: float = 0.78         # 新手：mania 诱空需价格 ≥78% 区间上沿才绘制候选。
    SIGNAL_CLUSTER_SAME_SOFT = 2                  # 新手：同方向 ≥2 次后进入“软限制”，需要更强驱动才放行。
    SIGNAL_CLUSTER_SAME_HARD = 4                  # 新手：同方向 ≥4 次视为扎堆，除非超级趋势否则暂停继续追单。
    SIGNAL_CLUSTER_ALIGN_STRICT = 0.42            # 新手：密集/反向信号需满足的多周期偏置阈值。
    SIGNAL_CLUSTER_ALIGN_FAST = 0.60              # 新手：快车道 override 所需偏置，确保真强趋势才连击。
    SIGNAL_CLUSTER_OPP_COOLDOWN = 6               # 新手：反向信号需等待 ≥6 根（≈30 分钟），避免马上打脸。
    SIGNAL_CLUSTER_TRI_BONUS = 0.08               # 新手：反向对冲额外需要的三锚偏置增量，过滤假反转。
    SIGNAL_CLUSTER_BIAS_WEIGHT_ALIGN = 0.52       # 新手：同方向历史信号的对齐度权重，用于衡量偏向强度。
    SIGNAL_CLUSTER_BIAS_WEIGHT_TRI = 0.34         # 新手：三锚偏置权重，越接近 1 代表趋势更一致。
    SIGNAL_CLUSTER_BIAS_WEIGHT_PRIORITY = 0.28    # 新手：优先级/信心加成，帮助识别“真趋势”信号。
    SIGNAL_CLUSTER_BIAS_WEIGHT_FASTLANE = 0.14    # 新手：快车道额外奖励，代表行情在加速阶段。
    SIGNAL_CLUSTER_BIAS_WEIGHT_SLOWLANE = 0.09    # 新手：慢车道 + 结构良好的补票也给予一定分量。
    SIGNAL_CLUSTER_BIAS_DECAY = 0.92              # 新手：每根 K 线偏向衰减 8%，避免老旧信号一直压制新机会。
    SIGNAL_CLUSTER_BIAS_WARN = 1.15               # 新手：偏向分数 ≥1.15 时，反向信号需额外确认后才能放行。
    SIGNAL_CLUSTER_BIAS_BLOCK = 1.85              # 新手：偏向分数 ≥1.85 时直接拦截反向信号，直到偏向明显逆转。

    # === ATR/ADX/与 1h EMA200 距离窗（基础闸门） ===
    ADAPT_DIST = True
    ADX_TREND_MIN = 20             # 新手：参考 Binance 永续研究，ADX≥23 即具备动量统计显著性，放宽能提早捕捉趋势。
    ADX_TREND_STRONG = 30          # 新手：ADX≥37 视为强势趋势，比传统 40 略松，兼顾质量与出手频率。
    ATR_WIN_MIN = 0.00125          # 新手：ATR 最小窗降至 0.125%，覆盖波动收缩期的小行情。
    ATR_WIN_MAX = 0.032            # 新手：ATR 最大窗放宽到 3.2%，兼顾新闻波动下仍能给信号。

    DIST_EMA_NEED = 0.00125        # 新手：价格需离 1h EMA200 至少 0.125%，放宽后趋势初启更易获批。
    DIST_EMA_NEAR_MIN = 0.00095    # 新手：近距离容忍度 0.095%，结合快车道可允许贴着均线起跑。
    DIST_EMA_NEED_SHORT_BONUS = 1.06  # 新手：做空放宽 6% 的距离加成，降低恐慌反弹后错失顺空的概率。
    DIST_EMA_NEAR_MIN_SHORT_BONUS = 1.04  # 新手：近距离加成 1.04，使强趋势下的回抽空单更易通过。

    # === 反转基元/趋势补票 ===
    REENTRY_LOOKBACK = 18
    REENTRY_LONG_POS_RANGE  = (0.30, 0.85)
    REENTRY_SHORT_POS_RANGE = (0.15, 0.70)

    REV_TOP_POS = 0.75
    REV_BOT_POS = 0.25
    REV_RSI_HIGH = 70
    REV_RSI_LOW  = 30

    KEL_MULT = 2.1
    DIR_GUARD_BARS = 2

    # === 结构台阶/假破过滤 ===
    STRUCT_STAIR_EXIT_ENABLED = True
    STRUCT_STAIR_N = 1
    STRUCT_STEP_ATR = 0.13
    EXIT_CONFIRM_BARS = 1
    EXIT_ATR_PAD = 0.11
    WICK_FILTER = 0.25
    HTF_BIAS_HOLD = True
    RFS_HOLD_THR = 0.30

    # === 小目标/反手/止损策略（硬参数由 per-pair 覆盖） ===
    NO_STOPLOSS_MODE = True
    ALLOW_FLIP = True
    FLIP_REQUIRE_PROFIT = True
    FLIP_MIN_PROFIT = 0.0
    FLIP_BYPASS_MIN_PROFIT_EXIT = True

    # === 恢复止损/紧急路径 ===
    STOPLOSS_RECOVER_ADD_THRESHOLD = 1
    STOPLOSS_RECOVER_MODE = True
    STOPLOSS_RECOVER_ATR_K = 1.6
    STOPLOSS_RECOVER_MAX = 0.22
    EMERGENCY_RFS_THR = 0.20
    EMERGENCY_OPP_BARS = 2
    EMERGENCY_FLIP_ON_LOSS = True
    EMERGENCY_FLIP_MAX_LOSS = 0.12

    # === 止损兜底复核（接近 8.5% 触发时再看一次多空结构，避免无脑打损） ===
    STOPLOSS_REVIEW_TRIGGER = 0.594      # 新手：动态地板 ≥ 兜底的 59.4%（≈11.9%）或出现风险命中时，启动复核流程。
    STOPLOSS_REVIEW_DEFEND_MULT = 0.635  # 新手：宏观/多周期仍同向 → 把地板收至兜底的 63.5%（≈12.7%），并提示准备防守加仓。
    STOPLOSS_REVIEW_HOLD_MULT = 0.655    # 新手：结构模糊 → 默认把地板放在兜底的 65.5%（≈13.1%），稍提前离场以免被最后一脚打穿。
    STOPLOSS_REVIEW_TIGHTEN_MULT = 0.581 # 新手：宏观/多周期反向或爆尾反向 → 收紧到兜底的 58.1%（≈11.6%），兼顾风控与喘息。
    STOPLOSS_REVIEW_ALIGN_MIN = 0.18     # 新手：多周期偏置达到 0.18 视为“同向支持”，低于此值默认结构不足。
    STOPLOSS_REVIEW_ALIGN_STRONG = 0.32  # 新手：≥0.32 表示强同向趋势，可积极考虑防守加仓。
    STOPLOSS_REVIEW_HINT_BARS = 6        # 新手：复核结论保留 6 根 5m（≈30 分钟），供加仓治理参考。
    STOPLOSS_REVIEW_DEF_ADD_RELAX = 0.88 # 新手：复核建议防守时，加仓所需 ATR 回踩放宽至原来的 88%。
    STOPLOSS_REVIEW_DEF_ADD_MAX_PROFIT = 0.008  # 新手：复核建议防守时，允许亏损到 0.8% 以内仍触发防守腿。
    STOPLOSS_REVIEW_DEFEND_EXTRA_BARS = 24      # 新手：复核喊“防守”后，额外开放 24 根 5m 加仓窗口（≈2 小时），避免错过救火腿。

    # === 动态止损放宽（强趋势 & 极端护栏后缓释） ===
    STOPLOSS_ALIGN_RELAX_THRESHOLD = 0.34   # 新手：多周期偏置≥0.34（或≤-0.34）视为强趋势，止损基础宽度将放宽。
    STOPLOSS_ALIGN_RELAX_SCALE = 0.60       # 新手：每额外 0.01 的偏置，会再放宽 ≈0.60%，帮助强趋势仓位留出喘息空间。
    STOPLOSS_ALIGN_RELAX_MAX = 1.36         # 新手：放宽上限，避免遇到极端偏置时止损被无限放大。
    STOPLOSS_EXTREME_RELAX_AFTER = 6        # 新手：极端护栏（爆插/诱多）触发 6 根 K 以后，开始逐步释放止损紧度。
    STOPLOSS_EXTREME_RELAX_STEPS = 8        # 新手：再经历 8 根 K，止损将逐步放宽至目标水平，防止长期被“兜底”卡太紧。
    STOPLOSS_EXTREME_RELAX_TARGET = 0.97    # 新手：普通情况下，极端护栏的止损乘数最终放宽至 0.97（更接近原始宽度）。
    STOPLOSS_EXTREME_RELAX_STRONG_TARGET = 1.01  # 新手：若慢车道或强趋势同向，最终可放宽到 1.01，让顺势单多一点容忍度。
    STOPLOSS_EXTREME_STRONG_ALIGN = 0.38    # 新手：偏置绝对值≥0.38 视为“强趋势”，触发额外放宽目标。

    # === PB 小回调释放/拖尾 ===
    PB_RELEASE_ENABLE = True           # 新手：True=开启小回调锁盈释放；False=完全交由其它离场逻辑控制趋势尾声。
    PB_RELEASE_AFTER_ADDS = 2          # 新手：完成加仓次数 ≥2 后才允许触发回吐释放，避免刚加仓就被迫减仓。
    PB_MIN_PROFIT_GATE = 0.203         # 新手：回吐释放至少要有 ~0.203R（≈4.0%）的浮盈（per-pair 可覆盖），低波品可调低，高波品可调高。
    PB_ATR_K = 0.60                    # 新手：判定“回吐幅度”的 ATR 倍数，数值越小越敏感。
    PB_REQUIRE_MOMO = True             # 新手：True=需要动能转弱才释放；False=只要价格回吐就执行，风险更高。
    PB_LOOKBACK_SHADOW = 48            # 新手：回看 48 根影子，确认是否多次触碰回吐阈值后再执行。

    PB_TRAIL_ENABLE = True             # 新手：开启回吐释放后，允许开启拖尾，顺势把止盈慢慢抬高。
    PB_TRAIL_AFTER_GATE = 0.018        # 新手：浮盈达到 1.8% 后才开始拖尾；低波品可适度下调。
    PB_TRAIL_ATR_K = 0.55              # 新手：拖尾跟随 ATR 的比例，越小越贴近价格。

    # === Scale-out 减仓 ===
    SCALE_OUT_ENABLE = True            # 新手：True=启用分段减仓（near/exhaust/守卫联动）；False=全部仓位交给其它离场流程。
    SCALE_OUT_NEAR_FRAC = 0.50         # 新手：near-exit 成功时默认减掉 50% 仓位；可在 0.3~0.6 之间调节锁盈速度。
    SCALE_OUT_EXHAUST_FRAC = 0.30      # 新手：动能衰竭（exhaust）触发时减持 30%，避免趋势尾声全留在场内。
    RUNNER_MIN_FRAC = 0.20             # 新手：无论如何都至少保留 20% runner，让趋势单还有扩展空间。

    # === EMA 硬阈 & 量能衰竭 ===
    EMA_HARDLINE_EXIT = True           # 新手：True=价格跌破 EMA 硬阈时强制离场；False=交由其它事件处理。
    EMA_HARDLINE_PAD = 0.0010          # 新手：EMA 离场允许的缓冲，默认 0.10%；放大=更保守。
    VOL_EXHAUST_EXIT = True            # 新手：True=量能衰竭可触发离场，适合捕捉趋势尾声；False=禁用该事件。
    VOL_EXH_DECAY_BARS = 4             # 新手：观察量能衰退的窗口（4 根 5m），调大=更宽松、调小=更敏捷。
    VOL_EXH_DROP = 0.75                # 新手：量能跌至峰值的 75% 视为衰竭；调低=更敏感、调高=更稳健。

    # === 结构台阶离场模式 ===
    STRUCT_EXIT_MODE = "confirm"       # 新手：confirm=结构确认后离场；instant=破位立即离场；off=禁用结构台阶离场。
    STRUCT_EXIT_MIN_PROFIT = 0         # 新手：结构离场所需最低浮盈，0 表示只要结构成立即执行。（原0.3）

    # === 近目标提前释放（near-exit） ===
    MID_ADD_NEAR_RELEASE_ENABLE = True  # 新手：True=即使中途加仓也允许 near-exit 快速减仓；False=加仓后关闭提前减仓。
    NEAR_EXIT_MULT = 0.76               # 新手：near-exit 触发阈值（按目标 R ×0.76 计算），小一点=更早锁盈；各币种可 override。
    NEAR_EXIT_ALT  = 0.024              # 新手：静态利润地板（约 2.4%）；横盘品种可适度上调，趋势币可下调加快触发。

    # === 小目标锁盈调速（守住 5~10% 浮盈） ===
    MICRO_TARGET_ENABLE = True              # 新手：开启后 0.4% 附近的小浮盈也会被守护，回落到保本即主动离场。
    MICRO_TARGET_LEVEL = 0.004              # 新手：微型目标默认 0.4%，可改为 0.002~0.008 适配低波币种。
    MICRO_TARGET_CEIL = 0.012               # 新手：超过此浮盈交由常规小目标管理，默认 1.2%。
    MICRO_TARGET_LOCK_RATIO = 0.38          # 新手：微型目标锁盈地板占峰值的比例，0.38 ≈ 守住 38% 浮盈。
    MICRO_TARGET_FLOOR_MIN = 0.0            # 新手：可设置为 0.001（0.1%）避免直接跌回 0 再走人。
    MICRO_TARGET_FORCE_MINUTES = 18.0       # 新手：命中微型目标后，18 分钟仍无突破则尝试评分离场。
    MICRO_TARGET_RELAX_WEAKEN = True        # 新手：动能/结构转弱时可提前加分离场，避免拖成亏单。
    MICRO_TARGET_SCORE_LEVEL = "medium"     # 新手：微型目标事件的评分权重，可设为 medium 让其更快触发。
    MICRO_TARGET_MAX_DRAWDOWN = 0.005       # 新手：若回落超过 0.5% 且仍未离场，直接视为保本失败强制退出。

    # === 严格回吐守卫（浮盈拉开后强制抬升锁盈，避免回吐成亏损） ===
    STRICT_GIVEBACK_ENABLE: bool = True           # 新手：开启后，一旦浮盈达到阈值即锁定大于 0 的地板，防止“先盈后亏”。
    STRICT_GIVEBACK_ARM_R: float = 0.28           # 新手：默认浮盈达到 ~1.08R（≈4.3%）即启动守卫，4% 兜底下保持旧版 4.3% 体验。
    STRICT_GIVEBACK_ARM_MIN: float = 0.46         # 新手：即使情境要求更高，也至少在 ~0.81R（≈3.2%）启动收紧。
    STRICT_GIVEBACK_ARM_PAD: float = 1.369        # 新手：趋势情境会将启动阈值限制在目标 R 减去该缓冲（≈1.9%），避免太接近终极目标。
    STRICT_GIVEBACK_CONTEXT_ARM: Dict[str, float] = {
        "narrow": 0.162,
        "balance": 0.203,
        "range": 0.182,
        "decay": 0.162,
        "trend": 0.297,
    }
    STRICT_GIVEBACK_FLOOR_SHARE: float = 0.73     # 新手：守卫激活后，至少保住当前浮盈的 58%。
    STRICT_GIVEBACK_PEAK_SHARE: float = 0.78      # 新手：亦参考历史峰值，默认保留峰值浮盈的 48%。
    STRICT_GIVEBACK_FLOOR_R_MIN: float = 0.50     # 新手：即便浮盈回落，也至少留住 0.50R（≈2%）的利润，回到新版 0.5R 地板。
    STRICT_GIVEBACK_FLOOR_MIN: float = 0.0025     # 新手：兜底锁盈最小值（0.25%），防止刚过门槛就几乎归零。
    STRICT_GIVEBACK_BUFFER_SHARE: float = 0.04    # 新手：锁盈线与实时利润之间保留的比例缓冲（默认 14% 浮盈空间）。
    STRICT_GIVEBACK_BUFFER_ABS: float = 0.0012    # 新手：锁盈线与当前利润的最小绝对缓冲（默认 0.12%）。
    STRICT_GIVEBACK_EXIT_TOLERANCE: float = 0.0008  # 新手：守卫锁盈落地的退出容差（默认 0.08%），避免因噪声迟迟无法落袋。
    STRICT_GIVEBACK_BASIS_HINT_PCT: float = 0.0   # 若填写，将与实时风险基准对比，帮助提醒是否遗忘调参。
    STRICT_GIVEBACK_BASIS_MISMATCH_THRESHOLD: float = 0.15  # 基准偏离超过 15% 即触发提示。
    STRICT_GIVEBACK_BASIS_WARN_COOLDOWN_MIN: float = 30.0   # 同一笔交易的基准偏离提示冷却时间（分钟）。
    SMALL_TARGET_ENABLE = True              # 新手：开启后当历史浮盈穿越小目标就抬高锁盈地板，避免只赚 0.x%。
    SMALL_TARGET_LEVEL = 0.04               # 新手：小目标默认锁定 4% 浮盈（≈1:0.4 盈亏比），可按币种节奏改为 0.04~0.08。
    SMALL_TARGET_LEVEL_R = 0.40             # 新手：若能获取风险基准，则以 0.4R 作为小目标最低标准。
    SMALL_TARGET_LOCK_RATIO = 0.76          # 新手：锁盈地板=小目标×系数，0.55≈保留 55% 浮盈，防止回吐过多。
    SMALL_TARGET_FLOOR_MIN = 0.018          # 新手：再差也至少守住 1.8%（与 near-exit、PB 阈值协调）。
    SMALL_TARGET_RELAX_WEAKEN = True        # 新手：命中小目标后放宽离场触发条件，结构转弱即优先兑现。
    SMALL_TARGET_USE_PEAK = True            # 新手：True=用历史峰值×系数抬地板（8%→守住约4.4%），False=只按 level 固定。
    # [CODEX-NEW] 小目标强制离场零等待：满足 0.25R~0.5R 浮盈后立即走 force exit，避免“臭止损”回吐。
    SMALL_TARGET_FORCE_BARS = 0             # 新手：达到小目标后无需额外等待，维持在释放门槛即可即刻强制兑现。
    SMALL_TARGET_FORCE_R = 0.50             # 新手：当浮盈达到 0.5R 即刻启动强制离场闸门。
    SMALL_TARGET_FORCE_TOLERANCE = 0.0015   # 新手：0.5R 强制离场允许的回落容差（默认 15bp）。
    SMALL_TARGET_FORCE_MAX_ADDS = 2         # 新手：默认允许整套 6 段冰山腿都触发 0.5R 强制兑现，避免加仓后迟迟不落袋。
    SMALL_TARGET_BREAKEVEN_RELEASE = True   # 新手：小目标曾命中后，如利润跌回盈亏平衡线（含轻微滑点）则直接落袋，避免盈利转亏。
    SMALL_TARGET_BREAKEVEN_FLOOR = 0.0      # 允许的保本释放底线（默认不亏）；可覆写为 -0.002 等，让最多亏 0.2% 也接受离场。
    SMALL_TARGET_BREAKEVEN_TOLERANCE = 0.0008  # 保本释放的浮动容差，默认 8bp，避免因手续费或滑点迟迟不触发。
    SMALL_TARGET_MAX_HOLD_MINUTES = 40      # 新手：命中小目标后最长持仓时间（分钟），超时仍未达更高目标则按锁盈/保本逻辑自动离场。
    # [CODEX-NEW] 0.25R 及格线提优先级：只要浮盈达到约 0.25R（基于实时风险基准），强制锁盈放行不再被守卫阻挡。
    FORCE_EXIT_MIN_R = 0.20                 # 新手：可接受的“落袋为安” R 倍数，默认 0.20R；为 0 关闭该放行阈值。
    # [CODEX-NEW] 成交滑点治理：按最近成交滑点/跳空统计，动态收紧风险基线、成本缓冲与名义上限。
    EXECUTION_SLIPPAGE_WINDOW = 14          # 新手：记录最近 N 笔成交滑点（默认 14 笔）用于判断是否需要收紧。
    EXECUTION_SLIPPAGE_TIGHTEN_BPS = 18.0   # 新手：绝对滑点均值/峰值超过 18bp 视为“偏高”，触发轻度收紧。
    EXECUTION_SLIPPAGE_SEVERE_BPS = 32.0    # 新手：绝对滑点峰值超过 32bp 视为“严重”，触发更强收紧。
    EXECUTION_SLIPPAGE_RISK_SCALE = 0.92    # 新手：滑点偏高时，将风险基线乘以 0.92，降低允许的单笔风险。
    EXECUTION_SLIPPAGE_SEVERE_RISK_SCALE = 0.86  # 新手：滑点严重时进一步将风险基线降至 86%。
    EXECUTION_SLIPPAGE_COST_BOOST = 1.05    # 新手：滑点偏高时，提高成本缓冲乘数 5%，更多覆盖费用/冲击成本。
    EXECUTION_SLIPPAGE_SEVERE_COST_BOOST = 1.12  # 新手：滑点严重时提高 12% 的成本缓冲。
    EXECUTION_SLIPPAGE_CAP_SHARE = 0.82     # 新手：滑点偏高时，将名义上限按 82% 降幅添加 slippage_cap 候选。
    EXECUTION_SLIPPAGE_SEVERE_CAP_SHARE = 0.72  # 新手：滑点严重时，将名义上限按 72% 降幅添加候选。

    # [CODEX-NEW] 成交偏差（名义与目标不一致）自动重锚：超额成交时抬高锁盈/降低后续腿。
    FILL_SLIPPAGE_THRESHOLD = 0.06          # 新手：成交名义与目标名义偏差超过 6% 触发重锚。
    FILL_SLIPPAGE_LOCK_BOOST = 0.55         # 新手：偏差触发后锁盈地板按 dev×0.55 线性抬升（上限受 max 限制）。
    FILL_SLIPPAGE_LOCK_BOOST_MAX = 1.42     # 新手：锁盈地板最多抬升到原值的 1.42 倍。
    FILL_SLIPPAGE_TARGET_PENALTY = 0.42     # 新手：偏差触发后目标/near-exit 按 dev×0.42 下降，减小贪心。
    FILL_SLIPPAGE_LEG_PENALTY = 0.60        # 新手：下一腿默认按 dev×0.60 降低 leg_ratio，防止重仓。
    FILL_SLIPPAGE_LEG_FLOOR = 0.58          # 新手：加仓腿最低乘数，避免被扣到 0；默认保留 58% 的腿尺寸。
    # [CODEX-NEW] 反向信号优先平仓 + 接力灵敏度短暂提升：持仓出现反向终审信号时先行强制离场，接力单在限定时间内略微放宽三锚/对齐需求，成交后恢复原阈值。
    OPP_SIGNAL_FORCE_EXIT_PROFIT_MAX = 0.02  # 新手：反向信号触发强平时允许的最大浮盈（2% 以内优先落袋回避反杀）。
    OPP_SIGNAL_FORCE_EXIT_LOSS_MAX = 0.05    # 新手：反向信号触发强平时允许的最深亏损（-5% 以内仍可止血离场）。
    OPP_SIGNAL_FORCE_EXIT_RISK_NEED = 2      # 新手：风险命中项（反向候选/DI/结构/动能/EMA）累计达到该数量才执行强平。
    OPP_SIGNAL_HANDOFF_RELAX_MINUTES = 18    # 新手：反向强平后的接力观察窗口（分钟），窗口内略微放宽接力信号灵敏度。
    OPP_SIGNAL_HANDOFF_TRI_RELAX = 0.96      # 新手：接力窗口内三锚需求乘数（<1 更敏感）。
    OPP_SIGNAL_HANDOFF_ALIGN_BONUS = 0.02    # 新手：接力窗口内对齐度加分（提高微弱对齐的放行率）。
    # [CODEX-NEW] 反向信号分三段落袋：0.25R~0.50R 先小幅减仓，~1R 加速减仓，~2R 或超时全平。
    OPP_STAGE1_R: float = 0.30                # 第 1 阶段触发 R：默认 0.30R（≈0.25R~0.50R 中枢）。
    OPP_STAGE1_REDUCE: float = 0.78           # 第 1 阶段减仓后保留仓位比例（默认留 78% 作为 runner）。
    OPP_STAGE2_R: float = 1.00                # 第 2 阶段触发 R：默认 ~1R（核心落袋）。
    OPP_STAGE2_REDUCE: float = 0.38           # 第 2 阶段减仓后保留仓位比例（默认仅留 38% runner）。
    OPP_STAGE3_R: float = 1.90                # 第 3 阶段触发 R：默认 ~2R，仍未触发则等待超时强平。
    OPP_STAGE3_REDUCE: float = 0.0            # 第 3 阶段全平（可在覆写中留极少 runner）。
    OPP_STAGE_TIMEOUT_MINUTES: float = 90.0   # 超过该持仓时间仍未完成三段落袋，则触发超时全平。
    # [CODEX-NEW] 反向三段落袋并入 stoploss 责任：以下 pullback_pct 为“相对峰值回撤需求”，默认 0=关闭以保持旧版直接触发；
    #             优先级说明：stoploss（反向三段/兜底/组合锁盈） > trailing floor > exit 弹性止盈 > ROI（硬 TP 关闭）。
    OPP_STAGE1_PULLBACK: float = 0.002        # 第 1 阶段默认需回撤 0.2% 后落袋，过滤未见兑现的假拉升。
    OPP_STAGE2_PULLBACK: float = 0.006        # 第 2 阶段默认需回撤 0.6%，确保 1R 后有兑现动能再加速减仓。
    OPP_STAGE3_PULLBACK: float = 0.012        # 第 3 阶段/超时全平前默认需回撤 1.2%，避免高位误杀 runner。

    """参数—功能映射（风险等级/优先级概览，便于人工调节）
    - 低风险（守护/兜底，先执行）：STOPLOSS_MIN/动态兜底、Keltner 缓冲、portfolio_lock（stoploss 层负责）。
    - 中风险（锁盈/追踪，继承 stoploss）：opp_stage*_trim/exit 分段落袋、trailing_floor、Strict Giveback/Expectation Guard（stoploss 层减仓/锁盈）。
    - 中高风险（主动止盈，exit 层负责）：elastic exit 事件、peak_retreat/stagnation/EMA 硬阈，受 stoploss 地板保护。
    - 可选（ROI/硬 TP，若启用则低优先级）：minimal_roi/hard_tp；默认关闭避免与 stoploss 冲突。
    互斥/依赖：opp_stage_* 依赖反向终审信号与风险命中数；pullback_pct>0 时需满足回撤条件才放行分段；Strict Giveback/Expectation Guard
    始终在 stoploss 层抬地板，不会阻断 opp_stage_* 的触发；elastic exit 得分通过后若未击穿 stoploss 地板则优先使用 exit 释放。
    """
    # === 进场质量分层（高质单提速锁盈 / 低质单偏防守）===
    ENTRY_QUALITY_HIGH_RATIO = 1.18         # 新手：质量分 ≥需求×1.18 视为高质量信号，启动“打赢就收”的护航逻辑。
    ENTRY_QUALITY_LOW_RATIO = 0.92          # 新手：质量分 <需求×0.92 视为低质量，仅小心试单，优先防守。
    HIGH_QUALITY_MICRO_LOCK_RATIO = 0.52    # 高质量单命中微目标后，默认保留 ≥52% 浮盈，避免回吐变亏。
    HIGH_QUALITY_MICRO_FLOOR_MIN = 0.0025   # 高质量单的微目标至少守住约0.25%。
    HIGH_QUALITY_MICRO_FORCE_MINUTES = 12.0 # 高质量单在微目标附近停留 12 分钟仍未突破 → 快速复核兑现。
    HIGH_QUALITY_MICRO_MAX_DRAWDOWN = 0.0035# 高质量单一旦从微目标回落超过 0.35% 即视为保本失败。
    LOW_QUALITY_MICRO_LOCK_RATIO = 0.32     # 低质量单遇到微目标只保留约32% 浮盈，多给行情喘息空间。
    LOW_QUALITY_MICRO_FORCE_MINUTES = 24.0  # 低质量单在微目标附近可等待更久，避免频繁误触退出。
    LOW_QUALITY_MICRO_MAX_DRAWDOWN = 0.006  # 低质量单允许最大 0.6% 回撤后再判定失败。
    HIGH_QUALITY_SMALL_LOCK_SHARE = 0.62    # 高质量单命中小目标后至少守住 62% 峰值浮盈。
    HIGH_QUALITY_SMALL_LOCK_MIN = 0.012     # 高质量单小目标回吐到 1.2% 即启动锁盈释放。
    HIGH_QUALITY_SMALL_FORCE_BARS = 0       # 高质量单命中小目标后无需等待额外 K 线即可走强制兑现，确保 0.25R~0.5R 区间迅速落袋。
    HIGH_QUALITY_SMALL_FORCE_MAX_ADDS = 2   # 高质量单即便已金字塔 1-2 次仍允许触发强制兑现。
    LOW_QUALITY_SMALL_LOCK_SHARE = 0.48     # 低质量单小目标仅守住 48% 浮盈，留待行情继续确认。
    LOW_QUALITY_SMALL_FORCE_BARS = 0        # 低质量单命中小目标也立即允许强制兑现，优先守住 0.25R~0.5R 的盈利。
    LOW_QUALITY_SMALL_FORCE_MAX_ADDS = 0    # 低质量单默认仍只在未加仓时启用强制小目标。
    # [CODEX-NEW] 加仓阈值收紧：高/低质量 ATR 需求与浮盈腿门槛抬升，防止“重仓第二腿”。
    HIGH_QUALITY_PULLBACK_MULT = 0.92       # 高质量单加仓所需 ATR 回踩提高至 0.92 倍，过滤浅回踩的二次追击。
    LOW_QUALITY_PULLBACK_MULT = 1.28        # 低质量单加仓需更深回踩，避免在可疑信号上加注。
    HIGH_QUALITY_FADD_MULT = 0.86           # 高质量单浮盈金字塔门槛收紧，优质趋势也需更实质回踩才加注。
    LOW_QUALITY_FADD_MULT = 1.12            # 低质量单浮盈金字塔门槛提高 12%，更谨慎。
    HIGH_QUALITY_ALLOW_DEF_ADD = False      # 高质量单默认不触发防守腿，避免把强势单摊薄成拖泥带水。
    LOW_QUALITY_DEF_ADD_MULT = 1.02         # 低质量单防守腿触发所需 ATR 回踩提高，减少可疑信号上的摊薄。

    # === 量度涨跌幅（Measured Move） ===
    MEASURED_MOVE_ENABLE = True             # 新手：开启后，当浮盈达到“初始风险 × 倍数”时纳入弹性止盈评分。
    MEASURED_MOVE_R_MULT = 1.30             # 新手：默认要求赚取 ≥~1.30R（≈26%）才触发量度目标事件。
    MEASURED_MOVE_MIN_PROFIT = 0.030        # 新手：再小也至少守住 3.0% 浮盈，避免 ATR 太小造成提前触发。
    MEASURED_MOVE_LOCK_SHARE = 0.64         # 新手：命中量度目标后默认保留 64% 浮盈作为地板。
    MEASURED_MOVE_LOCK_MIN = 0.019          # 新手：锁盈地板至少守住 1.9%，与新的目标基线一致。
    MEASURED_MOVE_LEVEL = "major"           # 新手：量度目标事件记作 major 级，权重足以驱动主动离场。
    MEASURED_MOVE_RETRY_MINUTES = 12.0      # 新手：未满足评分阈值时，至少等待 12 分钟再度尝试触发。
    MEASURED_MOVE_RISK_BASIS = "hybrid"     # 新手：量度目标风险基线（initial/actual/hybrid/max/min/avg），默认取初始与实时风险较大者。
    MEASURED_MOVE_NARROW_R = 0.338          # 新手：窄通道/震荡段优先争取 ~0.338R（≈6.8%），避免在低波动里贪图高盈亏比。
    MEASURED_MOVE_BALANCE_R = 0.675         # 新手：常规行情默认锁定 ~0.675R（≈13.5%），兼顾盈亏比与兑现效率。
    MEASURED_MOVE_TREND_R = 1.35            # 新手：强趋势（快车道/多周期同向）目标 ~1.35R（≈27%），对标“单边行情”收益预期。
    MEASURED_MOVE_DECAY_R = 0.540           # 新手：宽通道衰减期下调至 ~0.540R（≈10.8%），防止能量流失时目标过远。
    MEASURED_MOVE_TREND_ALIGN = 0.32        # 新手：|多周期对齐度| ≥0.32 视作强趋势，触发高 R 目标挑选。
    MEASURED_MOVE_SLOW_ALIGN = 0.22         # 新手：慢车道若对齐度 ≥0.22 亦可判定为趋势延续。
    MEASURED_MOVE_SUPER_ENABLE = True       # 新手：极强趋势场景开放“2R 续航”目标，避免早早落袋。
    MEASURED_MOVE_SUPER_R = 1.95            # 新手：超级趋势目标约 1.95R（≈39%），贴近 2R 收益想定。
    MEASURED_MOVE_SUPER_ALIGN = 0.46        # 新手：|多周期对齐度| ≥0.46 才认定为超级趋势（快+驱动并行）。
    MEASURED_MOVE_SUPER_ALIGN_DECAY = 0.40  # 新手：宽通道衰减但仍对齐 ≥0.40，可继续保留 2R 目标。
    MEASURED_MOVE_SUPER_TRIGGER_R = 1.10    # 新手：浮盈 ≥1.10R 且风控确认后，才考虑冲刺 2R。
    MEASURED_MOVE_SUPER_BLOCK_EXTREME = True  # 新手：panic/mania 极端区不再追 2R，优先保护收益。

    # === 盈亏比期望守护（推动平均 R 倍数接近 1:2）===
    # [CODEX-NEW] 期望守卫前移：near-exit 地板前置至 ~0.30R，目标覆盖 1~2R 并加速时间/回撤豁免。
    EXPECTATION_GUARD_ENABLE = True         # 新手：开启后，浮盈未达到目标 R 倍数前，会屏蔽“抢跑”型离场事件。
    EXPECTATION_TARGET_R = 1.20             # 新手：默认争取 1R~2R 区间的目标，辅以时间/回撤豁免，兼顾效率与盈亏比。
    EXPECTATION_RELEASE_R = 0.42            # 新手：当峰值 ≥0.42R 即记录“达标”，若回撤超阈值则允许提前兑现。
    EXPECTATION_RELEASE_FLOOR_R = 0.30      # 新手：实时浮盈 ≥0.30R（≈0.25R~0.5R 区间中枢）即放行 near-exit，并配合止损抬升保护该利润。
    EXPECTATION_RELEASE_FLOOR_PCT = 0.0     # 备选：若希望用“百分比”定义 near-exit 地板，可在覆写中填入该值，守卫会自动换算到 R。
    EXPECTATION_DRAWDOWN_R = 0.12           # 新手：达标后容许回撤 ~0.12R，兼顾 0.25R~0.5R 锁盈与波动缓冲。
    EXPECTATION_RELAX_MINUTES = 32.0        # 新手：持仓超过 ~32 分钟后视为任务完成，可让其它逻辑接管离场。
    EXPECTATION_LOG_COOLDOWN_MIN = 8.0      # 新手：守护日志最短间隔 8 分钟，避免复读刷屏。
    EXPECTATION_CONTEXT_PAD = 0.12          # 新手：情境目标上方保留 ~0.12R 缓冲，既尊重动态盈亏比也留给趋势发挥空间。
    EXPECTATION_FLOOR_MAX_R = 1.50          # 新手：浮盈到达 1R 以上后，守卫地板最多可抬到约 1.5R，覆盖 1R~2R 的锁盈需求。
    EXPECTATION_FLOOR_ESCALATE_AT_R = 1.05  # 新手：浮盈 ≥1.05R 即提前武装 1R+ 锁盈，预留少量缓冲避免因噪声反复触发。
    EXPECTATION_FLOOR_ESCALATE_PAD_R = 0.03 # 新手：抬升 1R 锁盈时保留 0.03R 缓冲（≈1.2%），减少因跳动造成的伪触发。
    EXPECTATION_TIME_ESCALATE_MINUTES =26.0   # 新手：持仓超过 ~26 分钟仍未离场时，自动抬升锁盈地板。
    EXPECTATION_TIME_ESCALATE_TARGET_R = 0.36  # 新手：时间升级锁盈目标（≈0.36R），兼顾趋势发挥与收益落袋。
    EXPECTATION_TIME_ESCALATE_MIN_R = 0.30     # 新手：至少浮盈达到 0.30R 才触发时间锁盈，避免噪声频繁触发。
    EXPECTATION_TIME_ESCALATE_PAD_R = 0.02     # 新手：时间锁盈保留 0.02R 缓冲，降低瞬时波动导致的假触发。
    EXPECTATION_BIAS_FLOOR_SHIFT_R = 0.18      # 新手：当 crowd/priority 偏置同向时，自动把 floor escalation 触发值下调至最多 0.18R。
    EXPECTATION_BIAS_TIME_SHIFT_MINUTES = 18.0 # 新手：偏置持续时，把时间锁盈触发窗口最多提前 18 分钟。
    EXPECTATION_BIAS_TIME_FLOOR_MINUTES = 20.0 # 新手：即便偏置强烈，时间锁盈也不会早于 24 分钟触发。

    # === 加仓治理（更克制 & 允许“防守均价”）===
    ADDS_LIFETIME_MAX_BARS = 96           # 新手：把加仓生命周期放宽到 96 根 5m，留出顺势加速的操作窗口。
    ADD_REQUIRE_TREND_OR_VOL = True       # ADX 强或放量激增 任一满足
    NO_ADD_AFTER_ROI = 0.14               # 新手：浮盈≥14% 后才停止追击，避免强趋势早早失去加仓资格。
    ICEBERG_PULLBACK_TREND_MULT = 0.70    # 新手：强趋势（多周期同向）时，将 ATR 回踩需求打 7 折，让浮盈腿更易触发。
    ICEBERG_PULLBACK_FAST_MULT = 0.56     # 新手：快车道顺势允许 56% 回踩即加仓，模拟专业交易员“打穿就追”。
    ICEBERG_PULLBACK_DEF_RELAX = 0.84     # 新手：防守均价腿的回踩阈值进一步放松，方便在震荡中稳住成本线。
    ICEBERG_PULLBACK_DECAY_MULT = 1.10    # 新手：宽通道衰减期仍需谨慎，但降低附加回撤以免错过趋势续杯。
    ICEBERG_FASTLANE_COOLOFF = 2          # 新手：快车道加仓后至少等待 2 根 5m，既追随动量也避免过密。
    ICEBERG_SLOWLANE_COOLOFF = 3          # 新手：慢车道加仓后等待 3 根 5m，确保结构延续后再补仓。

    # === 首单前置加码（高胜率信号多吃一段） ===
    ENTRY_FRONTLOAD_MIN = 0.32             # 新手：普通信号默认首单约 32% 总仓，给后续补仓留出弹性。
    ENTRY_FRONTLOAD_MAX = 0.52             # 新手：强势信号最多提前吃到 52% 的目标仓位，避免超过一半提前耗尽子弹。
    ENTRY_FRONTLOAD_ALIGN_THRESHOLD = 0.26 # 新手：多周期对齐 ≥0.26（或 ≤-0.26）视为强势，触发额外前置仓位。
    ENTRY_FRONTLOAD_ALIGN_SCALE = 0.45     # 新手：每多 0.01 的对齐度，大约额外前置 0.45% 仓位。
    ENTRY_FRONTLOAD_ALIGN_CAP = 0.24       # 新手：对齐度贡献的前置仓位最多再加 24%。
    ENTRY_FRONTLOAD_FASTLANE_BONUS = 0.12  # 新手：快车道成交量确认时，额外提前吃下 12% 仓位。
    ENTRY_FRONTLOAD_SLOWLANE_BONUS = 0.08  # 新手：慢车道结构扎实 → 再提前 8%。
    ENTRY_FRONTLOAD_NARROW_BONUS = 0.06    # 新手：窄通道趋势稳定 → 再提前 6%。
    ENTRY_FRONTLOAD_DRIVE_BONUS = 0.05     # 新手：高周期驱动也同向 → 再提前 5%。
    ENTRY_FRONTLOAD_PRIORITY_BONUS = 0.05  # 新手：方向优先级明确支持该方向 → 最多再提前 5%。
    ENTRY_FRONTLOAD_PRIORITY_SCALE = 0.18  # 新手：优先级置信度每 0.18 增加 1 倍 bonus，用于强势币优先上车。
    ENTRY_FRONTLOAD_EXTREME_PENALTY = 0.72 # 新手：处于爆插/诱多护栏时，首单乘以 0.72，避免极端区过量梭哈。
    ENTRY_FRONTLOAD_FRAGILE_PENALTY = 0.18 # 新手：组合回撤期扣掉 18% 仓位，等净值恢复再放松。
    ENTRY_FRONTLOAD_DARKSIDE_PASS_PENALTY = 0.58   # 暗面进场通过时首单乘以 0.58，保守试探行情反转。
    ENTRY_FRONTLOAD_DARKSIDE_ACTIVE_PENALTY = 0.82 # 暗面分数不足但仍处极端区时，轻度缩减首单节奏。

    # === 浮盈金字塔 ===
    FLOAT_ADD_ENABLE = True
    FADD_MIN_PROFIT_GATE = 0.0369         # 新手：浮盈加仓门槛放宽到约 3.69%，仍结合车道/通道动态调节。
    FADD_FASTLANE_MULT = 0.72             # 新手：快车道顺势时乘以 0.72，让强趋势金字塔更灵活。
    FADD_SLOWLANE_MULT = 0.84             # 新手：慢车道保守放宽到 84%，兼顾结构确认与盈利效率。
    FADD_EVENT_TIGHTEN = 0.69             # 新手：事件窗口内浮盈腿门槛自动提高 12%，防止高波动盲目追单。

    # === 防守型均价（微DCA）===
    DEF_ADD_ENABLE = True
    DEF_ADD_MAX_PROFIT = 0.019           # 新手：允许在 1.9% 浮盈内执行防守腿，及时稳住均价。
    DEF_ADD_MIN_DD_ATR = 0.45            # 新手：ATR 回撤阈值放宽到 0.45×ATR，让补防守腿更灵活。
    DEF_ADD_LEG_FRAC = 0.13              # 新手：防守腿默认 13% 仓位，提升对抗假突破的缓冲力。
    DEF_ADD_WICK_OB = 0.44               # 新手：长影线判定阈值略放宽，捕捉恐慌砸盘后的“吸筹”机会。
    DEF_ADD_KEL_TOL = 0.002
    DEF_ADD_WICK_OVERRIDE_ENABLE = True  # 新手：遇到极端长影或 stoprun 时，可放宽回踩/位置要求执行防守腿。
    DEF_ADD_WICK_OVERRIDE_SHARE = 0.62   # 极端长影阈值（影线占 K 线振幅的 62% 以上视为插针）。
    DEF_ADD_WICK_OVERRIDE_ATR_MULT = 0.74  # 极端长影触发时，ATR 回踩需求降至原来的 74%。
    DEF_ADD_STOPRUN_POS_RELAX = True     # 极端插针/stoprun 触发时，允许忽略 price_position 极值要求。
    DEF_ADD_EVENT_TIGHTEN = 1.15         # 新手：事件窗口内防守腿 ATR 阈值加严 15%，避免黑天鹅期越抄越深。
    DEF_ADD_DEFEND_MIN_COOLDOWN = 0      # 新手：复核建议防守时，只需等 0 根 5m 就能再补一腿，提升救火效率。
    DEF_ADD_DEFEND_TRI_RELAX = 0.82      # 新手：复核建议防守时，将三锚阈值乘以 0.82 放宽，让结构尚可时能落地执行。
    DEF_ADD_DEFEND_ALLOW_TREND_SKIP = True  # 新手：复核建议防守时，即便 ADX/放量不达标也允许执行防守腿。

    # === 金字塔单次/总仓上限（默认开启，中度防重仓） ===
    PYRAMID_MAX_ADD_AMOUNT = 160.0       # 单次加仓金额上限（USDT 计价，默认 160）
    PYRAMID_MAX_ADD_PCT = 0.22           # 单次加仓占可用余额比例上限（例：0.22=最多动用 22% 可用余额）。
    PYRAMID_MAX_POSITION_PCT = 0.55      # 策略总仓位（保证金）占可用/总余额比例上限（默认 55%，随余额/杠杆自动缩放）。

    ADD_LOG_COOLDOWN_MINUTES = 15.0      # 新手：加仓等待/资金上限类日志至少间隔 15 分钟输出一次，避免刷屏。

    # === 恢复止损治理（只在风险≥3项触发）===
    RECOVER_ONLY_ON_RISK = True

    # === 爆插后反抽保护（防止顺势反手误空）===
    PANIC_PIERCE_ATR = 1.60       # 新手：下影线穿透 ≥ 1.6×ATR 判定为“爆插”；偏保守可调高，激进可调低
    PANIC_WICK_SHARE = 0.55       # 新手：下影线要占整根 55% 以上才认定；想放松可降到 0.45~0.50
    PANIC_REBOUND_ATR = 0.80      # 新手：实体回拉 ≥ 0.8×ATR 才视为强力反抽；行情急促可调到 0.6
    PANIC_GUARD_BARS = 3          # 新手：保护窗长度（根数），内含信号全部禁空；想更久就调 4~5
    PANIC_SLOPE_LOOKBACK = 4      # 新手：额外检测“连续瀑布”长度（4 根 5m ≈20 分钟），可按节奏调整 3~5
    PANIC_SLOPE_DROP_ATR = 2.30   # 新手：连续瀑布下跌累计 ≥2.3×ATR 视为末端溃散，阻止尾部继续追空
    PANIC_SLOPE_REBOUND_ATR = 0.55# 新手：若随即反弹 ≥0.55×ATR（哪怕无长下影）也触发保护，识别无影线型 V 反
    PANIC_SLOPE_GUARD_BARS = 4    # 新手：连续瀑布保护窗长度，默认 4 根覆盖约 20 分钟反弹观察期

    # === 瀑布前夕保护（防止顶部诱多）===
    BLOWOFF_PIERCE_ATR = 1.45     # 新手：上影线向上冲出 ≥ 1.45×ATR 视为“假突破”
    BLOWOFF_WICK_SHARE = 0.52     # 新手：上影线至少占 52%；若想更宽松可降到 0.45
    BLOWOFF_FADE_ATR = 0.70       # 新手：收盘回落 ≥ 0.7×ATR 才确认诱多；走势顺滑可调 0.5
    BLOWOFF_GUARD_BARS = 3        # 新手：保护窗长度，窗口内禁止盲目追多

    # === 软反身性护栏（识别趋势末端能量崩塌，避免“最后一单”被反转） ===
    REFLEXIVE_WINDOW = 7               # 新手：回溯 7 根（≈35 分钟）评估“价格偏离 × 量能反馈”的反身性强度。
    REFLEXIVE_PEAK_THR = 0.16          # 新手：反身性反馈均值 ≥0.16 视为强趋势高能区，低于此不触发崩塌判定。
    REFLEXIVE_PERCEPTION_MIN = 0.0028  # 新手：价格需离 1h EMA200 ≥0.28%，确保仅在趋势明显时才评估反身性。
    REFLEXIVE_DROP_RATIO = 0.32        # 新手：正向反身性均值回落 ≥32% 判定为顶部能量塌陷，可根据风险偏好调节。
    REFLEXIVE_REBOUND_RATIO = 0.35     # 新手：负向反身性均值回升 ≥35% 判定为底部恐慌缓解，阻止继续追空。
    REFLEXIVE_Z_THR = 0.90             # 新手：反身性 z-score 绝对值 ≥0.9 视为突发剧烈变化，可配合 drop/rebound 判定。
    REFLEXIVE_GUARD_BARS = 4           # 新手：触发后维持 4 根 5m 冷静期，防止能量塌陷后仍追单。

    # === 通道形态识别参数 ===
    CHANNEL_NARROW_MAX = 0.017    # 新手：5m 通道宽度 ≤ 1.7% 判定为“窄趋势”；调低=更挑剔，调高=更宽松
    CHANNEL_WIDE_MIN = 0.0215     # 新手：5m 通道宽度 ≥ 2.15% 认定为“宽震荡”，轻微放宽以覆盖更多震荡箱体
    CHANNEL_RATIO_NARROW = 0.88   # 新手：5m 相对 1h/4h 趋于收敛（比例 <0.88）视为“缩口待爆发”
    CHANNEL_RATIO_WIDE = 1.15     # 新手：5m 比高周期宽 ≥1.15 视为“结构松散”，提升宽震荡识别频率
    CHANNEL_NARROW_ER_MIN = 0.37  # 新手：窄趋势至少要有 0.37 的 ER；参考加密日内动量文献，低于此值多为噪音
    CHANNEL_NARROW_CHOP_MAX = 0.58  # 新手：窄趋势的 CI 上限；放宽到 0.58 以容纳“噪声略高但方向一致”的行情
    CHANNEL_ALIGN_MIN = 0.11      # 新手：窄趋势需满足 ≥0.11 的多周期对齐度，确保不是孤立的 5m 假突破
    CHANNEL_WIDE_CHOP_MIN = 0.48  # 新手：宽震荡的 CI 下限；放宽到 0.48，让轻微震荡也能进入“网格模式”
    CHANNEL_DECAY_RATIO = 0.94    # 新手：宽通道衰减判定阈值，5m 宽度跌破过去 3 根的 94% 视为结构走弱
    CHANNEL_HTF_ALIGN_MIN = 0.32  # 新手：高周期驱动模式需要 ≥0.32 的对齐度，确保 1h/4h 真正参与
    CHANNEL_HTF_RATIO_MAX = 1.50  # 新手：5m 相对 4h 的宽度上限；放宽至 1.5 允许趋势延续期的小幅扩张
    CHANNEL_HTF_WIDTH_FRAC = 0.85 # 新手：4h 宽度需至少达到宽震荡阈值的 85%，避免高周期过窄时误判驱动

    # === 成交量均线参数 ===
    VOL_MA_FAST = 5
    VOL_MA_SLOW = 20
    VOL_ACCEL_RATIO = 1.24  # 新手：成交量加速度阈值调至 1.24，参考 Crypto microstructure 研究，抓住渐进式放量的慢热行情。
    VOL_SURGE_MULT = 1.65   # 新手：放量判定降至 1.65，使“多周期共振 + 量能回流”的趋势信号更易达标。

    # === 锁盈/拖尾（台阶地板）===
    BE_TRIGGER = 0.010
    FLOOR_STEPS = [(0.020, 0.006), (0.040, 0.012), (0.070, 0.020), (0.100, 0.030)]
    FLOOR_STEPS_R = [(0.50, 0.25), (0.75, 0.60), (1.00, 1.00), (1.30, 1.05)]
    VSL_MIN_FLOOR = 0.050

    # === 自适应锁盈增强（基于 ATR / 动能的动态止盈地板）===
    ATR_LOCK_MULT = 1.25                 # ATR 百分比乘子 → 计算允许回撤宽度
    ATR_LOCK_MIN = 0.0030                # 最低允许回撤（避免极小 ATR 时过近被扫）
    PROFIT_LOCK_THRESHOLD = 0.025        # 利润达到该值后，以比例方式锁定大部分利润
    PROFIT_LOCK_SHARE = 0.58             # 比例锁定：当前利润 * 该系数
    MOMO_LOCK_SHARE = 0.72               # 动能转弱时锁定的比例（更激进）
    LOCK_BUFFER_MIN = 0.0010             # 止盈地板与当前利润之间预留的最小缓冲
    LOCK_BUFFER_FRAC = 0.10              # 缓冲也跟随利润增长，避免锁得过近
    LOCK_BUFFER_R_SHARE = 0.18           # 缓冲下限至少覆盖风险基准的 18%，避免 1R 太小时被“探针”扫掉

    # === 自适应动态止损（亏损段灵敏度调校）===
    STOPLOSS_ATR_BASE = 1.36             # 新手：亏损时止损底线 = ATR 百分比 × 1.36，让趋势蓄力期的正常回踩也能承受。
    STOPLOSS_MIN_PCT = 0.0065            # 新手：最小止损宽度 0.65%，防止太紧频繁被扫；想更激进可降至 0.5%
    STOPLOSS_MAX_PCT = 0.303             # 新手：最大宽度与 4% 兜底保持一致，避免强势单提前被动态地板卡出又不过度放宽风险。
    STOPLOSS_FAST_MULT = 0.92            # 新手：快车道信号仍锁亏，但只收紧到 92%，给趋势单多一点回旋。
    STOPLOSS_SLOW_MULT = 1.28            # 新手：慢车道趋势单需更大回撤空间 → 乘 1.28 放宽
    STOPLOSS_NARROW_MULT = 0.86          # 新手：窄通道说明结构稳 → 乘 0.86 让止损靠近
    STOPLOSS_WIDE_MULT = 1.18            # 新手：宽震荡走上下网格 → 乘 1.18 留足空间
    STOPLOSS_DECAY_MULT = 0.90           # 新手：宽通道开始塌缩 → 乘 0.90 提前收紧，防止结构失真
    STOPLOSS_HTF_DRIVE_MULT = 0.96       # 新手：1h/4h 驱动方向明确 → 乘 0.96 略收紧，兼顾趋势回踩空间
    STOPLOSS_TREND_RELAX_ALIGN = 0.26    # 新手：当多周期对齐 ≥0.26 时视为强趋势，动态止损将按车道叠加放宽。
    STOPLOSS_TREND_RELAX_STEP = 0.08     # 新手：强趋势每满足一项（快车道/慢车道/HTF 驱动）额外放宽 8%。
    STOPLOSS_TREND_RELAX_CAP = 1.32      # 新手：强趋势最多放宽到 ×1.32，防止无限扩张。
    STOPLOSS_WIDTH_TIGHT = 0.015         # 新手：5m 通道≤1.5% 视为极窄，自动套用紧凑止损
    STOPLOSS_WIDTH_LOOSE = 0.028         # 新手：5m 通道≥2.8% 属于大波动，触发宽松止损
    STOPLOSS_WIDTH_TIGHTEN = 0.88        # 新手：极窄通道下额外乘 0.88，再次靠近保护
    STOPLOSS_WIDTH_RELAX = 1.16          # 新手：大波动区额外乘 1.16，避免被虚假震荡打掉
    STOPLOSS_PANIC_RELAX = 1.25          # 新手：底部爆插后做多 → 乘 1.25 给更多喘息空间
    STOPLOSS_MANIA_TIGHTEN = 0.84        # 新手：顶部诱多后做空 → 乘 0.84 贴近保护，防止反抽
    STOPLOSS_BLOWOFF_TIGHT = 0.88        # 新手：若长单仍处顶部诱多护栏内 → 乘 0.88 快速离场
    STOPLOSS_PANIC_TIGHT = 0.88          # 新手：若空单仍处底部爆插护栏内 → 乘 0.88，守住反弹风险
    STOPLOSS_PANIC_SLOPE_TIGHT = 0.82    # 新手：若触发“连续瀑布保护”再做空 → 乘 0.82 再次收紧，反手 V 反时能更快止损
    STOPLOSS_ADD_DECAY = 0.92            # 新手：每多一次加仓，止损乘 0.92，逐步收紧总风险
    STOPLOSS_TIME_TIGHTEN_AFTER = 9      # 新手：持仓≥9 根 K 后才逐步收紧，给趋势单更多耐心等待主升浪。
    STOPLOSS_TIME_TIGHTEN_EACH = 0.97    # 新手：每多坚持 1 根 K，止损乘 0.97，收紧节奏放缓。
    STOPLOSS_TIME_TIGHTEN_MAX = 0.78     # 新手：最长时间衰减后的最低乘数 0.78，仍会逐步靠近但不再“锁死”。
    STOPLOSS_EMERGENCY_TRIGGER = 0.035   # 新手：浮亏达到 3.5% 即触发紧急兜底，避免 4% regime 下等到兜底才发现灾难。
    STOPLOSS_EMERGENCY_CAP = 0.303       # 新手：紧急兜底最大亏损上限与 4% 兜底保持一致，防止放大灾难性亏损。

    # === QuietMode · 稀疏化/节流（开关 + 可调参数）===
    QUIET_MODE = True
    ENTRY_COOLDOWN_BARS = 4     # 新手：冷静期基线 4 根；若主时框更快，ENTRY_COOLDOWN_MIN_MINUTES 会自动把真实冷却抬到等价分钟数。
    ENTRY_MAX_PER_DAY = 0       # 新手：0 表示不限制日内新仓次数，完全交由冷静期/优先级治理节奏。
    DAILY_PROFIT_CAP_ENABLE: bool = True    # 新手：默认开启日盈利封顶，达标后当日休息，避免过度交易。
    DAILY_PROFIT_CAP_PCT: float = 0.04       # 新手：以“可用余额/总余额”百分比表示的当日盈利目标，默认 4%。
    DAILY_PROFIT_CAP_ABS: float = 120.0      # 新手：以绝对 USDT 金额表示的当日盈利目标，默认 120；两档同时配置时取更紧的阈值。
    DAILY_PROFIT_CAP_BASIS: str = "available"  # 可选 available/total：按可用余额或总余额计算百分比目标，默认引用可用余额（扣除预留资金）。

    CHOP_N = 14                 # Choppiness Index 回看
    CHOP_TREND_MAX = 0.65       # 新手：趋势闸门 0.62→0.65，允许运行中的宽通道在 1h/4h 同向时继续给快单机会。
    CHOP_RANGE_MIN = 0.46       # 新手：震荡闸门 0.48→0.46，保留结构尚可的上下沿小区间，利于慢单网格式处理。

    ER_N = 10                   # Kaufman ER 回看
    ER_TREND_MIN = 0.28         # 新手：ER 下限 0.30→0.28，照顾拉升初期的“慢热”K 线，配合上方 CI 放宽提高顺势命中率。
    ER_RANGE_MAX = 0.58         # 新手：ER 上限 0.55→0.58，容忍宽通道初期的余温，震荡多空小利润策略更连贯。

    # === 区间极值防呆（阻止“山顶追多/地板追空”）===
    ENTRY_POS_EXTREME_HIGH = 0.82        # 新手：20 根高低区间内，价格 ≥82% 判定为“靠近山顶”
    ENTRY_POS_EXTREME_LOW = 0.18         # 新手：价格 ≤18% 判定为“靠近地板”
    ENTRY_POS_ALIGN_NEED = 0.42          # 新手：在极值区仍要至少满足 0.42 的多周期对齐度
    ENTRY_POS_ALIGN_EASE = 0.06          # 新手：快车道/高周驱动可放松 0.06，对应“确认强势才追”
    ENTRY_POS_TRI_DELTA = 0.06           # 新手：极值区额外要求三锚再+0.06，防止假突破
    ENTRY_POS_RFS_NEED = 0.58            # 新手：RFS（动能体检）至少 0.58，确保不是强弩之末

    # === 多周期/信息源（微观 + 宏观）===
    MICRO_TIMEFRAME_DEFAULT: List[str] = ["1m"]         # 新手：默认 5m 主循环下额外拉 1m 供冲击/量能侦测。
    MICRO_TIMEFRAME_LAYERS: Dict[str, List[str]] = {
        # 新手：当主时框改成 15m/30m/1h 等时，会按分钟匹配下方列表，为 30m 自动启用 3m/5m/15m 微观视角。
        "15m": ["3m", "5m"],
        "30m": ["3m", "5m", "15m"],
        "45m": ["5m", "15m"],
        "1h": ["5m", "15m", "30m"],
        "2h": ["5m", "15m", "1h"],
    }
    macro_informative_timeframes: List[str] = ["30m", "2h"]   # 新手：保持原有 1h/4h 宏观趋势，必要时可扩展至 1d。
    fallback_pairs: List[str] = ["BTC/USDT:USDT", "ETH/USDT:USDT", "SOL/USDT:USDT", "BNB/USDT:USDT"]  # 新手：白名单缺失时备用

    # === 三锚软锁强度：0~1（越高=越严格）===
    GLOBAL_SOFTLOCK_STRICTNESS = 0.615  # 新手：软锁严格度设为 0.615，tri_need≈0.385，兼顾共振放行与对冲噪音的研究建议。

    # === 盈亏节奏调速（盈利放大 + 回撤刹车）===
    PERFORMANCE_GUARD = True              # 新手：开启后根据最近胜率/回撤自动调整出手节奏
    PERF_WINDOW = 3                       # 新手：绩效观察窗口（最近 N 笔平仓），想更敏感可调小，想更稳可调大
    PERF_MAX_LOSS_STREAK = 1              # 新手：连续亏损 ≥2 笔触发“回撤刹车”，想更严格可设 1，想更宽松设 3
    PERF_DRAWDOWN_LIMIT = 0.45           # 新手：最近窗口累计亏损超过 45% 启动刹车；波动更大可调高
    PERF_RECOVERY_RESET = 0.18           # 新手：单笔盈利 ≥18% 视作恢复，自动解除回撤累计
    PERF_HOT_WIN_STREAK = 2               # 新手：连续盈利 ≥2 笔视作“热手”，放松闸门以提高盈利弹性
    PERF_HOT_AVG_MIN = 0.12              # 新手：热手模式要求窗口平均收益 ≥1.2%，避免虚假小盈
    PERF_DRAW_LOCK_SHARE = 0.85           # 新手：回撤期锁盈地板至少留住 85% 浮盈，保护已得利润
    PERF_DRAW_SL_TIGHTEN = 0.88           # 新手：回撤期亏损止损乘 0.88 → 更快止损，减轻继续回撤
    PERF_HOT_DIST_RELAX = 0.96            # 新手：热手模式下将距离需求乘 0.96，适当放宽以吃到更多顺势机会
    PERF_HOT_LOCK_RELAX = 0.92            # 新手：热手模式下锁盈地板乘 0.92，让盈利单留更多呼吸空间
    PERF_HOT_SL_RELAX = 1.06              # 新手：热手模式下亏损止损乘 1.06，给趋势单更多修复机会

    # === per-pair 默认（最终以 config.pair_overrides 合并为准）===
    pair_overrides: Dict[str, Dict[str, Any]] = {
        "BTC/USDT:USDT": {
            "strict_long_htf": False,
            "strict_short_htf": True,
            "max_notional_usdt": 880,
            "min_profit_exit": 0.02,
            "near_exit_mult": 0.90,
            "near_exit_alt": 0.017,
            "pb_min_profit_gate": 0.019,
            "runner_min_frac": 0.20,
            "small_target_max_hold_minutes": 40,
            "def_add_enable": False,
            "hard_tp": 0.10,
            "execution_slippage": {
                "tighten_bps": 20.0,
                "severe_bps": 34.0,
                "risk_scale": 0.94,
                "risk_scale_severe": 0.88,
                "cap_share": 0.80,
                "cap_share_severe": 0.70,
            },
            "fill_slippage_adjust": {
                "threshold": 0.055,
                "lock_boost": 0.60,
                "lock_boost_max": 1.45,
                "target_penalty": 0.38,
                "leg_penalty": 0.55,
                "leg_floor": 0.60,
            },
            "exit_tuning": {
                "measured_move_r_mult": 1.384,
                "measured_move_min_profit": 0.034,
                "measured_move_lock_share": 0.68,
                "measured_move_lock_min": 0.021,
                "measured_move_risk_basis": "hybrid",
            },
            "expectation_guard_enable": True,
            "expectation_target_r": 1.35,
            "expectation_release_r": 0.45,
            "expectation_release_floor_r": 0.30,
            "expectation_release_floor_pct": 0.000,
            "expectation_drawdown_r": 0.14,
            "expectation_floor_max_r": 1.60,
            "expectation_floor_escalate_at_r": 1.10,
            "expectation_relax_minutes": 50.0,
            "expectation_log_cooldown": 8.0,
            "expectation_context_pad": 0.140,
        },
        "ETH/USDT:USDT": {
            "strict_long_htf": True,
            "strict_short_htf": True,
            "max_notional_usdt": 650,
            "min_profit_exit": 0.02,
            "near_exit_mult": 0.90,
            "near_exit_alt": 0.017,
            "pb_min_profit_gate": 0.019,
            "runner_min_frac": 0.20,
            "small_target_max_hold_minutes": 35,
            "def_add_enable": True,
            "def_add_min_dd_atr": 0.70,
            "def_add_leg_frac": 0.06,
            "def_add_max_profit": 0.005,
            "hard_tp": 0.10,
            "execution_slippage": {
                "tighten_bps": 18.0,
                "severe_bps": 30.0,
                "risk_scale": 0.90,
                "risk_scale_severe": 0.84,
                "cap_share": 0.78,
                "cap_share_severe": 0.68,
            },
            "fill_slippage_adjust": {
                "threshold": 0.05,
                "lock_boost": 0.64,
                "lock_boost_max": 1.48,
                "target_penalty": 0.46,
                "leg_penalty": 0.62,
                "leg_floor": 0.58,
            },
            "exit_tuning": {
                "measured_move_r_mult": 1.323,
                "measured_move_min_profit": 0.032,
                "measured_move_lock_share": 0.66,
                "measured_move_lock_min": 0.020,
                "measured_move_risk_basis": "hybrid",
            },
            "expectation_guard_enable": True,
            "expectation_target_r": 1.20,
            "expectation_release_r": 0.40,
            "expectation_release_floor_r": 0.30,
            "expectation_drawdown_r": 0.10,
            "expectation_relax_minutes": 52.0,
            "expectation_log_cooldown": 8.0,
        },
        "SOL/USDT:USDT": {
            "strict_long_htf": False,
            "strict_short_htf": True,
            "max_notional_usdt": 520,
            "min_profit_exit": 0.024,
            "near_exit_mult": 0.90,
            "near_exit_alt": 0.020,
            "pb_min_profit_gate": 0.018,
            "runner_min_frac": 0.20,
            "small_target_max_hold_minutes": 40,
            "def_add_enable": True,
            "def_add_min_dd_atr": 0.70,
            "def_add_leg_frac": 0.08,
            "def_add_max_profit": 0.005,
            "hard_tp": 0.12,
            "execution_slippage": {
                "tighten_bps": 18.0,
                "severe_bps": 32.0,
                "risk_scale": 0.90,
                "risk_scale_severe": 0.84,
                "cap_share": 0.78,
                "cap_share_severe": 0.68,
            },
            "fill_slippage_adjust": {
                "threshold": 0.05,
                "lock_boost": 0.60,
                "lock_boost_max": 1.46,
                "target_penalty": 0.44,
                "leg_penalty": 0.62,
                "leg_floor": 0.57,
            },
            "exit_tuning": {
                "measured_move_r_mult": 1.256,
                "measured_move_min_profit": 0.035,
                "measured_move_lock_share": 0.64,
                "measured_move_lock_min": 0.021,
                "measured_move_risk_basis": "hybrid",
            },
            "expectation_guard_enable": True,
            "expectation_target_r": 1.45,
            "expectation_release_r": 0.48,
            "expectation_release_floor_r": 0.32,
            "expectation_release_floor_pct": 0.000,
            "expectation_drawdown_r": 0.16,
            "expectation_floor_max_r": 1.70,
            "expectation_floor_escalate_at_r": 1.20,
            "expectation_relax_minutes": 54.0,
            "expectation_log_cooldown": 9.0,
            "expectation_context_pad": 0.160,
        },
        "BNB/USDT:USDT": {
            "strict_long_htf": False,
            "strict_short_htf": True,
            "max_notional_usdt": 500,
            "min_profit_exit": 0.024,
            "near_exit_mult": 0.90,
            "near_exit_alt": 0.020,
            "pb_min_profit_gate": 0.018,
            "scale_out_near_frac": 0.45,
            "scale_out_exhaust_frac": 0.30,
            "runner_min_frac": 0.20,
            "small_target_max_hold_minutes": 40,
            "def_add_enable": True,
            "def_add_min_dd_atr": 0.60,
            "def_add_leg_frac": 0.06,
            "def_add_max_profit": 0.005,
            "hard_tp": 0.12,
            "execution_slippage": {
                "tighten_bps": 17.0,
                "severe_bps": 30.0,
                "risk_scale": 0.90,
                "risk_scale_severe": 0.84,
                "cap_share": 0.78,
                "cap_share_severe": 0.68,
            },
            "fill_slippage_adjust": {
                "threshold": 0.05,
                "lock_boost": 0.58,
                "lock_boost_max": 1.44,
                "target_penalty": 0.44,
                "leg_penalty": 0.62,
                "leg_floor": 0.57,
            },
            "exit_tuning": {
                "measured_move_r_mult": 1.229,
                "measured_move_min_profit": 0.033,
                "measured_move_lock_share": 0.63,
                "measured_move_lock_min": 0.020,
                "measured_move_narrow_r": 0.52,
                "measured_move_balance_r": 1.04,
                "measured_move_trend_r": 2.05,
                "measured_move_risk_basis": "hybrid",
            },
            "expectation_guard_enable": True,
            "expectation_target_r": 1.40,
            "expectation_release_r": 0.48,
            "expectation_release_floor_r": 0.32,
            "expectation_release_floor_pct": 0.000,
            "expectation_drawdown_r": 0.14,
            "expectation_floor_max_r": 1.80,
            "expectation_floor_escalate_at_r": 1.25,
            "expectation_relax_minutes": 60.0,
            "expectation_log_cooldown": 9.0,
            "expectation_context_pad": 0.170,
        },
        "DOGE/USDT:USDT": {
            "strict_long_htf": False,
            "strict_short_htf": True,
            "max_notional_usdt": 460,
            "min_profit_exit": 0.024,
            "near_exit_mult": 0.90,
            "near_exit_alt": 0.020,
            "pb_min_profit_gate": 0.022,
            "runner_min_frac": 0.20,
            "small_target_max_hold_minutes": 35,
            "def_add_enable": True,
            "def_add_min_dd_atr": 0.72,
            "def_add_leg_frac": 0.06,
            "def_add_max_profit": 0.005,
            "hard_tp": 0.12,
            "execution_slippage": {
                "tighten_bps": 16.0,
                "severe_bps": 28.0,
                "risk_scale": 0.88,
                "risk_scale_severe": 0.82,
                "cap_share": 0.76,
                "cap_share_severe": 0.66,
            },
            "fill_slippage_adjust": {
                "threshold": 0.045,
                "lock_boost": 0.68,
                "lock_boost_max": 1.50,
                "target_penalty": 0.48,
                "leg_penalty": 0.68,
                "leg_floor": 0.56,
            },
            "exit_tuning": {
                "measured_move_r_mult": 1.175,
                "measured_move_min_profit": 0.031,
                "measured_move_lock_share": 0.62,
                "measured_move_lock_min": 0.019,
                "measured_move_narrow_r": 0.50,
                "measured_move_balance_r": 1.02,
                "measured_move_trend_r": 1.96,
                "measured_move_risk_basis": "hybrid",
            },
            "directional_guard": {
                "short_min_long": 20,
                "short_max_open": 0,
                "short_max_ratio": 0.05,
            },
            "channel_pivot": {
                "follow_up": {
                    "up_wait": 4,
                    "down_wait": 4,
                    "up_retrace": 0.20,
                    "down_retrace": 0.20,
                    "up_pos": 0.64,
                    "down_pos": 0.36,
                }
            },
            "expectation_guard_enable": True,
            "expectation_target_r": 1.15,
            "expectation_release_r": 0.38,
            "expectation_release_floor_r": 0.28,
            "expectation_release_floor_pct": 0.000,
            "expectation_drawdown_r": 0.10,
            "expectation_floor_max_r": 1.40,
            "expectation_floor_escalate_at_r": 1.00,
            "expectation_relax_minutes": 44.0,
            "expectation_log_cooldown": 7.0,
            "expectation_context_pad": 0.130,
        },
    }
    _entry_quality_pair_settings: Dict[str, Dict[str, Any]] = {}
    _exit_tuning_pair_settings: Dict[str, Dict[str, Any]] = {}
    NOTIONAL_CAP_USDT = 500.0
    POSITION_TIER_SCHEDULE: Tuple[Dict[str, Any], ...] = (  # 按余额分层调整仓位切片/加仓窗口，兼顾 1k~10k USDT 体量。
        {
            "label": "starter",
            "max_total": 1500.0,
            "iceberg_legs": (0.46, 0.20, 0.14, 0.12, 0.05, 0.03),
            "max_entry_position_adjustment": 4,
            "entry_frontload_min": 0.38,
            "entry_frontload_max": 0.78,
            "iceberg_min_pullback_atr": 0.20,
            "iceberg_cooldown_bars": 2,
            "iceberg_fastlane_cooloff": 2,
            "iceberg_slowlane_cooloff": 3,
            "def_add_min_dd_atr": 0.46,
            "def_add_leg_frac": 0.12,
        },
        {
            "label": "growth",
            "max_total": 6000.0,
            "iceberg_legs": (0.42, 0.20, 0.15, 0.11, 0.07, 0.05),
            "max_entry_position_adjustment": 5,
            "entry_frontload_min": 0.36,
            "entry_frontload_max": 0.70,
            "iceberg_min_pullback_atr": 0.21,
            "iceberg_cooldown_bars": 2,
            "iceberg_fastlane_cooloff": 2,
            "iceberg_slowlane_cooloff": 3,
            "def_add_min_dd_atr": 0.44,
            "def_add_leg_frac": 0.14,
        },
        {
            "label": "stability",
            "max_total": 16000.0,
            "iceberg_legs": (0.31, 0.21, 0.17, 0.13, 0.10, 0.08),
            "max_entry_position_adjustment": 5,
            "entry_frontload_min": 0.30,
            "entry_frontload_max": 0.52,
            "entry_frontload_hard_cap": 0.48,
            "iceberg_min_pullback_atr": 0.22,
            "iceberg_cooldown_bars": 3,
            "iceberg_fastlane_cooloff": 3,
            "iceberg_slowlane_cooloff": 4,
            "def_add_min_dd_atr": 0.42,
            "def_add_leg_frac": 0.16,
        },
    )

    ACCOUNT_NOTIONAL_PROFILE: Dict[str, Dict[str, Any]] = {
        "default": {
            "enable": True,            # 新手：开启后依据账户余额自动缩放名义资金上限
            "leverage": DEFAULT_LEVERAGE,  # 新手：假设默认使用 5x 杠杆，可与实际 config 对齐
            "total_ratio": 0.22,       # 新手：最多动用总权益的 22% × 杠杆 作为名义资金
            "free_ratio": 0.32,        # 新手：优先参照可用余额的 32% × 杠杆，余额越小 cap 越小
            "buffer": 0.88,            # 新手：预留 12% 保险，避免刚好顶到权益导致强平风险
            "reserve_ratio": 0.1,      # 新手：额外保留 10% 保证金专门应对手续费/资金费
            "reserve_static": 3.0,     # 新手：至少保留 3 USDT 不下单，避免余额被全部占用
            "fee_rate": 0.0005,        # 新手：按 0.05% taker 手续费预留开仓成本，可按交易所调整
            "funding_rate": 0.0001,    # 新手：按 0.01% 资金费预估（8 小时），可根据实际修改
            "funding_horizon_hours": 8.0,  # 新手：默认按 8 小时资金费窗口计算预留
            "min_cap": 120.0,          # 新手：基础名义下限调至 120，低余额账户也能匹配比例
            "min_cap_ratio": 0.18,     # 新手：也可按总权益 × 18% × 杠杆设置动态下限，谁大取谁
            "max_cap": 16000.0,        # 新手：大账户默认不超过 1600 USDT，可根据偏好提高/降低
            "balance_tiers": [         # 新手：针对不同余额自动调低/调高占比，避免参数冲突
                {"max_total": 80.0, "min_cap": 90.0, "free_ratio": 0.28, "total_ratio": 0.18},
                {"max_total": 150.0, "min_cap": 110.0, "free_ratio": 0.30, "total_ratio": 0.20},
                {"max_total": 600.0, "min_cap": 130.0, "free_ratio": 0.31, "total_ratio": 0.21},
                {"max_total": 2000.0, "min_cap": 150.0, "free_ratio": 0.30, "total_ratio": 0.20, "max_cap": 1500.0},
                {"max_total": 6000.0, "min_cap": 170.0, "free_ratio": 0.28, "total_ratio": 0.19, "max_cap": 1620.0},
                {"max_total": 16000.0, "min_cap": 190.0, "free_ratio": 0.26, "total_ratio": 0.18, "max_cap": 1700.0},
            ],
        },
        # 如果 OKX/Gate 名义资金习惯不同，可在这里或 config.strategy_parameters.account_notional_override 覆写
    }

    # === 可视化/调试 ===
    DEBUG_LOG = False
    DEBUG_GATES_TO_UI = True
    LOG_DECISIONS = True                      # 新手：开启后将入场/离场放行或拦截原因写入 freqtrade WebUI 日志
    LOG_DECISIONS_LEVEL = "info"              # 新手：日志级别（debug/info/warning/error），默认 info 便于直接观察
    ENTRY_SIGNAL_STALE_MINUTES = 0.0          # 新手：候选信号超时心跳，0 表示按 timeframe 自动估算等待时间
    ENTRY_COOLDOWN_MIN_MINUTES = 4.0          # 新手：每笔交易后至少等待 4 分钟（按主时框自动换算根数）再放行下一笔
    ENTRY_BLOCK_HIDE_SIGNALS: bool = True     # 当终审已拦截该蜡烛的候选时，是否在 WebUI 中隐藏对应 enter_* 信号
    ENTRY_SIGNAL_FREEZE_BARS: int = 5         # 历史信号冻结前需要保留的最近 K 数，避免尚未成熟的蜡烛被过早锁定
    ENTRY_SIGNAL_HISTORY_CAPTURE_BARS: int = 720       # 记录候选影子历史时扫描的最大窗口（约 12 小时）
    ENTRY_SIGNAL_HISTORY_MAX_ENTRIES: int = 960        # 候选影子历史最多保留的条目，自动裁剪最旧的记录
    ENTRY_BLOCK_MARK_TOLERANCE_MINUTES: float = 2.5    # 允许“终审拦截记录”匹配图表蜡烛的时间容忍（分钟）
    ENTRY_SIGNAL_QUEUE_LIMIT = 12                      # 新手：记录最近 12 个候选信号，帮助定位“有影子无下单”的根因
    ENTRY_EXECUTION_LATENCY_WARN_SEC = 75.0            # 新手：候选信号放行后若 ≥75 秒仍未执行，将输出“终审延迟”提示
    ENTRY_EXECUTION_LATENCY_ALERT_SEC = 180.0          # 新手：候选信号放行后若 ≥180 秒仍未执行，将输出“严重延迟”提示
    ENTRY_SLIPPAGE_WARN_PCT = 0.0008                   # 新手：成交价偏离信号价 ≥0.08%（8 bps）时记录滑点警告
    ENTRY_SLIPPAGE_ALERT_PCT = 0.0015                  # 新手：成交价偏离信号价 ≥0.15%（15 bps）时标记严重滑点
    WEBUI_STOP_FALLBACK_BACKFILL_BARS = 5              # 新手：仅靠 fallback 快照绘图时，向前填充最近 5 根 K 让线条可见

    # === 持仓信号复核（把“新信号”转换为高优先级的加减仓/离场建议） ===
    POSITION_SIGNAL_REVIEW_ENABLE = True            # 新手：开启后，持仓会优先审阅最新信号决定加仓/减仓/离场
    POSITION_SIGNAL_REVIEW_OPP_CONF = 0.26          # 反向信号置信度 ≥ 0.26（约等于 26%）且同向守护失效时优先考虑离场
    POSITION_SIGNAL_REVIEW_MIN_PROFIT = 0.012       # 反向信号出现且已有 ≥1.2% 浮盈时倾向直接兑现利润
    POSITION_SIGNAL_TRIM_MIN_PROFIT = 0.05          # 反向信号触发 trim 至少需保留的浮盈门槛，默认仅在非负利润时拆仓
    POSITION_SIGNAL_REVIEW_ALIGN_NEED = 0.20        # 反向信号 + 多周期对齐达到 0.20 视作结构破坏，哪怕尚未达到置信阈值也会收紧
    POSITION_SIGNAL_REVIEW_SAME_CONF = 0.369        # 同向信号置信度 ≥ 0.18 时记录“优先加仓”提示，供加仓治理使用
    POSITION_SIGNAL_REVIEW_MAX_AGE = 15             # 同/反向信号复核在 15 分钟内有效，过期自动忽略

    # === 推荐币池预设（未在 config 指定白名单时将 fallback 到这里） ===
    PAIR_POOL_PRESET: Tuple[str, ...] = (
        "BTC/USDT:USDT",
        "ETH/USDT:USDT",
        "SOL/USDT:USDT",
        "BNB/USDT:USDT",
        "DOGE/USDT:USDT",
        "XRP/USDT:USDT",
        "ADA/USDT:USDT",
        "LINK/USDT:USDT",
        "AVAX/USDT:USDT",
        "LTC/USDT:USDT",
        "TRX/USDT:USDT",
        "SUI/USDT:USDT",
    )

    # === 动态热门币种列表（默认启用，结合上方币池自动轮换） ===
    DYNAMIC_PAIRLIST_ENABLE = True                  # 新手：默认开启热榜过滤，直接结合预设币池挑选当日热门
    DYNAMIC_PAIRLIST_FORCE_DISABLE = True           # 教学：若设为 True 将完全停用热榜（例如临时排障或手动轮动）
    DYNAMIC_PAIRLIST_MODE = "focus"                 # focus=只允许热榜币；prefer=热榜优先，其它币会被额外收紧闸门
    DYNAMIC_PAIRLIST_LIMIT = 6                      # 每次取前 6 名热榜币（可按持仓数量或交易所限制调整）
    DYNAMIC_PAIRLIST_REFRESH_MINUTES = 15           # 热榜刷新间隔（分钟）
    DYNAMIC_PAIRLIST_MIN_CHANGE = 1.0               # 24 小时涨幅至少 3% 才视作热榜候选
    DYNAMIC_PAIRLIST_MIN_QUOTE = 800000.0           # 24 小时成交额至少 80 万 USDT，过滤小市值干扰
    DYNAMIC_PAIRLIST_FALLBACK = "whitelist"         # 当热榜为空时的降级策略：whitelist=退回静态白名单，allow=直接放行
    DYNAMIC_PAIRLIST_SOURCE = "gainers"             # 可写 gainers/volume/combined，供日志标记使用
    DYNAMIC_PAIRLIST_RESPECT_WHITELIST = True       # 仅在现有白名单内挑选热榜，避免频繁换币导致缺数据
    DYNAMIC_PAIRLIST_ALLOW_HELD = True              # 已持仓的币即便暂时掉出热榜仍允许继续管理仓位
    DYNAMIC_PAIRLIST_LOG_LEVEL = "info"             # 热榜刷新日志级别，可按需改成 debug 降低噪声

    # === 日志复盘报告（自动汇总入场/离场/止盈/止损细节） ===
    REVIEW_REPORT_ENABLE = True                     # 新手：默认开启每日复盘报告，集中输出关键事件与拒单理由。
    REVIEW_REPORT_DIR = "docs/review_reports"       # 新手：复盘报告存放目录，默认写入项目内，可按需改到共享盘路径。
    REVIEW_REPORT_TZ_OFFSET_HOURS: float = 0.0      # 复盘按哪个时区分日：0=UTC，8=北京时间；影响文件名与本地时间列。
    REVIEW_REPORT_PREFIX = "daily_review_"          # 新手：文件名前缀（会自动追加 YYYY-MM-DD 与 .md）。
    REVIEW_REPORT_LIVE_UPDATE = True                # 新手：True=当天内持续增量写入，False=次日首次触发时统一写入。
    REVIEW_REPORT_WRITE_COOLDOWN_SECONDS = 90.0     # 新手：连续事件写入间隔（秒），避免在高频触发时重复刷写文件。
    REVIEW_REPORT_MAX_TIMELINE = 120                # 新手：时间线最多保留最近 120 条事件，防止文档过长。
    REVIEW_REPORT_SUBLIST_LIMIT = 10                # 新手：附带的子事件（例如弹性止盈的事件堆栈）最多展示 10 条。
    REVIEW_REPORT_BOT_LABEL: Optional[str] = None   # 新手：默认自动读取 config.bot_name；也可手动覆写。
    REVIEW_REPORT_SPLIT_BY_BOT: bool = True         # 新手：设为 True 时，复盘/analytics/review_state 会落到按机器人标签划分的子目录。
    REVIEW_REPORT_EXPORT_SPLIT_BY_BOT: Optional[bool] = None  # 若单独设置，可覆盖复盘 Markdown 的 split 配置。
    REVIEW_STATE_SPLIT_BY_BOT: Optional[bool] = None          # 若单独设置，可覆盖 review_state 子目录是否按机器人划分。
    REVIEW_REPORT_EXPORT_JSON = True                # 新手：若设为 True，会在生成 Markdown 时同步输出结构化 JSON。
    REVIEW_REPORT_EXPORT_CSV = True                 # 新手：若设为 True，会输出含 stoploss/entry 记录的 CSV，便于外部 BI 分析。
    REVIEW_REPORT_EXPORT_DIR = "docs/review_reports/analytics"    # 新手：结构化导出目录，默认放在复盘目录下的 analytics 子目录。
    REVIEW_STATE_EXPORT_DIR = "docs/review_reports/review_state"  # 新手：review_state 体检摘要导出目录，自动在 user_data 下创建 review_state/。
    REVIEW_REPORT_HOST_ROOT: Optional[str] = None   # 新手：若在 Docker 中运行，可额外指定宿主机 user_data 根路径供日志提示。
    REVIEW_REPORT_EXPORT_HOST_ROOT: Optional[str] = None      # 新手：结构化导出宿主机路径映射，缺省沿用 REVIEW_REPORT_HOST_ROOT。
    REVIEW_STATE_HOST_ROOT: Optional[str] = None    # 新手：review_state 快照宿主机路径映射，缺省沿用 REVIEW_REPORT_EXPORT_HOST_ROOT。
    REVIEW_STATE_EXPORT_STANDALONE: bool = True     # 新手：即便未启用 JSON analytics，也会独立输出 review_state 快照，方便体检。
    PARAMETER_BASELINE_DIR = "docs/parameter_baselines"  # 新手：参数基线输出目录，自动生成调参快照供复盘参考。

    # === 数据新鲜度 & 低余额冷却（解决“历史过旧 / 保证金不足”频繁告警） ===
    DATA_STALE_THRESHOLD_MINUTES = 5          # 新手：最新 K 线距离当前超过 20 分钟视为“数据延迟”
    DATA_STALE_RECHECK_MINUTES = 3            # 新手：触发延迟后至少等待 5 分钟再复查，避免无意义重试
    DATA_STALE_LOG_COOLDOWN_MINUTES = 10      # 新手：同一交易对的数据延迟日志至少间隔 30 分钟输出一次
    LOW_BALANCE_SKIP_MINUTES = 6              # 新手：保证金不足最小下单量后冷静 12 分钟，等待余额恢复
    LOW_BALANCE_LOG_COOLDOWN_MINUTES = 10     # 新手：低余额提示每 30 分钟最多记录一次，避免刷屏
    LOW_BALANCE_ALLOW_RESERVE_TAP = False     # 新手：默认允许在极限情况下动用部分预留保证金，避免小额账户被迫停机
    LOW_BALANCE_RESERVE_TAP_FRAC = 0.75       # 新手：最多动用预留保证金的 75%，保留 25% 以支付手续费/资金费

    # === 运行期状态缓存 ===
    _pair_state: Dict[str, Dict[str, Any]] = {}
    _peak: Dict[int, float] = {}
    _peak_time: Dict[int, datetime] = {}
    _portfolio_traces: Dict[int, Dict[str, Any]] = {}
    _portfolio_snapshot_cache: Dict[str, Any] = {}
    _dynamic_pairlist_cache: Dict[str, Any] = {}

    # -------------------- 小工具 --------------------
    def _d(self, msg: str):
        """教学提示：内部调试打印，小白可忽略；开启 DEBUG_LOG 会在日志里看到辅助信息。"""
        if self.DEBUG_LOG:
            logger.info(msg)

    def _utc_now(self, current_time: Optional[datetime] = None) -> datetime:
        """教学提示：统一生成 UTC 时间，兼容 freqtrade 传入的 current_time。"""
        if isinstance(current_time, datetime):
            now = current_time
        else:
            now = datetime.now(timezone.utc)
        if now.tzinfo is None:
            now = now.replace(tzinfo=timezone.utc)
        else:
            now = now.astimezone(timezone.utc)
        return now

    def _to_utc_datetime(self, value: Any) -> Optional[datetime]:
        """教学提示：把 pandas.Timestamp/时间戳/字符串等统一转为带 tz 的 UTC datetime。"""
        if value is None:
            return None
        if isinstance(value, datetime):
            dt = value
        elif isinstance(value, pd.Timestamp):
            dt = value.to_pydatetime()
        elif isinstance(value, (int, float)):
            try:
                dt = datetime.fromtimestamp(float(value), tz=timezone.utc)
            except Exception:
                return None
        else:
            try:
                dt = pd.to_datetime(value).to_pydatetime()
            except Exception:
                return None
        if dt.tzinfo is None:
            return dt.replace(tzinfo=timezone.utc)
        return dt.astimezone(timezone.utc)

    def _safe_float(self, value: Any) -> Optional[float]:
        """教学提示：把任意输入尽量转换为 float，无法转换时返回 None。"""
        try:
            if value is None:
                return None
            res = float(value)
        except (TypeError, ValueError):
            return None
        if not np.isfinite(res):
            return None
        return res

    def _normalize_daily_limit_value(self, value: Any) -> Optional[int]:
        """把外部传入的日内限次值标准化，<=0 或无效时返回 None 代表不设上限。"""
        try:
            if value is None:
                return None
            limit = int(value)
        except (TypeError, ValueError):
            return None
        return limit if limit > 0 else None

    def _daily_entry_limit(self) -> Optional[int]:
        """获取当前策略生效的日内新仓上限，None 表示不限次。"""
        limit_attr = getattr(self, "ENTRY_MAX_PER_DAY", None)
        limit = self._normalize_daily_limit_value(limit_attr)
        if limit is not None:
            return limit
        return None

    def _daily_profit_cap_state(
        self,
        ts: datetime,
        pair: Optional[str] = None,
        realized_abs: Optional[float] = None,
    ) -> Dict[str, Any]:
        """按当日已实现收益追踪“提前下班”状态，兼容旧版（默认关闭）。"""

        tz_offset = getattr(self, "DAILY_PROFIT_CAP_TZ_OFFSET", 8.0)
        try:
            tz_offset = float(tz_offset)
        except (TypeError, ValueError):
            tz_offset = 8.0

        target_tz = timezone(timedelta(hours=tz_offset))
        ts_with_tz = ts if ts.tzinfo else ts.replace(tzinfo=target_tz)
        ts_local = ts_with_tz.astimezone(target_tz)
        day_key = ts_local.date().isoformat()

        enable = bool(getattr(self, "DAILY_PROFIT_CAP_ENABLE", False))
        cap_pct = max(0.0, float(getattr(self, "DAILY_PROFIT_CAP_PCT", 0.0) or 0.0))
        cap_abs_cfg = max(0.0, float(getattr(self, "DAILY_PROFIT_CAP_ABS", 0.0) or 0.0))
        basis_mode = str(getattr(self, "DAILY_PROFIT_CAP_BASIS", "available") or "available").lower()

        state = getattr(self, "_daily_profit_state", None)
        if not isinstance(state, dict):
            state = {}
            self._daily_profit_state = state

        day_state = state.setdefault(day_key, {})
        if day_state.get("_day") != day_key:
            day_state.clear()
            day_state["_day"] = day_key
            day_state["realized_abs"] = 0.0
            day_state["hit"] = False

        progress_abs = float(day_state.get("realized_abs", 0.0) or 0.0)
        if realized_abs is not None and np.isfinite(realized_abs):
            progress_abs += float(realized_abs)
            day_state["realized_abs"] = progress_abs

        profile: Mapping[str, Any] = {}
        usable_free = 0.0
        usable_total = 0.0
        if pair is not None and enable and (cap_pct > 0 or cap_abs_cfg > 0):
            profile, free_balance, total_balance = self._resolve_notional_profile(pair)
            if profile:
                usable_free = self._usable_balance_amount(profile, free_balance)
                usable_total = self._usable_balance_amount(profile, total_balance)

        basis_val = usable_total if basis_mode == "total" else usable_free

        cap_candidates: List[Tuple[str, float]] = []
        if cap_abs_cfg > 0:
            cap_candidates.append(("abs", cap_abs_cfg))
        if cap_pct > 0 and basis_val > 0:
            cap_candidates.append((basis_mode, basis_val * cap_pct))

        cap_value = min((val for _, val in cap_candidates if val > 0), default=0.0)
        hit = enable and cap_value > 0 and progress_abs >= cap_value
        if hit:
            day_state["hit"] = True

        return {
            "active": bool(enable and (cap_pct > 0 or cap_abs_cfg > 0)),
            "hit": bool(day_state.get("hit", False)),
            "progress_abs": progress_abs,
            "cap_abs": cap_value,
            "basis": ("total" if basis_mode == "total" else "available"),
            "basis_value": basis_val,
            "sources": "/".join([label for label, _ in cap_candidates]) if cap_candidates else "",
        }

    def _parameter_snapshot(self) -> Dict[str, Any]:
        """提取当前实例所有大写参数的快照，便于生成调参基线。"""
        snapshot: Dict[str, Any] = {}
        for name in dir(self):
            if name.startswith("_"):
                continue
            if name.upper() != name:
                continue
            try:
                value = getattr(self, name)
            except AttributeError:
                continue
            if callable(value):
                continue
            snapshot[name] = value
        return dict(sorted(snapshot.items(), key=lambda item: item[0]))

    def _format_param_value(self, value: Any) -> str:
        """把参数值转换为 Markdown 友好的字符串。"""
        if isinstance(value, bool):
            return "true" if value else "false"
        if isinstance(value, (int, float)):
            if isinstance(value, bool):  # bool 是 int 的子类，前面已返回
                return "true" if value else "false"
            return json.dumps(value, ensure_ascii=False)
        if isinstance(value, str):
            return value
        if isinstance(value, (list, tuple)):
            try:
                return json.dumps(list(value), ensure_ascii=False)
            except Exception:
                return str(value)
        if isinstance(value, dict):
            try:
                return json.dumps(value, ensure_ascii=False, sort_keys=True)
            except Exception:
                return str(value)
        return str(value)

    def _write_parameter_baseline_report(
        self,
        snapshot: Dict[str, Any],
        target_dir: Optional[str] = None,
    ) -> Optional[Path]:
        """把参数快照写入 Markdown，返回生成的文件路径。"""

        if not snapshot:
            return None

        label = getattr(self, "_review_bot_label", None) or "default"
        label_slug = re.sub(r"[^A-Za-z0-9_-]+", "-", str(label)).strip("-") or "default"
        base_dir_value = target_dir or getattr(self, "PARAMETER_BASELINE_DIR", "docs/parameter_baselines")

        out_dir = self._resolve_output_dir(base_dir_value, "docs/parameter_baselines")

        try:
            out_dir.mkdir(parents=True, exist_ok=True)
        except Exception as exc:
            logger.warning("参数基线目录创建失败：%s", exc)
            return None

        now = self._utc_now()
        date_txt = now.astimezone(timezone.utc).strftime("%Y-%m-%d")
        filename = f"parameter_baseline_{date_txt}_{label_slug}.md"
        out_path = out_dir / filename

        lines: List[str] = []
        lines.append(f"# ReflexivityStrategy 参数基线（{label} · {date_txt}）")
        lines.append("")
        lines.append("> 自动生成：列出了当前实例全部大写参数及其默认值，便于多 Bot 校对与调参复盘。")
        lines.append("")
        lines.append("| # | 参数 | 当前值 | 类型 |")
        lines.append("|---|------|--------|------|")

        for idx, (name, value) in enumerate(snapshot.items(), start=1):
            val_txt = self._format_param_value(value)
            type_txt = type(value).__name__
            lines.append(f"| {idx} | `{name}` | `{val_txt}` | `{type_txt}` |")

        try:
            out_path.write_text("\n".join(lines), encoding="utf-8")
            return out_path
        except Exception as exc:
            logger.warning("参数基线写入失败：%s", exc)
            return None

    def _build_validation_playbook_summary(self) -> Dict[str, Any]:
        """把科学验证作业指导书整理成结构化摘要，写入 review_state。"""

        playbook = getattr(self, "SCIENTIFIC_VALIDATION_PLAYBOOK", tuple()) or tuple()
        steps: List[Dict[str, Any]] = []
        ref_index: Dict[str, Dict[str, str]] = {}

        for idx, raw in enumerate(playbook, start=1):
            if not isinstance(raw, dict):
                continue

            step_id = str(raw.get("id") or f"step_{idx}").strip() or f"step_{idx}"
            title = str(raw.get("title") or step_id).strip() or step_id
            objective = str(raw.get("objective") or "").strip()

            def _normalize_sequence(value: Any) -> List[str]:
                if value is None:
                    return []
                if isinstance(value, str):
                    return [value.strip()]
                items: List[str] = []
                for item in value:
                    try:
                        txt = str(item).strip()
                    except Exception:
                        continue
                    if txt:
                        items.append(txt)
                return items

            actions = _normalize_sequence(raw.get("actions"))
            evidence = _normalize_sequence(raw.get("evidence"))

            references: List[Dict[str, str]] = []
            ref_items = raw.get("references")
            if isinstance(ref_items, dict):
                ref_items = [ref_items]
            if ref_items is None:
                ref_items = []
            for ref in ref_items:
                if isinstance(ref, dict):
                    citation = str(ref.get("citation") or ref.get("cite") or "").strip()
                    topic = str(ref.get("topic") or "").strip()
                    mapping = str(ref.get("mapping") or "").strip()
                else:
                    citation = str(ref).strip()
                    topic = ""
                    mapping = ""
                if not citation:
                    continue
                ref_entry = {"citation": citation}
                if topic:
                    ref_entry["topic"] = topic
                if mapping:
                    ref_entry["mapping"] = mapping
                references.append(ref_entry)
                if citation not in ref_index:
                    ref_index[citation] = dict(ref_entry)

            steps.append(
                {
                    "id": step_id,
                    "title": title,
                    "objective": objective,
                    "actions": actions,
                    "evidence": evidence,
                    "references": references,
                }
            )

        if not steps:
            return {}

        summary: Dict[str, Any] = {
            "version": getattr(self, "SCIENTIFIC_VALIDATION_VERSION", None),
            "steps": steps,
        }

        try:
            summary["generated_at"] = self._utc_now().isoformat()
        except Exception:
            pass

        if ref_index:
            summary["reference_index"] = list(ref_index.values())

        return summary

    def __init__(self, *args, **kwargs) -> None:
        """初始化时自检关键参数，避免与 freqtrade 文档要求或内部逻辑冲突。"""
        super().__init__(*args, **kwargs)
        self._current_tf_minutes = max(1.0, float(self._tf_minutes()))
        self._timeframe_scaled_params: Dict[str, int] = {}
        self._apply_timeframe_param_scaling()
        self._configure_timeframe_layers()
        self._validate_static_params()
        self._exchange_profile = self._build_exchange_profile()
        if self.DEBUG_LOG:
            self._d(f"exchange_profile={self._exchange_profile}")
        self._notional_pair_overrides: Dict[str, Dict[str, Any]] = {}
        self._entry_price_guard_cache: Optional[Dict[str, Any]] = None
        self._notional_profile = self._build_account_notional_profile()
        self._feature_audit_report = self._audit_feature_conflicts()
        self._directional_audit_report = self._audit_directional_parity()
        self._portfolio_traces = {}
        self._portfolio_snapshot_cache = {}
        self._dynamic_pairlist_cache = {}
        self._data_stale_until: Dict[str, datetime] = {}
        self._data_stale_last_log: Dict[str, datetime] = {}
        self._low_balance_until: Dict[str, datetime] = {}
        self._low_balance_last_log: Dict[str, datetime] = {}
        self._entry_guard_status: Dict[str, Dict[str, Any]] = {"data": {}, "balance": {}}
        self._parameter_baseline_snapshot: Dict[str, Any] = {}
        self._informative_missing_until: Dict[Tuple[str, str], float] = {}
        self._review_events: Dict[str, Dict[str, Any]] = {}
        self._review_last_flush: Optional[datetime] = None
        preset_label = getattr(self, "REVIEW_REPORT_BOT_LABEL", None)
        self._review_bot_label: Optional[str] = str(preset_label).strip() if preset_label else None
        self._review_dirs_ready: bool = False
        self._review_state: Dict[str, Any] = {}
        if isinstance(self._feature_audit_report, dict):
            self._review_state["feature_audit"] = dict(self._feature_audit_report)
        if isinstance(self._directional_audit_report, dict):
            self._review_state["directional_audit"] = dict(self._directional_audit_report)
        self._scientific_validation = self._build_validation_playbook_summary()
        if self._scientific_validation:
            self._review_state["scientific_validation"] = dict(self._scientific_validation)
        self._entry_mode_health = self._entry_mode_health_check()
        self._preflight_report = self._preflight_disaster_guard()
        self._expectation_override_audit = self._audit_expectation_override_health()
        if isinstance(self._expectation_override_audit, dict):
            self._review_state["expectation_override_audit"] = dict(self._expectation_override_audit)
        sweep_ok = True
        try:
            self._final_pretrade_bug_sweep(stage="init")
        except Exception as exc:
            sweep_ok = False
            if self.DEBUG_LOG:
                self._d(f"[catastrophic_sweep_failed]init err={exc}")
        if sweep_ok and isinstance(getattr(self, "_feature_registry_report", None), dict):
            registry_snapshot = getattr(self, "_feature_registry_report", {})
            if registry_snapshot:
                self._review_state["feature_registry"] = dict(registry_snapshot)
        else:
            try:
                self._feature_registry_report = self._compile_feature_registry()
            except Exception as exc:
                self._feature_registry_report = {}
                logger.warning("[功能巡检] 初始化失败：%s", exc)
            else:
                registry_snapshot = getattr(self, "_feature_registry_report", {})
                if isinstance(registry_snapshot, dict) and registry_snapshot:
                    self._review_state["feature_registry"] = dict(registry_snapshot)
        self._min_margin_override_log: Dict[str, bool] = {}
        self._directional_entry_history: List[Tuple[datetime, str]] = []

        try:
            self._review_prepare_directories(force=True)
        except Exception as exc:
            if self.DEBUG_LOG:
                self._d(f"[review_prepare_failed] err={exc}")

        try:
            dyn_cfg = ((self.config or {}).get("strategy_parameters", {})).get("dynamic_pairlist", {})
        except Exception:
            dyn_cfg = {}
        if isinstance(dyn_cfg, dict):
            if dyn_cfg.get("enable") is not None:
                self.DYNAMIC_PAIRLIST_ENABLE = bool(dyn_cfg.get("enable"))
            if dyn_cfg.get("disable") is not None:
                self.DYNAMIC_PAIRLIST_FORCE_DISABLE = bool(dyn_cfg.get("disable"))
                if self.DYNAMIC_PAIRLIST_FORCE_DISABLE:
                    self.DYNAMIC_PAIRLIST_ENABLE = False
            elif dyn_cfg.get("force_disable") is not None:
                self.DYNAMIC_PAIRLIST_FORCE_DISABLE = bool(dyn_cfg.get("force_disable"))
                if self.DYNAMIC_PAIRLIST_FORCE_DISABLE:
                    self.DYNAMIC_PAIRLIST_ENABLE = False
            if dyn_cfg.get("mode") is not None:
                self.DYNAMIC_PAIRLIST_MODE = str(dyn_cfg.get("mode"))
            if dyn_cfg.get("limit") is not None:
                try:
                    self.DYNAMIC_PAIRLIST_LIMIT = int(dyn_cfg.get("limit"))
                except (TypeError, ValueError):
                    pass
            if dyn_cfg.get("refresh_minutes") is not None:
                try:
                    self.DYNAMIC_PAIRLIST_REFRESH_MINUTES = int(dyn_cfg.get("refresh_minutes"))
                except (TypeError, ValueError):
                    pass
            if dyn_cfg.get("min_change") is not None:
                try:
                    self.DYNAMIC_PAIRLIST_MIN_CHANGE = float(dyn_cfg.get("min_change"))
                except (TypeError, ValueError):
                    pass
            if dyn_cfg.get("min_quote") is not None:
                try:
                    self.DYNAMIC_PAIRLIST_MIN_QUOTE = float(dyn_cfg.get("min_quote"))
                except (TypeError, ValueError):
                    pass
            if dyn_cfg.get("respect_whitelist") is not None:
                self.DYNAMIC_PAIRLIST_RESPECT_WHITELIST = bool(dyn_cfg.get("respect_whitelist"))
            if dyn_cfg.get("allow_held") is not None:
                self.DYNAMIC_PAIRLIST_ALLOW_HELD = bool(dyn_cfg.get("allow_held"))
            if dyn_cfg.get("fallback") is not None:
                self.DYNAMIC_PAIRLIST_FALLBACK = str(dyn_cfg.get("fallback"))
            if dyn_cfg.get("source") is not None:
                self.DYNAMIC_PAIRLIST_SOURCE = str(dyn_cfg.get("source"))
            if dyn_cfg.get("log_level") is not None:
                self.DYNAMIC_PAIRLIST_LOG_LEVEL = str(dyn_cfg.get("log_level"))

    def _configure_timeframe_layers(self) -> None:
        """教学提示：根据主时框自动匹配微观/宏观信息源列表。"""
        base_minutes = float(getattr(self, "_current_tf_minutes", self._tf_minutes()))
        fallback = list(getattr(self, "MICRO_TIMEFRAME_DEFAULT", []))
        layers = dict(getattr(self, "MICRO_TIMEFRAME_LAYERS", {}) or {})
        chosen_micro = list(fallback)
        tf_str = str(getattr(self, "timeframe", "")).lower()
        best_diff = float("inf")
        for key, values in layers.items():
            key_minutes = self._timeframe_to_minutes(str(key), base_minutes)
            if key_minutes > base_minutes + 1e-6:
                continue
            diff = abs(base_minutes - key_minutes)
            if diff < best_diff - 1e-6:
                chosen_micro = list(values)
                best_diff = diff
            elif math.isclose(diff, best_diff, rel_tol=1e-6, abs_tol=1e-6) and key_minutes <= base_minutes:
                chosen_micro = list(values)
                best_diff = diff

        parsed_micro: List[str] = []
        seen: Set[str] = set()
        for tf in chosen_micro:
            minutes = self._timeframe_to_minutes(tf, base_minutes)
            if minutes >= base_minutes:
                continue
            if tf in seen:
                continue
            parsed_micro.append(tf)
            seen.add(tf)

        if not parsed_micro and base_minutes > self.BASE_TIMEFRAME_MINUTES:
            # 当 fallback 被过滤光时，退回到默认 1m 微观，以保持 tri_shock 仍可用。
            parsed_micro = [tf for tf in fallback if self._timeframe_to_minutes(tf, base_minutes) < base_minutes]

        parsed_micro.sort(key=lambda tf: self._timeframe_to_minutes(tf, base_minutes))

        self._micro_timeframes: List[str] = parsed_micro
        macro = list(dict.fromkeys(getattr(self, "macro_informative_timeframes", ["1h", "4h"])))
        self._macro_timeframes: List[str] = macro
        self.informative_timeframes = list(dict.fromkeys(self._micro_timeframes + macro))
        if self.DEBUG_LOG:
            self._d(f"[多时框配置] timeframe={tf_str or self.timeframe} micro={self._micro_timeframes} macro={macro}")

    def _apply_timeframe_param_scaling(self) -> None:
        """教学提示：当主时框改为 15m/30m/1h 时，将所有基于“5m 根数”的窗口自动换算。"""
        base_minutes = float(getattr(self, "BASE_TIMEFRAME_MINUTES", 5.0) or 5.0)
        tf_minutes = max(1.0, float(getattr(self, "_current_tf_minutes", self._tf_minutes())))
        self._current_tf_minutes = tf_minutes
        if base_minutes <= 0:
            return
        if math.isclose(tf_minutes, base_minutes, rel_tol=1e-9):
            return

        scaled_changes: Dict[str, Tuple[int, int]] = {}
        for name in getattr(self, "TIMEFRAME_SCALED_PARAMS", tuple()):
            base_val = getattr(type(self), name, None)
            if base_val is None:
                continue
            try:
                base_float = float(base_val)
            except (TypeError, ValueError):
                continue
            if base_float <= 0:
                continue
            scaled_bars = max(1, int(math.ceil((base_float * base_minutes) / tf_minutes)))
            base_int = int(round(base_float))
            if scaled_bars == base_int:
                continue
            setattr(self, name, scaled_bars)
            scaled_changes[name] = (base_int, scaled_bars)

        if scaled_changes:
            self._timeframe_scaled_params = {k: v for k, (_, v) in scaled_changes.items()}
            if self.DEBUG_LOG:
                detail = ", ".join(f"{k}:{old}->{new}" for k, (old, new) in scaled_changes.items())
                self._d(f"[时框缩放] timeframe={self.timeframe} {detail}")

    def _log_decision(self, stage: str, pair: str, side: Optional[str], verdict: str,
                      reason: str, extra: Optional[Dict[str, Any]] = None) -> None:
        """教学提示：把终审/离场等关键判定以中文理由写入日志，方便 WebUI 快速定位。"""
        if not bool(getattr(self, "LOG_DECISIONS", True)):
            return
        level = str(getattr(self, "LOG_DECISIONS_LEVEL", "info")).lower()
        log_fn = {
            "debug": logger.debug,
            "warning": logger.warning,
            "error": logger.error,
            "critical": logger.critical,
        }.get(level, logger.info)
        side_txt = side if side else "-"
        msg = f"[{stage}] {pair} {side_txt} {verdict}：{reason}"
        if extra:
            extras: List[str] = []
            for key, value in extra.items():
                if isinstance(value, float):
                    if np.isfinite(value):
                        extras.append(f"{key}={value:.4f}")
                    else:
                        extras.append(f"{key}=nan")
                else:
                    extras.append(f"{key}={value}")
            if extras:
                msg += " | " + ", ".join(extras)
        log_fn(msg)
        try:
            self._review_capture_event(stage, pair, side_txt, verdict, reason, extra)
        except Exception as exc:
            if self.DEBUG_LOG:
                self._d(f"[review_capture_failed] stage={stage} pair={pair} err={exc}")

    def _entry_log_highlights(self, snapshot: Dict[str, Any]) -> Dict[str, Any]:
        """抽取入场日志需要的重点字段，方便复盘报告对齐优先级/护栏。"""
        keep_keys = (
            "entry_tag", "session", "session_bias", "price_position", "rfs",
            "fast_lane", "slow_lane", "channel_narrow", "channel_wide", "channel_decay",
            "htf_drive", "panic_guard", "panic_slope_guard", "panic_tail_block",
            "panic_slope_block", "panic_slope_drop", "panic_slope_rebound", "blowoff_guard",
            "reflex_guard", "vol_any", "align", "priority_long", "priority_short",
            "priority_prefer", "priority_conf", "portfolio_fragile", "portfolio_net",
            "portfolio_losers", "portfolio_loss_pressure", "portfolio_loss_need",
            "dynamic_mode", "dynamic_reason", "dynamic_change", "dynamic_quote_volume",
            "dynamic_penalty",
            "profile_align_long", "profile_align_short",
            "profile_mania_align_need", "profile_mania_align_floor",
            "profile_mania_need_pass", "profile_mania_floor_pass",
            "profile_panic_align_need", "profile_panic_need_pass",
            "profile_tri_need_mult", "profile_dist_relax_mult",
            "profile_extreme_tri_relief", "profile_extreme_dist_relief",
            "profile_entry_cooldown_mult", "mania_lane_active", "panic_lane_active",
            "channel_regime", "channel_last_break", "channel_pullback_taken",
            "channel_pivot_age",
            "entry_quality", "entry_quality_need", "quality_align", "quality_tri",
            "quality_rfs", "quality_priority", "quality_base", "quality_lane_bonus",
            "quality_price_penalty", "quality_decay_penalty",
            "quality_darkside_bonus", "quality_need_relaxed",
            "darkside_active", "darkside_pass", "darkside_mode", "darkside_score",
            "darkside_need", "darkside_guard", "darkside_price_component",
            "darkside_align_component", "darkside_tri_component", "darkside_rfs_component",
            "darkside_reflex_component", "darkside_lane_component", "darkside_tri_relief",
            "darkside_align_relief", "darkside_quality_bonus", "darkside_quality_relief",
            "darkside_vol_required", "darkside_vol_any", "darkside_penalty_pass",
            "darkside_penalty_active",
            "cluster_same", "cluster_opp", "cluster_last_side", "cluster_bias",
            "cluster_bias_side", "entries_today",
            "daily_limit", "entries_left", "tri_need_base", "tri_need",
            "balance_reserve_tap", "balance_available", "balance_usable",
            "balance_min_required", "balance_need_margin", "balance_need_notional",
            "balance_reserve_gap", "balance_reserve_buffer", "balance_reserve_tap_frac",
            "balance_reserve_mode", "balance_reserve_ratio_used", "balance_reserve_static_used",
            "balance_requirement_source", "balance_requirement_leverage",
            "balance_requirement_override", "balance_requirement_baseline",
            "balance_requirement_details",
        )
        info: Dict[str, Any] = {}
        for key in keep_keys:
            if key in snapshot:
                info[key] = snapshot[key]
        return info

    def _update_trade_risk_profile(
        self,
        pair: str,
        trade_id: int,
        *,
        risk_pct: float,
        mode: str,
        current_time: datetime,
        context: Optional[Dict[str, Any]] = None,
        cap: Optional[float] = None,
    ) -> None:
        """教学提示：记录当前止损风险，为 Measured Move 与期望值评估提供基线。"""

        if trade_id <= 0:
            return
        try:
            risk_val = float(risk_pct)
        except (TypeError, ValueError):
            return
        if not np.isfinite(risk_val):
            return

        stoploss_min = max(0.0, float(getattr(self, "STOPLOSS_MIN_PCT", 0.0)))
        fallback_open = float(getattr(self, "STOPLOSS_FALLBACK", 0.20))
        stoploss_max = float(getattr(self, "STOPLOSS_MAX_PCT", fallback_open))
        cap_val = cap if cap is not None and np.isfinite(cap) else max(stoploss_min, max(stoploss_max, fallback_open))

        if cap_val > 0:
            risk_val = float(np.clip(risk_val, stoploss_min, cap_val))
        else:
            risk_val = max(risk_val, stoploss_min)

        st = self._pair_state.setdefault(pair, {})
        profiles_obj = st.setdefault("trade_profiles", {})
        if not isinstance(profiles_obj, dict):
            profiles_obj = {}
            st["trade_profiles"] = profiles_obj

        profile = profiles_obj.get(trade_id)
        if not isinstance(profile, dict):
            profile = {}
            profiles_obj[trade_id] = profile

        risk_live = round(max(risk_val, 0.0), 6)
        profile["risk_live_pct"] = risk_live
        profile["risk_actual_pct"] = risk_live
        profile["risk_live_mode"] = str(mode or "")
        ts = current_time if current_time.tzinfo else current_time.replace(tzinfo=timezone.utc)
        profile["risk_live_ts"] = ts
        if context:
            if isinstance(context, dict):
                profile["risk_live_context"] = dict(context)
            elif isinstance(context, (list, tuple)):
                profile["risk_live_context"] = {str(ix): val for ix, val in enumerate(context)}
            else:
                profile["risk_live_context"] = {"context": str(context)}
        else:
            profile.pop("risk_live_context", None)

    def _record_stoploss_ui_snapshot(self, pair: str, snapshot: Dict[str, Any]) -> None:
        """教学提示：缓存止损地板快照，供 WebUI 绘制风险/R 倍数轨迹。"""

        if not pair or not isinstance(snapshot, dict):
            return

        st = self._pair_state.setdefault(pair, {})
        history_obj = st.setdefault("stoploss_ui_history", [])
        if not isinstance(history_obj, list):
            history_obj = []
            st["stoploss_ui_history"] = history_obj

        snap: Dict[str, Any] = dict(snapshot)
        tf_label = str(snap.get("timeframe") or getattr(self, "timeframe", "") or "").strip()
        snap["timeframe"] = tf_label

        ts_key_raw = snap.get("ts_key")
        ts_key: Optional[pd.Timestamp] = None
        if isinstance(ts_key_raw, pd.Timestamp):
            ts_key = ts_key_raw
        elif ts_key_raw is not None:
            try:
                ts_key = pd.Timestamp(ts_key_raw)
            except Exception:
                ts_key = None
        if ts_key is not None:
            snap["ts_key"] = ts_key

        ts_raw = snap.get("ts")
        ts_val: Optional[pd.Timestamp] = None
        if isinstance(ts_raw, pd.Timestamp):
            ts_val = ts_raw if ts_raw.tzinfo else ts_raw.tz_localize(timezone.utc)
        elif isinstance(ts_raw, datetime):
            ts_local = ts_raw if ts_raw.tzinfo else ts_raw.replace(tzinfo=timezone.utc)
            ts_val = pd.Timestamp(ts_local)
        elif ts_raw is not None:
            try:
                ts_tmp = pd.Timestamp(ts_raw)
            except Exception:
                ts_tmp = None
            if ts_tmp is not None:
                ts_val = ts_tmp if ts_tmp.tzinfo else ts_tmp.tz_localize(timezone.utc)
        if ts_val is None and ts_key is not None:
            ts_val = ts_key if ts_key.tzinfo else ts_key.tz_localize(timezone.utc)
        snap["ts"] = ts_val

        num_fields = (
            "final_floor_pct",
            "fallback_floor_pct",
            "expectation_floor_pct",
            "strict_floor_pct",
            "adaptive_floor_pct",
            "dynamic_floor_pct",
            "portfolio_floor_pct",
            "review_floor_pct",
            "stop_floor_expect_pct",
            "stop_floor_strict_pct",
            "stop_floor_adaptive_pct",
            "stop_floor_dynamic_pct",
            "stop_floor_fallback_pct",
            "stop_floor_final_pct",
            "current_profit_pct",
            "risk_basis_pct",
            "current_r",
            "final_floor_r",
            "expectation_floor_r",
            "strict_floor_r",
            "adaptive_floor_r",
            "dynamic_floor_r",
            "portfolio_floor_r",
            "fallback_floor_r",
            "stop_r_current",
            "stop_r_release",
            "stop_r_final",
            "stop_r_expect",
            "stop_r_strict",
        )
        for key in num_fields:
            if key not in snap:
                continue
            try:
                val = float(snap[key])
            except (TypeError, ValueError):
                val = float("nan")
            if not np.isfinite(val):
                val = float("nan")
            snap[key] = val

        try:
            snap["trade_id"] = int(snap.get("trade_id", 0) or 0)
        except (TypeError, ValueError):
            snap["trade_id"] = 0
        side_txt = str(snap.get("side") or "").lower()
        snap["side"] = "short" if side_txt.startswith("short") else "long"

        # 若新快照与最后一条在同一时间/交易上，直接覆盖，避免同一根 K 重复追加。
        if history_obj:
            last = history_obj[-1]
            if isinstance(last, dict):
                same_trade = last.get("trade_id") == snap.get("trade_id")
                same_tf = str(last.get("timeframe") or "") == tf_label
                last_ts = last.get("ts_key") or last.get("ts")
                snap_ts = snap.get("ts_key") or snap.get("ts")
                if same_trade and same_tf and last_ts is not None and snap_ts is not None and last_ts == snap_ts:
                    history_obj[-1] = snap
                    return

        history_obj.append(snap)
        max_len = int(getattr(self, "WEBUI_STOP_HISTORY_MAX", 720) or 720)
        if max_len > 0 and len(history_obj) > max_len:
            del history_obj[:-max_len]

        latest_obj = st.setdefault("stoploss_ui_latest", {})
        if not isinstance(latest_obj, dict):
            latest_obj = {}
            st["stoploss_ui_latest"] = latest_obj
        latest_obj[tf_label] = dict(snap)

    def _lookup_trade_profile(self, trade_id: int) -> Optional[Dict[str, Any]]:
        """教学提示：按 trade_id 在所有币种的档案里寻找对应的 trade_profile。"""

        if trade_id <= 0:
            return None
        for state in self._pair_state.values():
            if not isinstance(state, dict):
                continue
            profiles = state.get("trade_profiles")
            if not isinstance(profiles, dict):
                continue
            profile = profiles.get(trade_id)
            if isinstance(profile, dict):
                return profile
        return None

    def _latest_stoploss_snapshot(self, pair: str, timeframe: str) -> Optional[Dict[str, Any]]:
        st = self._pair_state.get(pair)
        if not isinstance(st, dict):
            return None
        latest_obj = st.get("stoploss_ui_latest")
        if not isinstance(latest_obj, dict):
            return None
        label = str(timeframe or "")
        snap = latest_obj.get(label)
        if snap is None:
            fallback_label = str(getattr(self, "timeframe", "") or "")
            snap = latest_obj.get(fallback_label)
        return snap if isinstance(snap, dict) else None

    @staticmethod
    def _apply_stoploss_overlay_snapshot(
        df: DataFrame,
        target_idx: Any,
        snapshot: Dict[str, Any],
        overlay_pct_cols: Sequence[str],
        overlay_r_cols: Sequence[str],
    ) -> bool:
        if df is None or len(df.index) == 0:
            return False
        if not isinstance(snapshot, dict):
            return False
        if target_idx not in df.index:
            try:
                target_idx = df.index[-1]
            except Exception:
                return False
        applied = False
        for col in overlay_pct_cols:
            val = snapshot.get(col)
            if val is None:
                continue
            try:
                df.at[target_idx, col] = float(val)
                applied = True
            except Exception:
                continue
        for col in overlay_r_cols:
            val = snapshot.get(col)
            if val is None:
                continue
            try:
                df.at[target_idx, col] = float(val)
                applied = True
            except Exception:
                continue
        return applied

    def _profile_risk_basis_pct(self, profile: Optional[Dict[str, Any]]) -> float:
        """教学提示：从 trade_profile 提取可用的风险基线百分比。"""

        if not isinstance(profile, dict):
            return 0.0

        def _safe(val: Any) -> float:
            try:
                num = float(val)
            except (TypeError, ValueError):
                return 0.0
            return num if np.isfinite(num) and num > 0 else 0.0

        keys = (
            "risk_basis_pct",
            "risk_actual_pct",
            "risk_live_pct",
            "risk_context_floor_pct",
            "risk_entry_initial_pct",
            "initial_risk_pct",
        )
        for key in keys:
            if key in profile:
                candidate = _safe(profile.get(key, 0.0))
                if candidate > 0:
                    return candidate
        return 0.0

    def _update_leg_n_shape_state(
        self,
        trade: Trade,
        trade_profile: Optional[Dict[str, Any]],
        *,
        open_rate: float,
        favorable_price: float,
        current_rate: float,
        atr: float,
        pullback_need: float,
        pullback_ok: bool,
    ) -> None:
        """教学提示：把自入场后的推进/回踩幅度登记下来，检视首腿-次腿是否满足 N 字节奏。"""

        if not isinstance(trade_profile, dict):
            return

        try:
            open_val = float(open_rate)
            fav_val = float(favorable_price)
            cur_val = float(current_rate)
            atr_val = float(atr)
            need_val = float(pullback_need)
        except (TypeError, ValueError):
            return

        if atr_val <= 0 or not all(np.isfinite(v) for v in (open_val, fav_val, cur_val)):
            return

        progress_atr = 0.0
        pullback_atr = 0.0
        if trade.is_short:
            progress_atr = max(0.0, (open_val - fav_val) / atr_val)
            pullback_atr = max(0.0, (cur_val - fav_val) / atr_val)
        else:
            progress_atr = max(0.0, (fav_val - open_val) / atr_val)
            pullback_atr = max(0.0, (fav_val - cur_val) / atr_val)

        leg_index = max(0, int(getattr(trade, "nr_of_successful_entries", 0) or 0) - 1)
        trade_profile["n_shape_leg_index"] = leg_index
        trade_profile["n_shape_progress_atr"] = round(progress_atr, 4)
        trade_profile["n_shape_pullback_atr"] = round(pullback_atr, 4)
        trade_profile["n_shape_need_atr"] = round(max(0.0, need_val), 4)
        trade_profile["n_shape_ready"] = bool(pullback_ok and (progress_atr >= max(need_val, 1e-9)))

        if np.isfinite(fav_val):
            trade_profile["n_shape_extreme_price"] = round(fav_val, 6)
        if np.isfinite(open_val):
            trade_profile["n_shape_open_price"] = round(open_val, 6)

    def _resolve_trade_risk_basis(
        self,
        pair: str,
        trade_profile: Optional[Dict[str, Any]],
        *,
        pair_cfg: Optional[Dict[str, Any]] = None,
        risk_basis_mode: Optional[str] = None,
        trade: Optional[Trade] = None,
        current_rate: Optional[float] = None,
    ) -> Dict[str, Any]:
        """教学提示：统一计算初始/实时风险与期望守护所需的 R 倍数基线。"""

        po = pair_cfg if isinstance(pair_cfg, dict) else self._pair_cfg(pair)
        stoploss_min_pct = max(0.0, float(getattr(self, "STOPLOSS_MIN_PCT", 0.0)))
        fallback_floor = max(0.0, float(getattr(self, "STOPLOSS_FALLBACK", 0.20)))
        stoploss_max_pct = float(getattr(self, "STOPLOSS_MAX_PCT", fallback_floor))
        risk_cap = max(stoploss_min_pct, max(stoploss_max_pct, fallback_floor))

        profile = trade_profile if isinstance(trade_profile, dict) else {}

        account_profile: Dict[str, Any] = {}
        try:
            account_profile, _, _ = self._resolve_notional_profile(pair)
        except Exception:
            account_profile = {}

        def _profile_param(key: str, default: float = 0.0) -> float:
            val = _safe_float(profile.get(key)) if isinstance(profile, dict) else 0.0
            if (val is None or val <= 0) and account_profile:
                try:
                    alt = float(account_profile.get(key, 0.0) or 0.0)
                except (TypeError, ValueError):
                    alt = 0.0
                if np.isfinite(alt) and alt > 0:
                    val = alt
            if val is None or not np.isfinite(val) or val <= 0:
                val = default
            return max(0.0, float(val)) if np.isfinite(val) else 0.0

        def _safe_float(value: Any) -> float:
            try:
                val = float(value)
            except (TypeError, ValueError):
                return 0.0
            if not np.isfinite(val):
                return 0.0
            return val

        entry_target_notional = max(0.0, _safe_float(profile.get("entry_target_notional")))
        entry_cap_notional = max(0.0, _safe_float(profile.get("entry_cap_usdt")))
        entry_notional = max(0.0, _safe_float(profile.get("entry_notional")))
        entry_leverage = _safe_float(profile.get("entry_leverage"))
        entry_margin = max(0.0, _safe_float(profile.get("entry_margin_usdt")))
        entry_margin_source = "profile" if entry_margin > 0 else "unknown"

        leverage = entry_leverage if entry_leverage > 0 else 0.0
        stake_amount = 0.0
        position_amount = 0.0
        open_rate_val = 0.0

        if trade is not None:
            stake_amount = max(0.0, _safe_float(getattr(trade, "stake_amount", 0.0)))
            leverage_trade = _safe_float(getattr(trade, "leverage", 0.0))
            if leverage_trade > 0:
                leverage = leverage_trade
            try:
                position_amount = abs(float(getattr(trade, "amount", 0.0)) or 0.0)
            except (TypeError, ValueError):
                position_amount = 0.0
            open_rate_val = _safe_float(getattr(trade, "open_rate", 0.0))
            if open_rate_val <= 0:
                alt_rate = _safe_float(getattr(trade, "open_order_price", 0.0))
                if alt_rate > 0:
                    open_rate_val = alt_rate

        if entry_notional <= 0 and position_amount > 0 and open_rate_val > 0:
            entry_notional = position_amount * open_rate_val
        if entry_notional <= 0 and stake_amount > 0 and leverage > 0:
            entry_notional = stake_amount * leverage
        if entry_target_notional <= 0 and entry_notional > 0:
            entry_target_notional = entry_notional

        margin_tol = 1e-9
        if stake_amount > 0:
            entry_margin = stake_amount
            entry_margin_source = "trade_stake"
        elif entry_margin > 0:
            entry_margin_source = "profile"
        elif entry_notional > 0 and leverage > 0:
            entry_margin = entry_notional / leverage
            entry_margin_source = "inferred_notional"
        else:
            entry_margin = 0.0
            entry_margin_source = "unknown"

        if entry_margin > 0 and stake_amount > 0 and abs(entry_margin - stake_amount) > margin_tol:
            entry_margin = stake_amount
            entry_margin_source = "trade_stake_override"

        current_rate_val = _safe_float(current_rate)
        if current_rate_val <= 0:
            current_rate_val = open_rate_val

        current_notional = 0.0
        if position_amount > 0 and current_rate_val > 0:
            current_notional = position_amount * current_rate_val
        if current_notional <= 0:
            current_notional = entry_notional

        if leverage <= 0 and entry_notional > 0 and stake_amount > 0:
            try:
                inferred = entry_notional / stake_amount
            except ZeroDivisionError:
                inferred = 0.0
            else:
                if np.isfinite(inferred) and inferred > 0:
                    leverage = inferred
        if leverage <= 0 and current_notional > 0 and stake_amount > 0:
            try:
                inferred = current_notional / stake_amount
            except ZeroDivisionError:
                inferred = 0.0
            else:
                if np.isfinite(inferred) and inferred > 0:
                    leverage = inferred
        if leverage <= 0:
            try:
                leverage = float(getattr(self, "DEFAULT_LEVERAGE", 1.0) or 1.0)
            except Exception:
                leverage = 1.0
        leverage_cap = float(getattr(self, "MAX_LEVERAGE_CAP", 0.0) or 0.0)
        if leverage_cap > 0 and np.isfinite(leverage_cap):
            leverage = min(leverage, leverage_cap)

        if stake_amount > 0:
            current_margin = stake_amount
            current_margin_source = "trade_stake"
        elif leverage > 0 and current_notional > 0:
            current_margin = current_notional / leverage
            current_margin_source = "inferred_notional"
        else:
            current_margin = 0.0
            current_margin_source = "unknown"

        if entry_cap_notional <= 0:
            try:
                entry_cap_notional = max(0.0, float(self._account_notional_cap(pair)))
            except Exception:
                entry_cap_notional = 0.0

        notional_cap_ratio = 0.0
        if entry_cap_notional > 0 and current_notional > 0:
            notional_cap_ratio = current_notional / entry_cap_notional

        profile = trade_profile if isinstance(trade_profile, dict) else {}
        entry_initial_pct = float(profile.get("initial_risk_pct", 0.0) or 0.0)
        forecast_pct = float(profile.get("risk_forecast_pct", 0.0) or 0.0)
        entry_risk_pct = float(entry_initial_pct)
        if forecast_pct > 0:
            entry_risk_pct = forecast_pct
        if entry_risk_pct <= 0:
            entry_atr_profile = float(profile.get("entry_atr_pct", 0.0) or 0.0)
            stoploss_atr_base = float(getattr(self, "STOPLOSS_ATR_BASE", 0.0))
            if entry_atr_profile > 0 and stoploss_atr_base > 0:
                entry_risk_pct = entry_atr_profile * stoploss_atr_base
        if entry_risk_pct <= 0:
            entry_risk_pct = fallback_floor if fallback_floor > 0 else stoploss_min_pct
        context_floor_pct: Optional[float] = None
        context_guard_pct: Optional[float] = None
        context_info = profile.get("stoploss_context") if isinstance(profile, dict) else None
        context_active = False
        ctx_floor_raw: Optional[float] = None
        ctx_guard_raw: Optional[float] = None
        if isinstance(context_info, dict):
            try:
                ctx_floor_raw = float(context_info.get("floor", 0.0) or 0.0)
            except (TypeError, ValueError):
                ctx_floor_raw = 0.0
            try:
                ctx_guard_raw = float(context_info.get("guard_floor", 0.0) or 0.0)
            except (TypeError, ValueError):
                ctx_guard_raw = 0.0
            context_active = bool(context_info.get("active")) or str(context_info.get("mode", "")).startswith("context")

        def _append_cap_candidate(val: Any, *, store: List[float]) -> None:
            try:
                candidate = float(val)
            except (TypeError, ValueError):
                return
            if candidate and candidate > 0 and np.isfinite(candidate):
                store.append(float(candidate))

        cap_candidates: List[float] = [float(risk_cap)] if risk_cap > 0 else []
        _append_cap_candidate(entry_initial_pct, store=cap_candidates)
        if isinstance(profile, dict):
            _append_cap_candidate(profile.get("risk_live_pct"), store=cap_candidates)
            _append_cap_candidate(profile.get("risk_actual_pct"), store=cap_candidates)
            _append_cap_candidate(profile.get("risk_basis_pct"), store=cap_candidates)
            _append_cap_candidate(profile.get("risk_forecast_pct"), store=cap_candidates)
            _append_cap_candidate(profile.get("risk_context_floor_pct"), store=cap_candidates)
            _append_cap_candidate(profile.get("risk_context_guard_pct"), store=cap_candidates)
        if ctx_floor_raw is not None and ctx_floor_raw > 0:
            _append_cap_candidate(ctx_floor_raw, store=cap_candidates)
        if ctx_guard_raw is not None and ctx_guard_raw > 0:
            _append_cap_candidate(ctx_guard_raw, store=cap_candidates)
        live_ctx = profile.get("risk_live_context") if isinstance(profile, dict) else None
        if isinstance(live_ctx, dict):
            for key in ("fallback_new", "fallback_cap", "floor", "guard_floor", "risk", "risk_pct", "cap"):
                if key in live_ctx:
                    _append_cap_candidate(live_ctx.get(key), store=cap_candidates)
        if cap_candidates:
            risk_cap = max(cap_candidates)

        if isinstance(ctx_floor_raw, (int, float)) and ctx_floor_raw > 0:
            ctx_floor_val = float(np.clip(ctx_floor_raw, stoploss_min_pct, risk_cap)) if risk_cap > 0 else max(ctx_floor_raw, stoploss_min_pct)
            context_floor_pct = ctx_floor_val
            if context_active and ctx_floor_val < entry_risk_pct:
                entry_risk_pct = ctx_floor_val
        if isinstance(ctx_guard_raw, (int, float)) and ctx_guard_raw > 0:
            ctx_guard_val = float(np.clip(ctx_guard_raw, stoploss_min_pct, risk_cap)) if risk_cap > 0 else max(ctx_guard_raw, stoploss_min_pct)
            context_guard_pct = ctx_guard_val
        if risk_cap > 0:
            entry_risk_pct = min(entry_risk_pct, risk_cap)
        entry_risk_pct = max(entry_risk_pct, stoploss_min_pct)

        actual_risk_raw = profile.get("risk_live_pct")
        if actual_risk_raw in (None, 0, 0.0):
            actual_risk_raw = profile.get("risk_actual_pct", 0.0)
        actual_risk_pct = float(actual_risk_raw or 0.0)
        if actual_risk_pct > 0 and risk_cap > 0:
            actual_risk_pct = min(actual_risk_pct, risk_cap)
        if actual_risk_pct > 0:
            actual_risk_pct = max(actual_risk_pct, stoploss_min_pct)
        elif context_floor_pct is not None and context_floor_pct > 0:
            actual_risk_pct = max(float(context_floor_pct), stoploss_min_pct)
        else:
            actual_risk_pct = 0.0

        if risk_basis_mode is None:
            risk_basis_mode = str(po.get("measured_move_risk_basis", getattr(self, "MEASURED_MOVE_RISK_BASIS", "hybrid")))
        risk_basis_mode = str(risk_basis_mode or "initial").strip().lower()
        candidates = [v for v in (entry_risk_pct, actual_risk_pct) if v and v > 0]
        risk_basis_pct = entry_risk_pct
        if risk_basis_mode in ("actual", "live", "current"):
            if actual_risk_pct > 0:
                risk_basis_pct = actual_risk_pct
        elif risk_basis_mode in ("max", "hybrid", "larger"):
            if candidates:
                risk_basis_pct = max(candidates)
        elif risk_basis_mode in ("min", "tight", "smaller"):
            if candidates:
                risk_basis_pct = min(candidates)
        elif risk_basis_mode in ("avg", "mean", "average"):
            if len(candidates) > 1:
                risk_basis_pct = sum(candidates) / len(candidates)
            elif actual_risk_pct > 0:
                risk_basis_pct = actual_risk_pct
        if risk_basis_pct <= 0:
            risk_basis_pct = entry_risk_pct
        if risk_cap > 0:
            risk_basis_pct = min(risk_basis_pct, risk_cap)
        risk_basis_pct = max(risk_basis_pct, stoploss_min_pct)

        slip_guard = self._slippage_guard_snapshot(pair)
        if slip_guard.get("active"):
            slip_scale = float(slip_guard.get("risk_scale", 1.0) or 1.0)
            if slip_scale > 0 and np.isfinite(slip_scale):
                risk_basis_pct = max(stoploss_min_pct, risk_basis_pct * slip_scale)

        notional_basis = current_notional if current_notional > 0 else 0.0
        if notional_basis <= 0 and entry_target_notional > 0:
            notional_basis = entry_target_notional
        if notional_basis <= 0 and entry_notional > 0:
            notional_basis = entry_notional
        risk_unit_value = notional_basis * risk_basis_pct if risk_basis_pct > 0 else 0.0

        fee_rate = _profile_param("fee_rate", 0.0)
        funding_rate = _profile_param("funding_rate", 0.0)
        funding_hours = _profile_param("funding_horizon_hours", 8.0)
        if funding_hours <= 0:
            funding_hours = 8.0
        funding_scale = max(1.0, funding_hours / 8.0 if funding_hours > 0 else 0.0)

        fee_buffer = 0.0
        if notional_basis > 0 and fee_rate > 0:
            fee_buffer = notional_basis * fee_rate * 2.0
        funding_buffer = 0.0
        if notional_basis > 0 and funding_rate > 0:
            funding_buffer = notional_basis * funding_rate * funding_scale
        total_cost_buffer = fee_buffer + funding_buffer
        cost_multiplier = 1.0
        if fee_rate > 0 or funding_rate > 0:
            cost_multiplier = 1.0 + 2.0 * fee_rate + funding_rate * funding_scale
        if slip_guard.get("active"):
            slip_cost_boost = float(slip_guard.get("cost_boost", 1.0) or 1.0)
            if slip_cost_boost > 0 and np.isfinite(slip_cost_boost):
                cost_multiplier *= slip_cost_boost
        if cost_multiplier > 1.0 and total_cost_buffer > 0:
            total_cost_buffer *= cost_multiplier
        risk_unit_plus_cost = risk_unit_value + total_cost_buffer if risk_unit_value > 0 else total_cost_buffer

        metrics = {
            "entry_risk_pct": float(entry_risk_pct),
            "entry_risk_initial_pct": float(entry_initial_pct),
            "risk_forecast_pct": float(forecast_pct),
            "live_risk_pct": float(actual_risk_pct),
            "actual_risk_pct": float(actual_risk_pct),
            "risk_basis_pct": float(risk_basis_pct),
            "risk_basis_mode": risk_basis_mode,
            "risk_cap_pct": float(risk_cap),
            "stoploss_min_pct": float(stoploss_min_pct),
            "entry_notional_usdt": float(entry_notional),
            "current_notional_usdt": float(current_notional),
            "target_notional_usdt": float(entry_target_notional),
            "notional_cap_usdt": float(entry_cap_notional),
            "notional_cap_ratio": float(notional_cap_ratio),
            "stake_margin_usdt": float(entry_margin),
            "margin_current_usdt": float(current_margin),
            "effective_leverage": float(leverage) if leverage > 0 else 0.0,
            "notional_basis_usdt": float(notional_basis),
            "risk_unit_value_usdt": float(risk_unit_value),
            "fee_rate": float(fee_rate),
            "funding_rate": float(funding_rate),
            "funding_hours": float(funding_hours),
            "funding_scale": float(funding_scale),
            "fee_buffer_usdt": float(fee_buffer),
            "funding_buffer_usdt": float(funding_buffer),
            "total_cost_buffer_usdt": float(total_cost_buffer),
            "risk_unit_with_cost_usdt": float(risk_unit_plus_cost),
            "cost_multiplier": float(cost_multiplier),
        }
        if slip_guard.get("active"):
            metrics["slippage_guard"] = slip_guard
        if isinstance(trade_profile, dict) and trade_profile.get("fill_slippage_ratio"):
            metrics["fill_slippage_ratio"] = float(self._safe_float(trade_profile.get("fill_slippage_ratio")) or 0.0)
        metrics["entry_margin_source"] = entry_margin_source
        metrics["current_margin_source"] = current_margin_source

        margin_cross = (current_notional / leverage) if (leverage > 0 and current_notional > 0) else 0.0
        if margin_cross > 0:
            metrics["margin_cross_check_usdt"] = float(margin_cross)
            metrics["margin_cross_diff_usdt"] = abs(float(current_margin) - float(margin_cross))

        if context_floor_pct is not None:
            metrics["context_floor_pct"] = float(context_floor_pct)
        if context_guard_pct is not None:
            metrics["context_guard_pct"] = float(context_guard_pct)
        metrics["risk_basis_mode_effective"] = risk_basis_mode
        if isinstance(trade_profile, dict):
            trade_profile.setdefault("risk_basis_mode", risk_basis_mode)
            trade_profile["risk_basis_pct"] = float(risk_basis_pct)
            trade_profile["risk_entry_initial_pct"] = float(entry_initial_pct)
            trade_profile["risk_cap_pct"] = float(risk_cap)
            if context_floor_pct is not None:
                trade_profile["risk_context_floor_pct"] = float(context_floor_pct)
            if context_guard_pct is not None:
                trade_profile["risk_context_guard_pct"] = float(context_guard_pct)
            if leverage > 0:
                trade_profile["entry_leverage"] = float(leverage)
            if entry_margin > 0:
                trade_profile["entry_margin_usdt"] = float(entry_margin)
                trade_profile["entry_margin_source"] = entry_margin_source
            if current_margin > 0:
                trade_profile["current_margin_usdt"] = float(current_margin)
                trade_profile["current_margin_source"] = current_margin_source
            if entry_notional > 0:
                trade_profile["entry_notional"] = float(entry_notional)
            if current_notional > 0:
                trade_profile["current_notional_usdt"] = float(current_notional)
            if entry_target_notional > 0:
                trade_profile.setdefault("entry_target_notional", float(entry_target_notional))
            if entry_cap_notional > 0:
                trade_profile["notional_cap_usdt"] = float(entry_cap_notional)
            if notional_cap_ratio > 0:
                trade_profile["notional_cap_ratio"] = float(notional_cap_ratio)
            if notional_basis > 0:
                trade_profile["notional_basis_usdt"] = float(notional_basis)
            if risk_unit_value > 0:
                trade_profile["risk_unit_value_usdt"] = float(risk_unit_value)
            if fee_rate > 0:
                trade_profile["fee_rate"] = float(fee_rate)
            if funding_rate > 0:
                trade_profile["funding_rate"] = float(funding_rate)
            if funding_hours > 0:
                trade_profile["funding_horizon_hours"] = float(funding_hours)
            if funding_scale > 0:
                trade_profile["funding_scale"] = float(funding_scale)
            if fee_buffer > 0:
                trade_profile["fee_buffer_usdt"] = float(fee_buffer)
            if funding_buffer > 0:
                trade_profile["funding_buffer_usdt"] = float(funding_buffer)
            if total_cost_buffer > 0:
                trade_profile["total_cost_buffer_usdt"] = float(total_cost_buffer)
            if risk_unit_plus_cost > 0:
                trade_profile["risk_unit_with_cost_usdt"] = float(risk_unit_plus_cost)
        return metrics

    def _crowd_flow_adjustment(
        self,
        *,
        pair: str,
        trade: Optional[Trade],
        trade_profile: Optional[Dict[str, Any]],
        pair_cfg: Optional[Dict[str, Any]] = None,
        risk_info: Optional[Dict[str, Any]] = None,
        measured_state: Optional[Dict[str, Any]] = None,
        session_ctx: Optional[Dict[str, Any]] = None,
        current_profit: Optional[float] = None,
    ) -> Dict[str, Any]:
        """教学提示：根据近期信号扎堆（同向/对向）调节目标 R 与锁盈守卫。"""

        po = pair_cfg if isinstance(pair_cfg, dict) else self._pair_cfg(pair)
        enable = bool(po.get("crowd_flow_enable", getattr(self, "CROWD_FLOW_ENABLE", False)))
        if not enable:
            return {}

        side = "short" if (trade and getattr(trade, "is_short", False)) else "long"
        profile = trade_profile if isinstance(trade_profile, dict) else {}

        def _int_val(value: Any) -> int:
            try:
                return int(value or 0)
            except (TypeError, ValueError):
                return 0

        def _float_val(value: Any) -> float:
            try:
                val = float(value)
            except (TypeError, ValueError):
                return 0.0
            return float(val) if np.isfinite(val) else 0.0

        same_count = _int_val(profile.get("cluster_same"))
        opp_count = _int_val(profile.get("cluster_opp"))
        bias_score = _float_val(profile.get("cluster_bias"))
        bias_side = str(profile.get("cluster_bias_side", "") or "").lower()

        if same_count <= 0 and opp_count <= 0:
            st = self._pair_state.get(pair, {})
            cluster_hist = st.get("entry_cluster") if isinstance(st, dict) else None
            if isinstance(cluster_hist, list) and cluster_hist:
                now = datetime.now(timezone.utc)
                window = timedelta(minutes=self._cluster_window_minutes())
                decay = float(getattr(self, "SIGNAL_CLUSTER_BIAS_DECAY", 0.92))
                bias_align_w = float(getattr(self, "SIGNAL_CLUSTER_BIAS_WEIGHT_ALIGN", 0.52))
                bias_tri_w = float(getattr(self, "SIGNAL_CLUSTER_BIAS_WEIGHT_TRI", 0.34))
                bias_priority_w = float(getattr(self, "SIGNAL_CLUSTER_BIAS_WEIGHT_PRIORITY", 0.28))
                bias_fastlane_w = float(getattr(self, "SIGNAL_CLUSTER_BIAS_WEIGHT_FASTLANE", 0.14))
                bias_slowlane_w = float(getattr(self, "SIGNAL_CLUSTER_BIAS_WEIGHT_SLOWLANE", 0.09))
                tf_minutes = max(1.0, float(self._tf_minutes()))
                bias_acc = 0.0
                same_calc = 0
                opp_calc = 0
                for rec in cluster_hist:
                    when = rec.get("time")
                    if isinstance(when, str):
                        try:
                            when = datetime.fromisoformat(when)
                        except ValueError:
                            continue
                    if not isinstance(when, datetime):
                        continue
                    when = when if when.tzinfo else when.replace(tzinfo=timezone.utc)
                    if now - when > window:
                        continue
                    rec_side = str(rec.get("side", "") or "").lower()
                    if rec_side not in ("long", "short"):
                        continue
                    if rec_side == side:
                        same_calc += 1
                    else:
                        opp_calc += 1
                    age_minutes = max(0.0, (now - when).total_seconds() / 60.0)
                    age_bars = age_minutes / tf_minutes
                    decay_mult = 1.0
                    if 0.0 < decay < 1.0:
                        decay_mult = decay ** age_bars
                    align_comp = abs(_float_val(rec.get("align"))) * bias_align_w
                    tri_comp = abs(_float_val(rec.get("tri_bias"))) * bias_tri_w
                    priority_comp = abs(_float_val(rec.get("priority_conf"))) * bias_priority_w
                    lane_bonus = 0.0
                    if _int_val(rec.get("fast_lane")):
                        lane_bonus += bias_fastlane_w
                    if _int_val(rec.get("slow_lane")):
                        lane_bonus += bias_slowlane_w
                    weight = (align_comp + tri_comp + priority_comp + lane_bonus) * decay_mult
                    if weight <= 0:
                        continue
                    direction = 1.0 if rec_side == "long" else -1.0
                    bias_acc += weight * direction
                if same_count <= 0:
                    same_count = same_calc
                if opp_count <= 0:
                    opp_count = opp_calc
                if abs(bias_score) <= 1e-9:
                    bias_score = bias_acc
                    if abs(bias_score) >= 1e-6:
                        bias_side = "long" if bias_score > 0 else "short"

        risk = risk_info or self._resolve_trade_risk_basis(
            pair,
            trade_profile,
            pair_cfg=po,
            trade=trade,
        )
        basis_pct = _float_val(risk.get("risk_basis_pct")) if isinstance(risk, dict) else 0.0
        profit_r: Optional[float] = None
        if basis_pct > 0 and current_profit is not None:
            profit_r = current_profit / basis_pct
        min_profit_r = _float_val(po.get("crowd_flow_min_profit_r", getattr(self, "CROWD_FLOW_MIN_PROFIT_R", 0.0)))

        adjustments: Dict[str, Any] = {
            "same_count": int(same_count),
            "opp_count": int(opp_count),
            "bias": float(round(bias_score, 4)),
            "bias_side": bias_side,
            "min_profit_r": float(min_profit_r),
        }

        if profit_r is not None and np.isfinite(profit_r):
            adjustments["current_r"] = float(profit_r)
        else:
            profit_r = None

        if profit_r is not None and profit_r < max(min_profit_r, 0.0):
            adjustments["active"] = 0
            if isinstance(trade_profile, dict):
                trade_profile.setdefault("crowd_flow", {}).update(adjustments)
            return adjustments

        same_soft = max(0, _int_val(po.get("crowd_flow_same_soft", getattr(self, "CROWD_FLOW_SAME_SOFT", 0))))
        same_hard = max(same_soft, _int_val(po.get("crowd_flow_same_hard", getattr(self, "CROWD_FLOW_SAME_HARD", same_soft + 1))))
        opp_soft = max(0, _int_val(po.get("crowd_flow_opp_soft", getattr(self, "CROWD_FLOW_OPP_SOFT", 0))))
        opp_hard = max(opp_soft, _int_val(po.get("crowd_flow_opp_hard", getattr(self, "CROWD_FLOW_OPP_HARD", opp_soft + 1))))

        same_factor = 0.0
        if same_count >= same_soft and same_soft > 0:
            denom = max(1, same_hard - same_soft + 1)
            same_factor = min(1.0, (same_count - same_soft + 1) / denom)

        opp_factor = 0.0
        if opp_count >= opp_soft and opp_soft > 0:
            denom = max(1, opp_hard - opp_soft + 1)
            opp_factor = min(1.0, (opp_count - opp_soft + 1) / denom)

        bias_trigger = _float_val(po.get("crowd_flow_bias_trigger", getattr(self, "CROWD_FLOW_BIAS_TRIGGER", 0.0)))
        bias_cap = _float_val(po.get("crowd_flow_bias_cap", getattr(self, "CROWD_FLOW_BIAS_CAP", max(bias_trigger, 1.0))))
        bias_abs = abs(bias_score)
        bias_factor = 0.0
        if bias_cap > bias_trigger and bias_abs >= bias_trigger > 0:
            bias_factor = min(1.0, (bias_abs - bias_trigger) / max(1e-9, bias_cap - bias_trigger))

        same_penalty = _float_val(po.get("crowd_flow_same_penalty", getattr(self, "CROWD_FLOW_SAME_PENALTY", 0.0))) * same_factor
        release_penalty = _float_val(po.get("crowd_flow_release_penalty", getattr(self, "CROWD_FLOW_RELEASE_PENALTY", same_penalty))) * same_factor
        opp_bonus = _float_val(po.get("crowd_flow_opp_bonus", getattr(self, "CROWD_FLOW_OPP_BONUS", 0.0))) * opp_factor
        bias_bonus_base = _float_val(po.get("crowd_flow_bias_bonus", getattr(self, "CROWD_FLOW_BIAS_BONUS", 0.0))) * bias_factor

        if bias_bonus_base > 0:
            if bias_side == side:
                same_penalty += bias_bonus_base
                release_penalty += bias_bonus_base
            elif bias_side in ("long", "short") and bias_side:
                opp_bonus += bias_bonus_base

        min_target_r = _float_val(po.get("crowd_flow_min_target_r", getattr(self, "CROWD_FLOW_MIN_TARGET_R", 0.0)))
        floor_base_r = _float_val(po.get("crowd_flow_floor_base_r", getattr(self, "CROWD_FLOW_FLOOR_BASE_R", 0.0)))
        drawdown_clamp_r = _float_val(po.get("crowd_flow_drawdown_clamp_r", getattr(self, "CROWD_FLOW_DRAWDOWN_CLAMP_R", 0.0)))

        floor_min_r = 0.0
        if floor_base_r > 0 and same_factor > 0:
            floor_min_r = floor_base_r * same_factor
        if floor_base_r > 0 and bias_side == side and bias_factor > 0:
            floor_min_r = max(floor_min_r, floor_base_r * min(1.0, max(same_factor, bias_factor)))

        drawdown_cap_r = 0.0
        if drawdown_clamp_r > 0 and (same_factor > 0 or (bias_side == side and bias_factor > 0)):
            drawdown_cap_r = drawdown_clamp_r * max(same_factor, bias_factor if bias_side == side else 0.0)

        total_penalty = max(0.0, same_penalty)
        total_release_penalty = max(0.0, release_penalty)
        total_bonus = max(0.0, opp_bonus)

        adjustments.update(
            {
                "active": 1,
                "same_factor": float(round(same_factor, 4)),
                "opp_factor": float(round(opp_factor, 4)),
                "bias_factor": float(round(bias_factor, 4)),
                "target_penalty_r": float(round(total_penalty, 6)),
                "release_penalty_r": float(round(total_release_penalty, 6)),
                "opponent_bonus_r": float(round(total_bonus, 6)),
                "min_target_r": float(round(min_target_r, 6)) if min_target_r > 0 else float(min_target_r),
                "floor_min_r": float(round(floor_min_r, 6)) if floor_min_r > 0 else float(floor_min_r),
                "drawdown_cap_r": float(round(drawdown_cap_r, 6)) if drawdown_cap_r > 0 else float(drawdown_cap_r),
            }
        )

        if isinstance(measured_state, dict) and "context" in measured_state:
            adjustments.setdefault("context", measured_state.get("context"))
        if isinstance(session_ctx, dict) and session_ctx:
            try:
                adjustments.setdefault("session_ceiling_r", float(session_ctx.get("profit_ceiling_r", 0.0) or 0.0))
            except (TypeError, ValueError):
                pass

        if isinstance(trade_profile, dict):
            trade_profile.setdefault("crowd_flow", {}).update(adjustments)

        return adjustments

    def _measured_move_context_target(
        self,
        *,
        pair: str,
        trade: Trade,
        fast_lane: bool,
        slow_lane: bool,
        channel_narrow: bool,
        channel_wide: bool,
        channel_decay: bool,
        htf_drive_lane: bool,
        align_score: float,
        is_short: bool,
        panic_lane: bool,
        mania_lane: bool,
        risk_info: Optional[Dict[str, Any]] = None,
        trade_profile: Optional[Dict[str, Any]] = None,
        session_ctx: Optional[Dict[str, Any]] = None,
        current_profit: Optional[float] = None,
    ) -> Dict[str, Any]:
        """教学提示：根据车道/通道/对齐度，推导量度目标所需的情境化 R 倍数。"""

        po = self._pair_cfg(pair)
        base_r_cfg = float(po.get("measured_move_r_mult", getattr(self, "MEASURED_MOVE_R_MULT", 0.0)) or 0.0)
        if base_r_cfg <= 0:
            base_r_cfg = float(getattr(self, "MEASURED_MOVE_R_MULT", 0.0) or 0.0)
        if base_r_cfg <= 0:
            base_r_cfg = float(getattr(self, "MEASURED_MOVE_TREND_R", 2.0) or 2.0)

        narrow_r = float(po.get("measured_move_narrow_r", getattr(self, "MEASURED_MOVE_NARROW_R", 0.5)) or 0.0)
        if narrow_r <= 0:
            narrow_r = float(getattr(self, "MEASURED_MOVE_NARROW_R", 0.5) or 0.5)
        balance_r = float(po.get("measured_move_balance_r", getattr(self, "MEASURED_MOVE_BALANCE_R", 1.0)) or 0.0)
        if balance_r <= 0:
            balance_r = float(getattr(self, "MEASURED_MOVE_BALANCE_R", 1.0) or 1.0)
        trend_r = float(po.get("measured_move_trend_r", getattr(self, "MEASURED_MOVE_TREND_R", base_r_cfg)) or 0.0)
        if trend_r <= 0:
            trend_r = max(base_r_cfg, float(getattr(self, "MEASURED_MOVE_TREND_R", 2.0) or 2.0))
        decay_r = float(po.get("measured_move_decay_r", getattr(self, "MEASURED_MOVE_DECAY_R", balance_r)) or 0.0)
        if decay_r <= 0:
            decay_r = max(min(balance_r, base_r_cfg), narrow_r)

        align_abs = abs(float(align_score))
        trend_align_need = float(getattr(self, "MEASURED_MOVE_TREND_ALIGN", 0.32) or 0.32)
        slow_align_need = float(getattr(self, "MEASURED_MOVE_SLOW_ALIGN", 0.22) or 0.22)

        super_enable = bool(po.get("measured_move_super_enable", getattr(self, "MEASURED_MOVE_SUPER_ENABLE", False)))
        super_r = float(po.get("measured_move_super_r", getattr(self, "MEASURED_MOVE_SUPER_R", 0.0)) or 0.0)
        super_align = float(po.get("measured_move_super_align", getattr(self, "MEASURED_MOVE_SUPER_ALIGN", 0.0)) or 0.0)
        if super_align <= 0:
            super_align = 0.46
        super_align_decay = float(
            po.get("measured_move_super_align_decay", getattr(self, "MEASURED_MOVE_SUPER_ALIGN_DECAY", super_align)) or super_align
        )
        super_trigger_r = float(
            po.get("measured_move_super_trigger_r", getattr(self, "MEASURED_MOVE_SUPER_TRIGGER_R", 0.0)) or 0.0
        )
        super_block_extreme = bool(
            po.get("measured_move_super_block_extreme", getattr(self, "MEASURED_MOVE_SUPER_BLOCK_EXTREME", True))
        )

        trend_flags: List[str] = []
        if fast_lane:
            trend_flags.append("fast_lane")
        if slow_lane and align_abs >= trend_align_need:
            trend_flags.append("slow_lane_align")
        if htf_drive_lane and align_abs >= slow_align_need:
            trend_flags.append("htf_drive")
        if channel_narrow and align_abs >= trend_align_need:
            trend_flags.append("narrow_align")

        trend_lane = bool(trend_flags)
        range_lane = bool(channel_wide)
        decay_lane = bool(channel_decay)
        narrow_lane = bool(channel_narrow)

        default_r = balance_r if balance_r > 0 else base_r_cfg
        if default_r <= 0:
            default_r = trend_r
        context = "balance"
        target_r = float(default_r)
        reasons: List[str] = []

        if range_lane:
            context = "range"
            target_r = max(balance_r, 0.0)
            reasons.append("wide_range")

        if decay_lane and not trend_lane:
            context = "decay"
            target_r = max(narrow_r, min(decay_r, max(balance_r, 0.0)))
            reasons.append("wide_decay")

        if narrow_lane and not trend_lane and not decay_lane:
            context = "narrow"
            target_r = max(narrow_r, 0.0)
            reasons.append("narrow_channel")

        if trend_lane:
            context = "trend"
            target_r = max(trend_r, base_r_cfg, default_r)
            reasons.extend(trend_flags)

        if target_r <= 0:
            target_r = max(default_r, narrow_r, trend_r)

        session_ceiling_r = 0.0
        session_ceiling_pad = float(getattr(self, "SESSION_PROFIT_CEILING_PAD", 0.0) or 0.0)
        session_realized_r = 0.0
        session_peak_r = 0.0
        session_reason = ""
        session_count = 0
        if isinstance(session_ctx, dict):
            try:
                session_ceiling_r = float(session_ctx.get("profit_ceiling_r", 0.0) or 0.0)
            except (TypeError, ValueError):
                session_ceiling_r = 0.0
            try:
                pad_val = float(session_ctx.get("profit_ceiling_pad", session_ceiling_pad) or session_ceiling_pad)
            except (TypeError, ValueError):
                pad_val = session_ceiling_pad
            session_ceiling_pad = pad_val
            try:
                session_realized_r = float(session_ctx.get("session_realized_r", 0.0) or 0.0)
            except (TypeError, ValueError):
                session_realized_r = 0.0
            try:
                session_peak_r = float(session_ctx.get("session_peak_r", 0.0) or 0.0)
            except (TypeError, ValueError):
                session_peak_r = 0.0
            try:
                session_count = int(session_ctx.get("session_realized_count", 0) or 0)
            except (TypeError, ValueError):
                session_count = 0
            session_reason = str(session_ctx.get("session_ceiling_reason", ""))

        if session_ceiling_r > 0:
            ceiling_allow = session_ceiling_r + max(session_ceiling_pad, 0.0)
            if ceiling_allow > 0 and target_r > ceiling_allow:
                target_r = max(session_ceiling_r, min(target_r, ceiling_allow))
                reasons.append("session_ceiling")
            target_r = max(target_r, session_ceiling_r)

        crowd_same_factor = 0.0
        crowd_bias_factor = 0.0
        crowd_bias_side = ""
        crowd_ctx = self._crowd_flow_adjustment(
            pair=pair,
            trade=trade,
            trade_profile=trade_profile,
            pair_cfg=po,
            risk_info=risk_info,
            measured_state=None,
            session_ctx={
                "profit_ceiling_r": session_ceiling_r,
                "profit_ceiling_pad": session_ceiling_pad,
            },
            current_profit=current_profit,
        )
        if crowd_ctx:
            penalty_r = float(crowd_ctx.get("target_penalty_r", 0.0) or 0.0)
            bonus_r = float(crowd_ctx.get("opponent_bonus_r", 0.0) or 0.0)
            min_target_r = float(crowd_ctx.get("min_target_r", 0.0) or 0.0)
            if penalty_r > 0 and target_r > 0:
                target_r = max(min_target_r, target_r - penalty_r)
                reasons.append("crowd_penalty")
            else:
                target_r = max(target_r, min_target_r)
            if bonus_r > 0 and target_r > 0:
                target_r = max(target_r, min(target_r + bonus_r, target_r + bonus_r))
                reasons.append("crowd_bonus")

        risk_basis_pct = 0.0
        if isinstance(risk_info, dict):
            for key in ("risk_basis_pct", "entry_risk_pct", "live_risk_pct", "actual_risk_pct"):
                try:
                    candidate = float(risk_info.get(key, 0.0) or 0.0)
                except (TypeError, ValueError):
                    candidate = 0.0
                if candidate > 0:
                    risk_basis_pct = max(risk_basis_pct, candidate)
        if risk_basis_pct <= 0 and isinstance(trade_profile, dict):
            for key in ("risk_basis_pct", "risk_context_floor_pct", "risk_context_guard_pct"):
                try:
                    candidate = float(trade_profile.get(key, 0.0) or 0.0)
                except (TypeError, ValueError):
                    candidate = 0.0
                if candidate > 0:
                    risk_basis_pct = max(risk_basis_pct, candidate)

        current_r = 0.0
        if current_profit is not None and risk_basis_pct > 0:
            try:
                current_r = float(current_profit) / float(risk_basis_pct)
            except Exception:
                current_r = 0.0

        super_context: Dict[str, Any] = {}
        super_active = False
        extreme_active = bool(mania_lane) if is_short else bool(panic_lane)
        if super_enable and super_r > 0:
            align_need = super_align_decay if channel_decay else super_align
            align_gate = align_abs >= align_need
            lanes_gate = fast_lane and htf_drive_lane
            if not lanes_gate and slow_lane and htf_drive_lane and align_abs >= super_align:
                lanes_gate = True
            profit_gate = True
            if super_trigger_r > 0 and current_r > 0:
                profit_gate = current_r >= super_trigger_r
            if lanes_gate and align_gate and not range_lane and profit_gate and not (super_block_extreme and extreme_active):
                super_active = True
                target_r = max(target_r, super_r)
                if "super_trend" not in reasons:
                    reasons.append("super_trend")
                super_context = {
                    "target_r": float(super_r),
                    "align": round(float(align_abs), 4),
                    "align_need": round(float(align_need), 4),
                    "current_r": round(float(current_r), 4),
                    "lanes_gate": int(lanes_gate),
                    "htf_drive": int(bool(htf_drive_lane)),
                    "block_extreme": int(bool(super_block_extreme and extreme_active)),
                }
                if super_trigger_r > 0:
                    super_context["trigger_r"] = round(float(super_trigger_r), 4)

        result = {
            "target_r": float(target_r),
            "base_r": float(base_r_cfg),
            "balance_r": float(balance_r),
            "narrow_r": float(narrow_r),
            "trend_r": float(trend_r),
            "decay_r": float(decay_r),
            "context": context,
            "reasons": reasons,
            "trend_lane": trend_lane,
            "trend_flags": trend_flags,
            "range_lane": range_lane,
            "decay_lane": decay_lane,
            "narrow_lane": narrow_lane,
            "fast_lane": bool(fast_lane),
            "slow_lane": bool(slow_lane),
            "htf_drive_lane": bool(htf_drive_lane),
            "channel_wide": bool(channel_wide),
            "channel_decay": bool(channel_decay),
            "channel_narrow": bool(channel_narrow),
            "align_score": float(align_score),
            "align_abs": float(align_abs),
            "session_ceiling_r": float(session_ceiling_r),
            "session_ceiling_pad": float(session_ceiling_pad),
            "session_realized_r": float(session_realized_r),
            "session_peak_r": float(session_peak_r),
            "session_realized_count": int(session_count),
            "risk_basis_pct": float(risk_basis_pct),
            "current_r": float(current_r),
            "panic_lane": int(bool(panic_lane)),
            "mania_lane": int(bool(mania_lane)),
        }

        if super_active:
            result["super_trend"] = super_context

        if crowd_ctx:
            result["crowd_flow"] = crowd_ctx

        if isinstance(risk_info, dict):
            try:
                result["entry_risk_pct"] = float(risk_info.get("entry_risk_pct", 0.0) or 0.0)
            except (TypeError, ValueError):
                result["entry_risk_pct"] = 0.0
            try:
                live_src = risk_info.get("live_risk_pct")
                if live_src in (None, 0, 0.0):
                    live_src = risk_info.get("actual_risk_pct", 0.0)
                result["live_risk_pct"] = float(live_src or 0.0)
            except (TypeError, ValueError):
                result["live_risk_pct"] = 0.0

        if isinstance(trade_profile, dict):
            ctx_store = trade_profile.setdefault("measured_context", {})
            ctx_store.update(
                {
                    "context": context,
                    "target_r": float(target_r),
                    "trend_lane": int(trend_lane),
                    "range_lane": int(range_lane),
                    "decay_lane": int(decay_lane),
                    "narrow_lane": int(narrow_lane),
                    "align_abs": float(align_abs),
                }
            )
            ctx_store["current_r"] = float(current_r)
            ctx_store["panic_lane"] = int(bool(panic_lane))
            ctx_store["mania_lane"] = int(bool(mania_lane))
            if session_ceiling_r > 0:
                ctx_store["session_ceiling_r"] = float(session_ceiling_r)
                ctx_store["session_ceiling_pad"] = float(session_ceiling_pad)
            else:
                ctx_store.pop("session_ceiling_r", None)
                ctx_store.pop("session_ceiling_pad", None)
            if crowd_ctx:
                ctx_store["crowd_flow"] = {k: crowd_ctx[k] for k in crowd_ctx if k not in ("session_ceiling_r",)}
            else:
                ctx_store.pop("crowd_flow", None)
            if session_realized_r > 0:
                ctx_store["session_realized_r"] = float(session_realized_r)
            else:
                ctx_store.pop("session_realized_r", None)
            if session_peak_r > 0:
                ctx_store["session_peak_r"] = float(session_peak_r)
            else:
                ctx_store.pop("session_peak_r", None)
            if session_reason:
                ctx_store["session_ceiling_reason"] = session_reason
            else:
                ctx_store.pop("session_ceiling_reason", None)
            if super_active:
                ctx_store["super_trend"] = dict(super_context)
            else:
                ctx_store.pop("super_trend", None)
        return result

    def _contextual_stoploss_tighten(
        self,
        *,
        fallback_open: float,
        mm_context: Optional[Dict[str, Any]],
        pair_cfg: Optional[Dict[str, Any]],
        trade_profile: Optional[Dict[str, Any]],
        align_score: float,
        fast_lane: bool,
        slow_lane: bool,
        htf_drive_lane: bool,
        channel_narrow: bool,
        channel_wide: bool,
        channel_decay: bool,
    ) -> Tuple[float, Optional[Dict[str, Any]]]:
        """教学提示：依据当前通道/车道情境调节兜底止损，防止震荡行情承受 20% 满额亏损。"""

        try:
            fallback_val = float(fallback_open)
        except (TypeError, ValueError):
            return 0.0, None
        if fallback_val <= 0:
            return fallback_val, None
        if not isinstance(mm_context, dict):
            return fallback_val, None

        po = pair_cfg if isinstance(pair_cfg, dict) else {}
        context_label = str(mm_context.get("context", "") or "balance")
        target_r = 0.0
        try:
            target_r = float(mm_context.get("target_r", 0.0) or 0.0)
        except (TypeError, ValueError):
            target_r = 0.0

        base_cfg = getattr(self, "STOPLOSS_CONTEXT_MULTIPLIERS", {})
        mult_cfg: Dict[str, float] = {}
        if isinstance(base_cfg, dict):
            for key, val in base_cfg.items():
                try:
                    mult_cfg[str(key)] = float(val)
                except (TypeError, ValueError):
                    continue
        override_cfg = po.get("stoploss_context_multipliers")
        if isinstance(override_cfg, dict):
            for key, val in override_cfg.items():
                try:
                    mult_cfg[str(key)] = float(val)
                except (TypeError, ValueError):
                    continue

        default_mult = mult_cfg.get("default")
        if default_mult is None:
            default_mult = mult_cfg.get("balance", 0.90)
        try:
            ctx_mult = float(mult_cfg.get(context_label, default_mult if default_mult is not None else 0.90))
        except (TypeError, ValueError):
            ctx_mult = float(default_mult if default_mult is not None else 0.90)

        min_mult = float(getattr(self, "STOPLOSS_CONTEXT_MIN_MULT", 0.52))
        max_mult = float(getattr(self, "STOPLOSS_CONTEXT_MAX_MULT", 1.10))
        ctx_mult = float(np.clip(ctx_mult, min_mult, max_mult))

        align_abs = abs(float(align_score))
        align_need = float(getattr(self, "STOPLOSS_CONTEXT_ALIGN_NEED", 0.0) or 0.0)
        align_bonus = float(getattr(self, "STOPLOSS_CONTEXT_ALIGN_BONUS", 0.0) or 0.0)
        lane_strength = int(bool(fast_lane)) + int(bool(slow_lane)) + int(bool(htf_drive_lane))
        if align_bonus > 0 and align_need > 0 and lane_strength > 0 and align_abs >= align_need:
            ctx_mult = min(max_mult, ctx_mult + align_bonus * lane_strength)

        entry_min_mult = float(getattr(self, "STOPLOSS_CONTEXT_ENTRY_MIN", 0.78))
        try:
            override_entry_min = float(po.get("stoploss_context_entry_min"))
        except (TypeError, ValueError, AttributeError):
            override_entry_min = None
        if override_entry_min is not None and override_entry_min > 0:
            entry_min_mult = max(0.0, override_entry_min)
        guard_floor = max(0.0, float(getattr(self, "STOPLOSS_MIN_PCT", 0.0)))
        if isinstance(trade_profile, dict):
            risk_keys = (
                "initial_risk_pct",
                "risk_basis_pct",
                "risk_live_pct",
                "risk_actual_pct",
            )
            for key in risk_keys:
                try:
                    risk_val = float(trade_profile.get(key, 0.0) or 0.0)
                except (TypeError, ValueError):
                    risk_val = 0.0
                if risk_val > 0 and entry_min_mult > 0:
                    guard_floor = max(guard_floor, risk_val * entry_min_mult)

        guard_floor = min(guard_floor, fallback_val)

        candidate = fallback_val * ctx_mult
        if ctx_mult <= 1.0:
            candidate = min(fallback_val, candidate)
            candidate = max(guard_floor, candidate)
        else:
            candidate = max(fallback_val, candidate)

        info: Dict[str, Any] = {
            "context": context_label,
            "target_r": float(target_r),
            "multiplier": float(ctx_mult),
            "lane_strength": lane_strength,
            "align_abs": float(round(align_abs, 4)),
            "guard_floor": float(round(guard_floor, 6)),
        }
        info["channel_wide"] = int(channel_wide)
        info["channel_decay"] = int(channel_decay)
        info["channel_narrow"] = int(channel_narrow)

        if isinstance(trade_profile, dict):
            ctx_store = trade_profile.setdefault("stoploss_context", {})
            ctx_store.update(
                {
                    "context": context_label,
                    "multiplier": float(ctx_mult),
                    "floor": float(round(candidate, 6)),
                    "guard_floor": float(round(guard_floor, 6)),
                }
            )
            if target_r > 0:
                ctx_store["target_r"] = float(target_r)

        return float(candidate), info

    def _stoploss_risk_snapshot(
        self,
        *,
        pair: str,
        trade_profile: Optional[Dict[str, Any]],
        pair_cfg: Optional[Dict[str, Any]],
        trade: Trade,
        current_rate: Optional[float],
        risk_info: Optional[Dict[str, Any]] = None,
    ) -> Tuple[Optional[Dict[str, Any]], Optional[str]]:
        stoploss_min_pct = max(0.0, float(getattr(self, "STOPLOSS_MIN_PCT", 0.0) or 0.0))
        fallback_floor_pct = max(0.0, float(getattr(self, "STOPLOSS_FALLBACK", 0.0) or 0.0))
        fallback_basis_pct = max(stoploss_min_pct, fallback_floor_pct)

        cache: Optional[Dict[str, Any]] = None
        if isinstance(trade_profile, dict):
            cache_candidate = trade_profile.get("stoploss_risk_cache")
            if isinstance(cache_candidate, dict):
                cache = dict(cache_candidate)

        cfg = pair_cfg if isinstance(pair_cfg, dict) else self._pair_cfg(pair)

        def _finalize_payload(payload: Optional[Dict[str, Any]]) -> Optional[Dict[str, Any]]:
            snapshot_payload: Dict[str, Any] = dict(payload) if isinstance(payload, dict) else {}

            raw_basis = snapshot_payload.get("risk_basis_pct", 0.0)
            try:
                basis_pct = float(raw_basis or 0.0)
            except (TypeError, ValueError):
                basis_pct = 0.0
            if not np.isfinite(basis_pct):
                basis_pct = 0.0

            fallback_applied = False
            if basis_pct <= 0 and fallback_basis_pct > 0:
                snapshot_payload["risk_basis_pct"] = float(fallback_basis_pct)
                snapshot_payload.setdefault("risk_basis_mode_effective", "fallback_floor")
                snapshot_payload.setdefault("risk_basis_source", "stoploss_fallback")
                snapshot_payload["risk_basis_fallback"] = 1
                snapshot_payload.setdefault(
                    "risk_basis_warning",
                    f"fallback_to_floor:{fallback_basis_pct:.6f}",
                )
                basis_pct = float(fallback_basis_pct)
                fallback_applied = True
            elif basis_pct > 0:
                snapshot_payload["risk_basis_pct"] = float(basis_pct)
                snapshot_payload["risk_basis_fallback"] = 0
                snapshot_payload.pop("risk_basis_warning", None)
            else:
                return None

            if fallback_floor_pct > 0 and "stoploss_fallback_pct" not in snapshot_payload:
                snapshot_payload["stoploss_fallback_pct"] = float(fallback_floor_pct)
            if stoploss_min_pct > 0 and "stoploss_min_pct" not in snapshot_payload:
                snapshot_payload["stoploss_min_pct"] = float(stoploss_min_pct)

            if isinstance(trade_profile, dict):
                trade_profile["risk_basis_pct"] = float(basis_pct)
                if fallback_applied:
                    trade_profile["risk_basis_fallback"] = True
                else:
                    trade_profile.pop("risk_basis_fallback", None)
                mode_effective = snapshot_payload.get("risk_basis_mode_effective")
                if mode_effective and not trade_profile.get("risk_basis_mode"):
                    trade_profile["risk_basis_mode"] = mode_effective

            return snapshot_payload

        if isinstance(risk_info, dict):
            snapshot = _finalize_payload(risk_info)
            if snapshot is None:
                if isinstance(trade_profile, dict):
                    trade_profile.pop("stoploss_risk_cache", None)
                return None, None
            if isinstance(trade_profile, dict):
                trade_profile["stoploss_risk_cache"] = dict(snapshot)
            return snapshot, None

        error_msg: Optional[str] = None
        snapshot: Optional[Dict[str, Any]] = None
        try:
            snapshot = self._resolve_trade_risk_basis(
                pair,
                trade_profile,
                pair_cfg=cfg,
                trade=trade,
                current_rate=current_rate,
            )
        except Exception as exc:
            error_msg = f"{type(exc).__name__}: {exc}"
            snapshot = None

        finalized_snapshot = _finalize_payload(snapshot)
        if finalized_snapshot is not None:
            if isinstance(trade_profile, dict):
                trade_profile["stoploss_risk_cache"] = dict(finalized_snapshot)
            return finalized_snapshot, error_msg

        if cache is not None:
            finalized_cache = _finalize_payload(cache)
            if finalized_cache is not None:
                if isinstance(trade_profile, dict):
                    trade_profile["stoploss_risk_cache"] = dict(finalized_cache)
                return finalized_cache, error_msg

        if isinstance(trade_profile, dict):
            trade_profile.pop("stoploss_risk_cache", None)

        if fallback_basis_pct > 0:
            fallback_snapshot = _finalize_payload({})
            if fallback_snapshot is not None:
                if isinstance(trade_profile, dict):
                    trade_profile["stoploss_risk_cache"] = dict(fallback_snapshot)
                return fallback_snapshot, error_msg

        return None, error_msg

    def _breakeven_floor_steps(self, risk_basis_pct: float) -> List[Dict[str, float]]:
        """教学提示：按风险基准把台阶地板换算成实际利润百分比。"""

        steps: List[Dict[str, float]] = []
        basis = float(risk_basis_pct or 0.0)
        r_steps = getattr(self, "FLOOR_STEPS_R", None)
        if basis > 0 and isinstance(r_steps, (list, tuple)):
            for entry in r_steps:
                if not isinstance(entry, (list, tuple)) or len(entry) < 2:
                    continue
                try:
                    thr_r = float(entry[0])
                    lock_r = float(entry[1])
                except (TypeError, ValueError):
                    continue
                if thr_r <= 0 or lock_r <= 0:
                    continue
                lock_r_clamped = min(lock_r, thr_r)
                thr_pct = basis * thr_r
                lock_pct = basis * lock_r_clamped
                if thr_pct <= 0 or lock_pct <= 0:
                    continue
                steps.append(
                    {
                        "threshold_pct": float(thr_pct),
                        "lock_pct": float(lock_pct),
                        "threshold_r": float(thr_r),
                        "lock_r": float(lock_r_clamped),
                    }
                )
        if not steps:
            for entry in getattr(self, "FLOOR_STEPS", []) or []:
                if not isinstance(entry, (list, tuple)) or len(entry) < 2:
                    continue
                try:
                    thr_pct = float(entry[0])
                    lock_pct = float(entry[1])
                except (TypeError, ValueError):
                    continue
                if thr_pct <= 0 or lock_pct <= 0:
                    continue
                steps.append(
                    {
                        "threshold_pct": float(thr_pct),
                        "lock_pct": float(lock_pct),
                        "threshold_r": None,
                        "lock_r": None,
                    }
                )
        return sorted(steps, key=lambda item: float(item.get("threshold_pct", 0.0)))

    def _strict_giveback_guard(
        self,
        *,
        pair: str,
        trade: Trade,
        current_profit: float,
        trade_profile: Optional[Dict[str, Any]],
        risk_info: Optional[Dict[str, Any]] = None,
        mm_context: Optional[Dict[str, Any]] = None,
        peak_profit: float = float("nan"),
        current_rate: Optional[float] = None,
    ) -> Tuple[float, Optional[Dict[str, Any]]]:
        """教学提示：浮盈达到阈值后强制抬升锁盈地板，防止“先盈后亏”。"""

        if not isinstance(trade_profile, dict):
            return 0.0, None
        po = self._pair_cfg(pair)
        enable = po.get("strict_giveback_enable", getattr(self, "STRICT_GIVEBACK_ENABLE", False))
        guard_state = trade_profile.setdefault("strict_giveback", {})
        if not bool(enable) or current_profit <= 0:
            guard_state.clear()
            guard_state["active"] = False
            guard_state["armed"] = False
            guard_state["floor"] = 0.0
            guard_state["current_profit"] = float(current_profit)
            return 0.0, guard_state

        risk_info_payload, risk_error = self._stoploss_risk_snapshot(
            pair=pair,
            trade_profile=trade_profile,
            pair_cfg=po,
            trade=trade,
            current_rate=current_rate,
            risk_info=risk_info,
        )
        if risk_error:
            guard_state["risk_resolve_error"] = risk_error
        else:
            guard_state.pop("risk_resolve_error", None)
            guard_state.pop("risk_resolve_note", None)

        risk_source: Dict[str, Any]
        if isinstance(risk_info_payload, dict):
            risk_source = risk_info_payload
        elif isinstance(risk_info, dict):
            risk_source = cast(Dict[str, Any], risk_info)
            if risk_error:
                guard_state.setdefault(
                    "risk_resolve_note",
                    "using cached risk snapshot after resolution error",
                )
        else:
            risk_source = {}
            if risk_error:
                guard_state.setdefault(
                    "risk_resolve_note",
                    "risk snapshot unavailable; using empty fallback",
                )

        risk_info_dict: Dict[str, Any] = risk_source

        basis_pct = float(risk_info_dict.get("risk_basis_pct", 0.0) or 0.0)
        if basis_pct <= 0:
            guard_state["active"] = False
            guard_state["armed"] = False
            guard_state.pop("floor", None)
            guard_state["current_profit"] = float(current_profit)
            guard_state["risk_basis_pct"] = 0.0
            return 0.0, guard_state

        ctx_dict = mm_context if isinstance(mm_context, dict) else {}
        context_label = str(ctx_dict.get("context", guard_state.get("context", "")) or "")
        try:
            context_target_r = float(ctx_dict.get("target_r", guard_state.get("target_r", 0.0)) or 0.0)
        except (TypeError, ValueError):
            context_target_r = float(guard_state.get("target_r", 0.0) or 0.0)

        session_ceiling_r = None
        session_pad = float(getattr(self, "SESSION_PROFIT_CEILING_PAD", 0.0) or 0.0)
        session_reason = None
        if isinstance(ctx_dict, dict):
            try:
                raw = ctx_dict.get("session_ceiling_r")
                session_ceiling_r = float(raw) if raw is not None else None
            except (TypeError, ValueError):
                session_ceiling_r = None
            try:
                pad_raw = ctx_dict.get("session_ceiling_pad")
                if pad_raw is not None:
                    session_pad = float(pad_raw)
            except (TypeError, ValueError):
                session_pad = float(getattr(self, "SESSION_PROFIT_CEILING_PAD", 0.0) or 0.0)
            reason_raw = ctx_dict.get("session_ceiling_reason")
            if reason_raw:
                session_reason = str(reason_raw)

        def _safe_float(val: Any, default: float = 0.0) -> float:
            try:
                return float(val)
            except (TypeError, ValueError):
                return float(default)

        arm_map: Dict[str, float] = {}
        base_map = getattr(self, "STRICT_GIVEBACK_CONTEXT_ARM", {})
        if isinstance(base_map, dict):
            for key, val in base_map.items():
                arm_map[str(key)] = _safe_float(val)
        override_map = po.get("strict_giveback_context_arm")
        if isinstance(override_map, dict):
            for key, val in override_map.items():
                arm_map[str(key)] = _safe_float(val)

        arm_base = _safe_float(po.get("strict_giveback_arm_r", getattr(self, "STRICT_GIVEBACK_ARM_R", 0.0)))
        arm_min = max(0.0, _safe_float(po.get("strict_giveback_arm_min", getattr(self, "STRICT_GIVEBACK_ARM_MIN", 0.0))))
        arm_pad = max(0.0, _safe_float(po.get("strict_giveback_arm_pad", getattr(self, "STRICT_GIVEBACK_ARM_PAD", 0.0))))
        arm_r = arm_base if arm_base > 0 else arm_min
        if context_label and context_label in arm_map:
            ctx_arm = _safe_float(arm_map.get(context_label, arm_r), arm_r)
            if ctx_arm > 0:
                arm_r = ctx_arm
        if arm_min > 0:
            arm_r = max(arm_r, arm_min)
        if context_target_r > 0:
            max_allow = context_target_r - arm_pad if arm_pad > 0 else context_target_r
            if max_allow > 0:
                arm_r = min(arm_r, max_allow)
            arm_r = min(arm_r, context_target_r)
        if arm_r <= 0 and context_target_r > 0:
            arm_r = max(arm_min, max(context_target_r - arm_pad, 0.0))
        if arm_r <= 0:
            arm_r = arm_min

        es_enable = bool(po.get("expected_shortfall_enable", getattr(self, "EXPECTED_SHORTFALL_ENABLE", True)))
        es_ratio = 1.0
        es_floor_bonus = 0.0
        if es_enable:
            tail_summary = self._risk_tail_summary()
            es_trigger = float(po.get("expected_shortfall_trigger_r", getattr(self, "EXPECTED_SHORTFALL_TRIGGER_R", -1.20)) or -1.20)
            es_penalty = float(po.get("expected_shortfall_penalty", getattr(self, "EXPECTED_SHORTFALL_PENALTY", 0.35)) or 0.0)
            es_min_samples = int(po.get("expected_shortfall_min_count", getattr(self, "EXPECTED_SHORTFALL_MIN_COUNT", 8)) or 0)
            if (
                isinstance(tail_summary, dict)
                and es_penalty > 0
                and tail_summary.get("count", 0) >= es_min_samples > 0
            ):
                try:
                    cvar_val = float(tail_summary.get("cvar", 0.0) or 0.0)
                except (TypeError, ValueError):
                    cvar_val = 0.0
                if cvar_val <= es_trigger:
                    severity = 1.0
                    if es_trigger != 0:
                        try:
                            severity = min(1.0, max(0.0, (es_trigger - cvar_val) / abs(es_trigger)))
                        except Exception:
                            severity = 1.0
                    es_ratio = max(0.0, 1.0 - es_penalty * severity)
                    es_floor_bonus = max(0.0, basis_pct * es_penalty * severity)
                    guard_state["es_active"] = True
                    guard_state["es_cvar"] = cvar_val
                    guard_state["es_trigger"] = es_trigger
                    guard_state["es_severity"] = severity
                    guard_state["es_ratio"] = es_ratio
                else:
                    guard_state.pop("es_active", None)
                    guard_state.pop("es_cvar", None)
                    guard_state.pop("es_trigger", None)
                    guard_state.pop("es_severity", None)
                    guard_state.pop("es_ratio", None)
            else:
                guard_state.pop("es_active", None)
                guard_state.pop("es_cvar", None)
                guard_state.pop("es_trigger", None)
                guard_state.pop("es_severity", None)
                guard_state.pop("es_ratio", None)

        arm_r = max(0.0, arm_r * es_ratio)

        session_allowed = None
        if session_ceiling_r is not None and session_ceiling_r > 0:
            session_allowed = session_ceiling_r + max(session_pad, 0.0)
            limit_val = session_allowed if session_allowed and session_allowed > 0 else session_ceiling_r
            arm_r = min(arm_r, limit_val) if limit_val > 0 else arm_r

        profit_r = (current_profit / basis_pct) if basis_pct > 0 else 0.0
        armed = bool(guard_state.get("armed")) or (arm_r > 0 and profit_r >= arm_r)

        guard_state["context"] = context_label
        guard_state["target_r"] = context_target_r
        guard_state["arm_r"] = float(arm_r)
        guard_state["risk_basis_pct"] = float(basis_pct)
        basis_hint_pct = float(
            po.get(
                "strict_giveback_basis_hint_pct",
                getattr(self, "STRICT_GIVEBACK_BASIS_HINT_PCT", getattr(self, "STOPLOSS_FALLBACK", 0.0)),
            )
            or 0.0
        )
        mismatch_threshold = max(
            0.0,
            float(getattr(self, "STRICT_GIVEBACK_BASIS_MISMATCH_THRESHOLD", 0.15)),
        )
        warn_cooldown = max(
            0.0,
            float(getattr(self, "STRICT_GIVEBACK_BASIS_WARN_COOLDOWN_MIN", 30.0)),
        )
        if basis_hint_pct > 0:
            guard_state["basis_hint_pct"] = float(basis_hint_pct)
            diff_ratio = abs(basis_pct - basis_hint_pct) / basis_hint_pct
            if diff_ratio >= mismatch_threshold:
                guard_state["basis_mismatch_ratio"] = float(diff_ratio)
                now_ts = datetime.now(timezone.utc)
                last_warn_dt = self._to_utc_datetime(guard_state.get("basis_warn_ts"))
                should_log = True
                if last_warn_dt and warn_cooldown > 0:
                    should_log = (now_ts - last_warn_dt).total_seconds() >= warn_cooldown * 60.0
                if should_log:
                    guard_state["basis_warn_ts"] = now_ts.isoformat()
                    side_txt = "short" if trade.is_short else "long"
                    self._log_decision(
                        "止损守卫",
                        pair,
                        side_txt,
                        "提示",
                        "strict_giveback_basis_mismatch",
                        {
                            "risk_basis_pct": round(basis_pct, 6),
                            "basis_hint_pct": round(basis_hint_pct, 6),
                            "mismatch_ratio": round(diff_ratio, 4),
                        },
                    )
            else:
                guard_state.pop("basis_mismatch_ratio", None)
                guard_state.pop("basis_warn_ts", None)
        else:
            guard_state.pop("basis_hint_pct", None)
            guard_state.pop("basis_mismatch_ratio", None)
            guard_state.pop("basis_warn_ts", None)
        guard_state["current_profit"] = float(current_profit)
        guard_state["current_r"] = float(profit_r)
        if session_ceiling_r is not None and session_ceiling_r > 0:
            guard_state["session_ceiling_r"] = float(session_ceiling_r)
            guard_state["session_ceiling_pad"] = float(session_pad)
            if session_reason:
                guard_state["session_ceiling_reason"] = session_reason
            else:
                guard_state.pop("session_ceiling_reason", None)
        else:
            guard_state.pop("session_ceiling_r", None)
            guard_state.pop("session_ceiling_pad", None)
            guard_state.pop("session_ceiling_reason", None)
        guard_state.setdefault("history", {}).update({"last_update": datetime.now(timezone.utc)})

        peak_candidates: List[float] = []
        for val in (peak_profit, guard_state.get("peak_profit"), current_profit):
            try:
                val_f = float(val)
            except (TypeError, ValueError):
                continue
            if np.isfinite(val_f) and val_f > 0:
                peak_candidates.append(val_f)
        peak_use = max(peak_candidates) if peak_candidates else max(0.0, float(current_profit))
        guard_state["peak_profit"] = float(peak_use)
        guard_state["peak_r"] = (peak_use / basis_pct) if basis_pct > 0 and peak_use > 0 else 0.0
        exposure_info: Dict[str, float] = {}
        current_notional_info = float(risk_source.get("current_notional_usdt", 0.0) or 0.0)
        if current_notional_info > 0:
            exposure_info["current_notional_usdt"] = current_notional_info
        margin_info = float(risk_source.get("margin_current_usdt", 0.0) or 0.0)
        if margin_info <= 0:
            margin_info = float(risk_source.get("stake_margin_usdt", 0.0) or 0.0)
        if margin_info > 0:
            exposure_info["margin_usdt"] = margin_info
        risk_unit_info = float(risk_source.get("risk_unit_value_usdt", 0.0) or 0.0)
        if risk_unit_info > 0:
            exposure_info["risk_unit_usdt"] = risk_unit_info
        leverage_info = float(risk_source.get("effective_leverage", 0.0) or 0.0)
        if leverage_info > 0:
            exposure_info["leverage"] = leverage_info
        if exposure_info:
            guard_state["exposure"] = exposure_info
        else:
            guard_state.pop("exposure", None)

        if not armed:
            guard_state["active"] = False
            guard_state["armed"] = False
            guard_state.pop("floor", None)
            guard_state.pop("floor_r", None)
            return 0.0, guard_state

        crowd_ctx = self._crowd_flow_adjustment(
            pair=pair,
            trade=trade,
            trade_profile=trade_profile,
            pair_cfg=po,
            risk_info=risk_source,
            measured_state=mm_context,
            session_ctx={
                "profit_ceiling_r": session_ceiling_r,
                "profit_ceiling_pad": session_pad,
            },
            current_profit=current_profit,
        )
        if crowd_ctx:
            guard_state["crowd_flow"] = crowd_ctx
        else:
            guard_state.pop("crowd_flow", None)

        floor_share = max(0.0, _safe_float(po.get("strict_giveback_floor_share", getattr(self, "STRICT_GIVEBACK_FLOOR_SHARE", 0.0))))
        peak_share = max(0.0, _safe_float(po.get("strict_giveback_peak_share", getattr(self, "STRICT_GIVEBACK_PEAK_SHARE", floor_share))))
        floor_r_min = max(0.0, _safe_float(po.get("strict_giveback_floor_r_min", getattr(self, "STRICT_GIVEBACK_FLOOR_R_MIN", 0.0))))
        floor_min = max(0.0, _safe_float(po.get("strict_giveback_floor_min", getattr(self, "STRICT_GIVEBACK_FLOOR_MIN", 0.0))))
        buffer_share = max(0.0, _safe_float(po.get("strict_giveback_buffer_share", getattr(self, "STRICT_GIVEBACK_BUFFER_SHARE", 0.0))))
        buffer_abs = max(0.0, _safe_float(po.get("strict_giveback_buffer_abs", getattr(self, "STRICT_GIVEBACK_BUFFER_ABS", 0.0))))
        exit_tol = max(0.0, _safe_float(po.get("strict_giveback_exit_tolerance", getattr(self, "STRICT_GIVEBACK_EXIT_TOLERANCE", 0.0))))

        if session_ceiling_r is not None and session_ceiling_r > 0 and floor_r_min > 0:
            floor_r_min = min(floor_r_min, session_ceiling_r)

        floor_candidates: List[float] = [floor_min]
        if floor_share > 0:
            floor_candidates.append(current_profit * floor_share)
        if peak_share > 0 and peak_use > 0:
            floor_candidates.append(peak_use * peak_share)
        if floor_r_min > 0:
            floor_candidates.append(basis_pct * floor_r_min)
        if crowd_ctx:
            crowd_floor_r = float(crowd_ctx.get("floor_min_r", 0.0) or 0.0)
            if crowd_floor_r > 0 and basis_pct > 0:
                floor_candidates.append(basis_pct * crowd_floor_r)
        if es_floor_bonus > 0:
            floor_candidates.append(es_floor_bonus)
        floor_val = max([val for val in floor_candidates if np.isfinite(val) and val >= 0.0]) if floor_candidates else 0.0

        cap_offset = max(buffer_abs, current_profit * buffer_share)
        floor_cap = max(0.0, current_profit - cap_offset)
        if floor_cap <= 0:
            floor_cap = max(0.0, current_profit * (1.0 - min(buffer_share, 0.5)))
        floor_val = min(floor_val, max(floor_cap, 0.0))
        floor_val = min(floor_val, max(current_profit - 1e-6, 0.0))

        prev_floor = _safe_float(guard_state.get("floor", 0.0))
        if prev_floor > 0:
            prev_cap = min(prev_floor, max(current_profit - 1e-6, floor_cap)) if floor_cap > 0 else min(prev_floor, current_profit)
            floor_val = max(floor_val, prev_cap)

        floor_val = max(floor_val, floor_min)
        floor_val = min(floor_val, max(current_profit - 1e-6, 0.0)) if current_profit > 0 else 0.0

        if session_allowed is not None and session_allowed > 0 and basis_pct > 0:
            floor_cap_session = basis_pct * session_allowed
            floor_val = min(floor_val, floor_cap_session)

        guard_state["active"] = True
        guard_state["armed"] = True
        guard_state["floor"] = float(floor_val)
        guard_state["floor_r"] = (floor_val / basis_pct) if basis_pct > 0 and floor_val > 0 else 0.0
        guard_state["buffer_share"] = float(buffer_share)
        guard_state["buffer_abs"] = float(buffer_abs)
        guard_state["exit_tolerance"] = float(exit_tol)

        info = {
            "floor": float(floor_val),
            "arm_r": float(arm_r),
            "current_r": float(profit_r),
            "basis_pct": float(basis_pct),
            "context": context_label,
        }
        if context_target_r > 0:
            info["target_r"] = float(context_target_r)
        if peak_use > 0:
            info["peak_profit"] = float(peak_use)
        info["buffer_share"] = float(buffer_share)
        info["buffer_abs"] = float(buffer_abs)
        if exit_tol > 0:
            info["exit_tolerance"] = float(exit_tol)

        return float(floor_val), info

    def _expectation_guard_state(
        self,
        pair: str,
        trade: Trade,
        current_profit: float,
        *,
        now_ctx: datetime,
        trade_profile: Optional[Dict[str, Any]] = None,
        risk_info: Optional[Dict[str, Any]] = None,
        peak_profit: float = float("nan"),
        measured_state: Optional[Dict[str, Any]] = None,
        current_rate: Optional[float] = None,
    ) -> Optional[Dict[str, Any]]:
        """教学提示：根据目标 R 倍数/时间/回撤，决定是否继续持有以追求更高盈亏比。"""

        if current_profit <= 0:
            return None
        if not isinstance(trade_profile, dict):
            return None

        guard_state = trade_profile.setdefault("expectation_guard", {})
        trade_side = "short" if bool(getattr(trade, "is_short", False)) else "long"
        priority_prefer = ""
        priority_conf_val = 0.0
        cluster_bias_side = ""
        cluster_bias_score = 0.0
        cluster_same_count = 0.0
        if isinstance(trade_profile, dict):
            raw_pref = trade_profile.get("priority_prefer")
            if isinstance(raw_pref, str):
                priority_prefer = raw_pref.strip().lower()
            try:
                priority_conf_val = float(trade_profile.get("priority_conf", 0.0) or 0.0)
            except (TypeError, ValueError):
                priority_conf_val = 0.0
            raw_bias_side = trade_profile.get("cluster_bias_side")
            if isinstance(raw_bias_side, str):
                cluster_bias_side = raw_bias_side.strip().lower()
            try:
                cluster_bias_score = float(trade_profile.get("cluster_bias", 0.0) or 0.0)
            except (TypeError, ValueError):
                cluster_bias_score = 0.0
            try:
                cluster_same_count = float(trade_profile.get("cluster_same", 0.0) or 0.0)
            except (TypeError, ValueError):
                cluster_same_count = 0.0
        base_pair_cfg = self._pair_cfg(pair)
        po = self._exit_tuning_merge_cfg(base_pair_cfg, pair)
        enable = po.get("expectation_guard_enable", getattr(self, "EXPECTATION_GUARD_ENABLE", False))
        if not bool(enable):
            guard_state["active"] = False
            guard_state["satisfied"] = True
            guard_state.pop("reason", None)
            return None

        risk_info_payload, risk_error = self._stoploss_risk_snapshot(
            pair=pair,
            trade_profile=trade_profile,
            pair_cfg=po,
            trade=trade,
            current_rate=current_rate,
            risk_info=risk_info,
        )
        if risk_error:
            guard_state["risk_resolve_error"] = risk_error
        else:
            guard_state.pop("risk_resolve_error", None)
            guard_state.pop("risk_resolve_note", None)

        risk_source: Dict[str, Any]
        if isinstance(risk_info_payload, dict):
            risk_source = risk_info_payload
        elif isinstance(risk_info, dict):
            risk_source = cast(Dict[str, Any], risk_info)
            if risk_error:
                guard_state.setdefault(
                    "risk_resolve_note",
                    "using cached risk snapshot after resolution error",
                )
        else:
            risk_source = {}
            if risk_error:
                guard_state.setdefault(
                    "risk_resolve_note",
                    "risk snapshot unavailable; using empty fallback",
                )

        risk_info_dict: Dict[str, Any] = risk_source

        basis_pct = float(risk_info_dict.get("risk_basis_pct", 0.0) or 0.0)
        current_r = current_profit / basis_pct if basis_pct > 0 else float("nan")
        guard_state["current_r"] = current_r
        if guard_state.get("floor_satisfied"):
            guard_state["active"] = False
            guard_state["satisfied"] = True
            guard_state.pop("reason", None)
            if np.isfinite(current_r):
                guard_state["satisfied_r"] = current_r
            return None
        if basis_pct <= 0:
            guard_state["active"] = False
            guard_state["satisfied"] = True
            guard_state.pop("reason", None)
            return None

        target_r = float(po.get("expectation_target_r", getattr(self, "EXPECTATION_TARGET_R", 0.0)) or 0.0)
        release_r = float(po.get("expectation_release_r", getattr(self, "EXPECTATION_RELEASE_R", 0.0)) or 0.0)
        floor_r = float(
            po.get("expectation_release_floor_r", getattr(self, "EXPECTATION_RELEASE_FLOOR_R", 0.0)) or 0.0
        )
        floor_pct_override = float(
            po.get(
                "expectation_release_floor_pct",
                po.get("expectation_floor_pct", getattr(self, "EXPECTATION_RELEASE_FLOOR_PCT", 0.0)),
            )
            or 0.0
        )
        drawdown_r = float(po.get("expectation_drawdown_r", getattr(self, "EXPECTATION_DRAWDOWN_R", 0.0)) or 0.0)
        relax_minutes = float(po.get("expectation_relax_minutes", getattr(self, "EXPECTATION_RELAX_MINUTES", 0.0)) or 0.0)
        context_pad = float(po.get("expectation_context_pad", getattr(self, "EXPECTATION_CONTEXT_PAD", 0.0)) or 0.0)
        floor_max_r = float(po.get("expectation_floor_max_r", getattr(self, "EXPECTATION_FLOOR_MAX_R", 0.0)) or 0.0)
        floor_escalate_at_r = float(
            po.get("expectation_floor_escalate_at_r", getattr(self, "EXPECTATION_FLOOR_ESCALATE_AT_R", 0.0)) or 0.0
        )
        floor_escalate_pad_r = max(
            0.0,
            float(
                po.get(
                    "expectation_floor_escalate_pad_r",
                    getattr(self, "EXPECTATION_FLOOR_ESCALATE_PAD_R", 0.0),
                )
                or 0.0
            ),
        )
        time_escalate_minutes = float(
            po.get(
                "expectation_time_escalate_minutes",
                getattr(self, "EXPECTATION_TIME_ESCALATE_MINUTES", 0.0),
            )
            or 0.0
        )
        time_escalate_target_r = float(
            po.get(
                "expectation_time_escalate_target_r",
                getattr(self, "EXPECTATION_TIME_ESCALATE_TARGET_R", 0.0),
            )
            or 0.0
        )
        time_escalate_min_r = float(
            po.get(
                "expectation_time_escalate_min_r",
                getattr(self, "EXPECTATION_TIME_ESCALATE_MIN_R", 0.0),
            )
            or 0.0
        )
        time_escalate_pad_r = max(
            0.0,
            float(
                po.get(
                    "expectation_time_escalate_pad_r",
                    getattr(self, "EXPECTATION_TIME_ESCALATE_PAD_R", 0.0),
                )
                or 0.0
            ),
        )
        bias_floor_shift_r = max(
            0.0,
            float(
                po.get(
                    "expectation_bias_floor_shift_r",
                    getattr(self, "EXPECTATION_BIAS_FLOOR_SHIFT_R", 0.0),
                )
                or 0.0
            ),
        )
        bias_time_shift_minutes = max(
            0.0,
            float(
                po.get(
                    "expectation_bias_time_shift_minutes",
                    getattr(self, "EXPECTATION_BIAS_TIME_SHIFT_MINUTES", 0.0),
                )
                or 0.0
            ),
        )
        bias_time_floor_minutes = max(
            0.0,
            float(
                po.get(
                    "expectation_bias_time_floor_minutes",
                    getattr(self, "EXPECTATION_BIAS_TIME_FLOOR_MINUTES", 0.0),
                )
                or 0.0
            ),
        )

        es_enable = bool(po.get("expected_shortfall_enable", getattr(self, "EXPECTED_SHORTFALL_ENABLE", True)))
        es_ratio = 1.0
        es_state: Optional[Dict[str, Any]] = None
        if es_enable:
            tail_summary = self._risk_tail_summary()
            es_trigger = float(po.get("expected_shortfall_trigger_r", getattr(self, "EXPECTED_SHORTFALL_TRIGGER_R", -1.20)) or -1.20)
            es_penalty = float(po.get("expected_shortfall_penalty", getattr(self, "EXPECTED_SHORTFALL_PENALTY", 0.35)) or 0.0)
            es_min_samples = int(po.get("expected_shortfall_min_count", getattr(self, "EXPECTED_SHORTFALL_MIN_COUNT", 8)) or 0)
            if (
                isinstance(tail_summary, dict)
                and es_penalty > 0
                and tail_summary.get("count", 0) >= es_min_samples > 0
            ):
                try:
                    cvar_val = float(tail_summary.get("cvar", 0.0) or 0.0)
                except (TypeError, ValueError):
                    cvar_val = 0.0
                if cvar_val <= es_trigger:
                    severity = 1.0
                    if es_trigger != 0:
                        try:
                            severity = min(1.0, max(0.0, (es_trigger - cvar_val) / abs(es_trigger)))
                        except Exception:
                            severity = 1.0
                    es_ratio = max(0.0, 1.0 - es_penalty * severity)
                    es_state = {
                        "cvar": cvar_val,
                        "trigger": es_trigger,
                        "severity": severity,
                        "ratio": es_ratio,
                    }

        context_r = None
        context_label = None
        context_floor_pct = float(risk_info_dict.get("context_floor_pct", 0.0) or 0.0)
        context_guard_pct = float(risk_info_dict.get("context_guard_pct", 0.0) or 0.0)
        if context_floor_pct > 0:
            guard_state["context_floor_pct"] = float(context_floor_pct)
        else:
            guard_state.pop("context_floor_pct", None)
        if context_guard_pct > 0:
            guard_state["context_guard_pct"] = float(context_guard_pct)
        else:
            guard_state.pop("context_guard_pct", None)
        if isinstance(measured_state, dict):
            ctx_val = measured_state.get("context_r")
            try:
                context_r = float(ctx_val) if ctx_val is not None else None
            except (TypeError, ValueError):
                context_r = None
            context_label_raw = measured_state.get("context")
            if context_label_raw is not None:
                context_label = str(context_label_raw)

        if context_r is not None and context_r > 0:
            guard_state["context_r"] = float(context_r)
            guard_state["context_pad"] = float(context_pad)
            if context_label:
                guard_state["context_label"] = context_label
            if target_r <= 0:
                target_r = context_r
            elif context_r < target_r:
                max_allow = context_r + max(context_pad, 0.0)
                if max_allow > 0:
                    target_r = min(target_r, max_allow)
                target_r = max(target_r, context_r)
            else:
                target_r = max(target_r, context_r)
        else:
            guard_state.pop("context_r", None)
            guard_state.pop("context_pad", None)
            guard_state.pop("context_label", None)

        session_ceiling_r = None
        session_pad = float(getattr(self, "SESSION_PROFIT_CEILING_PAD", 0.0) or 0.0)
        session_realized_r = None
        session_peak_r = None
        session_reason = None
        session_count = 0
        session_floor_r = 0.0
        session_allowed_r: Optional[float] = None
        if isinstance(measured_state, dict):
            try:
                val = measured_state.get("session_ceiling_r")
                session_ceiling_r = float(val) if val is not None else None
            except (TypeError, ValueError):
                session_ceiling_r = None
            try:
                pad_val = measured_state.get("session_ceiling_pad")
                if pad_val is not None:
                    session_pad = float(pad_val)
            except (TypeError, ValueError):
                session_pad = float(getattr(self, "SESSION_PROFIT_CEILING_PAD", 0.0) or 0.0)
            try:
                realized_val = measured_state.get("session_realized_r")
                if realized_val is not None:
                    session_realized_r = float(realized_val)
            except (TypeError, ValueError):
                session_realized_r = None
            try:
                peak_val = measured_state.get("session_peak_r")
                if peak_val is not None:
                    session_peak_r = float(peak_val)
            except (TypeError, ValueError):
                session_peak_r = None
            try:
                session_count = int(measured_state.get("session_realized_count", 0) or 0)
            except (TypeError, ValueError):
                session_count = 0
            reason_raw = measured_state.get("session_ceiling_reason")
            if reason_raw:
                session_reason = str(reason_raw)

        if session_ceiling_r is not None and session_ceiling_r > 0:
            guard_state["session_ceiling_r"] = float(session_ceiling_r)
            guard_state["session_ceiling_pad"] = float(session_pad)
            if session_realized_r is not None and session_realized_r > 0:
                guard_state["session_realized_r"] = float(session_realized_r)
            else:
                guard_state.pop("session_realized_r", None)
            if session_peak_r is not None and session_peak_r > 0:
                guard_state["session_peak_r"] = float(session_peak_r)
            else:
                guard_state.pop("session_peak_r", None)
            if session_count > 0:
                guard_state["session_realized_count"] = int(session_count)
            else:
                guard_state.pop("session_realized_count", None)
            if session_reason:
                guard_state["session_ceiling_reason"] = session_reason
            else:
                guard_state.pop("session_ceiling_reason", None)

            allowed_r = session_ceiling_r + max(session_pad, context_pad)
            session_floor_r = max(session_ceiling_r, 0.0)
            if allowed_r > 0:
                session_allowed_r = allowed_r
                if target_r > 0:
                    target_r = min(target_r, allowed_r)
                else:
                    target_r = session_floor_r
                target_r = max(session_floor_r, target_r)
                if release_r > 0:
                    release_r = max(session_floor_r, min(release_r, allowed_r))
                if drawdown_r > 0 and release_r > session_floor_r:
                    max_draw = max(release_r - session_floor_r, 0.0)
                    drawdown_r = min(drawdown_r, max_draw)
        else:
            guard_state.pop("session_ceiling_r", None)
            guard_state.pop("session_ceiling_pad", None)
            guard_state.pop("session_realized_r", None)
            guard_state.pop("session_peak_r", None)
            guard_state.pop("session_realized_count", None)
            guard_state.pop("session_ceiling_reason", None)
            session_allowed_r = None

        crowd_ctx = self._crowd_flow_adjustment(
            pair=pair,
            trade=trade,
            trade_profile=trade_profile,
            pair_cfg=po,
            risk_info=risk_info,
            measured_state=measured_state,
            session_ctx={
                "profit_ceiling_r": session_ceiling_r or 0.0,
                "profit_ceiling_pad": session_pad,
            },
            current_profit=current_profit,
        )
        if crowd_ctx:
            guard_state["crowd_flow"] = crowd_ctx
            penalty_r = float(crowd_ctx.get("target_penalty_r", 0.0) or 0.0)
            release_penalty_r = float(crowd_ctx.get("release_penalty_r", 0.0) or 0.0)
            bonus_r = float(crowd_ctx.get("opponent_bonus_r", 0.0) or 0.0)
            min_target_r = float(crowd_ctx.get("min_target_r", 0.0) or 0.0)
            drawdown_cap_r = float(crowd_ctx.get("drawdown_cap_r", 0.0) or 0.0)
            if penalty_r > 0 and target_r > 0:
                target_r = max(min_target_r, target_r - penalty_r)
            else:
                target_r = max(target_r, min_target_r)
            if release_penalty_r > 0 and release_r > 0:
                min_release = max(min_target_r, 0.0)
                release_r = max(min_release, release_r - release_penalty_r)
            if bonus_r > 0 and release_r > 0:
                release_r = max(release_r, target_r + bonus_r)
            if drawdown_cap_r > 0:
                if drawdown_r > 0:
                    drawdown_r = min(drawdown_r, drawdown_cap_r)
                else:
                    drawdown_r = drawdown_cap_r
            try:
                crowd_same_factor = max(0.0, float(crowd_ctx.get("same_factor", 0.0) or 0.0))
            except (TypeError, ValueError):
                crowd_same_factor = 0.0
            try:
                crowd_bias_factor = max(0.0, float(crowd_ctx.get("bias_factor", 0.0) or 0.0))
            except (TypeError, ValueError):
                crowd_bias_factor = 0.0
            bias_side_val = crowd_ctx.get("bias_side")
            if isinstance(bias_side_val, str):
                crowd_bias_side = bias_side_val.strip().lower()
        else:
            guard_state.pop("crowd_flow", None)

        bias_pressure = 0.0
        if priority_prefer == trade_side and priority_conf_val > 0:
            bias_pressure = max(bias_pressure, min(1.0, priority_conf_val))
        if cluster_bias_side == trade_side and cluster_bias_score > 0:
            bias_pressure = max(bias_pressure, min(1.0, abs(cluster_bias_score)))
        if cluster_same_count > 0:
            bias_pressure = max(bias_pressure, min(1.0, cluster_same_count / 12.0))
        if crowd_same_factor > 0:
            bias_pressure = max(bias_pressure, min(1.0, crowd_same_factor))
        if crowd_bias_factor > 0 and crowd_bias_side == trade_side:
            bias_pressure = max(bias_pressure, min(1.0, crowd_bias_factor))

        open_dt = self._to_utc_datetime(
            getattr(trade, "open_date_utc", None) or getattr(trade, "open_date", None)
        )
        age_minutes = 0.0
        if open_dt:
            age_minutes = max(0.0, (now_ctx - open_dt).total_seconds() / 60.0)

        if release_r > 0:
            if session_allowed_r is not None and session_allowed_r > 0:
                release_r = min(max(release_r, session_floor_r), session_allowed_r)
            else:
                release_r = max(release_r, session_floor_r)
            if context_r is not None and context_r > 0:
                max_release = context_r + max(context_pad, 0.0)
                if max_release > 0:
                    release_r = min(release_r, max_release)
                    if session_floor_r > 0 and release_r < session_floor_r:
                        release_r = session_floor_r
        desired_floor_r: Optional[float] = None
        floor_escalated = False
        if floor_max_r > 0 and np.isfinite(current_r):
            escalate_trigger = max(floor_escalate_at_r, floor_r, 0.0)
            if current_r >= escalate_trigger:
                candidate = min(floor_max_r, current_r)
                if floor_escalate_pad_r > 0 and candidate > floor_escalate_pad_r:
                    candidate = max(floor_r, candidate - floor_escalate_pad_r)
                candidate = max(floor_r, candidate)
                if release_r > 0:
                    candidate = min(candidate, release_r)
                if session_allowed_r is not None and session_allowed_r > 0:
                    candidate = min(candidate, session_allowed_r)
                if context_r is not None and context_r > 0:
                    max_floor = context_r + max(context_pad, 0.0)
                    if max_floor > 0:
                        candidate = min(candidate, max_floor)
                    candidate = max(candidate, context_r)
                if candidate > floor_r and candidate > 0:
                    floor_r = candidate
                    floor_escalated = True
                desired_floor_r = candidate if candidate > 0 else None
        time_floor_applied = False
        time_floor_candidate: Optional[float] = None
        if (
            time_escalate_minutes > 0
            and age_minutes >= time_escalate_minutes
            and np.isfinite(current_r)
        ):
            min_required = max(time_escalate_min_r, floor_r, 0.0)
            if current_r >= min_required:
                candidate = current_r
                if time_escalate_target_r > 0:
                    candidate = min(candidate, time_escalate_target_r)
                candidate = max(candidate, min_required)
                if time_escalate_pad_r > 0 and candidate > time_escalate_pad_r:
                    candidate = max(min_required, candidate - time_escalate_pad_r)
                if release_r > 0:
                    candidate = min(candidate, release_r)
                if session_allowed_r is not None and session_allowed_r > 0:
                    candidate = min(candidate, session_allowed_r)
                if context_r is not None and context_r > 0:
                    max_floor = context_r + max(context_pad, 0.0)
                    if max_floor > 0:
                        candidate = min(candidate, max_floor)
                    candidate = max(candidate, context_r)
                if candidate > floor_r and candidate > 0:
                    floor_r = candidate
                    time_floor_applied = True
                if candidate > 0:
                    time_floor_candidate = candidate
        if floor_escalated:
            guard_state["floor_escalated"] = True
            guard_state["floor_escalate_r"] = float(floor_r)
        else:
            guard_state.pop("floor_escalated", None)
            if desired_floor_r is not None and desired_floor_r > 0:
                guard_state["floor_escalate_r"] = float(desired_floor_r)
            else:
                guard_state.pop("floor_escalate_r", None)
        if time_floor_applied:
            guard_state["time_floor_escalated"] = True
            guard_state["time_floor_minutes"] = float(time_escalate_minutes)
            guard_state["time_floor_r"] = float(floor_r)
        else:
            guard_state.pop("time_floor_escalated", None)
            guard_state.pop("time_floor_minutes", None)
            if time_floor_candidate is not None and time_floor_candidate > 0:
                guard_state["time_floor_r"] = float(time_floor_candidate)
            else:
                guard_state.pop("time_floor_r", None)
        if floor_r > 0:
            if release_r > 0:
                floor_r = min(floor_r, release_r)
            if session_allowed_r is not None and session_allowed_r > 0:
                floor_r = min(floor_r, session_allowed_r)
            if session_floor_r > 0:
                floor_r = max(floor_r, session_floor_r)
            if context_r is not None and context_r > 0:
                max_floor = context_r + max(context_pad, 0.0)
                if max_floor > 0:
                    floor_r = min(floor_r, max_floor)
                floor_r = max(floor_r, context_r)
            floor_r = max(floor_r, 0.0)
        else:
            floor_r = 0.0
        if drawdown_r > 0 and release_r > 0:
            anchor_r = 0.0
            if target_r > 0 and release_r >= target_r:
                anchor_r = target_r
            else:
                anchor_r = session_floor_r
            max_drawdown = max(release_r - anchor_r, 0.0)
            if max_drawdown <= 0 and release_r > 0:
                max_drawdown = release_r
            if max_drawdown > 0:
                drawdown_r = min(drawdown_r, max_drawdown)
            else:
                drawdown_r = 0.0

        if bias_pressure > 0:
            guard_state["bias_pressure"] = round(bias_pressure, 4)
        else:
            guard_state.pop("bias_pressure", None)

        if bias_pressure > 0 and floor_escalate_at_r > 0 and bias_floor_shift_r > 0:
            floor_shift = min(bias_floor_shift_r * bias_pressure, floor_escalate_at_r)
            adjusted_floor_trigger = max(floor_r, floor_escalate_at_r - floor_shift)
            if adjusted_floor_trigger < floor_escalate_at_r:
                guard_state["floor_escalate_bias"] = {
                    "base": floor_escalate_at_r,
                    "active": adjusted_floor_trigger,
                    "pressure": round(bias_pressure, 4),
                }
                floor_escalate_at_r = adjusted_floor_trigger
            else:
                guard_state.pop("floor_escalate_bias", None)
        else:
            guard_state.pop("floor_escalate_bias", None)

        if (
            bias_pressure > 0
            and time_escalate_minutes > 0
            and bias_time_shift_minutes > 0
        ):
            max_reduction = max(0.0, time_escalate_minutes - bias_time_floor_minutes)
            reduction = min(bias_time_shift_minutes * bias_pressure, max_reduction)
            adjusted_minutes = max(bias_time_floor_minutes, time_escalate_minutes - reduction)
            if adjusted_minutes < time_escalate_minutes:
                guard_state["time_escalate_bias"] = {
                    "base": time_escalate_minutes,
                    "active": adjusted_minutes,
                    "pressure": round(bias_pressure, 4),
                }
                time_escalate_minutes = adjusted_minutes
            else:
                guard_state.pop("time_escalate_bias", None)
        else:
            guard_state.pop("time_escalate_bias", None)

        guard_state["target_r"] = target_r
        guard_state["release_r"] = release_r
        guard_state["drawdown_r"] = drawdown_r
        guard_state["relax_minutes"] = relax_minutes
        if floor_escalate_at_r > 0:
            guard_state["floor_escalate_at_r_active"] = floor_escalate_at_r
            guard_state["floor_escalate_pad_r"] = floor_escalate_pad_r
        else:
            guard_state.pop("floor_escalate_at_r_active", None)
            guard_state.pop("floor_escalate_pad_r", None)
        if time_escalate_minutes > 0:
            guard_state["time_escalate_minutes_active"] = time_escalate_minutes
            guard_state["time_escalate_target_r"] = time_escalate_target_r
            guard_state["time_escalate_min_r"] = time_escalate_min_r
            guard_state["time_escalate_pad_r"] = time_escalate_pad_r
        else:
            guard_state.pop("time_escalate_minutes_active", None)
            guard_state.pop("time_escalate_target_r", None)
            guard_state.pop("time_escalate_min_r", None)
            guard_state.pop("time_escalate_pad_r", None)
        guard_state["risk_basis_pct"] = basis_pct
        if floor_pct_override > 0 and basis_pct > 0:
            floor_r = max(floor_r, floor_pct_override / basis_pct)
            guard_state["release_floor_pct"] = float(floor_pct_override)
        else:
            guard_state.pop("release_floor_pct", None)

        if floor_r > 0:
            guard_state["release_floor_r"] = floor_r
            guard_state["floor_profit_target"] = float(basis_pct * floor_r)
        else:
            guard_state.pop("release_floor_r", None)
            guard_state.pop("floor_profit_target", None)
        guard_state["current_r"] = current_r
        guard_state["peak_r"] = (peak_profit / basis_pct) if (basis_pct > 0 and np.isfinite(peak_profit)) else float("nan")
        guard_state["last_check"] = now_ctx
        if risk_info:
            def _store_guard_metric(target: str, source: str) -> None:
                try:
                    val = float(risk_info.get(source, 0.0) or 0.0)
                except (TypeError, ValueError):
                    val = 0.0
                if val > 0:
                    guard_state[target] = val
                else:
                    guard_state.pop(target, None)

            _store_guard_metric("current_notional_usdt", "current_notional_usdt")
            _store_guard_metric("risk_unit_value_usdt", "risk_unit_value_usdt")
            _store_guard_metric("effective_leverage", "effective_leverage")

        release_stop_r_candidate = 0.0
        if release_r > 0:
            stop_candidates: List[float] = []
            if drawdown_r > 0:
                stop_candidates.append(max(0.0, release_r - drawdown_r))
            if floor_r > 0:
                stop_candidates.append(floor_r)
            if session_floor_r > 0:
                stop_candidates.append(session_floor_r)
            finite_candidates = [val for val in stop_candidates if np.isfinite(val) and val > 0]
            if finite_candidates:
                release_stop_r_candidate = max(finite_candidates)

        prev_stop_r = guard_state.get("release_stop_r")
        prev_stop_profit = guard_state.get("release_stop_profit")
        prev_stop_peak = guard_state.get("release_peak_profit")
        guard_state.pop("release_stop_r", None)
        guard_state.pop("release_stop_profit", None)
        guard_state.pop("release_peak_profit", None)

        if es_state:
            target_r *= es_ratio
            if release_r > 0:
                release_r = max(release_r * es_ratio, floor_r)
            if drawdown_r > 0:
                drawdown_r = max(0.0, drawdown_r * es_ratio)
            guard_state["es_active"] = True
            guard_state["es_ratio"] = es_ratio
            guard_state["es_cvar"] = es_state.get("cvar")
            guard_state["es_trigger"] = es_state.get("trigger")
            guard_state["es_severity"] = es_state.get("severity")
        else:
            guard_state.pop("es_active", None)
            guard_state.pop("es_ratio", None)
            guard_state.pop("es_cvar", None)
            guard_state.pop("es_trigger", None)
            guard_state.pop("es_severity", None)

        if target_r <= 0 or basis_pct <= 0:
            guard_state["active"] = False
            guard_state["satisfied"] = True
            guard_state.pop("reason", None)
            return None

        target_profit = basis_pct * target_r
        guard_state["target_profit"] = target_profit
        if current_profit >= target_profit:
            guard_state["active"] = False
            guard_state["satisfied"] = True
            guard_state["satisfied_r"] = guard_state["current_r"]
            guard_state.pop("reason", None)
            return None

        if bool(measured_state) and bool(measured_state.get("fired")):
            guard_state["active"] = False
            guard_state["satisfied"] = True
            guard_state["satisfied_r"] = guard_state["current_r"]
            guard_state.pop("reason", None)
            return None

        guard_state["age_minutes"] = age_minutes

        if relax_minutes > 0 and age_minutes >= relax_minutes:
            guard_state["active"] = False
            guard_state["satisfied"] = True
            guard_state["satisfied_r"] = guard_state["current_r"]
            guard_state.pop("reason", None)
            return None

        release_profit = basis_pct * release_r if release_r > 0 else 0.0
        drawdown_profit = basis_pct * drawdown_r if drawdown_r > 0 else 0.0
        peak_val = peak_profit if np.isfinite(peak_profit) else current_profit
        if release_profit > 0 and peak_val >= release_profit:
            guard_state["armed"] = True
            guard_state["release_peak_profit"] = float(peak_val)
            if release_stop_r_candidate > 0 and basis_pct > 0:
                guard_state["release_stop_r"] = release_stop_r_candidate
                guard_state["release_stop_profit"] = basis_pct * release_stop_r_candidate
            if drawdown_profit > 0 and (peak_val - current_profit) >= drawdown_profit:
                guard_state["active"] = False
                guard_state["satisfied"] = True
                guard_state["satisfied_r"] = guard_state["current_r"]
                guard_state.pop("reason", None)
                return None
        elif release_profit > 0:
            guard_state.pop("armed", None)
            guard_state.pop("release_peak_profit", None)
            guard_state.pop("release_stop_r", None)
            guard_state.pop("release_stop_profit", None)
        else:
            guard_state.pop("armed", None)
            guard_state.pop("release_peak_profit", None)
            guard_state.pop("release_stop_r", None)
            guard_state.pop("release_stop_profit", None)

        if floor_r > 0 and np.isfinite(current_r) and current_r >= floor_r:
            epsilon = max(1e-6, min(1e-4, floor_r * 1e-3))
            upper_r = release_stop_r_candidate if release_stop_r_candidate > 0 else floor_r
            upper_r = max(floor_r, upper_r)
            stop_r_from_floor = max(floor_r, min(upper_r, current_r - epsilon))

            if stop_r_from_floor >= current_r and current_r > floor_r:
                stop_r_from_floor = floor_r

            if stop_r_from_floor > 0 and stop_r_from_floor < current_r:
                prev_logged_r = float(guard_state.get("floor_last_log_r", 0.0) or 0.0)
                prev_logged_profit = float(guard_state.get("floor_last_log_profit", 0.0) or 0.0)
                guard_state["release_stop_r"] = float(stop_r_from_floor)
                if basis_pct > 0:
                    guard_state["release_stop_profit"] = float(basis_pct * stop_r_from_floor)
                if np.isfinite(peak_val):
                    guard_state["release_peak_profit"] = float(peak_val)
                guard_state["active"] = False
                guard_state["satisfied"] = True
                guard_state["floor_satisfied"] = True
                guard_state["satisfied_r"] = current_r
                guard_state.pop("reason", None)
                guard_state.pop("armed", None)
                guard_state["floor_last_log_r"] = float(stop_r_from_floor)
                guard_state["floor_last_log_profit"] = float(basis_pct * stop_r_from_floor if basis_pct > 0 else 0.0)
                side_cn = "空" if bool(getattr(trade, "is_short", False)) else "多"
                if (
                    not np.isclose(prev_logged_r, stop_r_from_floor, atol=1e-6)
                    or not np.isclose(prev_logged_profit, guard_state["floor_last_log_profit"], atol=1e-6)
                ):
                    logger.info(
                        "[期望守卫] %s %s 记录 %.3fR 止盈锁（≈%.4f%%），当前浮盈 %.4f%%，风险基准 %.4f%%",
                        pair,
                        side_cn,
                        stop_r_from_floor,
                        (basis_pct * stop_r_from_floor * 100.0) if basis_pct > 0 else 0.0,
                        current_profit * 100.0,
                        basis_pct * 100.0,
                    )
                return None

            if prev_stop_r and prev_stop_r > 0 and prev_stop_profit and prev_stop_profit > 0 and prev_stop_r < current_r:
                guard_state["release_stop_r"] = float(prev_stop_r)
                guard_state["release_stop_profit"] = float(prev_stop_profit)
                if prev_stop_peak:
                    guard_state["release_peak_profit"] = float(prev_stop_peak)
                guard_state["active"] = False
                guard_state["satisfied"] = True
                guard_state["floor_satisfied"] = True
                guard_state["satisfied_r"] = current_r
                guard_state.pop("reason", None)
                guard_state.pop("armed", None)
                guard_state["floor_last_log_r"] = float(prev_stop_r)
                guard_state["floor_last_log_profit"] = float(prev_stop_profit)
                return None

            logger.debug(
                "expectation_guard floor clamp deferred: %s current_r %.6f floor %.6f eps %.6f candidate %.6f",
                pair,
                current_r,
                floor_r,
                epsilon,
                stop_r_from_floor,
            )

        reason_parts = [
            f"当前 {guard_state['current_r']:.2f}R < 目标 {target_r:.2f}R"
        ]
        if floor_r > 0 and (not np.isfinite(current_r) or current_r + 1e-9 < floor_r):
            reason_parts.append(f"浮盈未达释放底线 {floor_r:.2f}R")
        if relax_minutes > 0:
            reason_parts.append(f"持仓 {age_minutes:.1f}m < {relax_minutes:.0f}m")
        if time_escalate_minutes > 0:
            if age_minutes < time_escalate_minutes:
                reason_parts.append(
                    f"等待持仓 ≥{time_escalate_minutes:.0f}m 触发时间锁盈"
                )
            elif np.isfinite(current_r) and current_r + 1e-9 < max(time_escalate_min_r, floor_r, 0.0):
                reason_parts.append(
                    f"浮盈未达时间锁盈门槛 {max(time_escalate_min_r, floor_r, 0.0):.2f}R"
                )
        if release_profit > 0:
            peak_r = guard_state["peak_r"]
            if np.isfinite(peak_r):
                reason_parts.append(f"峰值 {peak_r:.2f}R 未回撤 {drawdown_r:.2f}R")
        guard_state["reason"] = "; ".join(reason_parts)
        guard_state.setdefault("since", now_ctx)
        guard_state["active"] = True
        guard_state["satisfied"] = False
        info = {
            "reason": guard_state["reason"],
            "target_r": target_r,
            "current_r": guard_state["current_r"],
            "age_minutes": age_minutes,
            "target_profit": target_profit,
            "basis_pct": basis_pct,
            "release_r": release_r,
            "drawdown_r": drawdown_r,
            "peak_r": guard_state["peak_r"],
        }
        if floor_r > 0:
            info["floor_r"] = floor_r
            info["floor_profit"] = float(basis_pct * floor_r)
        if desired_floor_r is not None and desired_floor_r > 0:
            info["floor_escalate_r"] = float(desired_floor_r)
        if time_floor_candidate is not None and time_floor_candidate > 0:
            info["time_floor_candidate_r"] = float(time_floor_candidate)
        return info

    def _update_channel_pivot_state(
        self,
        st: Dict[str, Any],
        row: pd.Series,
        now: datetime,
        row_ts: datetime,
    ) -> Dict[str, Any]:
        """教学提示：维护最近一次 Keltner 突破的方向与回落状态。"""

        if not bool(getattr(self, "CHANNEL_PIVOT_ENABLE", True)):
            return {}

        state = st.setdefault("channel_pivot", {})
        regime_before = state.get("regime", "neutral")
        state.setdefault("regime", "neutral")

        outside_up = int(row.get("kel_outside_up", 0) or 0)
        outside_dn = int(row.get("kel_outside_dn", 0) or 0)
        break_up = int(row.get("kel_break_up_now", 0) or 0)
        break_dn = int(row.get("kel_break_dn_now", 0) or 0)
        pos = float(row.get("price_position", 0.5) or 0.5)

        clear_low = float(getattr(self, "CHANNEL_PIVOT_CLEAR_POS_LOW", 0.36))
        clear_high = float(getattr(self, "CHANNEL_PIVOT_CLEAR_POS_HIGH", 0.64))
        clear_bars = max(1, int(getattr(self, "CHANNEL_PIVOT_CLEAR_BARS", 3)))
        inside_count = int(state.get("inside_count", 0))

        if outside_up:
            state["regime"] = "up_break"
            state["since_ts"] = row_ts
            state["since_time"] = now
            state["last_break"] = "up"
            state["inside_count"] = 0
            if break_up:
                state["pullback_taken"] = False
                state.pop("pullback_ts", None)
        elif outside_dn:
            state["regime"] = "down_break"
            state["since_ts"] = row_ts
            state["since_time"] = now
            state["last_break"] = "down"
            state["inside_count"] = 0
            if break_dn:
                state["pullback_taken"] = False
                state.pop("pullback_ts", None)
        else:
            if clear_low <= pos <= clear_high:
                inside_count += 1
            else:
                inside_count = 0
            state["inside_count"] = inside_count
            if inside_count >= clear_bars:
                state["regime"] = "neutral"
                state["since_ts"] = row_ts
                state["since_time"] = now
                state["pullback_taken"] = False
                state.pop("pullback_ts", None)

        state["last_ts"] = row_ts
        regime = state.get("regime", "neutral")
        info = {
            "channel_regime": regime,
            "channel_last_break": state.get("last_break", ""),
            "channel_pullback_taken": int(bool(state.get("pullback_taken", False))),
            "channel_inside_count": int(state.get("inside_count", 0)),
            "channel_pivot_age": self._bars_since(state.get("since_ts"), row_ts),
        }
        if regime_before != regime and self.DEBUG_LOG:
            self._d(
                f"[pivot_state] regime={regime_before}->{regime} pos={pos:.3f} inside={inside_count} pair_state={st.get('pair')}"
            )
        return info

    def _channel_pivot_guard(
        self,
        *,
        pair: str,
        side: str,
        row: pd.Series,
        st: Dict[str, Any],
        align_score: float,
        now: datetime,
        row_ts: datetime,
        pair_cfg: Optional[Dict[str, Any]] = None,
    ) -> Tuple[bool, Optional[str], Optional[Dict[str, Any]], Dict[str, Any]]:
        """教学提示：突破后短期内避免反复反手或在极值区继续追价。"""

        if not bool(getattr(self, "CHANNEL_PIVOT_ENABLE", True)):
            return True, None, None, {}

        state = st.setdefault("channel_pivot", {})
        regime = state.get("regime", "neutral") or "neutral"
        snapshot = {
            "channel_regime": regime,
            "channel_last_break": state.get("last_break", ""),
            "channel_pullback_taken": int(bool(state.get("pullback_taken", False))),
            "channel_pivot_age": self._bars_since(state.get("since_ts"), row_ts),
        }

        if regime not in ("up_break", "down_break"):
            return True, None, None, snapshot

        pos = float(row.get("price_position", 0.5) or 0.5)
        kel_up = float(row.get("kel_up", 0.0) or 0.0)
        kel_dn = float(row.get("kel_dn", 0.0) or 0.0)
        kel_mid = float(row.get("kel_mid", 0.0) or 0.0)
        close = float(row.get("close", 0.0) or 0.0)
        width = max(1e-9, kel_up - kel_dn)
        below_mid_frac = max(0.0, (kel_mid - close) / width)
        above_mid_frac = max(0.0, (close - kel_mid) / width)
        lookback = max(1, int(getattr(self, "CHANNEL_PIVOT_LOOKBACK_BARS", 9)))
        cooldown = max(0, int(getattr(self, "CHANNEL_PIVOT_PULLBACK_COOLDOWN", 4)))
        age_bars = snapshot["channel_pivot_age"]

        follow_override: Dict[str, Any] = {}
        if isinstance(pair_cfg, dict):
            cp_cfg = pair_cfg.get("channel_pivot")
            if isinstance(cp_cfg, dict):
                follow_block = cp_cfg.get("follow_up")
                if isinstance(follow_block, dict):
                    follow_override = follow_block

        if regime == "up_break" and side == "short":
            revert_pos = float(getattr(self, "CHANNEL_PIVOT_UP_REVERT_POS", 0.58))
            align_need = float(getattr(self, "CHANNEL_PIVOT_UP_ALIGN_NEED", 0.34))
            mid_frac_need = float(getattr(self, "CHANNEL_PIVOT_UP_MID_FRAC", 0.14))
            revert_ok = (
                pos <= revert_pos
                or below_mid_frac >= mid_frac_need
                or align_score <= -align_need
                or age_bars >= lookback
            )
            if state.get("pullback_taken"):
                bars_since_pull = self._bars_since(state.get("pullback_ts"), row_ts)
                snapshot["channel_pullback_cooldown"] = bars_since_pull
                if cooldown and bars_since_pull < cooldown:
                    revert_ok = False
                    snapshot["channel_pullback_limit"] = cooldown
            if not revert_ok:
                extra = dict(snapshot)
                extra.update({
                    "price_position": round(pos, 4),
                    "align": round(float(align_score), 4),
                    "below_mid_frac": round(below_mid_frac, 4),
                    "pivot_need_pos": revert_pos,
                    "pivot_need_mid": mid_frac_need,
                    "pivot_need_align": -align_need,
                })
                return False, "Keltner 上沿突破后回调尚未确认反转", extra, snapshot

        if regime == "down_break" and side == "long":
            revert_pos = float(getattr(self, "CHANNEL_PIVOT_DOWN_REVERT_POS", 0.42))
            align_need = float(getattr(self, "CHANNEL_PIVOT_DOWN_ALIGN_NEED", 0.34))
            mid_frac_need = float(getattr(self, "CHANNEL_PIVOT_DOWN_MID_FRAC", 0.14))
            revert_ok = (
                pos >= revert_pos
                or above_mid_frac >= mid_frac_need
                or align_score >= align_need
                or age_bars >= lookback
            )
            if state.get("pullback_taken"):
                bars_since_pull = self._bars_since(state.get("pullback_ts"), row_ts)
                snapshot["channel_pullback_cooldown"] = bars_since_pull
                if cooldown and bars_since_pull < cooldown:
                    revert_ok = False
                    snapshot["channel_pullback_limit"] = cooldown
            if not revert_ok:
                extra = dict(snapshot)
                extra.update({
                    "price_position": round(pos, 4),
                    "align": round(float(align_score), 4),
                    "above_mid_frac": round(above_mid_frac, 4),
                    "pivot_need_pos": revert_pos,
                    "pivot_need_mid": mid_frac_need,
                    "pivot_need_align": align_need,
                })
                return False, "Keltner 下沿突破后反弹尚未确认反转", extra, snapshot

        if regime == "up_break" and side == "long":
            follow_wait = int(follow_override.get("up_wait", getattr(self, "CHANNEL_PIVOT_UP_FOLLOW_WAIT", 0)))
            follow_retrace = float(follow_override.get("up_retrace", getattr(self, "CHANNEL_PIVOT_UP_FOLLOW_RETRACE", 0.0)))
            follow_pos = float(follow_override.get("up_pos", getattr(self, "CHANNEL_PIVOT_UP_FOLLOW_POS", 1.0)))
            follow_ok = (
                (follow_wait <= 0 or age_bars >= follow_wait)
                or (follow_retrace <= 0 or below_mid_frac >= follow_retrace)
                or (np.isfinite(follow_pos) and pos <= follow_pos)
            )
            if not follow_ok:
                extra = dict(snapshot)
                extra.update({
                    "price_position": round(pos, 4),
                    "follow_wait": follow_wait,
                    "follow_retrace_need": follow_retrace,
                    "follow_pos_need": follow_pos,
                })
                return False, "突破刚发生，等待回踩后再加多", extra, snapshot

        if regime == "down_break" and side == "short":
            follow_wait = int(follow_override.get("down_wait", getattr(self, "CHANNEL_PIVOT_DOWN_FOLLOW_WAIT", 0)))
            follow_retrace = float(follow_override.get("down_retrace", getattr(self, "CHANNEL_PIVOT_DOWN_FOLLOW_RETRACE", 0.0)))
            follow_pos = float(follow_override.get("down_pos", getattr(self, "CHANNEL_PIVOT_DOWN_FOLLOW_POS", 0.0)))
            follow_ok = (
                (follow_wait <= 0 or age_bars >= follow_wait)
                or (follow_retrace <= 0 or above_mid_frac >= follow_retrace)
                or (np.isfinite(follow_pos) and pos >= follow_pos)
            )
            if not follow_ok:
                extra = dict(snapshot)
                extra.update({
                    "price_position": round(pos, 4),
                    "follow_wait": follow_wait,
                    "follow_retrace_need": follow_retrace,
                    "follow_pos_need": follow_pos,
                })
                return False, "跌破刚发生，等待反弹后再加空", extra, snapshot

        return True, None, None, snapshot

    def _entry_quality_default_settings(self) -> Dict[str, Any]:
        """教学提示：读取当前 ENTRY_QUALITY_* 配置，提供覆盖/归一化的基础值。"""

        enable = bool(getattr(self, "ENTRY_QUALITY_ENABLE", self.ENTRY_QUALITY_ENABLE))
        align_weight = float(getattr(self, "ENTRY_QUALITY_ALIGN_WEIGHT", self.ENTRY_QUALITY_ALIGN_WEIGHT))
        tri_weight = float(getattr(self, "ENTRY_QUALITY_TRI_WEIGHT", self.ENTRY_QUALITY_TRI_WEIGHT))
        rfs_weight = float(getattr(self, "ENTRY_QUALITY_RFS_WEIGHT", self.ENTRY_QUALITY_RFS_WEIGHT))
        priority_weight = float(getattr(self, "ENTRY_QUALITY_PRIORITY_WEIGHT", self.ENTRY_QUALITY_PRIORITY_WEIGHT))

        settings: Dict[str, Any] = {
            "enable": enable,
            "align_weight": align_weight,
            "tri_weight": tri_weight,
            "rfs_weight": rfs_weight,
            "priority_weight": priority_weight,
            "fast_bonus": float(getattr(self, "ENTRY_QUALITY_FAST_BONUS", self.ENTRY_QUALITY_FAST_BONUS)),
            "slow_bonus": float(getattr(self, "ENTRY_QUALITY_SLOW_BONUS", self.ENTRY_QUALITY_SLOW_BONUS)),
            "htf_bonus": float(getattr(self, "ENTRY_QUALITY_HTF_BONUS", self.ENTRY_QUALITY_HTF_BONUS)),
            "channel_bonus": float(getattr(self, "ENTRY_QUALITY_CHANNEL_BONUS", self.ENTRY_QUALITY_CHANNEL_BONUS)),
            "decay_penalty": float(getattr(self, "ENTRY_QUALITY_DECAY_PENALTY", self.ENTRY_QUALITY_DECAY_PENALTY)),
            "vol_bonus": float(getattr(self, "ENTRY_QUALITY_VOL_BONUS", self.ENTRY_QUALITY_VOL_BONUS)),
            "price_ceil": float(getattr(self, "ENTRY_QUALITY_PRICE_CEIL", self.ENTRY_QUALITY_PRICE_CEIL)),
            "price_floor": float(getattr(self, "ENTRY_QUALITY_PRICE_FLOOR", self.ENTRY_QUALITY_PRICE_FLOOR)),
            "price_weight": float(getattr(self, "ENTRY_QUALITY_PRICE_WEIGHT", self.ENTRY_QUALITY_PRICE_WEIGHT)),
            "price_anchor_weight": float(getattr(self, "ENTRY_QUALITY_PRICE_ANCHOR_WEIGHT", self.ENTRY_QUALITY_PRICE_ANCHOR_WEIGHT)),
            "base_need": float(getattr(self, "ENTRY_QUALITY_BASE_NEED", self.ENTRY_QUALITY_BASE_NEED)),
            "slow_need": float(getattr(self, "ENTRY_QUALITY_SLOW_NEED", self.ENTRY_QUALITY_SLOW_NEED)),
            "fast_need": float(getattr(self, "ENTRY_QUALITY_FAST_NEED", self.ENTRY_QUALITY_FAST_NEED)),
            "dynamic_add": float(getattr(self, "ENTRY_QUALITY_DYNAMIC_ADD", self.ENTRY_QUALITY_DYNAMIC_ADD)),
            "fragile_add": float(getattr(self, "ENTRY_QUALITY_FRAGILE_ADD", self.ENTRY_QUALITY_FRAGILE_ADD)),
            "extreme_add": float(getattr(self, "ENTRY_QUALITY_EXTREME_ADD", self.ENTRY_QUALITY_EXTREME_ADD)),
            "decay_add": float(getattr(self, "ENTRY_QUALITY_DECAY_ADD", self.ENTRY_QUALITY_DECAY_ADD)),
            "prefer_relief": float(getattr(self, "ENTRY_QUALITY_PREFER_RELIEF", self.ENTRY_QUALITY_PREFER_RELIEF)),
            "need_buffer": float(getattr(self, "ENTRY_QUALITY_NEED_BUFFER", self.ENTRY_QUALITY_NEED_BUFFER)),
            "need_buffer_fast_mult": float(getattr(self, "ENTRY_QUALITY_NEED_BUFFER_FAST_MULT", self.ENTRY_QUALITY_NEED_BUFFER_FAST_MULT)),
            "need_buffer_slow_mult": float(getattr(self, "ENTRY_QUALITY_NEED_BUFFER_SLOW_MULT", self.ENTRY_QUALITY_NEED_BUFFER_SLOW_MULT)),
            "need_buffer_extreme_mult": float(getattr(self, "ENTRY_QUALITY_NEED_BUFFER_EXTREME_MULT", self.ENTRY_QUALITY_NEED_BUFFER_EXTREME_MULT)),
            "pullback_bonus": float(getattr(self, "ENTRY_QUALITY_PULLBACK_BONUS", self.ENTRY_QUALITY_PULLBACK_BONUS)),
            "pullback_penalty": float(getattr(self, "ENTRY_QUALITY_PULLBACK_PENALTY", self.ENTRY_QUALITY_PULLBACK_PENALTY)),
            "pass_ratio_min": float(getattr(self, "ENTRY_QUALITY_PASS_RATIO_MIN", self.ENTRY_QUALITY_PASS_RATIO_MIN)),
            "pass_ratio_fast_min": float(getattr(self, "ENTRY_QUALITY_PASS_RATIO_FAST_MIN", self.ENTRY_QUALITY_PASS_RATIO_FAST_MIN)),
            "pass_ratio_slow_min": float(getattr(self, "ENTRY_QUALITY_PASS_RATIO_SLOW_MIN", self.ENTRY_QUALITY_PASS_RATIO_SLOW_MIN)),
            "pass_ratio_extreme_min": float(getattr(self, "ENTRY_QUALITY_PASS_RATIO_EXTREME_MIN", self.ENTRY_QUALITY_PASS_RATIO_EXTREME_MIN)),
        }

        settings["_fallback_weights"] = (
            align_weight,
            tri_weight,
            rfs_weight,
            priority_weight,
        )
        return settings

    def _entry_quality_parse_overrides(
        self,
        overrides: Optional[Dict[str, Any]],
        *,
        scope: str,
    ) -> Dict[str, Any]:
        """教学提示：将 entry_quality 覆盖项解析成扁平键值对。"""

        if not isinstance(overrides, dict) or not overrides:
            return {}

        flat: Dict[str, Any] = {}

        def _flatten(prefix: str, value: Any) -> None:
            if isinstance(value, dict):
                for sub_key, sub_val in value.items():
                    if not isinstance(sub_key, str):
                        continue
                    new_prefix = f"{prefix}_{sub_key}" if prefix else str(sub_key)
                    _flatten(new_prefix, sub_val)
            else:
                if prefix:
                    flat[prefix] = value

        _flatten("", overrides)

        alias_map: Dict[str, str] = {
            "enable": "enable",
            "align_weight": "align_weight",
            "weights_align": "align_weight",
            "align": "align_weight",
            "tri_weight": "tri_weight",
            "weights_tri": "tri_weight",
            "tri": "tri_weight",
            "rfs_weight": "rfs_weight",
            "weights_rfs": "rfs_weight",
            "rfs": "rfs_weight",
            "priority_weight": "priority_weight",
            "weights_priority": "priority_weight",
            "priority": "priority_weight",
            "fast_bonus": "fast_bonus",
            "bonus_fast": "fast_bonus",
            "slow_bonus": "slow_bonus",
            "bonus_slow": "slow_bonus",
            "htf_bonus": "htf_bonus",
            "bonus_htf": "htf_bonus",
            "channel_bonus": "channel_bonus",
            "bonus_channel": "channel_bonus",
            "decay_penalty": "decay_penalty",
            "penalty_decay": "decay_penalty",
            "vol_bonus": "vol_bonus",
            "bonus_vol": "vol_bonus",
            "price_ceil": "price_ceil",
            "price_ceiling": "price_ceil",
            "price_floor": "price_floor",
            "price_weight": "price_weight",
            "price_anchor_weight": "price_anchor_weight",
            "base_need": "base_need",
            "needs_base": "base_need",
            "slow_need": "slow_need",
            "needs_slow": "slow_need",
            "fast_need": "fast_need",
            "needs_fast": "fast_need",
            "dynamic_add": "dynamic_add",
            "add_dynamic": "dynamic_add",
            "fragile_add": "fragile_add",
            "add_fragile": "fragile_add",
            "extreme_add": "extreme_add",
            "add_extreme": "extreme_add",
            "decay_add": "decay_add",
            "add_decay": "decay_add",
            "prefer_relief": "prefer_relief",
            "relief_prefer": "prefer_relief",
            "need_buffer": "need_buffer",
            "buffer": "need_buffer",
            "needbuffer": "need_buffer",
            "need_buffer_fast": "need_buffer_fast_mult",
            "need_buffer_fast_mult": "need_buffer_fast_mult",
            "need_buffer_slow": "need_buffer_slow_mult",
            "need_buffer_slow_mult": "need_buffer_slow_mult",
            "need_buffer_extreme": "need_buffer_extreme_mult",
            "need_buffer_extreme_mult": "need_buffer_extreme_mult",
            "pullback_bonus": "pullback_bonus",
            "pullback_penalty": "pullback_penalty",
        }

        parsed: Dict[str, Any] = {}

        def _normalize_key(key: str) -> str:
            text = str(key).strip().lower()
            text = text.replace("-", "_").replace(" ", "_").replace(".", "_")
            if text.startswith("entry_quality_"):
                text = text[len("entry_quality_") :]
            return text

        for raw_key, raw_value in flat.items():
            norm_key = _normalize_key(raw_key)
            target = alias_map.get(norm_key)
            if not target:
                continue
            if target == "enable":
                parsed[target] = bool(raw_value)
            else:
                try:
                    value_f = float(raw_value)
                except (TypeError, ValueError):
                    logger.warning(
                        "ENTRY_QUALITY 覆盖项 %s=%r 无法解析为浮点数（scope=%s），已忽略。",
                        raw_key,
                        raw_value,
                        scope,
                    )
                    continue
                if not np.isfinite(value_f):
                    logger.warning(
                        "ENTRY_QUALITY 覆盖项 %s=%r 不是有限值（scope=%s），已忽略。",
                        raw_key,
                        raw_value,
                        scope,
                    )
                    continue
                parsed[target] = value_f

        return parsed

    def _normalize_entry_quality_weights(
        self,
        settings: Dict[str, Any],
        fallback_weights: Tuple[float, float, float, float],
        *,
        scope: str,
        log: bool = False,
    ) -> None:
        """教学提示：确保权重和为 1；如输入无效则回退到默认权重。"""

        align_weight = float(settings.get("align_weight", fallback_weights[0]))
        tri_weight = float(settings.get("tri_weight", fallback_weights[1]))
        rfs_weight = float(settings.get("rfs_weight", fallback_weights[2]))
        priority_weight = float(settings.get("priority_weight", fallback_weights[3]))

        total_weight = align_weight + tri_weight + rfs_weight + priority_weight
        if not np.isfinite(total_weight) or total_weight <= 0:
            settings["align_weight"] = fallback_weights[0]
            settings["tri_weight"] = fallback_weights[1]
            settings["rfs_weight"] = fallback_weights[2]
            settings["priority_weight"] = fallback_weights[3]
            if log:
                logger.warning(
                    "ENTRY_QUALITY 权重总和 %.4f 非法（scope=%s），已回退至 %.3f/%.3f/%.3f/%.3f。",
                    total_weight,
                    scope,
                    *fallback_weights,
                )
            return

        if not np.isclose(total_weight, 1.0):
            settings["align_weight"] = align_weight / total_weight
            settings["tri_weight"] = tri_weight / total_weight
            settings["rfs_weight"] = rfs_weight / total_weight
            settings["priority_weight"] = priority_weight / total_weight
            if log:
                logger.warning(
                    "ENTRY_QUALITY 权重总和 %.4f ≠ 1.0（scope=%s），已自动归一。",
                    total_weight,
                    scope,
                )

    def _entry_quality_settings(
        self,
        overrides: Optional[Dict[str, Any]] = None,
        *,
        scope: str = "runtime",
        log: bool = False,
    ) -> Dict[str, Any]:
        """教学提示：合并默认设置与覆盖项，并确保权重归一。"""

        base = self._entry_quality_default_settings()
        fallback_weights = tuple(base.get("_fallback_weights", (0.36, 0.27, 0.21, 0.16)))
        settings = dict(base)
        settings.pop("_fallback_weights", None)

        side_overrides: Dict[str, Dict[str, Any]] = {}
        overrides_common: Optional[Dict[str, Any]] = overrides
        if isinstance(overrides, dict) and overrides:
            overrides_common = {}
            for key, value in overrides.items():
                key_lower = str(key).strip().lower()
                if key_lower in {"long", "short"} and isinstance(value, dict):
                    side_overrides[key_lower] = value
                else:
                    overrides_common[key] = value

        if overrides_common:
            parsed = self._entry_quality_parse_overrides(overrides_common, scope=scope)
            if parsed:
                settings.update(parsed)

        self._normalize_entry_quality_weights(settings, fallback_weights, scope=scope, log=log)

        # 保持阈值在合理区间
        for key in ("base_need", "slow_need", "fast_need"):
            try:
                settings[key] = float(np.clip(float(settings.get(key, 0.0)), 0.0, 0.95))
            except (TypeError, ValueError):
                settings[key] = float(np.clip(fallback_weights[0], 0.0, 0.95))
        for key in ("fast_bonus", "slow_bonus", "htf_bonus", "channel_bonus", "vol_bonus", "decay_penalty",
                    "dynamic_add", "fragile_add", "extreme_add", "decay_add", "prefer_relief"):
            try:
                settings[key] = float(settings.get(key, 0.0))
            except (TypeError, ValueError):
                settings[key] = 0.0
        settings["price_ceil"] = float(np.clip(settings.get("price_ceil", 0.76), 0.0, 1.0))
        settings["price_floor"] = float(np.clip(settings.get("price_floor", 0.24), 0.0, 1.0))
        settings["price_weight"] = float(max(0.0, settings.get("price_weight", 0.14)))
        for key in ("price_anchor_weight", "pullback_bonus", "pullback_penalty"):
            try:
                settings[key] = float(settings.get(key, base.get(key, 0.0)))
            except (TypeError, ValueError):
                settings[key] = float(base.get(key, 0.0))
        for key in (
            "need_buffer",
            "need_buffer_fast_mult",
            "need_buffer_slow_mult",
            "need_buffer_extreme_mult",
        ):
            try:
                settings[key] = float(settings.get(key, base.get(key, 0.0)))
            except (TypeError, ValueError):
                settings[key] = float(base.get(key, 0.0))

        if side_overrides:
            per_side: Dict[str, Dict[str, Any]] = {}
            base_snapshot = dict(settings)
            base_snapshot.pop("_per_side", None)
            for side_key, side_cfg in side_overrides.items():
                parsed_side = self._entry_quality_parse_overrides(side_cfg, scope=f"{scope}:{side_key}")
                if not parsed_side:
                    continue
                side_settings = dict(base_snapshot)
                side_settings.update(parsed_side)
                self._normalize_entry_quality_weights(
                    side_settings,
                    fallback_weights,
                    scope=f"{scope}:{side_key}",
                    log=log,
                )
                for key in ("base_need", "slow_need", "fast_need"):
                    try:
                        side_settings[key] = float(np.clip(float(side_settings.get(key, 0.0)), 0.0, 0.95))
                    except (TypeError, ValueError):
                        side_settings[key] = float(np.clip(fallback_weights[0], 0.0, 0.95))
                for key in (
                    "fast_bonus",
                    "slow_bonus",
                    "htf_bonus",
                    "channel_bonus",
                    "vol_bonus",
                    "decay_penalty",
                    "dynamic_add",
                    "fragile_add",
                    "extreme_add",
                    "decay_add",
                    "prefer_relief",
                ):
                    try:
                        side_settings[key] = float(side_settings.get(key, 0.0))
                    except (TypeError, ValueError):
                        side_settings[key] = 0.0
                side_settings["price_ceil"] = float(np.clip(side_settings.get("price_ceil", settings["price_ceil"]), 0.0, 1.0))
                side_settings["price_floor"] = float(np.clip(side_settings.get("price_floor", settings["price_floor"]), 0.0, 1.0))
                side_settings["price_weight"] = float(max(0.0, side_settings.get("price_weight", settings["price_weight"])))
                for key in (
                    "need_buffer",
                    "need_buffer_fast_mult",
                    "need_buffer_slow_mult",
                    "need_buffer_extreme_mult",
                ):
                    try:
                        side_settings[key] = float(side_settings.get(key, settings.get(key)))
                    except (TypeError, ValueError):
                        side_settings[key] = float(settings.get(key))
                per_side[side_key] = side_settings
            if per_side:
                settings["_per_side"] = per_side

        if log:
            logger.info(
                "ENTRY_QUALITY 配置生效（%s）：权重 align=%.3f tri=%.3f rfs=%.3f priority=%.3f | need=%.3f/%.3f/%.3f | 奖励 fast=%.3f slow=%.3f htf=%.3f channel=%.3f",
                scope,
                settings["align_weight"],
                settings["tri_weight"],
                settings["rfs_weight"],
                settings["priority_weight"],
                settings["base_need"],
                settings["slow_need"],
                settings["fast_need"],
                settings["fast_bonus"],
                settings["slow_bonus"],
                settings["htf_bonus"],
                settings["channel_bonus"],
            )

        return settings

    def _signal_filter_settings(self, pair_cfg: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """读取信号质量/深度过滤配置（默认开启，可在 pair_overrides 调低或关闭）。"""

        settings = {
            "enable": bool(getattr(self, "SIGNAL_FILTER_ENABLE", False)),
            "strength_threshold": float(getattr(self, "SIGNAL_STRENGTH_THRESHOLD", 0.0)),
            "volume_filter": float(getattr(self, "SIGNAL_VOLUME_FILTER", 0.0)),
            "multi_tf_enable": bool(getattr(self, "SIGNAL_MULTI_TF_ENABLE", False)),
            "multi_tf_weight": float(getattr(self, "SIGNAL_MULTI_TF_WEIGHT", 0.35)),
            "depth_enable": bool(getattr(self, "SIGNAL_DEPTH_ENABLE", False)),
            "depth_weight": float(getattr(self, "SIGNAL_DEPTH_WEIGHT", 0.25)),
            "ob_imbalance_need": float(getattr(self, "SIGNAL_OB_IMBALANCE_NEED", 0.0)),
            "flow_rate_need": float(getattr(self, "SIGNAL_FLOW_RATE_NEED", 0.0)),
            "exit_cluster_enable": bool(getattr(self, "SIGNAL_EXIT_CLUSTER_ENABLE", False)),
            "exit_cluster_weight": float(getattr(self, "SIGNAL_EXIT_CLUSTER_WEIGHT", 0.0)),
            "exit_cluster_window": int(getattr(self, "SIGNAL_EXIT_CLUSTER_WINDOW", 0)),
            "exit_cluster_min": float(getattr(self, "SIGNAL_EXIT_CLUSTER_MIN", 0.0)),
        }

        if isinstance(pair_cfg, dict):
            overrides = pair_cfg.get("signal_filters") or pair_cfg.get("signal")
            if isinstance(overrides, dict):
                for key, dest in {
                    "enable": "enable",
                    "strength_threshold": "strength_threshold",
                    "volume_filter": "volume_filter",
                    "multi_tf_enable": "multi_tf_enable",
                    "multi_tf_weight": "multi_tf_weight",
                    "depth_enable": "depth_enable",
                    "depth_weight": "depth_weight",
                    "orderbook_imbalance_need": "ob_imbalance_need",
                    "ob_imbalance_need": "ob_imbalance_need",
                    "flow_rate_need": "flow_rate_need",
                    "exit_cluster_enable": "exit_cluster_enable",
                    "exit_cluster_weight": "exit_cluster_weight",
                    "exit_cluster_window": "exit_cluster_window",
                    "exit_cluster_min": "exit_cluster_min",
                }.items():
                    if key in overrides:
                        try:
                            if isinstance(settings.get(dest), bool):
                                settings[dest] = bool(overrides.get(key))
                            else:
                                settings[dest] = float(overrides.get(key))
                        except (TypeError, ValueError):
                            continue

        return settings

    def _signal_quality_gate(
        self,
        *,
        side: str,
        quality_score: float,
        quality_need: float,
        align_score: float,
        tri_bias: float,
        rfs_value: float,
        volume: float,
        volume_ma: float,
        orderbook_imbalance: float,
        flow_rate: float,
        exit_cluster_score: float,
        settings: Dict[str, Any],
    ) -> Tuple[bool, Optional[str], Dict[str, Any]]:
        """信号质量注释 + 多周期确认 + 盘口深度过滤（默认仅记录，不改变旧版行为）。"""

        tags: List[str] = []
        enforce = bool(settings.get("enable", False))
        meta: Dict[str, Any] = {"signal_filter_enabled": enforce}
        if not enforce:
            tags.append("signal.filter_disabled")

        # 基础质量线（沿用质量分/需求分数）
        strength_threshold = float(settings.get("strength_threshold", 0.0) or 0.0)
        quality_pass = True
        if strength_threshold > 0 and quality_score < strength_threshold:
            quality_pass = False
            tags.append(f"signal.strength<th={strength_threshold:.3f}")
        meta["quality_strength_threshold"] = strength_threshold

        # 成交量过滤：近期成交量/均值
        volume_filter = float(settings.get("volume_filter", 0.0) or 0.0)
        volume_ratio = float("nan")
        if volume_ma and np.isfinite(volume_ma) and volume_ma > 0:
            volume_ratio = float(volume) / float(volume_ma)
            meta["signal_volume_ratio"] = round(float(volume_ratio), 4)
            meta["signal_volume_filter"] = volume_filter
            if volume_filter > 0 and volume_ratio < volume_filter:
                quality_pass = False
                tags.append(f"signal.volume<{volume_filter:.3f}")

        # 多周期确认组件（对齐/三锚/动能简化得分）
        multi_tf_score = float("nan")
        if bool(settings.get("multi_tf_enable", False)):
            align_component = max(0.0, align_score)
            tri_component = max(0.0, tri_bias)
            rfs_component = max(0.0, rfs_value)
            multi_tf_score = float(np.clip((align_component + tri_component + rfs_component) / 3.0, 0.0, 1.0))
            meta["multi_tf_score"] = round(multi_tf_score, 4)
            tags.append("signal.multitf_on")

        # 盘口深度/流速组件
        depth_score = float("nan")
        depth_enabled = bool(settings.get("depth_enable", False))
        if depth_enabled:
            imbalance_need = float(settings.get("ob_imbalance_need", 0.0) or 0.0)
            flow_need = float(settings.get("flow_rate_need", 0.0) or 0.0)
            ob_ok = True
            flow_ok = True
            if np.isfinite(orderbook_imbalance):
                meta["orderbook_imbalance"] = round(float(orderbook_imbalance), 4)
                if imbalance_need != 0.0:
                    if side == "long" and orderbook_imbalance < imbalance_need:
                        ob_ok = False
                    if side == "short" and orderbook_imbalance > -imbalance_need:
                        ob_ok = False
            if np.isfinite(flow_rate):
                meta["orderflow_rate"] = round(float(flow_rate), 4)
                if flow_need > 0 and abs(flow_rate) < flow_need:
                    flow_ok = False
            depth_score = 1.0 if ob_ok and flow_ok else 0.0
            meta["depth_score"] = depth_score
            meta["depth_enable"] = True
            if not ob_ok:
                tags.append("signal.ob_imbalance_block")
            if not flow_ok:
                tags.append("signal.flow_block")
            quality_pass = quality_pass and ob_ok and flow_ok

        # 汇总质量分（仅作为注释，避免改变原有阈值决策）
        final_score = quality_score
        weight_total = 1.0
        multi_tf_weight = float(settings.get("multi_tf_weight", 0.0) or 0.0)
        depth_weight = float(settings.get("depth_weight", 0.0) or 0.0)
        if np.isfinite(multi_tf_score):
            weight_total += multi_tf_weight
            final_score += multi_tf_score * multi_tf_weight
        if np.isfinite(depth_score):
            weight_total += depth_weight
            final_score += depth_score * depth_weight
        if bool(settings.get("exit_cluster_enable", False)) and np.isfinite(exit_cluster_score):
            cluster_weight = float(settings.get("exit_cluster_weight", 0.0) or 0.0)
            cluster_need = max(0.0, float(settings.get("exit_cluster_min", 0.0) or 0.0))
            meta["exit_cluster_score"] = round(float(exit_cluster_score), 4)
            meta["exit_cluster_need"] = round(cluster_need, 4)
            if cluster_weight > 0:
                if exit_cluster_score > cluster_need:
                    bonus = max(0.0, exit_cluster_score - cluster_need) * cluster_weight
                    weight_total += cluster_weight
                    final_score += bonus
                    tags.append("signal.exit_cluster_on")
                else:
                    tags.append("signal.exit_cluster_on_no_density")
            else:
                tags.append("signal.exit_cluster_obs")
        if weight_total > 0:
            final_score = float(final_score / weight_total)
        meta.update(
            {
                "signal_quality_final": round(float(final_score), 4),
                "signal_quality_need": round(float(quality_need), 4),
                "signal_tags": tags,
                "signal_filter_enforce": enforce,
                "signal_filter_pass": bool(quality_pass),
            }
        )

        if not quality_pass:
            if enforce:
                meta["signal_filter_blocked"] = True
                return False, "信号质量过滤未通过", meta
            meta["signal_filter_would_block"] = True
        else:
            meta["signal_filter_blocked"] = False

        return True, None, meta

    # -------------------- 风险预测配置 --------------------
    def _risk_forecast_default_settings(self) -> Dict[str, Any]:
        return {
            "mode": str(getattr(self, "RISK_FORECAST_MODE", "atr") or "atr").lower(),
            "ewma_alpha": float(getattr(self, "RISK_FORECAST_EWMA_ALPHA", 0.35) or 0.35),
            "ewma_source": str(getattr(self, "RISK_FORECAST_EWMA_SOURCE", "5m") or "5m").lower(),
            "har_windows": tuple(int(x) for x in getattr(self, "RISK_FORECAST_HAR_WINDOWS", (6, 24, 72))),
            "mix_atr": float(getattr(self, "RISK_FORECAST_MIX_ATR_SHARE", 0.5) or 0.0),
            "mix_ewma": float(getattr(self, "RISK_FORECAST_MIX_EWMA_SHARE", 0.3) or 0.0),
            "mix_har": float(getattr(self, "RISK_FORECAST_MIX_HAR_SHARE", 0.2) or 0.0),
            "scale": float(getattr(self, "RISK_FORECAST_SCALE", 1.0) or 1.0),
            "min_pct": float(max(0.0, getattr(self, "RISK_FORECAST_MIN_PCT", 0.0) or 0.0)),
            "max_pct": float(max(0.0, getattr(self, "RISK_FORECAST_MAX_PCT", 0.0) or 0.0)),
        }

    def _risk_forecast_settings(
        self,
        overrides: Optional[Dict[str, Any]],
        *,
        scope: str = "runtime",
        log: bool = False,
        include_defaults: bool = True,
    ) -> Dict[str, Any]:
        settings = self._risk_forecast_default_settings() if include_defaults else {}
        if isinstance(overrides, dict):
            mode_raw = overrides.get("mode")
            if mode_raw is not None:
                settings["mode"] = str(mode_raw).lower()
            if "ewma_alpha" in overrides:
                try:
                    alpha = float(overrides.get("ewma_alpha", settings.get("ewma_alpha", 0.35)))
                except (TypeError, ValueError):
                    alpha = settings.get("ewma_alpha", 0.35)
                settings["ewma_alpha"] = float(np.clip(alpha, 0.01, 0.99))
            if "ewma_source" in overrides:
                settings["ewma_source"] = str(overrides.get("ewma_source", settings.get("ewma_source", "5m"))).lower()
            if "har_windows" in overrides:
                win_val = overrides.get("har_windows")
                windows: Tuple[int, int, int]
                if isinstance(win_val, (list, tuple)):
                    windows = tuple(int(max(1, int(x))) for x in win_val[:3])
                elif isinstance(win_val, (int, float)):
                    num = int(max(1, int(win_val)))
                    windows = (num, num * 3, num * 6)
                else:
                    windows = settings.get("har_windows", (6, 24, 72))
                settings["har_windows"] = windows
            for key, attr in (("mix_atr", "mix_atr"), ("mix_ewma", "mix_ewma"), ("mix_har", "mix_har")):
                if key in overrides:
                    try:
                        settings[attr] = max(0.0, float(overrides.get(key, settings.get(attr, 0.0)) or 0.0))
                    except (TypeError, ValueError):
                        pass
            if "scale" in overrides:
                try:
                    settings["scale"] = max(0.0, float(overrides.get("scale", settings.get("scale", 1.0)) or 0.0))
                except (TypeError, ValueError):
                    pass
            if "min_pct" in overrides:
                try:
                    settings["min_pct"] = max(0.0, float(overrides.get("min_pct", settings.get("min_pct", 0.0)) or 0.0))
                except (TypeError, ValueError):
                    pass
            if "max_pct" in overrides:
                try:
                    settings["max_pct"] = max(0.0, float(overrides.get("max_pct", settings.get("max_pct", 0.0)) or 0.0))
                except (TypeError, ValueError):
                    pass

        total_mix = settings.get("mix_atr", 0.0) + settings.get("mix_ewma", 0.0) + settings.get("mix_har", 0.0)
        if total_mix <= 0:
            settings["mix_atr"], settings["mix_ewma"], settings["mix_har"] = 0.5, 0.3, 0.2
            total_mix = 1.0
        if not np.isclose(total_mix, 1.0):
            settings["mix_atr"] /= total_mix
            settings["mix_ewma"] /= total_mix
            settings["mix_har"] /= total_mix

        mode_norm = settings.get("mode", "atr")
        if mode_norm not in {"atr", "ewma", "har", "mix", "hybrid"}:
            if log:
                logger.warning("风险预测模式 %s 无效（scope=%s），已回退至 atr。", mode_norm, scope)
            settings["mode"] = "atr"
        elif mode_norm == "hybrid":
            settings["mode"] = "mix"

        if log:
            logger.info(
                "RISK_FORECAST 配置生效（%s）：mode=%s ewma_alpha=%.3f source=%s mix=%.2f/%.2f/%.2f scale=%.3f",
                scope,
                settings.get("mode"),
                settings.get("ewma_alpha"),
                settings.get("ewma_source"),
                settings.get("mix_atr"),
                settings.get("mix_ewma"),
                settings.get("mix_har"),
                settings.get("scale"),
            )

        return settings

    def _risk_forecast_cfg(self, pair: Optional[str] = None) -> Dict[str, Any]:
        runtime = getattr(self, "_risk_forecast_settings_runtime", None)
        if not isinstance(runtime, dict) or not runtime:
            runtime = self._risk_forecast_settings(None, scope="runtime", log=False, include_defaults=True)
            self._risk_forecast_settings_runtime = runtime
        config = dict(runtime)
        if pair:
            pair_map = getattr(self, "_risk_forecast_pair_settings", None)
            if isinstance(pair_map, dict):
                override = pair_map.get(pair)
                if isinstance(override, dict) and override:
                    config.update(override)
        return config

    def _apply_risk_forecast_features(self, df: DataFrame, metadata: dict) -> DataFrame:
        pair = "UNKNOWN"
        try:
            pair = metadata.get("pair", "UNKNOWN") if isinstance(metadata, dict) else "UNKNOWN"
        except Exception:
            pair = "UNKNOWN"

        cfg = self._risk_forecast_cfg(pair)
        if not isinstance(df, pd.DataFrame) or df.empty:
            return df

        close_series = df.get("close")
        if close_series is None:
            return df

        returns_5m = close_series.pct_change().replace([np.inf, -np.inf], np.nan)
        returns_5m = returns_5m.fillna(0.0)
        abs_returns_5m = returns_5m.abs()

        alpha = float(cfg.get("ewma_alpha", 0.35) or 0.35)
        alpha = float(np.clip(alpha, 0.01, 0.99))
        ewma_5m = abs_returns_5m.ewm(alpha=alpha, adjust=False).mean()

        ewma_components: List[pd.Series] = []
        source = str(cfg.get("ewma_source", "5m") or "5m").lower()
        if source in ("5m", "both"):
            ewma_components.append(ewma_5m)

        if source in ("3m", "both"):
            inf3m = self._fetch_informative_df(pair, "3m")
            if inf3m is not None and not inf3m.empty and "close" in inf3m:
                ret3m = inf3m["close"].pct_change().replace([np.inf, -np.inf], np.nan).fillna(0.0)
                abs_ret3m = ret3m.abs()
                inf3m = inf3m.copy()
                inf3m["risk_ewma_3m"] = abs_ret3m.ewm(alpha=alpha, adjust=False).mean()
                try:
                    existing_cols = set(df.columns)
                    df = merge_informative_pair(
                        df,
                        inf3m[["date", "risk_ewma_3m"]],
                        self.timeframe,
                        "3m",
                        ffill=True,
                    )
                    new_cols = [col for col in df.columns if col not in existing_cols]
                    ewma_col = next(
                        (col for col in new_cols if "risk_ewma_3m" in str(col)),
                        "risk_ewma_3m",
                    )
                    ewma_3m = df.get(ewma_col)
                    if isinstance(ewma_3m, pd.Series):
                        ewma_components.append(ewma_3m.astype(float))
                        if ewma_col != "risk_ewma_3m":
                            df["risk_ewma_3m"] = ewma_3m.astype(float)
                except Exception:
                    pass

        if not ewma_components:
            ewma_components.append(ewma_5m)

        ewma_combined = sum(comp.ffill().fillna(0.0) for comp in ewma_components) / max(
            1, len(ewma_components)
        )
        ewma_combined = ewma_combined.replace([np.inf, -np.inf], np.nan)

        har_windows = cfg.get("har_windows", (6, 24, 72))
        har_series_list: List[pd.Series] = []
        if isinstance(har_windows, (list, tuple)):
            for window in har_windows:
                try:
                    win = int(window)
                except (TypeError, ValueError):
                    continue
                if win <= 0:
                    continue
                har_series = abs_returns_5m.rolling(win, min_periods=max(1, win // 2)).mean()
                har_series_list.append(har_series)
        if har_series_list:
            har_combined = sum(series.ffill().fillna(0.0) for series in har_series_list) / max(
                1, len(har_series_list)
            )
        else:
            har_combined = abs_returns_5m.rolling(6, min_periods=1).mean()

        har_combined = har_combined.replace([np.inf, -np.inf], np.nan)

        df["risk_forecast_ewma_pct"] = ewma_combined.ffill().fillna(0.0)
        df["risk_forecast_har_pct"] = har_combined.ffill().fillna(0.0)

        return df

    def _risk_tail_summary(self) -> Optional[Dict[str, Any]]:
        state = getattr(self, "_review_state", None)
        if not isinstance(state, dict):
            return None
        tail_state = state.get("risk_tail")
        if not isinstance(tail_state, dict):
            return None
        rolling = tail_state.get("rolling")
        if not isinstance(rolling, dict):
            return None
        return rolling

    def _risk_forecast_resolve_pct(
        self,
        row: pd.Series,
        cfg: Dict[str, Any],
        *,
        atr_risk_pct: float,
        fallback_floor: float,
        stoploss_min_pct: float,
        risk_cap: float,
    ) -> Tuple[float, Dict[str, Any]]:
        mode = str(cfg.get("mode", "atr") or "atr").lower()
        scale = float(cfg.get("scale", 1.0) or 1.0)
        min_pct = float(cfg.get("min_pct", 0.0) or 0.0)
        max_pct = float(cfg.get("max_pct", 0.0) or 0.0)

        def _safe(row_val: Any) -> float:
            try:
                val = float(row_val)
            except (TypeError, ValueError):
                return 0.0
            if not np.isfinite(val) or val <= 0:
                return 0.0
            return float(val)

        ewma_val = _safe(row.get("risk_forecast_ewma_pct"))
        har_val = _safe(row.get("risk_forecast_har_pct"))

        candidates: Dict[str, float] = {
            "atr": _safe(atr_risk_pct),
            "ewma": ewma_val,
            "har": har_val,
        }

        resolved = candidates.get("atr", 0.0)
        source = "atr"

        if mode == "ewma" and candidates.get("ewma", 0.0) > 0:
            resolved = candidates["ewma"]
            source = "ewma"
        elif mode == "har" and candidates.get("har", 0.0) > 0:
            resolved = candidates["har"]
            source = "har"
        elif mode == "mix":
            weights = {
                "atr": float(cfg.get("mix_atr", 0.0) or 0.0),
                "ewma": float(cfg.get("mix_ewma", 0.0) or 0.0),
                "har": float(cfg.get("mix_har", 0.0) or 0.0),
            }
            weighted_sum = 0.0
            total_weight = 0.0
            for key, weight in weights.items():
                val = candidates.get(key, 0.0)
                if weight > 0 and val > 0:
                    weighted_sum += weight * val
                    total_weight += weight
            if total_weight > 0 and weighted_sum > 0:
                resolved = weighted_sum / total_weight
                source = "mix"
            else:
                # 退化：优先 EWMA，其次 HAR，最后 ATR
                if candidates.get("ewma", 0.0) > 0:
                    resolved = candidates["ewma"]
                    source = "ewma"
                elif candidates.get("har", 0.0) > 0:
                    resolved = candidates["har"]
                    source = "har"

        if resolved <= 0:
            resolved = max(candidates.get("atr", 0.0), fallback_floor, stoploss_min_pct)
            source = "atr"

        resolved *= scale if np.isfinite(scale) and scale > 0 else 1.0

        if min_pct > 0:
            resolved = max(resolved, min_pct)
        if max_pct > 0:
            resolved = min(resolved, max_pct)

        if risk_cap > 0:
            resolved = min(resolved, risk_cap)

        resolved = max(resolved, stoploss_min_pct, fallback_floor)

        info = {
            "mode": mode,
            "source": source,
            "atr": candidates.get("atr", 0.0),
            "ewma": candidates.get("ewma", 0.0),
            "har": candidates.get("har", 0.0),
            "scale": scale,
            "min_pct": min_pct,
            "max_pct": max_pct,
        }

        return resolved, info

    # -------------------- 出场/止盈参数覆写 --------------------
    def _exit_tuning_field_map(self) -> Dict[str, Dict[str, Any]]:
        """教学提示：定义可覆写的止盈/锁盈字段、类型与对应属性。"""

        return {
            "measured_move_enable": {"attr": "MEASURED_MOVE_ENABLE", "type": "bool"},
            "measured_move_r_mult": {"attr": "MEASURED_MOVE_R_MULT", "type": "float", "min": 0.0},
            "measured_move_min_profit": {"attr": "MEASURED_MOVE_MIN_PROFIT", "type": "float", "min": 0.0},
            "measured_move_lock_share": {"attr": "MEASURED_MOVE_LOCK_SHARE", "type": "float", "min": 0.0, "max": 1.0},
            "measured_move_lock_min": {"attr": "MEASURED_MOVE_LOCK_MIN", "type": "float", "min": 0.0},
            "measured_move_level": {"attr": "MEASURED_MOVE_LEVEL", "type": "str"},
            "measured_move_retry_minutes": {"attr": "MEASURED_MOVE_RETRY_MINUTES", "type": "float", "min": 0.0},
            "measured_move_risk_basis": {"attr": "MEASURED_MOVE_RISK_BASIS", "type": "str"},
            "measured_move_narrow_r": {"attr": "MEASURED_MOVE_NARROW_R", "type": "float", "min": 0.0},
            "measured_move_balance_r": {"attr": "MEASURED_MOVE_BALANCE_R", "type": "float", "min": 0.0},
            "measured_move_trend_r": {"attr": "MEASURED_MOVE_TREND_R", "type": "float", "min": 0.0},
            "measured_move_decay_r": {"attr": "MEASURED_MOVE_DECAY_R", "type": "float", "min": 0.0},
            "measured_move_trend_align": {"attr": "MEASURED_MOVE_TREND_ALIGN", "type": "float", "min": 0.0, "max": 1.0},
            "measured_move_slow_align": {"attr": "MEASURED_MOVE_SLOW_ALIGN", "type": "float", "min": 0.0, "max": 1.0},
            "measured_move_super_enable": {"attr": "MEASURED_MOVE_SUPER_ENABLE", "type": "bool"},
            "measured_move_super_r": {"attr": "MEASURED_MOVE_SUPER_R", "type": "float", "min": 0.0},
            "measured_move_super_align": {"attr": "MEASURED_MOVE_SUPER_ALIGN", "type": "float", "min": 0.0, "max": 1.0},
            "measured_move_super_align_decay": {"attr": "MEASURED_MOVE_SUPER_ALIGN_DECAY", "type": "float", "min": 0.0, "max": 1.0},
            "measured_move_super_trigger_r": {"attr": "MEASURED_MOVE_SUPER_TRIGGER_R", "type": "float", "min": 0.0},
            "measured_move_super_block_extreme": {"attr": "MEASURED_MOVE_SUPER_BLOCK_EXTREME", "type": "bool"},
            "exit_profit_guard_enable": {"attr": "EXIT_PROFIT_GUARD_ENABLE", "type": "bool"},
            "exit_profit_guard_static": {"attr": "EXIT_PROFIT_GUARD_STATIC", "type": "float", "min": 0.0},
            "exit_profit_guard_peak_share": {"attr": "EXIT_PROFIT_GUARD_PEAK_SHARE", "type": "float", "min": 0.0, "max": 1.0},
            "exit_profit_guard_tolerance": {"attr": "EXIT_PROFIT_GUARD_TOLERANCE", "type": "float", "min": 0.0},
            "exit_profit_guard_book_tol": {"attr": "EXIT_PROFIT_GUARD_BOOK_TOL", "type": "float", "min": 0.0},
            "exit_profit_guard_relax_share": {"attr": "EXIT_PROFIT_GUARD_RELAX_SHARE", "type": "float", "min": 0.0, "max": 1.0},
            "exit_profit_guard_relax_drop_share": {"attr": "EXIT_PROFIT_GUARD_RELAX_DROP_SHARE", "type": "float", "min": 0.0, "max": 1.0},
            "exit_profit_guard_relax_drop_abs": {"attr": "EXIT_PROFIT_GUARD_RELAX_DROP_ABS", "type": "float", "min": 0.0},
            "exit_profit_guard_relax_clamp_to_profit": {
                "attr": "EXIT_PROFIT_GUARD_RELAX_CLAMP_TO_PROFIT",
                "type": "bool",
            },
            "exit_profit_guard_relax_tags": {"attr": "EXIT_PROFIT_GUARD_RELAX_TAGS", "type": "tags"},
            "lock_buffer_r_share": {"attr": "LOCK_BUFFER_R_SHARE", "type": "float", "min": 0.0, "max": 1.0},
            "micro_target_enable": {"attr": "MICRO_TARGET_ENABLE", "type": "bool"},
            "micro_target_level": {"attr": "MICRO_TARGET_LEVEL", "type": "float", "min": 0.0},
            "micro_target_ceil": {"attr": "MICRO_TARGET_CEIL", "type": "float", "min": 0.0},
            "micro_target_lock_ratio": {"attr": "MICRO_TARGET_LOCK_RATIO", "type": "float", "min": 0.0, "max": 1.0},
            "micro_target_floor_min": {"attr": "MICRO_TARGET_FLOOR_MIN", "type": "float", "min": 0.0},
            "micro_target_force_minutes": {"attr": "MICRO_TARGET_FORCE_MINUTES", "type": "float", "min": 0.0},
            "micro_target_relax_weaken": {"attr": "MICRO_TARGET_RELAX_WEAKEN", "type": "bool"},
            "micro_target_score_level": {"attr": "MICRO_TARGET_SCORE_LEVEL", "type": "str"},
            "micro_target_max_drawdown": {"attr": "MICRO_TARGET_MAX_DRAWDOWN", "type": "float", "min": 0.0},
            "small_target_enable": {"attr": "SMALL_TARGET_ENABLE", "type": "bool"},
            "small_target_level": {"attr": "SMALL_TARGET_LEVEL", "type": "float", "min": 0.0},
            "small_target_lock_ratio": {"attr": "SMALL_TARGET_LOCK_RATIO", "type": "float", "min": 0.0, "max": 1.0},
            "small_target_floor_min": {"attr": "SMALL_TARGET_FLOOR_MIN", "type": "float", "min": 0.0},
            "small_target_relax_weaken": {"attr": "SMALL_TARGET_RELAX_WEAKEN", "type": "bool"},
            "small_target_use_peak": {"attr": "SMALL_TARGET_USE_PEAK", "type": "bool"},
            "small_target_force_bars": {"attr": "SMALL_TARGET_FORCE_BARS", "type": "int", "min": 0},
            "small_target_force_max_adds": {"attr": "SMALL_TARGET_FORCE_MAX_ADDS", "type": "int", "min": 0},
            "small_target_breakeven_release": {"attr": "SMALL_TARGET_BREAKEVEN_RELEASE", "type": "bool"},
            "small_target_breakeven_floor": {"attr": "SMALL_TARGET_BREAKEVEN_FLOOR", "type": "float"},
            "small_target_breakeven_tolerance": {"attr": "SMALL_TARGET_BREAKEVEN_TOLERANCE", "type": "float", "min": 0.0},
            "small_target_max_hold_minutes": {"attr": "SMALL_TARGET_MAX_HOLD_MINUTES", "type": "float", "min": 0.0},
            "small_target_score_level": {"attr": "SMALL_TARGET_SCORE_LEVEL", "type": "str"},
            "small_target_promote_to_major": {"attr": "SMALL_TARGET_PROMOTE_TO_MAJOR", "type": "float", "min": 0.0},
            "small_target_promote_to_medium": {"attr": "SMALL_TARGET_PROMOTE_TO_MEDIUM", "type": "float", "min": 0.0},
            "expectation_guard_enable": {"attr": "EXPECTATION_GUARD_ENABLE", "type": "bool"},
            "expectation_target_r": {"attr": "EXPECTATION_TARGET_R", "type": "float", "min": 0.0},
            "expectation_release_r": {"attr": "EXPECTATION_RELEASE_R", "type": "float", "min": 0.0},
            "expectation_release_floor_r": {"attr": "EXPECTATION_RELEASE_FLOOR_R", "type": "float", "min": 0.0},
            "expectation_floor_max_r": {"attr": "EXPECTATION_FLOOR_MAX_R", "type": "float", "min": 0.0},
            "expectation_floor_escalate_at_r": {"attr": "EXPECTATION_FLOOR_ESCALATE_AT_R", "type": "float", "min": 0.0},
            "expectation_floor_escalate_pad_r": {"attr": "EXPECTATION_FLOOR_ESCALATE_PAD_R", "type": "float", "min": 0.0},
            "expectation_time_escalate_minutes": {"attr": "EXPECTATION_TIME_ESCALATE_MINUTES", "type": "float", "min": 0.0},
            "expectation_time_escalate_target_r": {"attr": "EXPECTATION_TIME_ESCALATE_TARGET_R", "type": "float", "min": 0.0},
            "expectation_time_escalate_min_r": {"attr": "EXPECTATION_TIME_ESCALATE_MIN_R", "type": "float", "min": 0.0},
            "expectation_time_escalate_pad_r": {"attr": "EXPECTATION_TIME_ESCALATE_PAD_R", "type": "float", "min": 0.0},
            "expectation_drawdown_r": {"attr": "EXPECTATION_DRAWDOWN_R", "type": "float", "min": 0.0},
            "expectation_relax_minutes": {"attr": "EXPECTATION_RELAX_MINUTES", "type": "float", "min": 0.0},
            "expectation_log_cooldown": {"attr": "EXPECTATION_LOG_COOLDOWN_MIN", "type": "float", "min": 0.0},
            "expectation_context_pad": {"attr": "EXPECTATION_CONTEXT_PAD", "type": "float", "min": 0.0},
            "expected_shortfall_enable": {"attr": "EXPECTED_SHORTFALL_ENABLE", "type": "bool"},
            "expected_shortfall_alpha": {"attr": "EXPECTED_SHORTFALL_ALPHA", "type": "float", "min": 0.0, "max": 0.5},
            "expected_shortfall_window": {"attr": "EXPECTED_SHORTFALL_WINDOW", "type": "int", "min": 1},
            "expected_shortfall_trigger_r": {"attr": "EXPECTED_SHORTFALL_TRIGGER_R", "type": "float"},
            "expected_shortfall_penalty": {"attr": "EXPECTED_SHORTFALL_PENALTY", "type": "float", "min": 0.0},
            "expected_shortfall_min_count": {"attr": "EXPECTED_SHORTFALL_MIN_COUNT", "type": "int", "min": 1},
        }

    def _exit_tuning_values_conflict(
        self,
        key: str,
        original: Any,
        override: Any,
        *,
        field_map: Optional[Dict[str, Dict[str, Any]]] = None,
    ) -> bool:
        """教学提示：检测 exit_tuning 新旧字段是否存在数值冲突。"""

        if original is None or override is None:
            return False
        field_map = field_map or self._exit_tuning_field_map()
        meta = field_map.get(key)
        if not meta:
            return False
        typ = meta.get("type")
        try:
            if typ == "float":
                orig_val = self._safe_float(original)
                new_val = self._safe_float(override)
                if orig_val is None or new_val is None:
                    return False
                return abs(orig_val - new_val) > 1e-6
            if typ == "int":
                return int(original) != int(override)
            if typ == "bool":
                return bool(original) != bool(override)
            if typ == "tags":
                def _normalize_tags(value: Any) -> Tuple[str, ...]:
                    if isinstance(value, (list, tuple, set)):
                        seq = [str(v).strip().lower() for v in value if str(v).strip()]
                    elif value is None:
                        seq = []
                    else:
                        seq = [part.strip().lower() for part in str(value).split(",") if part.strip()]
                    return tuple(sorted(seq))

                return _normalize_tags(original) != _normalize_tags(override)
            return str(original).strip().lower() != str(override).strip().lower()
        except (TypeError, ValueError):
            return False

    def _exit_tuning_default_settings(self) -> Dict[str, Any]:
        """教学提示：读取当前止盈/锁盈治理参数作为默认值。"""

        defaults: Dict[str, Any] = {}
        field_map = self._exit_tuning_field_map()
        for key, meta in field_map.items():
            attr = meta.get("attr")
            if not attr:
                continue
            value = getattr(self, attr, None)
            typ = meta.get("type")
            if typ == "bool":
                defaults[key] = bool(value)
            elif typ == "int":
                try:
                    defaults[key] = int(value)
                except (TypeError, ValueError):
                    defaults[key] = 0
            elif typ == "float":
                try:
                    val = float(value)
                except (TypeError, ValueError):
                    val = 0.0
                defaults[key] = float(val) if np.isfinite(val) else 0.0
            elif typ == "tags":
                if isinstance(value, (list, tuple, set)):
                    defaults[key] = tuple(str(v) for v in value if str(v).strip())
                elif isinstance(value, str):
                    parts = [part.strip() for part in value.split(",") if part.strip()]
                    defaults[key] = tuple(parts)
                else:
                    defaults[key] = tuple()
            else:
                defaults[key] = str(value) if value is not None else ""
        return defaults

    def _exit_tuning_parse_overrides(
        self,
        overrides: Optional[Dict[str, Any]],
        *,
        scope: str,
        log: bool = False,
    ) -> Dict[str, Any]:
        """教学提示：把 exit_tuning 覆盖项拉平成扁平键并做类型校验。"""

        if not isinstance(overrides, dict) or not overrides:
            return {}

        flat: Dict[str, Any] = {}

        def _flatten(prefix: str, value: Any) -> None:
            if isinstance(value, dict):
                for sub_key, sub_val in value.items():
                    if not isinstance(sub_key, str):
                        continue
                    new_prefix = f"{prefix}_{sub_key}" if prefix else sub_key
                    _flatten(new_prefix, sub_val)
            else:
                if prefix:
                    flat[prefix] = value

        _flatten("", overrides)

        field_map = self._exit_tuning_field_map()
        alias_map: Dict[str, str] = {key: key for key in field_map.keys()}
        alias_map.update(
            {
                "measured_move_r": "measured_move_r_mult",
                "measured_move_ratio": "measured_move_r_mult",
                "measured_move_retry": "measured_move_retry_minutes",
                "measured_move_basis": "measured_move_risk_basis",
                "exit_profit_guard_relax_drop": "exit_profit_guard_relax_drop_share",
                "exit_profit_guard_relax_dropshare": "exit_profit_guard_relax_drop_share",
                "lock_buffer_share": "lock_buffer_r_share",
                "micro_target_score": "micro_target_score_level",
                "small_target_score": "small_target_score_level",
                "small_target_force": "small_target_force_bars",
                "small_target_forceadds": "small_target_force_max_adds",
                "expectation_target": "expectation_target_r",
                "expectation_release": "expectation_release_r",
                "expectation_drawdown": "expectation_drawdown_r",
                "expectation_relax": "expectation_relax_minutes",
                "expectation_release_floor": "expectation_release_floor_r",
                "expectation_floor": "expectation_release_floor_r",
                "expectation_floor_r": "expectation_release_floor_r",
                "expectation_floor_share": "expectation_release_floor_r",
                "expectation_guard_target": "expectation_target_r",
                "expectation_guard_target_r": "expectation_target_r",
                "expectation_guard_release": "expectation_release_r",
                "expectation_guard_release_r": "expectation_release_r",
                "expectation_guard_release_floor": "expectation_release_floor_r",
                "expectation_guard_release_floor_r": "expectation_release_floor_r",
                "expectation_guard_drawdown": "expectation_drawdown_r",
                "expectation_guard_drawdown_r": "expectation_drawdown_r",
                "expectation_guard_relax": "expectation_relax_minutes",
                "expectation_guard_relax_minutes": "expectation_relax_minutes",
                "expectation_guard_log_cooldown": "expectation_log_cooldown",
                "expectation_guard_context_pad": "expectation_context_pad",
                "expected_shortfall_enable": "expected_shortfall_enable",
                "expected_shortfall.alpha": "expected_shortfall_alpha",
                "expected_shortfall_alpha": "expected_shortfall_alpha",
                "expected_shortfall.window": "expected_shortfall_window",
                "expected_shortfall_window": "expected_shortfall_window",
                "expected_shortfall.trigger": "expected_shortfall_trigger_r",
                "expected_shortfall.trigger_r": "expected_shortfall_trigger_r",
                "expected_shortfall_trigger": "expected_shortfall_trigger_r",
                "expected_shortfall.penalty": "expected_shortfall_penalty",
                "expected_shortfall_penalty": "expected_shortfall_penalty",
                "expected_shortfall.min_count": "expected_shortfall_min_count",
                "expected_shortfall_min_count": "expected_shortfall_min_count",
            }
        )

        parsed: Dict[str, Any] = {}

        def _normalize_key(key: str) -> str:
            text = str(key).strip().lower()
            text = text.replace("-", "_").replace(".", "_").replace(" ", "_")
            if text.startswith("exit_tuning_"):
                text = text[len("exit_tuning_") :]
            return text

        def _parse_bool(raw: Any) -> Optional[bool]:
            if isinstance(raw, bool):
                return bool(raw)
            if isinstance(raw, (int, np.integer)):
                return bool(int(raw))
            if isinstance(raw, str):
                val = raw.strip().lower()
                if val in {"true", "1", "yes", "on"}:
                    return True
                if val in {"false", "0", "no", "off"}:
                    return False
            return None

        for raw_key, raw_value in flat.items():
            norm_key = _normalize_key(raw_key)
            target_key = norm_key if norm_key in field_map else alias_map.get(norm_key)
            if not target_key:
                continue
            meta = field_map.get(target_key)
            if not meta:
                continue
            typ = meta.get("type")
            converted: Any
            if typ == "bool":
                parsed_bool = _parse_bool(raw_value)
                if parsed_bool is None:
                    if log:
                        logger.warning(
                            "EXIT_TUNING 覆盖项 %s=%r 无法解析为布尔值（scope=%s），已忽略。",
                            raw_key,
                            raw_value,
                            scope,
                        )
                    continue
                converted = parsed_bool
            elif typ == "int":
                try:
                    converted = int(float(raw_value))
                except (TypeError, ValueError):
                    if log:
                        logger.warning(
                            "EXIT_TUNING 覆盖项 %s=%r 无法解析为整数（scope=%s），已忽略。",
                            raw_key,
                            raw_value,
                            scope,
                        )
                    continue
            elif typ == "float":
                try:
                    converted = float(raw_value)
                except (TypeError, ValueError):
                    if log:
                        logger.warning(
                            "EXIT_TUNING 覆盖项 %s=%r 无法解析为浮点数（scope=%s），已忽略。",
                            raw_key,
                            raw_value,
                            scope,
                        )
                    continue
                if not np.isfinite(converted):
                    if log:
                        logger.warning(
                            "EXIT_TUNING 覆盖项 %s=%r 不是有限值（scope=%s），已忽略。",
                            raw_key,
                            raw_value,
                            scope,
                        )
                    continue
            elif typ == "tags":
                if isinstance(raw_value, (list, tuple, set)):
                    converted = tuple(str(v).strip() for v in raw_value if str(v).strip())
                else:
                    converted = tuple(
                        part.strip()
                        for part in str(raw_value).split(",")
                        if part.strip()
                    )
            else:
                converted = str(raw_value).strip()

            if typ == "float":
                if "min" in meta and converted < float(meta["min"]):
                    if log:
                        logger.warning(
                            "EXIT_TUNING 覆盖项 %s=%.4f 低于允许下限 %.4f（scope=%s），已忽略。",
                            raw_key,
                            converted,
                            float(meta["min"]),
                            scope,
                        )
                    continue
                if "max" in meta and converted > float(meta["max"]):
                    if log:
                        logger.warning(
                            "EXIT_TUNING 覆盖项 %s=%.4f 高于允许上限 %.4f（scope=%s），已忽略。",
                            raw_key,
                            converted,
                            float(meta["max"]),
                            scope,
                        )
                    continue
            if typ == "int":
                min_val = meta.get("min")
                if min_val is not None and converted < int(min_val):
                    if log:
                        logger.warning(
                            "EXIT_TUNING 覆盖项 %s=%d 低于允许下限 %d（scope=%s），已忽略。",
                            raw_key,
                            converted,
                            int(min_val),
                            scope,
                        )
                    continue
            if typ == "tags" and not converted:
                converted = tuple()

            parsed[target_key] = converted

        return parsed

    def _exit_tuning_settings(
        self,
        overrides: Optional[Dict[str, Any]] = None,
        *,
        scope: str = "runtime",
        log: bool = False,
        include_defaults: bool = True,
    ) -> Dict[str, Any]:
        """教学提示：组装最终的止盈/止损调参配置。"""

        settings = self._exit_tuning_default_settings() if include_defaults else {}
        parsed = self._exit_tuning_parse_overrides(overrides, scope=scope, log=log)
        if parsed:
            settings.update(parsed)
        return settings

    def _apply_exit_tuning_settings(self, settings: Dict[str, Any]) -> None:
        """教学提示：把调参结果写回策略属性，供运行时读取。"""

        field_map = self._exit_tuning_field_map()
        for key, value in settings.items():
            meta = field_map.get(key)
            if not meta:
                continue
            attr = meta.get("attr")
            if not attr:
                continue
            typ = meta.get("type")
            if typ == "tags":
                if isinstance(value, (list, tuple, set)):
                    cleaned = tuple(str(v).strip() for v in value if str(v).strip())
                elif isinstance(value, str):
                    cleaned = tuple(part.strip() for part in value.split(",") if part.strip())
                else:
                    cleaned = tuple()
                setattr(self, attr, cleaned)
            elif typ == "int":
                setattr(self, attr, int(value))
            elif typ == "float":
                setattr(self, attr, float(value))
            elif typ == "bool":
                setattr(self, attr, bool(value))
            else:
                setattr(self, attr, str(value))

    def _exit_tuning_merge_cfg(
        self,
        base_cfg: Optional[Dict[str, Any]],
        pair: Optional[str],
    ) -> Dict[str, Any]:
        """教学提示：把 per-pair exit_tuning 覆盖项叠加到 pair_cfg 上。"""

        cfg = dict(base_cfg or {})
        pair_map = getattr(self, "_exit_tuning_pair_settings", None)
        if pair and isinstance(pair_map, dict):
            overrides = pair_map.get(pair)
            if isinstance(overrides, dict) and overrides:
                cfg.update(overrides)
        return cfg

    def _audit_data_freshness_guards(self) -> None:
        """教学提示：复核行情刷新阈值，避免阈值过小或顺序错误导致灾难性漏单。"""

        try:
            tf_minutes = float(getattr(self, "_current_tf_minutes", self._tf_minutes()))
        except Exception:
            tf_minutes = float(self._tf_minutes())

        threshold = float(getattr(self, "DATA_STALE_THRESHOLD_MINUTES", 20) or 20)
        recheck = float(getattr(self, "DATA_STALE_RECHECK_MINUTES", 5) or 5)
        log_cd = float(getattr(self, "DATA_STALE_LOG_COOLDOWN_MINUTES", 30) or 30)

        issues: List[str] = []
        tol = 1e-6
        if threshold + tol < tf_minutes:
            issues.append(
                f"阈值 {threshold:.2f} 分钟 小于 timeframe {tf_minutes:.2f} 分钟，可能导致常态行情被误判为陈旧"
            )
        if recheck > threshold + tol:
            issues.append(
                f"复查间隔 {recheck:.2f} 分钟 大于阈值 {threshold:.2f} 分钟，冷却后将无法自动解除"
            )
        if log_cd + tol < recheck:
            issues.append(
                f"日志节流 {log_cd:.2f} 分钟 小于复查间隔 {recheck:.2f} 分钟，可能刷屏"
            )

        if issues:
            logger.warning(
                "DATA_FRESHNESS 配置异常：%s；请在实盘前校正阈值避免行情更新被卡住。",
                "；".join(issues),
            )

    def _merged_pair_override_settings(self) -> Dict[str, Dict[str, Any]]:
        """Merge class-level and config-level pair_overrides for downstream audits."""

        merged: Dict[str, Dict[str, Any]] = {}
        try:
            cfg_pairs = ((self.config or {}).get("pair_overrides")) or {}
        except Exception:
            cfg_pairs = {}
        sources: List[Tuple[str, Dict[str, Any]]] = [
            ("class", getattr(self, "pair_overrides", {}) or {}),
            ("config", cfg_pairs),
        ]

        for label, source in sources:
            if not isinstance(source, dict):
                continue
            for key, raw in source.items():
                if not isinstance(raw, dict):
                    continue
                pair_key = str(key).strip()
                if not pair_key:
                    continue
                payload = dict(raw)
                if payload:
                    payload = self._rebased_expectation_override_fields(
                        pair_key,
                        payload,
                        source=label,
                    )
                entry = merged.setdefault(pair_key, {})
                entry.update(payload)

        return merged

    def _rebased_expectation_override_fields(
        self,
        pair: str,
        payload: Dict[str, Any],
        *,
        source: str,
    ) -> Dict[str, Any]:
        """Scale legacy expectation overrides to the current stoploss fallback when needed."""

        if not isinstance(payload, dict) or not payload:
            return payload

        fallback = float(getattr(self, "STOPLOSS_FALLBACK", 0.0) or 0.0)
        baseline = float(getattr(self, "EXPECTATION_OVERRIDE_BASE_STOPLOSS", fallback) or fallback)
        if fallback <= 0 or baseline <= 0:
            return payload

        base_key = "expectation_override_base_stoploss"
        base_val = self._safe_float(payload.get(base_key))
        if base_val is None:
            base_val = baseline if source == "config" else fallback

        if base_val <= 0:
            base_val = fallback

        ratio = base_val / fallback
        tol = 1e-6
        if abs(ratio - 1.0) <= tol:
            payload[base_key] = fallback
            return payload

        rebase_fields = (
            "expectation_target_r",
            "expectation_release_r",
            "expectation_release_floor_r",
            "expectation_drawdown_r",
            "expectation_floor_max_r",
            "expectation_floor_escalate_at_r",
        )
        touched: List[str] = []
        for field in rebase_fields:
            if field not in payload:
                continue
            new_val = self._safe_float(payload.get(field))
            if new_val is None:
                continue
            payload[field] = new_val * ratio
            touched.append(field)

        if touched:
            payload[base_key] = fallback
            logger.info(
                "期望守卫覆写自动换算 %.1f%%→%.1f%%：pair=%s fields=%s",
                base_val * 100,
                fallback * 100,
                pair,
                ",".join(touched),
            )

        return payload
    def _audit_expectation_override_health(self) -> Optional[Dict[str, Any]]:
        """Summarise per-pair expectation guards and flag stale overrides."""
        # [CODEX-NEW] 启动期审计：校验期望守卫 R/地板/回撤与 config 覆写一致，避免参数漂移。

        fallback = float(getattr(self, "STOPLOSS_FALLBACK", 0.0) or 0.0)
        baseline = float(getattr(self, "EXPECTATION_OVERRIDE_BASE_STOPLOSS", fallback) or fallback)
        if baseline <= 0 or fallback <= 0:
            return None

        ratio = fallback / baseline
        drift = abs(fallback - baseline) / max(baseline, 1e-9)
        requires_pct = drift > 0.15
        overrides = self._merged_pair_override_settings()
        issue_list: List[Dict[str, Any]] = []
        profiles: List[Dict[str, Any]] = []

        def _profile(label: str, cfg: Optional[Dict[str, Any]], source: str) -> None:
            data = cfg or {}
            enable = bool(data.get("expectation_guard_enable", getattr(self, "EXPECTATION_GUARD_ENABLE", True)))
            target_r = float(data.get("expectation_target_r", getattr(self, "EXPECTATION_TARGET_R", 0.0)) or 0.0)
            release_r = float(data.get("expectation_release_r", getattr(self, "EXPECTATION_RELEASE_R", 0.0)) or 0.0)
            floor_r_raw = float(data.get("expectation_release_floor_r", getattr(self, "EXPECTATION_RELEASE_FLOOR_R", 0.0)) or 0.0)
            floor_pct_override = float(
                data.get("expectation_release_floor_pct", getattr(self, "EXPECTATION_RELEASE_FLOOR_PCT", 0.0)) or 0.0
            )
            drawdown_r = float(data.get("expectation_drawdown_r", getattr(self, "EXPECTATION_DRAWDOWN_R", 0.0)) or 0.0)
            floor_pct = floor_pct_override if floor_pct_override > 0 else floor_r_raw * fallback
            resolved_floor_r = floor_r_raw if floor_r_raw > 0 else (floor_pct / fallback if fallback > 0 else 0.0)
            profile = {
                "pair": label,
                "source": source,
                "enable": enable,
                "target_r": target_r,
                "release_r": release_r,
                "release_pct": release_r * fallback,
                "floor_r": resolved_floor_r,
                "floor_pct": floor_pct,
                "drawdown_r": drawdown_r,
                "drawdown_pct": drawdown_r * fallback,
            }
            profiles.append(profile)

            if not enable:
                return

            if resolved_floor_r > 0 and resolved_floor_r < 0.48:
                issue_list.append(
                    {
                        "pair": label,
                        "fields": ["expectation_release_floor_r"],
                        "message": "near-exit 地板低于 0.5R，实盘会过早放行，建议调高或改用 *_pct",
                        "resolved_floor_r": resolved_floor_r,
                    }
                )

            if release_r > 0 and release_r <= resolved_floor_r:
                issue_list.append(
                    {
                        "pair": label,
                        "fields": ["expectation_release_r", "expectation_release_floor_r"],
                        "message": "release 阈值不高于地板，无法触发守卫释放，请重新设定 R 倍数",
                    }
                )

        _profile("default", None, "class")

        if overrides:
            for pair, cfg in overrides.items():
                if isinstance(cfg, dict):
                    _profile(pair, cfg, "override")

        if requires_pct and overrides:
            for pair, cfg in overrides.items():
                if not isinstance(cfg, dict):
                    continue
                exp_fields = [k for k in cfg.keys() if isinstance(k, str) and k.startswith("expectation_")]
                if not exp_fields:
                    continue
                has_pct = any(field.endswith("_pct") for field in exp_fields)
                if has_pct:
                    continue
                issue = {
                    "pair": pair,
                    "fields": sorted(exp_fields),
                    "message": (
                        "期望守卫覆写仍基于 %.1f%% 风险基准，当前 STOPLOSS_FALLBACK=%.1f%%，"
                        "建议新增 *_pct 字段或改写 R 倍数。"
                    )
                    % (baseline * 100.0, fallback * 100.0),
                }
                issue_list.append(issue)
                warning_msg = (
                    "[期望守卫审计] pair=%s 覆写 %s 仍采用旧风险基准 %.1f%%，当前 STOPLOSS_FALLBACK=%.1f%%，"
                    "请同步改写为百分比或新的 R 倍数。"
                    % (
                        pair,
                        ",".join(exp_fields),
                        baseline * 100.0,
                        fallback * 100.0,
                    )
                )
                logger.warning(warning_msg)

        report: Dict[str, Any] = {
            "baseline_pct": baseline,
            "fallback_pct": fallback,
            "ratio_vs_baseline": ratio,
            "requires_pct_backup": requires_pct,
            "issues": issue_list,
            "profiles": profiles,
        }

        return report

    def _audit_stoploss_runtime(self) -> None:
        """教学提示：复核兜底与紧急止损阈值，避免旧版参数压缩新兜底。"""

        fallback = self._safe_float(getattr(self, "STOPLOSS_FALLBACK", None))
        if fallback is None or fallback <= 0:
            return

        tol = 1e-6
        issues: List[str] = []

        sl_max = self._safe_float(getattr(self, "STOPLOSS_MAX_PCT", None))
        if sl_max is not None and sl_max + tol < fallback:
            issues.append(
                f"STOPLOSS_MAX_PCT({sl_max:.4f}) < STOPLOSS_FALLBACK({fallback:.4f})"
            )

        emergency_cap = self._safe_float(getattr(self, "STOPLOSS_EMERGENCY_CAP", None))
        if emergency_cap is not None and emergency_cap + tol < fallback:
            issues.append(
                f"STOPLOSS_EMERGENCY_CAP({emergency_cap:.4f}) < STOPLOSS_FALLBACK({fallback:.4f})"
            )

        expand_cap = self._safe_float(getattr(self, "STOPLOSS_FALLBACK_EXPAND_CAP", None))
        if expand_cap is not None and expand_cap + tol < fallback:
            issues.append(
                f"STOPLOSS_FALLBACK_EXPAND_CAP({expand_cap:.4f}) < STOPLOSS_FALLBACK({fallback:.4f})"
            )

        if issues:
            logger.warning(
                "STOPLOSS 配置异常：%s；请同步更新新旧参数以免兜底失效。",
                "；".join(issues),
            )

    def _audit_exit_tuning_runtime(self) -> None:
        """教学提示：复核期望守卫等 exit_tuning 阈值，提前发现灾难性配置。"""

        try:
            base_settings = self._exit_tuning_settings(
                scope="audit",
                log=False,
            )
        except Exception as exc:
            logger.warning("EXIT_TUNING 自检失败：%s", exc)
            return

        contexts: List[Tuple[str, Dict[str, Any]]] = [("global", dict(base_settings))]

        known_pairs: Set[str] = set()
        base_overrides = getattr(self, "pair_overrides", {}) or {}
        if isinstance(base_overrides, dict):
            known_pairs.update(pair for pair in base_overrides.keys() if isinstance(pair, str))
        cfg = getattr(self, "config", {}) or {}
        cfg_pairs = cfg.get("pair_overrides") if isinstance(cfg, dict) else None
        if isinstance(cfg_pairs, dict):
            known_pairs.update(pair for pair in cfg_pairs.keys() if isinstance(pair, str))

        pair_exit_map = getattr(self, "_exit_tuning_pair_settings", {}) or {}
        if isinstance(pair_exit_map, dict):
            known_pairs.update(pair for pair in pair_exit_map.keys() if isinstance(pair, str))

        cfg_pairs_map = cfg_pairs if isinstance(cfg_pairs, dict) else {}
        field_map = self._exit_tuning_field_map()

        strategy_params = {}
        try:
            strategy_params = (cfg.get("strategy_parameters") or {}) if isinstance(cfg, dict) else {}
        except Exception:
            strategy_params = {}
        if isinstance(strategy_params, dict):
            exit_cfg = strategy_params.get("exit_tuning")
            parsed_exit = (
                self._exit_tuning_settings(
                    exit_cfg,
                    scope="strategy_parameters.exit_tuning",
                    log=False,
                    include_defaults=False,
                )
                if isinstance(exit_cfg, dict) and exit_cfg
                else {}
            )
            for key, override_val in (parsed_exit or {}).items():
                if key in strategy_params and self._exit_tuning_values_conflict(
                    key,
                    strategy_params.get(key),
                    override_val,
                    field_map=field_map,
                ):
                    logger.warning(
                        "EXIT_TUNING 配置冲突（global.%s）：顶层值=%r 与 exit_tuning 覆盖=%r 不一致；请清理旧字段避免覆盖顺序不明。",
                        key,
                        strategy_params.get(key),
                        override_val,
                    )

        for pair in sorted(known_pairs):
            try:
                pair_cfg = self._pair_cfg(pair)
            except Exception as exc:
                logger.warning("EXIT_TUNING 自检无法解析 %s：%s", pair, exc)
                continue

            raw_pair_cfg: Dict[str, Any] = {}
            base_pair = base_overrides.get(pair)
            if isinstance(base_pair, dict):
                raw_pair_cfg.update(base_pair)
            cfg_pair = cfg_pairs_map.get(pair)
            if isinstance(cfg_pair, dict):
                raw_pair_cfg.update(cfg_pair)

            merged = dict(base_settings)
            for key in base_settings.keys():
                if key in pair_cfg:
                    merged[key] = pair_cfg[key]
            contexts.append((f"pair:{pair}", merged))

            overrides = pair_exit_map.get(pair)
            if isinstance(overrides, dict) and overrides:
                for key, override_val in overrides.items():
                    if key in raw_pair_cfg and self._exit_tuning_values_conflict(
                        key,
                        raw_pair_cfg.get(key),
                        override_val,
                        field_map=field_map,
                    ):
                        logger.warning(
                            "EXIT_TUNING 配置冲突（pair:%s.%s）：顶层值=%r 与 exit_tuning 覆盖=%r 不一致；请清除重复定义以免守卫失效。",
                            pair,
                            key,
                            raw_pair_cfg.get(key),
                            override_val,
                        )

        tol = 1e-6
        for label, ctx in contexts:
            enable_val = ctx.get("expectation_guard_enable")
            if enable_val is None:
                enable_val = getattr(self, "EXPECTATION_GUARD_ENABLE", False)
            if not bool(enable_val):
                continue

            target_r = self._safe_float(ctx.get("expectation_target_r"))
            release_r = self._safe_float(ctx.get("expectation_release_r"))
            floor_r = self._safe_float(ctx.get("expectation_release_floor_r"))
            drawdown_r = self._safe_float(ctx.get("expectation_drawdown_r"))

            issues: List[str] = []
            if floor_r is None or floor_r <= 0:
                issues.append("release_floor_r<=0 将无法守住旧版 0.5R 浮盈")

            if release_r is None or release_r <= 0:
                issues.append("release_r<=0，守卫永远不会放行")
            else:
                if floor_r is not None and floor_r > 0 and release_r < floor_r - tol:
                    issues.append(
                        f"release_r({release_r:.3f}) < release_floor_r({floor_r:.3f})"
                    )
                if drawdown_r is not None and drawdown_r >= release_r - tol:
                    issues.append(
                        f"drawdown_r({drawdown_r:.3f}) ≥ release_r({release_r:.3f})"
                    )
                if target_r is not None and target_r > 0 and target_r < release_r - tol:
                    issues.append(
                        f"target_r({target_r:.3f}) < release_r({release_r:.3f})"
                    )

            if issues:
                logger.warning(
                    "EXPECTATION_GUARD 配置异常（%s）：%s；请调整参数避免守卫即时触发或失效。",
                    label,
                    "；".join(issues),
                )

    def _apply_entry_quality_settings(self, settings: Dict[str, Any]) -> None:
        """教学提示：将归一化结果写回类属性，供后续调用复用。"""

        if not isinstance(settings, dict):
            return
        self.ENTRY_QUALITY_ENABLE = bool(settings.get("enable", getattr(self, "ENTRY_QUALITY_ENABLE", True)))
        self.ENTRY_QUALITY_ALIGN_WEIGHT = float(settings.get("align_weight", self.ENTRY_QUALITY_ALIGN_WEIGHT))
        self.ENTRY_QUALITY_TRI_WEIGHT = float(settings.get("tri_weight", self.ENTRY_QUALITY_TRI_WEIGHT))
        self.ENTRY_QUALITY_RFS_WEIGHT = float(settings.get("rfs_weight", self.ENTRY_QUALITY_RFS_WEIGHT))
        self.ENTRY_QUALITY_PRIORITY_WEIGHT = float(settings.get("priority_weight", self.ENTRY_QUALITY_PRIORITY_WEIGHT))
        self.ENTRY_QUALITY_FAST_BONUS = float(settings.get("fast_bonus", self.ENTRY_QUALITY_FAST_BONUS))
        self.ENTRY_QUALITY_SLOW_BONUS = float(settings.get("slow_bonus", self.ENTRY_QUALITY_SLOW_BONUS))
        self.ENTRY_QUALITY_HTF_BONUS = float(settings.get("htf_bonus", self.ENTRY_QUALITY_HTF_BONUS))
        self.ENTRY_QUALITY_CHANNEL_BONUS = float(settings.get("channel_bonus", self.ENTRY_QUALITY_CHANNEL_BONUS))
        self.ENTRY_QUALITY_DECAY_PENALTY = float(settings.get("decay_penalty", self.ENTRY_QUALITY_DECAY_PENALTY))
        self.ENTRY_QUALITY_VOL_BONUS = float(settings.get("vol_bonus", self.ENTRY_QUALITY_VOL_BONUS))
        self.ENTRY_QUALITY_PRICE_CEIL = float(settings.get("price_ceil", self.ENTRY_QUALITY_PRICE_CEIL))
        self.ENTRY_QUALITY_PRICE_FLOOR = float(settings.get("price_floor", self.ENTRY_QUALITY_PRICE_FLOOR))
        self.ENTRY_QUALITY_PRICE_WEIGHT = float(settings.get("price_weight", self.ENTRY_QUALITY_PRICE_WEIGHT))
        self.ENTRY_QUALITY_BASE_NEED = float(settings.get("base_need", self.ENTRY_QUALITY_BASE_NEED))
        self.ENTRY_QUALITY_SLOW_NEED = float(settings.get("slow_need", self.ENTRY_QUALITY_SLOW_NEED))
        self.ENTRY_QUALITY_FAST_NEED = float(settings.get("fast_need", self.ENTRY_QUALITY_FAST_NEED))
        self.ENTRY_QUALITY_DYNAMIC_ADD = float(settings.get("dynamic_add", self.ENTRY_QUALITY_DYNAMIC_ADD))
        self.ENTRY_QUALITY_FRAGILE_ADD = float(settings.get("fragile_add", self.ENTRY_QUALITY_FRAGILE_ADD))
        self.ENTRY_QUALITY_EXTREME_ADD = float(settings.get("extreme_add", self.ENTRY_QUALITY_EXTREME_ADD))
        self.ENTRY_QUALITY_DECAY_ADD = float(settings.get("decay_add", self.ENTRY_QUALITY_DECAY_ADD))
        self.ENTRY_QUALITY_PREFER_RELIEF = float(settings.get("prefer_relief", self.ENTRY_QUALITY_PREFER_RELIEF))
        self.ENTRY_QUALITY_PASS_RATIO_MIN = float(settings.get("pass_ratio_min", self.ENTRY_QUALITY_PASS_RATIO_MIN))
        self.ENTRY_QUALITY_PASS_RATIO_FAST_MIN = float(settings.get("pass_ratio_fast_min", self.ENTRY_QUALITY_PASS_RATIO_FAST_MIN))
        self.ENTRY_QUALITY_PASS_RATIO_SLOW_MIN = float(settings.get("pass_ratio_slow_min", self.ENTRY_QUALITY_PASS_RATIO_SLOW_MIN))
        self.ENTRY_QUALITY_PASS_RATIO_EXTREME_MIN = float(settings.get("pass_ratio_extreme_min", self.ENTRY_QUALITY_PASS_RATIO_EXTREME_MIN))

    def _entry_quality_score(
        self,
        *,
        side: str,
        align_score: float,
        tri_bias: float,
        rfs_value: float,
        priority_conf: float,
        price_position: float,
        price_pos_60: float,
        price_pos_240: float,
        session_vwap_premium: float,
        pullback_ready: bool,
        pullback_needed: bool,
        fast_lane: bool,
        slow_lane: bool,
        htf_drive: bool,
        channel_narrow: bool,
        channel_wide: bool,
        channel_decay: bool,
        vol_surge: int,
        settings: Optional[Dict[str, Any]] = None,
    ) -> Tuple[float, Dict[str, float]]:
        """教学提示：把多周期/三锚/RFS/优先级综合为 0~1 的质量评分。"""
        cfg = settings if settings is not None else self._entry_quality_settings(None, scope="internal")

        align_weight = float(cfg.get("align_weight", 0.36))
        tri_weight = float(cfg.get("tri_weight", 0.27))
        rfs_weight = float(cfg.get("rfs_weight", 0.21))
        priority_weight = float(cfg.get("priority_weight", 0.16))

        total_weight = align_weight + tri_weight + rfs_weight + priority_weight
        if not np.isclose(total_weight, 1.0):
            if total_weight <= 0:
                align_weight, tri_weight, rfs_weight, priority_weight = 0.36, 0.27, 0.21, 0.16
                total_weight = 1.0
            else:
                align_weight /= total_weight
                tri_weight /= total_weight
                rfs_weight /= total_weight
                priority_weight /= total_weight

        align_norm = float(np.clip((align_score if side == "long" else -align_score), 0.0, 1.0))
        tri_norm = float(np.clip(tri_bias, 0.0, 1.0))
        rfs_norm = float(np.clip(rfs_value, 0.0, 1.0))
        priority_norm = float(np.clip(priority_conf, 0.0, 1.0))

        base_score = (
            align_norm * align_weight
            + tri_norm * tri_weight
            + rfs_norm * rfs_weight
            + priority_norm * priority_weight
        )

        lane_bonus = 0.0
        if fast_lane:
            lane_bonus += float(cfg.get("fast_bonus", getattr(self, "ENTRY_QUALITY_FAST_BONUS", self.ENTRY_QUALITY_FAST_BONUS)))
        elif slow_lane:
            lane_bonus += float(cfg.get("slow_bonus", getattr(self, "ENTRY_QUALITY_SLOW_BONUS", self.ENTRY_QUALITY_SLOW_BONUS)))

        htf_bonus = float(cfg.get("htf_bonus", getattr(self, "ENTRY_QUALITY_HTF_BONUS", self.ENTRY_QUALITY_HTF_BONUS))) if htf_drive else 0.0
        channel_bonus = float(cfg.get("channel_bonus", getattr(self, "ENTRY_QUALITY_CHANNEL_BONUS", self.ENTRY_QUALITY_CHANNEL_BONUS))) if channel_narrow else 0.0
        decay_penalty = float(cfg.get("decay_penalty", getattr(self, "ENTRY_QUALITY_DECAY_PENALTY", self.ENTRY_QUALITY_DECAY_PENALTY))) if channel_wide and channel_decay else 0.0
        vol_bonus = float(cfg.get("vol_bonus", getattr(self, "ENTRY_QUALITY_VOL_BONUS", self.ENTRY_QUALITY_VOL_BONUS))) if vol_surge == 1 else 0.0

        ceil = float(cfg.get("price_ceil", getattr(self, "ENTRY_QUALITY_PRICE_CEIL", self.ENTRY_QUALITY_PRICE_CEIL)))
        floor = float(cfg.get("price_floor", getattr(self, "ENTRY_QUALITY_PRICE_FLOOR", self.ENTRY_QUALITY_PRICE_FLOOR)))
        price_weight = float(cfg.get("price_weight", getattr(self, "ENTRY_QUALITY_PRICE_WEIGHT", self.ENTRY_QUALITY_PRICE_WEIGHT)))
        price_penalty = 0.0
        if side == "long" and np.isfinite(price_position):
            if price_position > ceil:
                span = max(1e-6, 1.0 - ceil)
                price_penalty = ((price_position - ceil) / span) * price_weight
        elif side == "short" and np.isfinite(price_position):
            if price_position < floor:
                span = max(1e-6, floor)
                price_penalty = ((floor - price_position) / span) * price_weight

        anchor_penalty = 0.0
        anchor_weight = float(cfg.get("price_anchor_weight", getattr(self, "ENTRY_QUALITY_PRICE_ANCHOR_WEIGHT", 0.0)))
        if anchor_weight > 0:
            guard_cfg = self._entry_price_guard_settings(scope="quality")
            anchor_values = {
                "price_position": float(price_position),
                "price_pos_60": float(price_pos_60),
                "price_pos_240": float(price_pos_240),
            }
            violation = 0.0
            if side == "long":
                long_caps = guard_cfg.get("long", {}).get("max", {}) if isinstance(guard_cfg.get("long"), dict) else {}
                for key, cap in long_caps.items():
                    val = anchor_values.get(key)
                    if not np.isfinite(val):
                        continue
                    cap_val = float(cap)
                    diff = val - cap_val
                    if diff <= 0:
                        continue
                    span = max(1e-6, 1.0 - min(0.99, cap_val))
                    violation = max(violation, diff / span)
                vwap_cap = float(guard_cfg.get("long", {}).get("vwap_max", getattr(self, "ENTRY_PRICE_LONG_VWAP_MAX", 0.012)))
                if np.isfinite(session_vwap_premium) and session_vwap_premium > vwap_cap:
                    span = max(1e-6, max(0.005, vwap_cap))
                    violation = max(violation, (session_vwap_premium - vwap_cap) / span)
            else:
                short_floors = guard_cfg.get("short", {}).get("min", {}) if isinstance(guard_cfg.get("short"), dict) else {}
                for key, floor_cap in short_floors.items():
                    val = anchor_values.get(key)
                    if not np.isfinite(val):
                        continue
                    floor_val = float(floor_cap)
                    diff = floor_val - val
                    if diff <= 0:
                        continue
                    span = max(1e-6, max(0.01, floor_val))
                    violation = max(violation, diff / span)
                vwap_floor = float(guard_cfg.get("short", {}).get("vwap_min", getattr(self, "ENTRY_PRICE_SHORT_VWAP_MIN", 0.006)))
                if np.isfinite(session_vwap_premium) and session_vwap_premium < vwap_floor:
                    span = max(1e-6, max(0.005, vwap_floor))
                    violation = max(violation, (vwap_floor - session_vwap_premium) / span)
            anchor_penalty = anchor_weight * float(np.clip(violation, 0.0, 1.0))

        pullback_component = 0.0
        if pullback_needed:
            bonus = float(cfg.get("pullback_bonus", getattr(self, "ENTRY_QUALITY_PULLBACK_BONUS", 0.0)))
            penalty = float(cfg.get("pullback_penalty", getattr(self, "ENTRY_QUALITY_PULLBACK_PENALTY", 0.0)))
            if pullback_ready and bonus > 0:
                pullback_component = bonus
            elif (not pullback_ready) and penalty > 0:
                pullback_component = -penalty

        score = base_score + lane_bonus + htf_bonus + channel_bonus + vol_bonus + pullback_component - decay_penalty - price_penalty - anchor_penalty
        score = float(np.clip(score, 0.0, 1.0))

        breakdown = {
            "base_score": float(base_score),
            "align_component": align_norm,
            "tri_component": tri_norm,
            "rfs_component": rfs_norm,
            "priority_component": priority_norm,
            "lane_bonus": float(lane_bonus),
            "htf_bonus": float(htf_bonus),
            "channel_bonus": float(channel_bonus),
            "vol_bonus": float(vol_bonus),
            "decay_penalty": float(decay_penalty),
            "price_penalty": float(price_penalty),
            "price_anchor_penalty": float(anchor_penalty),
            "pullback_component": float(pullback_component),
        }

        return score, breakdown

    def _entry_price_guard_defaults(self) -> Dict[str, Any]:
        base = {
            "enable": bool(getattr(self, "ENTRY_PRICE_BAND_GUARD_ENABLE", True)),
            "long": {
                "max": {
                    "price_position": float(getattr(self, "ENTRY_PRICE_LONG_MAX", 0.68)),
                    "price_pos_60": float(getattr(self, "ENTRY_PRICE_LONG_MAX_60", getattr(self, "ENTRY_PRICE_LONG_MAX", 0.68))),
                    "price_pos_240": float(
                        getattr(
                            self,
                            "ENTRY_PRICE_LONG_MAX_240",
                            getattr(self, "ENTRY_PRICE_LONG_MAX_60", getattr(self, "ENTRY_PRICE_LONG_MAX", 0.68)) - 0.04,
                        )
                    ),
                },
                "core": {
                    "price_position": float(getattr(self, "ENTRY_PRICE_LONG_CORE_MAX", 0.52)),
                    "price_pos_60": float(getattr(self, "ENTRY_PRICE_LONG_CORE_MAX_60", getattr(self, "ENTRY_PRICE_LONG_CORE_MAX", 0.52))),
                    "price_pos_240": float(
                        getattr(
                            self,
                            "ENTRY_PRICE_LONG_CORE_MAX_240",
                            getattr(self, "ENTRY_PRICE_LONG_CORE_MAX_60", getattr(self, "ENTRY_PRICE_LONG_CORE_MAX", 0.52)) - 0.04,
                        )
                    ),
                },
                "vwap_max": float(getattr(self, "ENTRY_PRICE_LONG_VWAP_MAX", 0.012)),
            },
            "short": {
                "min": {
                    "price_position": float(getattr(self, "ENTRY_PRICE_SHORT_MIN", 0.32)),
                    "price_pos_60": float(getattr(self, "ENTRY_PRICE_SHORT_MIN_60", getattr(self, "ENTRY_PRICE_SHORT_MIN", 0.32) + 0.04)),
                    "price_pos_240": float(
                        getattr(
                            self,
                            "ENTRY_PRICE_SHORT_MIN_240",
                            getattr(self, "ENTRY_PRICE_SHORT_MIN_60", getattr(self, "ENTRY_PRICE_SHORT_MIN", 0.32) + 0.04) + 0.04,
                        )
                    ),
                },
                "core": {
                    "price_position": float(getattr(self, "ENTRY_PRICE_SHORT_CORE_MIN", 0.48)),
                    "price_pos_60": float(getattr(self, "ENTRY_PRICE_SHORT_CORE_MIN_60", getattr(self, "ENTRY_PRICE_SHORT_CORE_MIN", 0.48))),
                    "price_pos_240": float(
                        getattr(
                            self,
                            "ENTRY_PRICE_SHORT_CORE_MIN_240",
                            getattr(self, "ENTRY_PRICE_SHORT_CORE_MIN_60", getattr(self, "ENTRY_PRICE_SHORT_CORE_MIN", 0.48)) + 0.04,
                        )
                    ),
                },
                "vwap_min": float(getattr(self, "ENTRY_PRICE_SHORT_VWAP_MIN", 0.006)),
            },
            "vwap_window": int(max(1, int(getattr(self, "ENTRY_PRICE_VWAP_WINDOW_BARS", 288))))
        }
        return base

    def _entry_price_guard_settings(self, *, scope: str = "runtime") -> Dict[str, Any]:
        if isinstance(getattr(self, "_entry_price_guard_cache", None), dict):
            return copy.deepcopy(self._entry_price_guard_cache)  # type: ignore[arg-type]

        settings = copy.deepcopy(self._entry_price_guard_defaults())

        try:
            sp = ((self.config or {}).get("strategy_parameters")) or {}
        except Exception:
            sp = {}
        cfg = sp.get("entry_price_guard") if isinstance(sp, dict) else None
        if isinstance(cfg, dict) and cfg:
            selected: Dict[str, Any] = {}

            def _merge(target: Dict[str, Any], source: Dict[str, Any]) -> None:
                for key, value in source.items():
                    if not isinstance(key, str):
                        continue
                    if isinstance(value, dict):
                        node = target.get(key)
                        if not isinstance(node, dict):
                            node = {}
                            target[key] = node
                        _merge(node, value)
                    else:
                        target[key] = value

            exchange_name = ""
            try:
                exchange_name = str(((self.config or {}).get("exchange", {}) or {}).get("name", "") or "").lower()
            except Exception:
                exchange_name = ""

            profiles = cfg.get("profiles") if isinstance(cfg.get("profiles"), dict) else None
            if isinstance(profiles, dict) and profiles:
                default_profile = profiles.get("default")
                if isinstance(default_profile, dict):
                    _merge(selected, default_profile)
                if exchange_name and isinstance(profiles.get(exchange_name), dict):
                    _merge(selected, profiles[exchange_name])
            else:
                generic: Dict[str, Any] = {}
                for key, value in cfg.items():
                    key_lower = str(key).strip().lower()
                    if key_lower in {"default", "profiles"}:
                        continue
                    if key_lower in {"okx", "gate", "binance"}:
                        continue
                    generic[key] = value
                if generic:
                    _merge(selected, generic)
                default_cfg = cfg.get("default")
                if isinstance(default_cfg, dict):
                    _merge(selected, default_cfg)
                if exchange_name and isinstance(cfg.get(exchange_name), dict):
                    _merge(selected, cfg[exchange_name])

            if selected:
                _merge(settings, selected)

        self._entry_price_guard_cache = copy.deepcopy(settings)
        return copy.deepcopy(settings)

    def _entry_price_band_guard(
        self,
        *,
        side: str,
        price_position: float,
        price_pos_60: float,
        price_pos_240: float,
        session_vwap_premium: float,
        fast_lane: bool,
        slow_lane: bool,
        panic_lane_active: bool,
        mania_lane_active: bool,
        darkside_ok: bool,
        vol_confirm: bool,
    ) -> Tuple[bool, Optional[str], Optional[Dict[str, Any]]]:
        """限制 1m 模式在极端价格位置追涨杀跌。"""

        if not bool(getattr(self, "ENTRY_PRICE_BAND_GUARD_ENABLE", False)):
            return True, None, None

        if not np.isfinite(price_position):
            return True, None, None

        extra: Dict[str, Any] = {
            "price_pos": round(float(price_position), 4),
            "side": side,
        }
        anchor_values = {
            "price_position": float(price_position),
            "price_pos_60": float(price_pos_60) if np.isfinite(price_pos_60) else float("nan"),
            "price_pos_240": float(price_pos_240) if np.isfinite(price_pos_240) else float("nan"),
        }
        for key, val in anchor_values.items():
            if np.isfinite(val):
                extra[key] = round(float(val), 4)
        if np.isfinite(session_vwap_premium):
            extra["vwap_premium"] = round(float(session_vwap_premium), 6)

        trend_relief = float(getattr(self, "ENTRY_PRICE_TREND_RELIEF", self.ENTRY_PRICE_TREND_RELIEF)) if fast_lane else 0.0
        slow_relief = float(getattr(self, "ENTRY_PRICE_SLOW_RELIEF", self.ENTRY_PRICE_SLOW_RELIEF)) if slow_lane else 0.0
        extreme_relief = 0.0
        require_vol = bool(getattr(self, "ENTRY_PRICE_EXTREME_REQUIRE_VOL", True))
        if side == "long" and panic_lane_active:
            if vol_confirm or not require_vol:
                extreme_relief = float(getattr(self, "ENTRY_PRICE_EXTREME_RELIEF", self.ENTRY_PRICE_EXTREME_RELIEF))
            else:
                extra["extreme_relief_blocked"] = 1
        elif side == "short" and mania_lane_active:
            if vol_confirm or not require_vol:
                extreme_relief = float(getattr(self, "ENTRY_PRICE_EXTREME_RELIEF", self.ENTRY_PRICE_EXTREME_RELIEF))
            else:
                extra["extreme_relief_blocked"] = 1

        relief_cap = float(getattr(self, "ENTRY_PRICE_RELIEF_CAP", self.ENTRY_PRICE_RELIEF_CAP))
        relief_total = min(relief_cap, trend_relief + slow_relief + extreme_relief)
        extra["relief"] = round(float(relief_total), 4)

        guard_settings = self._entry_price_guard_settings(scope="guard")
        long_caps = guard_settings.get("long", {}).get("max", {}) if isinstance(guard_settings.get("long"), dict) else {}
        long_core_caps = guard_settings.get("long", {}).get("core", {}) if isinstance(guard_settings.get("long"), dict) else {}
        short_floors = guard_settings.get("short", {}).get("min", {}) if isinstance(guard_settings.get("short"), dict) else {}
        short_core_floors = guard_settings.get("short", {}).get("core", {}) if isinstance(guard_settings.get("short"), dict) else {}

        if side == "long":
            long_max = float(long_caps.get("price_position", getattr(self, "ENTRY_PRICE_LONG_MAX", 0.68)))
            allowed = min(1.0, long_max + relief_total)
            if price_position > allowed and not darkside_ok:
                extra["limit"] = round(float(allowed), 4)
                return False, "价格仍接近区间上沿，等待回踩", extra
            core_cap = min(
                1.0,
                float(long_core_caps.get("price_position", getattr(self, "ENTRY_PRICE_LONG_CORE_MAX", 0.52)))
                + trend_relief * 0.5
                + slow_relief,
            )
            if (
                price_position > core_cap
                and not fast_lane
                and not panic_lane_active
                and not darkside_ok
            ):
                extra["core_cap"] = round(float(core_cap), 4)
                return False, "尚未回到安全区间，不在半山腰抄底", extra
            for anchor_key, anchor_cap in long_caps.items():
                val = anchor_values.get(anchor_key)
                if not np.isfinite(val):
                    continue
                cap_val = float(anchor_cap)
                if anchor_key == "price_position":
                    cap_val = min(1.0, cap_val + relief_total)
                if val > cap_val and not darkside_ok:
                    extra[f"anchor_{anchor_key}"] = round(float(val), 4)
                    extra[f"anchor_{anchor_key}_cap"] = round(float(cap_val), 4)
                    return False, "多周期价格锚仍偏高，等待回踩", extra
            for anchor_key, anchor_cap in long_core_caps.items():
                if anchor_key == "price_position":
                    continue
                if fast_lane or panic_lane_active or darkside_ok:
                    continue
                val = anchor_values.get(anchor_key)
                if not np.isfinite(val):
                    continue
                cap_val = float(anchor_cap)
                if val > cap_val:
                    extra[f"anchor_core_{anchor_key}"] = round(float(val), 4)
                    extra[f"anchor_core_{anchor_key}_cap"] = round(float(cap_val), 4)
                    return False, "长周期仍处半山腰，暂缓抄底", extra
            vwap_cap = float(guard_settings.get("long", {}).get("vwap_max", getattr(self, "ENTRY_PRICE_LONG_VWAP_MAX", 0.012)))
            if np.isfinite(session_vwap_premium) and session_vwap_premium > vwap_cap and not darkside_ok:
                extra["vwap_cap"] = round(float(vwap_cap), 6)
                return False, "价格高于 VWAP 过多，等待回踩", extra
        else:
            short_min = float(short_floors.get("price_position", getattr(self, "ENTRY_PRICE_SHORT_MIN", 0.32)))
            allowed = max(0.0, short_min - relief_total)
            if price_position < allowed and not darkside_ok:
                extra["limit"] = round(float(allowed), 4)
                return False, "价格仍接近区间下沿，避免抄底开空", extra
            core_floor = max(
                0.0,
                float(short_core_floors.get("price_position", getattr(self, "ENTRY_PRICE_SHORT_CORE_MIN", 0.48)))
                - (trend_relief * 0.5 + slow_relief),
            )
            if (
                price_position < core_floor
                and not fast_lane
                and not mania_lane_active
                and not darkside_ok
            ):
                extra["core_floor"] = round(float(core_floor), 4)
                return False, "尚未重新拉高，不在半山腰做空", extra
            for anchor_key, anchor_floor in short_floors.items():
                val = anchor_values.get(anchor_key)
                if not np.isfinite(val):
                    continue
                floor_val = float(anchor_floor)
                if anchor_key == "price_position":
                    floor_val = max(0.0, floor_val - relief_total)
                if val < floor_val and not darkside_ok:
                    extra[f"anchor_{anchor_key}"] = round(float(val), 4)
                    extra[f"anchor_{anchor_key}_floor"] = round(float(floor_val), 4)
                    return False, "价格仍偏低，等待反弹后再做空", extra
            for anchor_key, anchor_floor in short_core_floors.items():
                if anchor_key == "price_position":
                    continue
                if fast_lane or mania_lane_active or darkside_ok:
                    continue
                val = anchor_values.get(anchor_key)
                if not np.isfinite(val):
                    continue
                floor_val = float(anchor_floor)
                if val < floor_val:
                    extra[f"anchor_core_{anchor_key}"] = round(float(val), 4)
                    extra[f"anchor_core_{anchor_key}_floor"] = round(float(floor_val), 4)
                    return False, "长周期尚未抬高，暂缓做空", extra
            vwap_floor = float(guard_settings.get("short", {}).get("vwap_min", getattr(self, "ENTRY_PRICE_SHORT_VWAP_MIN", 0.006)))
            if np.isfinite(session_vwap_premium) and session_vwap_premium < vwap_floor and not darkside_ok:
                extra["vwap_floor"] = round(float(vwap_floor), 6)
                return False, "价格尚未高出 VWAP，避免腰部做空", extra

        return True, None, None

    def _audit_runtime_safety(self) -> None:
        """教学提示：综合执行实盘前的安全审计，优先找出灾难性配置。"""

        self._audit_data_freshness_guards()
        self._audit_stoploss_runtime()
        self._audit_exit_tuning_runtime()
        self._audit_entry_quality_runtime()

    def _audit_dataframe_integrity(self, df: DataFrame, stage: str = "indicators") -> None:
        """教学提示：检查时间顺序与缺失值，避免未来函数/灾难性 NaN。"""

        try:
            if df is None or len(df) == 0:
                return

            fatal: List[str] = []
            warnings: List[str] = []

            idx = getattr(df, "index", None)
            if idx is not None:
                if hasattr(idx, "is_monotonic_increasing") and not idx.is_monotonic_increasing:
                    fatal.append("数据索引未按时间递增，可能存在未来函数/乱序。")
                if hasattr(idx, "has_duplicates") and idx.has_duplicates:
                    warnings.append("数据索引包含重复时间，请检查数据源去重。")

            base_cols = ["open", "high", "low", "close", "volume"]
            missing = [col for col in base_cols if col not in df.columns]
            if missing:
                fatal.append("缺少基础列：" + ", ".join(missing))
            else:
                sample = df[base_cols].tail(min(len(df), 500))
                nan_cols = [f"{col}:{int(sample[col].isna().sum())}" for col in base_cols if sample[col].isna().any()]
                if nan_cols:
                    warnings.append("基础列存在缺失值（近样本）：" + ", ".join(nan_cols))

            snapshot = {
                "stage": stage,
                "rows": int(len(df)),
                "fatal": fatal,
                "warnings": warnings,
            }
            self._df_integrity_snapshot = snapshot

            if fatal:
                logger.error("[数据完整性] %s 阶段发现致命风险：%s", stage, "；".join(fatal))
            elif warnings:
                logger.warning("[数据完整性] %s 阶段需要关注：%s", stage, "；".join(warnings))
        except Exception as exc:
            if self.DEBUG_LOG:
                self._d(f"[df_integrity_audit_failed]{stage}:{exc}")

    def _audit_curfew_timeout_snapshot(self) -> Dict[str, Any]:
        """教学提示：汇总会话宵禁与小目标超时配置，避免睡觉时段误开仓或超时未落袋。"""

        result: Dict[str, Any] = {
            "warnings": [],
            "notes": [],
            "curfew_slots": [],
            "small_target_timeout": {},
            "timezone_offset_hours": None,
        }

        cfg_params: Dict[str, Any] = {}
        try:
            cfg_params = ((self.config or {}).get("strategy_parameters")) or {}
        except Exception:
            cfg_params = {}
        strat_params = getattr(self, "_strategy_parameters", None)
        if isinstance(strat_params, dict) and strat_params:
            merged_params = dict(cfg_params)
            merged_params.update(strat_params)
            cfg_params = merged_params
        strat_params = getattr(self, "_strategy_parameters", None)
        if isinstance(strat_params, dict) and strat_params:
            merged_params = dict(cfg_params)
            merged_params.update(strat_params)
            cfg_params = merged_params

        offset_hours = 0.0
        try:
            offset_hours = float(getattr(self, "SESSION_TZ_OFFSET_HOURS", 0.0) or 0.0)
        except Exception:
            offset_hours = 0.0
        try:
            cfg_offset = float(((self.config or {}).get("session_timezone_offset_hours", offset_hours)) or 0.0)
            offset_hours = cfg_offset
        except Exception:
            pass
        try:
            cfg_offset = float(cfg_params.get("session_timezone_offset_hours", offset_hours) or offset_hours)
            offset_hours = cfg_offset
        except Exception:
            pass
        result["timezone_offset_hours"] = offset_hours
        result["notes"].append(f"宵禁窗口按本地时区（UTC{offset_hours:+.1f}）计算，日志关键词 session_curfew。")

        local_now_desc = ""
        try:
            utc_now = datetime.utcnow()
            local_now = utc_now + timedelta(hours=offset_hours)
            cur_hour = local_now.hour
            local_now_desc = f"当前本地时间 {local_now.strftime('%Y-%m-%d %H:%M:%S')} (hour={cur_hour:02d})"
        except Exception:
            cur_hour = None
        if local_now_desc:
            result["notes"].append(local_now_desc)

        slots = tuple(cfg_params.get("session_biases") or getattr(self, "SESSION_BIASES", tuple()) or tuple())
        curfew_seen = False
        for slot in slots:
            if not isinstance(slot, dict):
                continue
            try:
                start = int(slot.get("start", 0)) % 24
                end = int(slot.get("end", start)) % 24
            except Exception:
                start, end = 0, 0
            entry_block = bool(slot.get("block_entry", False) or slot.get("block_entries", False))
            add_block = bool(slot.get("block_add", False) or slot.get("block_adds", False))
            add_mult = float(slot.get("add_mult", 1.0) or 0.0)
            tri_mult = float(slot.get("tri_mult", 1.0) or 0.0)
            dist_mult = float(slot.get("dist_mult", 1.0) or 0.0)
            curfew_slot = {
                "label": str(slot.get("label", "session")),
                "start": start,
                "end": end,
                "window_local": f"{start:02d}-{end:02d}",
                "tri_mult": tri_mult,
                "dist_mult": dist_mult,
                "add_mult": add_mult,
                "block_entry": int(entry_block),
                "block_add": int(add_block),
            }
            if entry_block or add_block or add_mult == 0.0:
                curfew_seen = True
                result["notes"].append(
                    f"宵禁档 {curfew_slot['label']} {curfew_slot['window_local']} 本地：block_entries={entry_block}, block_adds={add_block}, add_mult={add_mult}."
                )
                try:
                    in_window = False
                    if cur_hour is not None:
                        if start <= end:
                            in_window = start <= cur_hour < end
                        else:
                            in_window = cur_hour >= start or cur_hour < end
                    if in_window:
                        result["notes"].append(
                            f"当前本地 hour={cur_hour:02d} 处于宵禁档 {curfew_slot['label']}，新仓/加仓将因 session_curfew 被拒绝。"
                        )
                except Exception:
                    pass
            result["curfew_slots"].append(curfew_slot)

        if not curfew_seen:
            result["warnings"].append(
                "SESSION_BIASES 未设置 block_entries/block_adds 或 add_mult=0 的宵禁档，睡觉时段可能继续开仓/加仓。"
            )

        try:
            po_cfg = ((self.config or {}).get("pair_overrides")) or {}
        except Exception:
            po_cfg = {}
        base_po = getattr(self, "pair_overrides", {}) or {}
        try:
            whitelist = list(((self.config or {}).get("exchange") or {}).get("pair_whitelist") or [])
        except Exception:
            whitelist = []

        default_hold = float(getattr(self, "SMALL_TARGET_MAX_HOLD_MINUTES", 0.0) or 0.0)
        timeout_summary: Dict[str, Any] = {"default": default_hold, "overrides": []}
        for pair in whitelist:
            merged: Dict[str, Any] = {}
            try:
                merged.update(base_po.get(pair, {}))
            except Exception:
                merged = dict(base_po) if isinstance(base_po, dict) else {}
                merged = merged.get(pair, {}) if isinstance(merged, dict) else {}
            try:
                extra_cfg = po_cfg.get(pair, {}) if isinstance(po_cfg, dict) else {}
            except Exception:
                extra_cfg = {}
            if isinstance(extra_cfg, dict):
                merged.update(extra_cfg)
            if "small_target_max_hold_minutes" in merged:
                try:
                    hold_val = float(merged.get("small_target_max_hold_minutes", 0.0) or 0.0)
                except Exception:
                    hold_val = None
                if hold_val is not None:
                    timeout_summary["overrides"].append({"pair": pair, "max_hold_minutes": hold_val})

        if default_hold <= 0.0 and not timeout_summary["overrides"]:
            result["warnings"].append(
                "SMALL_TARGET_MAX_HOLD_MINUTES=0 且未提供 per-pair 覆盖，小目标超时强平将被关闭。"
            )
        result["small_target_timeout"] = timeout_summary
        return result

    def _record_shadow_init(self, stage: str, df: DataFrame, expected: Sequence[str]) -> None:
        """记录入场/离场影子列初始化状态，避免批量赋值优化引发缺列风险。"""

        state = getattr(self, "_shadow_init_state", {})
        try:
            missing = [col for col in expected if col not in df.columns]
            state[stage] = {
                "expected": list(expected),
                "missing": missing,
                "rows": int(len(df)),
            }
            if missing:
                logger.warning("[shadow_init_missing]%s 缺少列：%s", stage, ", ".join(missing))
        except Exception as exc:
            if self.DEBUG_LOG:
                self._d(f"[shadow_init_record_failed]{stage}:{exc}")
        self._shadow_init_state = state

    def _final_pretrade_bug_sweep(self, stage: str = "startup") -> Dict[str, Any]:
        """实盘前执行一次灾难性风险体检，聚合关键守卫状态。"""

        try:
            checked_at = self._utc_now().isoformat()
        except Exception:
            checked_at = None

        summary: Dict[str, Any] = {
            "stage": stage,
            "checked_at": checked_at,
            "version": getattr(self, "STRATEGY_VERSION", None),
            "fatal": [],
            "warnings": [],
            "notes": [],
            "guards": {},
            "review_dirs_ready": bool(getattr(self, "_review_dirs_ready", False)),
        }

        def _extend(target: List[str], values: Optional[Sequence[Any]]) -> None:
            if not values:
                return
            for raw in values:
                try:
                    text = str(raw).strip()
                except Exception:
                    text = ""
                if not text:
                    continue
                if text not in target:
                    target.append(text)

        preflight = getattr(self, "_preflight_report", None)
        if isinstance(preflight, dict):
            _extend(summary["fatal"], preflight.get("fatal"))
            _extend(summary["warnings"], preflight.get("warnings"))
            disabled = preflight.get("disabled")
            if disabled:
                disabled_txt = ", ".join(str(item).strip() for item in disabled if str(item).strip())
                if disabled_txt:
                    _extend(summary["notes"], [f"自动关闭：{disabled_txt}"])

        entry_health = getattr(self, "_entry_mode_health", None)
        if isinstance(entry_health, dict):
            _extend(summary["warnings"], entry_health.get("warnings"))
            _extend(summary["notes"], entry_health.get("notes"))

        feature_audit = getattr(self, "_feature_audit_report", None)
        if isinstance(feature_audit, dict):
            _extend(summary["warnings"], feature_audit.get("conflicts"))
            _extend(summary["warnings"], feature_audit.get("warnings"))
            _extend(summary["notes"], feature_audit.get("notes"))

        directional_audit = getattr(self, "_directional_audit_report", None)
        if isinstance(directional_audit, dict):
            _extend(summary["warnings"], directional_audit.get("warnings"))
            _extend(summary["notes"], directional_audit.get("notes"))

        if not summary["review_dirs_ready"]:
            _extend(summary["warnings"], ["复盘导出目录尚未准备，检查 review_export 路径或写权限。"])

        guard_snapshot: Dict[str, Dict[str, Any]] = {}
        guard_status = getattr(self, "_entry_guard_status", {}) or {}
        for guard, mapping in guard_status.items():
            if not mapping:
                continue
            guard_snapshot[guard] = {pair: dict(payload) for pair, payload in mapping.items()}
            for pair, payload in mapping.items():
                reason = "守卫锁定"
                resume = None
                if isinstance(payload, dict):
                    reason = str(payload.get("reason") or reason)
                    resume = payload.get("resume_at")
                message = f"入场守卫[{guard}] {pair} 仍在锁定：{reason}"
                if resume:
                    message += f"（预计恢复 {resume}）"
                _extend(summary["warnings"], [message])
        summary["guards"] = guard_snapshot

        curfew_audit = self._audit_curfew_timeout_snapshot()
        if isinstance(curfew_audit, dict):
            _extend(summary["warnings"], curfew_audit.get("warnings"))
            _extend(summary["notes"], curfew_audit.get("notes"))
            summary["curfew_snapshot"] = {
                "sessions": curfew_audit.get("curfew_slots"),
                "small_target_timeout": curfew_audit.get("small_target_timeout"),
            }

        df_integrity = getattr(self, "_df_integrity_snapshot", None)
        if isinstance(df_integrity, dict):
            _extend(summary["fatal"], df_integrity.get("fatal"))
            _extend(summary["warnings"], df_integrity.get("warnings"))
            summary["dataframe_integrity"] = dict(df_integrity)

        shadow_state = getattr(self, "_shadow_init_state", None)
        if isinstance(shadow_state, dict) and shadow_state:
            summary["shadow_init"] = {k: dict(v) for k, v in shadow_state.items()}
            for stage_key, payload in shadow_state.items():
                if not isinstance(payload, dict):
                    continue
                missing_cols = payload.get("missing") or []
                if missing_cols:
                    _extend(summary["warnings"], [f"{stage_key} 初始化缺少列：" + ", ".join(missing_cols)])
        else:
            _extend(summary["warnings"], ["影子列初始化状态未记录，检查 populate_entry_trend/populate_exit_trend 是否执行。"])

        try:
            fallback = float(getattr(self, "STOPLOSS_FALLBACK", 0.0) or 0.0)
            if fallback <= 0:
                _extend(summary["warnings"], ["STOPLOSS_FALLBACK 未配置为正值，无法提供资金兜底。"])
        except Exception:
            _extend(summary["warnings"], ["STOPLOSS_FALLBACK 解析失败，需检查策略参数。"])

        summary["ready"] = not bool(summary["fatal"])

        review_state = getattr(self, "_review_state", None)
        if isinstance(review_state, dict):
            stage_key = str(stage or "startup")
            existing = review_state.get("catastrophic_sweep")
            if isinstance(existing, dict):
                existing[stage_key] = dict(summary)
            else:
                review_state["catastrophic_sweep"] = {stage_key: dict(summary)}

        self._catastrophic_sweep_report = dict(summary)

        try:
            self._feature_registry_report = self._compile_feature_registry()
        except Exception as exc:
            if self.DEBUG_LOG:
                self._d(f"[feature_registry_refresh_failed]{exc}")
        else:
            if isinstance(review_state, dict):
                review_state["feature_registry"] = dict(self._feature_registry_report)

        registry_report = getattr(self, "_feature_registry_report", None)
        if isinstance(registry_report, dict):
            _extend(summary["warnings"], registry_report.get("attention"))
            recommended_disabled = registry_report.get("recommended_disabled") or []
            if recommended_disabled:
                _extend(summary["notes"], ["推荐功能关闭：" + ", ".join(recommended_disabled)])

        if summary["fatal"]:
            logger.error(
                "[灾难体检] %s 阶段发现致命风险：%s",
                stage,
                "；".join(summary["fatal"]),
            )
        elif summary["warnings"]:
            logger.warning(
                "[灾难体检] %s 阶段存在待确认项：%s",
                stage,
                "；".join(summary["warnings"]),
            )
        else:
            logger.info("[灾难体检] %s 阶段检查通过，资金守卫就绪。", stage)

        return summary

    def _audit_entry_quality_runtime(self) -> None:
        """检查入场质量阈值是否存在冲突或冗余配置。"""

        def _check_scope(label: str, cfg: Dict[str, Any]) -> None:
            warnings: List[str] = []
            notes: List[str] = []

            try:
                base_need = float(cfg.get("base_need", 0.0))
                slow_need = float(cfg.get("slow_need", base_need))
                fast_need = float(cfg.get("fast_need", slow_need))
            except (TypeError, ValueError):
                logger.warning("[入场阈值审计][%s] base/slow/fast need 无法解析，建议复查配置格式。", label)
                return

            tolerance = 1e-3
            if slow_need + tolerance < base_need:
                warnings.append(
                    f"慢车道需求 {slow_need:.3f} 低于基础阈值 {base_need:.3f}，可能导致区间信号更宽松。"
                )
            if fast_need + tolerance < slow_need:
                warnings.append(
                    f"快车道需求 {fast_need:.3f} 低于慢车道 {slow_need:.3f}，快线信号可能过于宽松。"
                )

            price_floor = float(cfg.get("price_floor", 0.0) or 0.0)
            price_ceil = float(cfg.get("price_ceil", 1.0) or 1.0)
            if price_floor + tolerance >= price_ceil:
                warnings.append(
                    f"价格评分区间 floor={price_floor:.3f} >= ceil={price_ceil:.3f}，请检查 price_floor/price_ceil 设置。"
                )

            price_weight = float(cfg.get("price_weight", 0.0) or 0.0)
            if price_weight <= 0.0:
                notes.append("价格权重未启用（price_weight<=0），可考虑移除相关配置或设为正值。")

            weight_sum = 0.0
            for key in ("align_weight", "tri_weight", "rfs_weight", "priority_weight"):
                try:
                    weight_sum += float(cfg.get(key, 0.0) or 0.0)
                except (TypeError, ValueError):
                    warnings.append(f"权重 {key} 解析失败，建议仅使用数字。")
            if not np.isfinite(weight_sum) or weight_sum <= 0.0:
                warnings.append("入场质量权重总和 <=0，评分将退回默认值。")

            buffer_val = float(cfg.get("need_buffer", 0.0) or 0.0)
            if buffer_val < 0.0:
                warnings.append("need_buffer 为负数，会导致阈值反向收紧，建议改为 ≥0。")
            elif buffer_val == 0.0:
                notes.append("质量缓冲 need_buffer=0，擦边信号将直接参考基础阈值。")

            for key in ("need_buffer_fast_mult", "need_buffer_slow_mult", "need_buffer_extreme_mult"):
                try:
                    mult_val = float(cfg.get(key, 0.0) or 0.0)
                except (TypeError, ValueError):
                    warnings.append(f"{key} 解析失败，建议仅使用数字。")
                    continue
                if mult_val < 0.0:
                    warnings.append(f"{key} 为负数，将导致缓冲符号翻转。")

            if warnings:
                for msg in warnings:
                    logger.warning("[入场阈值审计][%s] %s", label, msg)
            elif notes:
                for msg in notes:
                    logger.info("[入场阈值审计][%s] %s", label, msg)
            else:
                logger.debug("[入场阈值审计][%s] 阈值检查通过。", label)

        try:
            global_settings = self._entry_quality_settings(None, scope="audit")
        except Exception as exc:
            logger.warning("[入场阈值审计] 解析全局入场质量配置失败：%s", exc)
            return

        _check_scope("global", global_settings)
        per_side_global = dict(global_settings.get("_per_side", {}) or {})
        for side_name, side_cfg in per_side_global.items():
            _check_scope(f"global.{side_name}", side_cfg)

        pair_map = getattr(self, "_entry_quality_pair_settings", {}) or {}
        for pair_key, pair_cfg in pair_map.items():
            if not isinstance(pair_cfg, dict):
                continue
            _check_scope(pair_key, pair_cfg)
            per_side_cfg = dict(pair_cfg.get("_per_side", {}) or {})
            for side_name, side_cfg in per_side_cfg.items():
                _check_scope(f"{pair_key}.{side_name}", side_cfg)

    def _compile_feature_registry(self) -> Dict[str, Any]:
        """汇总核心功能启用状态，避免伪功能或被误关的守卫。"""

        def _safe_value(value: Any) -> Any:
            if value is None:
                return None
            if isinstance(value, (str, int, float, bool)):
                return value
            if isinstance(value, Decimal):
                try:
                    return float(value)
                except Exception:
                    return str(value)
            if isinstance(value, dict):
                return {str(k): _safe_value(v) for k, v in value.items()}
            if isinstance(value, (list, tuple, set)):
                return [_safe_value(item) for item in value]
            try:
                return float(value)
            except Exception:
                return str(value)

        def _check_preflight() -> Tuple[bool, Dict[str, Any], Optional[str]]:
            report = getattr(self, "_preflight_report", None)
            if isinstance(report, dict):
                fatals = list(report.get("fatal", []) or [])
                warnings = list(report.get("warnings", []) or [])
                disabled = list(report.get("disabled", []) or [])
                enabled = not bool(fatals)
                note = "preflight 存在致命风险" if fatals else None
                return enabled, {
                    "fatal": fatals,
                    "warnings": warnings,
                    "disabled": disabled,
                }, note
            return False, {"error": "preflight_report_missing"}, "preflight 尚未执行"

        def _check_catastrophic() -> Tuple[bool, Dict[str, Any], Optional[str]]:
            sweep = getattr(self, "_catastrophic_sweep_report", None)
            if isinstance(sweep, dict):
                fatals = list(sweep.get("fatal", []) or [])
                warnings = list(sweep.get("warnings", []) or [])
                ready = not bool(fatals)
                note = "灾难体检存在致命风险" if fatals else None
                return ready, {
                    "fatal": fatals,
                    "warnings": warnings,
                    "review_dirs_ready": bool(sweep.get("review_dirs_ready", False)),
                }, note
            return False, {"error": "catastrophic_sweep_missing"}, "灾难体检尚未执行"

        def _check_opp_stage() -> Tuple[bool, Dict[str, Any], Optional[str]]:
            try:
                stage1 = float(getattr(self, "OPP_STAGE1_R", 0.0) or 0.0)
                stage2 = float(getattr(self, "OPP_STAGE2_R", 0.0) or 0.0)
                stage3 = float(getattr(self, "OPP_STAGE3_R", 0.0) or 0.0)
                stage1_reduce = float(getattr(self, "OPP_STAGE1_REDUCE", 0.0) or 0.0)
                stage2_reduce = float(getattr(self, "OPP_STAGE2_REDUCE", 0.0) or 0.0)
                stage3_reduce = float(getattr(self, "OPP_STAGE3_REDUCE", 0.0) or 0.0)
                stage_timeout = float(getattr(self, "OPP_STAGE_TIMEOUT_MINUTES", 0.0) or 0.0)
            except Exception:
                return False, {"error": "opp_stage_parse_failed"}, "opp_stage_exit 参数解析失败"

            details = {
                "stage1_r": stage1,
                "stage1_reduce": stage1_reduce,
                "stage2_r": stage2,
                "stage2_reduce": stage2_reduce,
                "stage3_r": stage3,
                "stage3_reduce": stage3_reduce,
                "stage_timeout_minutes": stage_timeout,
            }
            enabled = stage1 > 0 and stage2 > 0 and stage3 > 0
            note = None
            if stage_timeout <= 0:
                note = "opp_stage_timeout 未设置，超时全平将失效"
            return enabled, details, note

        blueprint: List[Dict[str, Any]] = [
            {
                "name": "channel_pivot",
                "category": "entry",
                "description": "Channel pivot 反手冷静期",
                "attr": "CHANNEL_PIVOT_ENABLE",
                "params": [
                    "CHANNEL_PIVOT_PULLBACK_COOLDOWN",
                    "CHANNEL_PIVOT_LOOKBACK_BARS",
                    "CHANNEL_PIVOT_UP_ALIGN_NEED",
                    "CHANNEL_PIVOT_DOWN_ALIGN_NEED",
                ],
                "recommended": True,
            },
            {
                "name": "darkside_entry",
                "category": "entry",
                "description": "暗面进场减刑",
                "attr": "DARKSIDE_ENTRY_ENABLE",
                "params": [
                    "ENTRY_FRONTLOAD_DARKSIDE_PASS_PENALTY",
                    "ENTRY_FRONTLOAD_DARKSIDE_ACTIVE_PENALTY",
                ],
                "recommended": True,
            },
            {
                "name": "quiet_mode",
                "category": "entry",
                "description": "Quiet Mode 震荡过滤",
                "attr": "QUIET_MODE",
                "recommended": True,
            },
            {
                "name": "strict_giveback",
                "category": "exit",
                "description": "Strict Giveback 锁盈守卫",
                "attr": "STRICT_GIVEBACK_ENABLE",
                "params": [
                    "STRICT_GIVEBACK_ARM_R",
                    "STRICT_GIVEBACK_FLOOR_SHARE",
                    "STRICT_GIVEBACK_FLOOR_R_MIN",
                ],
                "recommended": True,
            },
            {
                "name": "expectation_guard",
                "category": "exit",
                "description": "Expectation Guard 期望守卫",
                "attr": "EXPECTATION_GUARD_ENABLE",
                "params": [
                    "EXPECTATION_RELEASE_FLOOR_R",
                    "EXPECTATION_TARGET_R",
                    "EXPECTATION_RELEASE_R",
                ],
                "recommended": True,
            },
            {
                "name": "opp_stage_exit",
                "category": "exit",
                "description": "反向信号三阶段减仓 + 超时全平",
                "check": _check_opp_stage,
                "recommended": True,
            },
            {
                "name": "measured_move",
                "category": "exit",
                "description": "Measured Move 弹性止盈",
                "attr": "MEASURED_MOVE_ENABLE",
                "params": [
                    "MEASURED_MOVE_R_MULT",
                    "MEASURED_MOVE_TREND_R",
                ],
                "recommended": True,
            },
            {
                "name": "measured_move_super",
                "category": "exit",
                "description": "2R 超级趋势放行",
                "attr": "MEASURED_MOVE_SUPER_ENABLE",
                "params": [
                    "MEASURED_MOVE_SUPER_R",
                    "MEASURED_MOVE_SUPER_ALIGN",
                ],
                "recommended": False,
            },
            {
                "name": "flash_vol_guard",
                "category": "risk",
                "description": "闪电插针风控",
                "attr": "FLASH_VOL_GUARD_ENABLE",
                "params": [
                    "FLASH_VOL_GUARD_WICK_SHARE",
                    "FLASH_VOL_GUARD_VOLUME_MULT",
                    "FLASH_VOL_GUARD_MOVE_PCT",
                ],
                "recommended": True,
            },
            {
                "name": "review_markdown",
                "category": "review",
                "description": "每日复盘 Markdown",
                "attr": "REVIEW_REPORT_ENABLE",
                "recommended": True,
            },
            {
                "name": "review_json",
                "category": "review",
                "description": "结构化 analytics JSON",
                "attr": "REVIEW_REPORT_EXPORT_JSON",
                "recommended": False,
            },
            {
                "name": "review_state_snapshot",
                "category": "review",
                "description": "review_state 独立快照",
                "attr": "REVIEW_STATE_EXPORT_STANDALONE",
                "recommended": True,
            },
            {
                "name": "short_guard",
                "category": "position",
                "description": "空单数量守卫",
                "attr": "DIRECTIONAL_SHORT_OPEN_ENABLE",
                "params": [
                    "DIRECTIONAL_SHORT_MAX_OPEN",
                ],
                "recommended": True,
            },
            {
                "name": "preflight_disaster_guard",
                "category": "safety",
                "description": "实盘前灾难体检",
                "check": _check_preflight,
                "recommended": True,
            },
            {
                "name": "catastrophic_sweep",
                "category": "safety",
                "description": "灾难性资金体检",
                "check": _check_catastrophic,
                "recommended": True,
            },
        ]

        try:
            generated_at = self._utc_now().isoformat()
        except Exception:
            generated_at = None

        entries: List[Dict[str, Any]] = []
        total = len(blueprint)
        enabled_count = 0
        disabled_count = 0
        missing_count = 0
        error_count = 0
        recommended_disabled: List[str] = []
        attention: List[str] = []

        for item in blueprint:
            record: Dict[str, Any] = {
                "name": item.get("name"),
                "category": item.get("category"),
                "description": item.get("description"),
                "recommended": bool(item.get("recommended", False)),
            }

            status = "unknown"
            notes: List[str] = []
            details: Dict[str, Any] = {}

            try:
                if item.get("check"):
                    enabled, extra, note = item["check"]()
                    record["enabled"] = bool(enabled)
                    status = "enabled" if enabled else "disabled"
                    if extra:
                        details.update(_safe_value(extra) if isinstance(extra, dict) else {"value": _safe_value(extra)})
                    if note:
                        notes.append(str(note))
                else:
                    attr_name = item.get("attr")
                    if attr_name is None:
                        raise ValueError("feature entry missing attr/check")
                    if not hasattr(self, attr_name):
                        status = "missing"
                        record["enabled"] = None
                        details["attr"] = attr_name
                    else:
                        raw_value = getattr(self, attr_name)
                        record["value"] = _safe_value(raw_value)
                        is_enabled = bool(raw_value)
                        record["enabled"] = is_enabled
                        status = "enabled" if is_enabled else "disabled"
                    params = item.get("params") or []
                    param_snapshot: Dict[str, Any] = {}
                    for param in params:
                        if hasattr(self, param):
                            param_snapshot[param] = _safe_value(getattr(self, param))
                    if param_snapshot:
                        details["params"] = param_snapshot
            except Exception as exc:
                status = "error"
                record["enabled"] = None
                notes.append(f"检查失败：{exc}")

            if details:
                record["details"] = details
            if notes:
                record["notes"] = notes

            if status == "enabled":
                enabled_count += 1
            elif status == "disabled":
                disabled_count += 1
                if record["recommended"]:
                    recommended_disabled.append(str(record.get("name")))
            elif status == "missing":
                missing_count += 1
                attention.append(f"{record.get('name')} 功能缺失（未找到对应属性/检查）。")
            elif status == "error":
                error_count += 1
                attention.append(f"{record.get('name')} 功能检查失败。")

            record["status"] = status
            entries.append(record)

        if recommended_disabled:
            attention.append(
                "推荐功能被关闭：" + ", ".join(recommended_disabled)
            )

        summary: Dict[str, Any] = {
            "generated_at": generated_at,
            "total": total,
            "enabled": enabled_count,
            "disabled": disabled_count,
            "missing": missing_count,
            "errors": error_count,
            "recommended_disabled": recommended_disabled,
            "attention": attention,
            "features": entries,
        }

        if attention:
            logger.warning("[功能巡检] 发现需关注项目：%s", "；".join(attention))
        elif self.DEBUG_LOG:
            self._d("feature_registry=ok")

        return summary

    def _preflight_disaster_guard(self) -> Dict[str, Any]:
        """实盘前自检：检查关键 config / 守卫状态，必要时关闭高风险逻辑。"""

        config_obj = getattr(self, "config", None)
        if not isinstance(config_obj, dict):
            config_obj = {}
            try:
                setattr(self, "config", config_obj)
            except Exception:
                pass
        config = config_obj
        exchange_cfg = (config.get("exchange") or {}) if isinstance(config, dict) else {}

        def _norm(value: Any) -> str:
            if value is None:
                return ""
            if isinstance(value, str):
                return value.strip().lower()
            return str(value).strip().lower()

        warnings: List[str] = []
        fatals: List[str] = []
        disabled: List[str] = []

        trading_mode = _norm(config.get("trading_mode") or exchange_cfg.get("trading_mode"))
        if trading_mode:
            if trading_mode not in {"futures"}:
                fatals.append(f"trading_mode={trading_mode}，与策略期货/永续假设不符。")
        else:
            warnings.append("未在 config 中显式设置 trading_mode=futures，建议同步模板。")

        margin_mode = _norm(config.get("margin_mode") or exchange_cfg.get("margin_mode"))
        if margin_mode:
            if margin_mode not in {"isolated"}:
                warnings.append(f"margin_mode={margin_mode}，可能触发交叉保证金风险，请确认。")
        else:
            warnings.append("未显式声明 margin_mode=isolated，默认值需手动确认。")

        hedge_mode = _norm(config.get("hedge_mode") or exchange_cfg.get("hedge_mode"))
        if hedge_mode and hedge_mode not in {"true", "1", "yes", "on"}:
            warnings.append("未启用 hedge_mode，多空同持将失效。")

        strat_timeframe = str(getattr(self, "timeframe", "") or "").strip()
        cfg_timeframe = str(
            (config.get("timeframe") if isinstance(config, dict) else None)
            or (config.get("ticker_interval") if isinstance(config, dict) else None)
            or ""
        ).strip()
        if strat_timeframe:
            if cfg_timeframe and cfg_timeframe != strat_timeframe:
                synced = False
                if isinstance(config, dict):
                    try:
                        config["timeframe"] = strat_timeframe
                        synced = True
                    except Exception:
                        synced = synced or False
                    try:
                        config["ticker_interval"] = strat_timeframe
                        synced = True
                    except Exception:
                        synced = synced or False
                if synced:
                    warnings.append(
                        f"config timeframe={cfg_timeframe} 已自动同步为 {strat_timeframe} 以匹配策略设置。"
                    )
                    cfg_timeframe = strat_timeframe
                else:
                    fatals.append(
                        f"config timeframe={cfg_timeframe} 与策略 {strat_timeframe} 不一致，且自动同步失败。"
                    )
            elif not cfg_timeframe and isinstance(config, dict):
                try:
                    config["timeframe"] = strat_timeframe
                    if "ticker_interval" not in config:
                        config["ticker_interval"] = strat_timeframe
                    warnings.append(
                        f"config 未声明 timeframe，已自动填入 {strat_timeframe} 与策略保持一致。"
                    )
                    cfg_timeframe = strat_timeframe
                except Exception:
                    warnings.append(
                        "config 未声明 timeframe，自动填充失败，请手动在配置中加入当前策略时间框架。"
                    )
        elif cfg_timeframe:
            warnings.append(
                f"策略时间框架缺失，沿用 config timeframe={cfg_timeframe}，请复查自定义代码。"
            )

        stake_currency = str(config.get("stake_currency") or "").upper()
        if stake_currency and stake_currency not in {"USDT", "USDC"}:
            warnings.append(f"stake_currency={stake_currency}，需确认撮合与风险参数是否匹配。")

        if not bool(getattr(self, "position_adjustment_enable", False)):
            warnings.append("position_adjustment_enable=False，将无法执行加仓/防守腿逻辑。")

        entry_health = getattr(self, "_entry_mode_health", {}) or {}
        entry_warnings = list(entry_health.get("warnings", []) or [])
        if entry_warnings:
            warnings.extend(f"[Entry] {msg}" for msg in entry_warnings)

        if getattr(self, "MEASURED_MOVE_SUPER_ENABLE", False) and entry_warnings:
            setattr(self, "MEASURED_MOVE_SUPER_ENABLE", False)
            disabled.append("MEASURED_MOVE_SUPER_ENABLE")
            warnings.append("entry_mode_health 未通过，自检自动关闭 2R 超级趋势，修复后再开启。")

        report: Dict[str, Any] = {
            "trading_mode": trading_mode or None,
            "margin_mode": margin_mode or None,
            "hedge_mode": hedge_mode or None,
            "timeframe": cfg_timeframe or None,
            "stake_currency": stake_currency or None,
            "warnings": warnings,
            "fatal": fatals,
            "disabled": disabled,
        }

        feature_audit = getattr(self, "_feature_audit_report", None)
        if isinstance(feature_audit, dict):
            report["feature_audit"] = {
                "warnings": list(feature_audit.get("warnings", []) or []),
                "conflicts": list(feature_audit.get("conflicts", []) or []),
                "notes": list(feature_audit.get("notes", []) or []),
                "sections": dict(feature_audit.get("sections", {}) or {}),
            }
            if feature_audit.get("conflicts"):
                warnings.append("功能冲突审计检测到冲突，详见 review_state.feature_audit.conflicts。")
            elif feature_audit.get("warnings"):
                warnings.append("功能冲突审计存在警告，详见 review_state.feature_audit.warnings。")

        directional_audit = getattr(self, "_directional_audit_report", None)
        if isinstance(directional_audit, dict):
            report["directional_audit"] = {
                "warnings": list(directional_audit.get("warnings", []) or []),
                "notes": list(directional_audit.get("notes", []) or []),
            }
            if directional_audit.get("warnings"):
                warnings.append("多空对称审计存在警告，详见 review_state.directional_audit.warnings。")

        expectation_audit: List[Dict[str, Any]] = []
        try:
            merged_pairs = self._merge_pair_overrides()
        except Exception:
            merged_pairs = {}

        def _expectation_val(payload: Dict[str, Any], key: str, attr: str) -> Optional[float]:
            val = payload.get(key)
            if val is None:
                val = getattr(self, attr, None)
            return self._safe_float(val)

        target_range = (1.0, 2.2)
        release_floor_range = (0.24, 0.55)
        default_drawdown = self._safe_float(getattr(self, "EXPECTATION_DRAWDOWN_R", None)) or 0.0

        if merged_pairs:
            for pair, payload in merged_pairs.items():
                if not isinstance(payload, dict):
                    continue
                guard_enable = payload.get("expectation_guard_enable", getattr(self, "EXPECTATION_GUARD_ENABLE", False))
                target_r = _expectation_val(payload, "expectation_target_r", "EXPECTATION_TARGET_R")
                release_r = _expectation_val(payload, "expectation_release_r", "EXPECTATION_RELEASE_R")
                floor_r = _expectation_val(payload, "expectation_release_floor_r", "EXPECTATION_RELEASE_FLOOR_R")
                drawdown_r = _expectation_val(payload, "expectation_drawdown_r", "EXPECTATION_DRAWDOWN_R") or default_drawdown
                escalate_r = _expectation_val(payload, "expectation_floor_escalate_at_r", "EXPECTATION_FLOOR_ESCALATE_AT_R")

                entry = {
                    "pair": pair,
                    "guard_enable": bool(guard_enable),
                    "target_r": target_r,
                    "release_r": release_r,
                    "floor_r": floor_r,
                    "drawdown_r": drawdown_r,
                    "escalate_at_r": escalate_r,
                }
                expectation_audit.append(entry)

                if not guard_enable:
                    warnings.append(f"{pair} 关闭 expectation guard，需确认与人工锁盈节奏一致。")
                    continue
                if target_r is not None and not (target_range[0] <= target_r <= target_range[1]):
                    warnings.append(f"{pair} expectation_target_r={target_r:.2f} 超出 1–2R 区间，请确认是否沿用人工节奏。")
                if floor_r is not None and not (release_floor_range[0] <= floor_r <= release_floor_range[1]):
                    warnings.append(f"{pair} expectation_release_floor_r={floor_r:.2f} 偏离 0.25–0.5R 落袋区，建议校正以贴合人工平仓百分比。")
                if release_r is not None and floor_r is not None and release_r < floor_r:
                    warnings.append(f"{pair} expectation_release_r={release_r:.2f} 低于 floor_r={floor_r:.2f}，请同步策略与配置。")
                if drawdown_r and drawdown_r > (floor_r or drawdown_r):
                    warnings.append(f"{pair} expectation_drawdown_r={drawdown_r:.2f} 高于地板，可能导致回吐过大。")

        if expectation_audit:
            report["expectation_audit"] = expectation_audit

        review_state = getattr(self, "_review_state", None)
        if isinstance(review_state, dict):
            review_state["preflight_disaster_guard"] = dict(report)

        if disabled:
            logger.warning("[实盘前自检] 自动关闭模块：%s", ", ".join(disabled))
        if fatals:
            logger.error("[实盘前自检] 致命配置冲突：%s", "；".join(fatals))
        if warnings:
            logger.warning("[实盘前自检] %s", "；".join(warnings))
        elif not fatals and self.DEBUG_LOG:
            self._d("preflight_disaster_guard=ok")

        return report

    def _entry_mode_health_check(self) -> Dict[str, Any]:
        """进场体检：确认 channel pivot 反手与暗面减刑仍按预期启用。"""

        pivot_enabled = bool(getattr(self, "CHANNEL_PIVOT_ENABLE", False))
        try:
            pivot_cooldown = int(getattr(self, "CHANNEL_PIVOT_PULLBACK_COOLDOWN", 0) or 0)
        except (TypeError, ValueError):
            pivot_cooldown = 0
        try:
            pivot_align_up = float(getattr(self, "CHANNEL_PIVOT_UP_ALIGN_NEED", 0.0) or 0.0)
        except (TypeError, ValueError):
            pivot_align_up = 0.0
        try:
            pivot_align_down = float(getattr(self, "CHANNEL_PIVOT_DOWN_ALIGN_NEED", 0.0) or 0.0)
        except (TypeError, ValueError):
            pivot_align_down = 0.0

        darkside_enabled = bool(getattr(self, "DARKSIDE_ENTRY_ENABLE", False))
        profile_raw = getattr(self, "DARKSIDE_ENTRY_PROFILE", {}) or {}
        profile_long = profile_raw.get("long") if isinstance(profile_raw, dict) else {}
        profile_short = profile_raw.get("short") if isinstance(profile_raw, dict) else {}
        darkside_has_long = isinstance(profile_long, dict) and bool(profile_long)
        darkside_has_short = isinstance(profile_short, dict) and bool(profile_short)
        pass_penalty = float(getattr(self, "ENTRY_FRONTLOAD_DARKSIDE_PASS_PENALTY", 0.0) or 0.0)
        active_penalty = float(getattr(self, "ENTRY_FRONTLOAD_DARKSIDE_ACTIVE_PENALTY", 0.0) or 0.0)

        warnings: List[str] = []
        notes: List[str] = []
        if not pivot_enabled:
            warnings.append("channel pivot 已关闭，突破后可能立即反手，需确认这是预期行为。")
        else:
            if pivot_cooldown <= 0:
                warnings.append("channel pivot 缺少冷静期（CHANNEL_PIVOT_PULLBACK_COOLDOWN<=0）。")
            if pivot_align_up <= 0 or pivot_align_down <= 0:
                warnings.append("channel pivot 对齐阈值未配置，反手守卫可能失效。")

        if not darkside_enabled:
            notes.append("暗面减刑关闭，panic/mania 极端区将完全拒单。")
        else:
            if not darkside_has_long or not darkside_has_short:
                warnings.append("暗面配置缺少 long/short 任一侧参数，衰竭区减刑可能失效。")
            if pass_penalty <= 0 or active_penalty <= 0:
                notes.append("暗面首腿惩罚<=0，探针仓可能放大。")

        summary = {
            "channel_pivot": {
                "enabled": pivot_enabled,
                "cooldown": pivot_cooldown,
                "align_up": round(pivot_align_up, 4),
                "align_down": round(pivot_align_down, 4),
            },
            "darkside": {
                "enabled": darkside_enabled,
                "has_long": bool(darkside_has_long),
                "has_short": bool(darkside_has_short),
                "pass_penalty": round(pass_penalty, 4),
                "active_penalty": round(active_penalty, 4),
            },
            "warnings": warnings,
            "notes": notes,
        }

        review_state = getattr(self, "_review_state", None)
        if isinstance(review_state, dict):
            review_state["entry_mode_health"] = summary

        if warnings:
            logger.warning("[进场体检] %s", "; ".join(warnings))
        elif self.DEBUG_LOG:
            self._d(f"entry_mode_health={summary}")

        return summary

    def _darkside_entry_context(
        self,
        *,
        side: str,
        tri_need: float,
        tri_bias: float,
        align_score: float,
        rfs_value: float,
        price_position: float,
        panic_guard: int,
        panic_slope_guard: int,
        blowoff_guard: int,
        reflex_z: float,
        fast_lane: bool,
        slow_lane: bool,
        channel_narrow: bool,
        channel_wide: bool,
        channel_decay: bool,
        vol_any: int,
    ) -> Dict[str, Any]:
        """当 panic/mania 极端护栏出现衰竭迹象时，评估是否给予“暗面进场”减刑。"""

        if not bool(getattr(self, "DARKSIDE_ENTRY_ENABLE", False)):
            return {}

        profile = getattr(self, "DARKSIDE_ENTRY_PROFILE", {}) or {}
        cfg = profile.get("long" if side == "long" else "short", {}) or {}

        price_trigger = float(cfg.get("price_trigger", 0.26 if side == "long" else 0.74))
        price_span = max(0.02, float(cfg.get("price_span", 0.09)))
        require_volume = bool(cfg.get("require_volume", True))

        if side == "long":
            guard_flag = int(max(panic_guard, panic_slope_guard))
            price_component = float(np.clip((price_trigger - price_position) / price_span, 0.0, 1.0))
            align_metric = max(0.0, float(align_score))
            reflex_metric = float(reflex_z)
        else:
            guard_flag = int(max(blowoff_guard, 0))
            price_component = float(np.clip((price_position - price_trigger) / price_span, 0.0, 1.0))
            align_metric = max(0.0, float(-align_score))
            reflex_metric = float(-reflex_z)

        active = bool(guard_flag >= 1 or price_component > 0.0)
        if not active:
            return {"active": 0}

        align_base = max(0.0, float(cfg.get("align_base", 0.18)))
        align_span = max(0.05, float(cfg.get("align_span", 0.26)))
        align_component = float(np.clip((align_metric - align_base) / align_span, 0.0, 1.0))

        tri_relief = max(0.0, float(cfg.get("tri_relief", 0.06)))
        tri_span = max(0.05, float(cfg.get("tri_span", 0.20)))
        tri_target = max(0.0, tri_need - tri_relief)
        tri_component = float(np.clip((tri_bias - tri_target) / tri_span, 0.0, 1.0))

        rfs_base = max(0.0, float(cfg.get("rfs_base", 0.40)))
        rfs_span = max(0.05, float(cfg.get("rfs_span", 0.24)))
        rfs_component = float(np.clip((rfs_value - rfs_base) / rfs_span, 0.0, 1.0))

        reflex_base = max(0.0, float(cfg.get("reflex_base", 1.0)))
        reflex_span = max(0.10, float(cfg.get("reflex_span", 0.60)))
        reflex_component = float(np.clip((reflex_metric - reflex_base) / reflex_span, 0.0, 1.0))

        lane_component = 0.0
        if fast_lane:
            lane_component = 1.0
        elif slow_lane:
            lane_component = 0.75
        elif channel_narrow:
            lane_component = 0.6
        elif channel_wide and not channel_decay:
            lane_component = 0.45

        weights = dict(cfg.get("weights", {}))
        if not weights:
            weights = {"align": 0.26, "tri": 0.24, "rfs": 0.18, "reflex": 0.20, "price": 0.08, "lane": 0.04}

        components = {
            "align": align_component,
            "tri": tri_component,
            "rfs": rfs_component,
            "reflex": reflex_component,
            "price": price_component,
            "lane": lane_component,
        }

        total_weight = sum(float(v) for v in weights.values()) or 1.0
        score = 0.0
        for key, weight in weights.items():
            score += components.get(key, 0.0) * float(weight)
        score = float(np.clip(score / total_weight, 0.0, 1.0))

        need = float(np.clip(float(cfg.get("score_need", 0.63)), 0.0, 1.0))
        vol_ok = (vol_any >= 1) or (not require_volume)
        ok = bool(score >= need and vol_ok)

        align_relief = max(0.0, float(cfg.get("align_relief", 0.05))) if ok else 0.0
        quality_bonus = max(0.0, float(cfg.get("quality_bonus", 0.04))) if ok else 0.0
        quality_relief = max(0.0, float(cfg.get("quality_relief", 0.0))) if ok else 0.0

        mode = "panic_long" if side == "long" else "mania_short"

        snapshot = {
            "darkside_active": 1,
            "darkside_mode": mode,
            "darkside_guard": int(guard_flag),
            "darkside_score": score,
            "darkside_need": need,
            "darkside_price_component": price_component,
            "darkside_align_component": align_component,
            "darkside_tri_component": tri_component,
            "darkside_rfs_component": rfs_component,
            "darkside_reflex_component": reflex_component,
            "darkside_lane_component": lane_component,
            "darkside_tri_target": tri_target,
            "darkside_align_base": align_base,
            "darkside_reflex_metric": reflex_metric,
            "darkside_vol_required": int(require_volume),
            "darkside_vol_any": int(vol_any >= 1),
            "darkside_pass": int(ok),
        }

        if ok:
            snapshot["darkside_tri_relief"] = tri_relief
            snapshot["darkside_align_relief"] = align_relief
            snapshot["darkside_quality_bonus"] = quality_bonus
            snapshot["darkside_quality_relief"] = quality_relief

        return {
            "active": 1,
            "mode": mode,
            "score": score,
            "need": need,
            "ok": ok,
            "tri_relief": tri_relief if ok else 0.0,
            "align_relief": align_relief,
            "quality_bonus": quality_bonus,
            "quality_relief": quality_relief,
            "components": components,
            "snapshot": snapshot,
            "vol_required": require_volume,
            "vol_ok": vol_ok,
        }

    def _review_clean_value(self, value: Any) -> Any:
        """把日志字段规整成可序列化/可阅读的轻量格式。"""
        if isinstance(value, dict):
            return {str(k): self._review_clean_value(v) for k, v in value.items()}
        if isinstance(value, (list, tuple, set)):
            seq = list(value)
            cleaned = [self._review_clean_value(v) for v in seq]
            limit = max(1, int(getattr(self, "REVIEW_REPORT_SUBLIST_LIMIT", 10)))
            if len(cleaned) > limit:
                return cleaned[-limit:]
            return cleaned
        if isinstance(value, pd.Series):
            return self._review_clean_value(value.tolist())
        if isinstance(value, np.ndarray):
            return self._review_clean_value(value.tolist())
        if isinstance(value, pd.Timestamp):
            return value.tz_convert("UTC").isoformat() if value.tzinfo else value.tz_localize("UTC").isoformat()
        if isinstance(value, datetime):
            dt = value if value.tzinfo else value.replace(tzinfo=timezone.utc)
            return dt.astimezone(timezone.utc).isoformat()
        if isinstance(value, Decimal):
            try:
                return float(value)
            except (InvalidOperation, ValueError):
                return str(value)
        if isinstance(value, (np.floating,)):
            val = float(value)
            return round(val, 6) if np.isfinite(val) else "nan"
        if isinstance(value, (np.integer,)):
            return int(value)
        if isinstance(value, (np.bool_,)):
            return bool(value)
        if isinstance(value, float):
            return round(value, 6) if np.isfinite(value) else "nan"
        return value

    def _review_value_to_str(self, value: Any) -> str:
        if isinstance(value, float):
            return f"{value:.4f}" if np.isfinite(value) else "nan"
        if isinstance(value, bool):
            return "是" if value else "否"
        return str(value)

    def _review_track_directional_guard(
        self,
        snapshot: Optional[Dict[str, Any]],
        *,
        pair: str,
        side: str,
        verdict: str,
        reason: Optional[str],
        timestamp: Optional[datetime],
    ) -> None:
        state = getattr(self, "_review_state", None)
        if not isinstance(state, dict):
            return
        if side != "short":
            return
        guard_state = state.setdefault("directional_guard", {})
        ts_obj = timestamp or self._utc_now()
        if ts_obj.tzinfo is None:
            ts_obj = ts_obj.replace(tzinfo=timezone.utc)
        entry: Dict[str, Any] = {
            "pair": pair,
            "side": side,
            "verdict": verdict,
            "timestamp": ts_obj.astimezone(timezone.utc).isoformat(),
        }
        if reason:
            entry["reason"] = reason
        metrics = snapshot if isinstance(snapshot, dict) else {}
        if metrics:
            for key in (
                "dir_short_long_count",
                "dir_short_short_count",
                "dir_short_quota",
                "dir_short_block_reason",
                "dir_short_resume_at",
                "dir_short_ratio",
                "dir_short_needed",
                "dir_short_lookback_min",
                "dir_short_open_count",
                "dir_short_open_limit",
            ):
                if key not in metrics:
                    continue
                value = metrics.get(key)
                if isinstance(value, datetime):
                    entry[key] = value.astimezone(timezone.utc).isoformat()
                else:
                    entry[key] = value
            histogram = guard_state.setdefault("histogram", {})
            try:
                histogram["long"] = int(metrics.get("dir_short_long_count", histogram.get("long", 0)) or 0)
                histogram["short"] = int(metrics.get("dir_short_short_count", histogram.get("short", 0)) or 0)
                histogram["quota"] = int(metrics.get("dir_short_quota", histogram.get("quota", 0)) or 0)
            except Exception:
                pass
            try:
                histogram["lookback_min"] = float(metrics.get("dir_short_lookback_min", histogram.get("lookback_min", 0.0)) or 0.0)
            except Exception:
                pass
            resume_val = entry.get("dir_short_resume_at") or metrics.get("dir_short_resume_at")
            if resume_val:
                histogram["resume_at"] = resume_val
        guard_state["latest"] = entry
        guard_state["updated_at"] = entry["timestamp"]
        if verdict in {"allow", "execute"}:
            guard_state["last_allow"] = entry
        elif verdict == "block":
            guard_state["last_block"] = entry

    def _review_extract_highlights(self, data: Dict[str, Any], stage: str, verdict: str) -> List[str]:
        preferred = (
            "level", "score", "threshold", "ratio", "remain",
            "need_major_events", "need_medium_events", "need_minor_events",
            "elastic_score", "elastic_need", "fastpath_ratio", "fastpath_level", "fastpath_blocked",
            "priority_conf", "priority_prefer", "priority_long", "priority_short",
            "align", "price_position", "rfs", "fast_lane", "slow_lane", "mania",
            "panic", "perf_guard", "perf_hot", "entries_today", "entries_left",
            "daily_limit", "risk_hits", "threshold_hits", "current_profit", "profit",
            "lock_gap", "buffer", "stoploss_floor", "stoploss_buffer", "stoploss_mult",
            "event", "phase", "dynamic_mode", "dynamic_reason", "portfolio_net",
            "portfolio_fragile", "cluster_same", "cluster_opp"
        )
        skip_keys = {"events", "elastic_events", "details", "dynamic_pairs", "resume_at",
                     "ts", "time", "timestamp", "info", "tag_list"}
        highlights: List[str] = []
        for key in preferred:
            if key in data:
                val = data[key]
                if isinstance(val, (dict, list)):
                    continue
                highlights.append(f"{key}={self._review_value_to_str(val)}")
        if len(highlights) < 6:
            for key, val in data.items():
                if key in preferred or key in skip_keys:
                    continue
                if isinstance(val, (dict, list)):
                    continue
                if val in (None, ""):
                    continue
                text = self._review_value_to_str(val)
                if len(text) > 48:
                    continue
                highlights.append(f"{key}={text}")
                if len(highlights) >= 6:
                    break
        return highlights[:6]

    def _review_get_bot_label_slug(self, override: Optional[str] = None) -> Optional[str]:
        label = override
        if label is None:
            label = getattr(self, "_review_bot_label", None) or getattr(self, "REVIEW_REPORT_BOT_LABEL", None)
        if not label:
            return None
        text = str(label).strip()
        if not text:
            return None
        slug = re.sub(r"[^0-9A-Za-z._-]+", "_", text)
        slug = slug.strip("._-")
        return slug or None

    def _review_candidate_path(self, value: Optional[str], fallback: str) -> Path:
        text = str(value or fallback or "").strip()
        if not text:
            text = fallback
        try:
            return Path(os.path.expanduser(text))
        except Exception:
            return Path(text)

    def _review_primary_base_dir(self) -> Path:
        base: Optional[Path] = None
        cfg = getattr(self, "config", None)
        if isinstance(cfg, dict):
            for key in ("user_data_dir", "user_data", "userdir"):
                base_txt = cfg.get(key)
                if base_txt:
                    try:
                        base = Path(str(base_txt)).expanduser()
                    except Exception:
                        base = Path(str(base_txt))
                    break
        if base is None:
            base = _STRATEGY_ROOT
        return base

    def _review_host_base_dir(self, override: Optional[str] = None) -> Optional[Path]:
        """根据配置、环境变量与治理参数推测宿主机 user_data 根目录。"""

        def _normalize(candidate: Optional[str]) -> Optional[str]:
            if candidate is None:
                return None
            text = str(candidate).strip()
            if not text:
                return None
            return text

        def _path_from(text: str) -> Optional[Path]:
            try:
                return Path(text).expanduser()
            except Exception:
                try:
                    return Path(text)
                except Exception:
                    return None

        candidates: List[str] = []

        normalized_override = _normalize(override)
        if normalized_override:
            candidates.append(normalized_override)

        cfg = getattr(self, "config", None)
        if isinstance(cfg, dict):
            review_cfg = cfg.get("review_export")
            if isinstance(review_cfg, dict):
                for key in (
                    "host_dir",
                    "host_root",
                    "host_path",
                    "analytics_host_dir",
                    "review_state_host_dir",
                ):
                    val = review_cfg.get(key)
                    norm = _normalize(val)
                    if norm:
                        candidates.append(norm)
                        break

            for key in (
                "user_data_host_dir",
                "user_data_host",
                "user_data_dir_host",
                "user_data_mount_dir",
                "user_data_mount",
            ):
                val = cfg.get(key)
                norm = _normalize(val)
                if norm:
                    candidates.append(norm)
                    break

        env_keys = (
            "REVIEW_REPORT_HOST_ROOT",
            "REVIEW_REPORT_EXPORT_HOST_ROOT",
            "REVIEW_STATE_HOST_ROOT",
            "FREQTRADE_HOST_USER_DATA_DIR",
            "FREQTRADE_HOST_USER_DATA",
            "HOST_USER_DATA_DIR",
            "HOST_USER_DATA",
            "USER_DATA_HOST_ROOT",
            "USER_DATA_HOST_DIR",
        )
        for key in env_keys:
            env_val = _normalize(os.environ.get(key))
            if env_val:
                candidates.append(env_val)
                break

        # 如果仍未匹配，尝试把绝对 user_data_dir 当作宿主机路径回退
        if isinstance(cfg, dict):
            base_txt = _normalize(cfg.get("user_data_dir"))
            if base_txt:
                base_path = _path_from(base_txt)
                if base_path and base_path.is_absolute():
                    candidates.append(base_txt)

        for text in candidates:
            path_obj = _path_from(text)
            if path_obj:
                return path_obj
        return None

    def _review_join_path(
        self,
        base: Path,
        candidate: Path,
        split_by_bot: bool,
        bot_label: Optional[str],
    ) -> Path:
        try:
            path = (base / candidate).resolve()
        except Exception:
            path = base / candidate
        if split_by_bot:
            slug = self._review_get_bot_label_slug(bot_label)
            if slug:
                path = path / slug
        return path

    def _review_resolve_output_bundle(
        self,
        value: Optional[str],
        fallback: str,
        *,
        split_by_bot: bool = False,
        bot_label: Optional[str] = None,
        host_override: Optional[str] = None,
        host_fallback: Optional[str] = None,
    ) -> Tuple[Path, Optional[Path]]:
        candidate = self._review_candidate_path(value, fallback)
        base = self._review_primary_base_dir()
        container_path = self._review_join_path(base, candidate, split_by_bot, bot_label)
        host_root = host_override
        if host_root is None:
            host_root = host_fallback
        if host_root is None and host_override is None:
            host_root = getattr(self, "REVIEW_REPORT_HOST_ROOT", None)
        host_path: Optional[Path] = None
        host_base = self._review_host_base_dir(host_root)
        if host_base is not None:
            try:
                host_path = self._review_join_path(host_base, candidate, split_by_bot, bot_label)
            except Exception:
                host_path = None
        return container_path, host_path

    def _review_prepare_directories(self, force: bool = False) -> None:
        if not bool(getattr(self, "REVIEW_REPORT_ENABLE", True)):
            return
        if getattr(self, "_review_dirs_ready", False) and not force:
            return

        bot_label = getattr(self, "_review_bot_label", None) or getattr(self, "REVIEW_REPORT_BOT_LABEL", None)
        split_markdown = bool(getattr(self, "REVIEW_REPORT_SPLIT_BY_BOT", False))
        export_split_override = getattr(self, "REVIEW_REPORT_EXPORT_SPLIT_BY_BOT", None)
        if export_split_override is None:
            export_split_override = split_markdown
        review_state_split_override = getattr(self, "REVIEW_STATE_SPLIT_BY_BOT", None)
        if review_state_split_override is None:
            review_state_split_override = export_split_override

        prepared: List[Tuple[str, Path, Optional[Path]]] = []

        markdown_host_root = getattr(self, "REVIEW_REPORT_HOST_ROOT", None)
        analytics_host_root = getattr(self, "REVIEW_REPORT_EXPORT_HOST_ROOT", None)
        if not analytics_host_root:
            analytics_host_root = markdown_host_root
        state_host_root = getattr(self, "REVIEW_STATE_HOST_ROOT", None)
        if not state_host_root:
            state_host_root = analytics_host_root

        def _ensure_dir(label: str, directory: Path, host_hint: Optional[Path]) -> None:
            try:
                directory.mkdir(parents=True, exist_ok=True)
            except Exception as exc:
                logger.warning("%s 目录创建失败：%s", label, exc)
            else:
                prepared.append((label, directory, host_hint))

        review_dir, review_host = self._review_resolve_output_bundle(
            getattr(self, "REVIEW_REPORT_DIR", "docs/review_reports"),
            "docs/review_reports",
            split_by_bot=split_markdown,
            bot_label=bot_label,
            host_override=markdown_host_root,
        )
        _ensure_dir("复盘 Markdown", review_dir, review_host)

        if bool(getattr(self, "REVIEW_REPORT_EXPORT_JSON", False)) or bool(
            getattr(self, "REVIEW_REPORT_EXPORT_CSV", False)
        ):
            analytics_dir, analytics_host = self._review_resolve_output_bundle(
                getattr(self, "REVIEW_REPORT_EXPORT_DIR", "docs/review_reports/analytics"),
                "docs/review_reports/analytics",
                split_by_bot=bool(export_split_override),
                bot_label=bot_label,
                host_override=analytics_host_root,
                host_fallback=markdown_host_root,
            )
            _ensure_dir("复盘结构化导出", analytics_dir, analytics_host)

        if bool(getattr(self, "REVIEW_STATE_EXPORT_STANDALONE", True)) or bool(
            getattr(self, "REVIEW_REPORT_EXPORT_JSON", False)
        ):
            state_dir, state_host = self._review_resolve_output_bundle(
                getattr(self, "REVIEW_STATE_EXPORT_DIR", "docs/review_reports/review_state"),
                "docs/review_reports/review_state",
                split_by_bot=bool(review_state_split_override),
                bot_label=bot_label,
                host_override=state_host_root,
                host_fallback=analytics_host_root or markdown_host_root,
            )
            _ensure_dir("review_state 快照", state_dir, state_host)

        if prepared:
            parts: List[str] = []
            for name, path, host_hint in prepared:
                if host_hint and host_hint != path:
                    parts.append(f"{name}={path}（宿主机：{host_hint}）")
                else:
                    parts.append(f"{name}={path}")
            summary = ", ".join(parts)
            logger.info("复盘导出目录已准备：%s", summary)
            self._review_dirs_ready = True
        else:
            logger.warning(
                "复盘导出目录未就绪：未能创建任何目标目录，请检查写入权限与路径配置。"
            )
            self._review_dirs_ready = False

    def _resolve_output_dir(self, value: Optional[str], fallback: str,
                             split_by_bot: bool = False,
                             bot_label: Optional[str] = None) -> Path:
        """教学提示：将复盘/基线目录转换为绝对路径，优先挂载 user_data，再退回策略目录。"""

        base_path, _ = self._review_resolve_output_bundle(
            value,
            fallback,
            split_by_bot=split_by_bot,
            bot_label=bot_label,
        )
        return base_path

    def _review_export_state_snapshot(self, day_key: str, snapshot: Dict[str, Any],
                                      bot_label: Optional[str] = None,
                                      split_by_bot: bool = False) -> None:
        markdown_host_root = getattr(self, "REVIEW_REPORT_HOST_ROOT", None)
        analytics_host_root = getattr(self, "REVIEW_REPORT_EXPORT_HOST_ROOT", None) or markdown_host_root
        state_host_root = getattr(self, "REVIEW_STATE_HOST_ROOT", None) or analytics_host_root
        review_state_dir, review_state_host = self._review_resolve_output_bundle(
            getattr(self, "REVIEW_STATE_EXPORT_DIR", "docs/review_reports/review_state"),
            "docs/review_reports/review_state",
            split_by_bot=split_by_bot,
            bot_label=bot_label,
            host_override=state_host_root,
            host_fallback=analytics_host_root or markdown_host_root,
        )
        try:
            review_state_dir.mkdir(parents=True, exist_ok=True)
        except Exception as exc:
            logger.warning("review_state 导出目录创建失败：%s", exc)
            return
        review_state_file = review_state_dir / f"review_state_{day_key}.json"
        host_file: Optional[Path] = None
        if review_state_host and review_state_host != review_state_dir:
            host_file = review_state_host / f"review_state_{day_key}.json"
        try:
            with open(review_state_file, "w", encoding="utf-8") as fh_state:
                json.dump(snapshot, fh_state, ensure_ascii=False, indent=2)
        except Exception as exc:
            logger.warning("review_state JSON 导出失败：%s", exc)
        else:
            host_note = ""
            if host_file and host_file != review_state_file:
                host_note = f"（宿主机：{host_file}）"
            logger.info("review_state 快照已写入：%s%s", review_state_file, host_note)

    def _review_capture_event(self, stage: str, pair: str, side: str, verdict: str,
                              reason: str, extra: Optional[Dict[str, Any]]) -> None:
        if not bool(getattr(self, "REVIEW_REPORT_ENABLE", True)):
            return
        now = self._utc_now()
        data = extra if isinstance(extra, dict) else {}
        ts_src = None
        for key in ("time", "timestamp", "ts", "now"):
            if key in data:
                ts_src = data.get(key)
                break
        ts = self._to_utc_datetime(ts_src) if ts_src is not None else now
        if ts is None:
            ts = now
        offset_hours = float(getattr(self, "REVIEW_REPORT_TZ_OFFSET_HOURS", 0.0) or 0.0)
        offset_td = timedelta(hours=offset_hours)
        ts_local = ts + offset_td
        day_key = ts_local.date().isoformat()
        day_data = self._review_events.setdefault(day_key, {
            "events": [],
            "stage_counts": {},
            "verdict_counts": {},
            "stage_verdict_counts": {},
            "reject_counts": {},
            "reject_events": [],
            "elastic_events": [],
            "pair_counts": {},
            "bot_label": self._review_bot_label,
            "dirty": False,
            "written": False,
            "last_write": None,
        })
        if not day_data.get("bot_label") and self._review_bot_label:
            day_data["bot_label"] = self._review_bot_label
        cleaned_extra = self._review_clean_value(data)
        event = {
            "stage": stage,
            "pair": pair,
            "side": side or "-",
            "verdict": verdict,
            "reason": reason,
            "timestamp": ts.astimezone(timezone.utc).isoformat(),
            "extra": cleaned_extra,
        }
        if offset_hours:
            event["timestamp_local"] = ts_local.isoformat()
        bot_label = self._review_bot_label or getattr(self, "REVIEW_REPORT_BOT_LABEL", None)
        if bot_label:
            event["bot"] = bot_label
        event["highlights"] = self._review_extract_highlights(cleaned_extra if isinstance(cleaned_extra, dict) else {}, stage, verdict)
        day_data["events"].append(event)
        day_data["dirty"] = True
        day_data["pair_counts"][pair] = day_data["pair_counts"].get(pair, 0) + 1
        stage_counts = day_data["stage_counts"]
        stage_counts[stage] = stage_counts.get(stage, 0) + 1
        if stage == "入场终审":
            side_key = str(side or "").lower()
            if side_key in ("long", "short"):
                allow_map = day_data.setdefault("direction_counts", {"long": 0, "short": 0})
                block_map = day_data.setdefault("direction_blocks", {"long": 0, "short": 0})
                if verdict in {"放行", "执行"}:
                    allow_map[side_key] = int(allow_map.get(side_key, 0)) + 1
                elif verdict in {"拦截", "拒绝", "搁置"}:
                    block_map[side_key] = int(block_map.get(side_key, 0)) + 1
        verdict_counts = day_data["verdict_counts"]
        verdict_counts[verdict] = verdict_counts.get(verdict, 0) + 1
        stage_verdict = day_data["stage_verdict_counts"]
        key = f"{stage}::{verdict}"
        stage_verdict[key] = stage_verdict.get(key, 0) + 1
        if verdict in {"拦截", "拒绝", "搁置"}:
            reject_key = f"{stage}·{reason}"
            rejects = day_data["reject_counts"]
            rejects[reject_key] = rejects.get(reject_key, 0) + 1
            day_data["reject_events"].append(event)
        if stage == "弹性止盈评分":
            day_data["elastic_events"].append(event)
        self._review_maybe_flush(now, day_key)

    def _review_maybe_flush(self, now: datetime, current_day_key: str) -> None:
        if not bool(getattr(self, "REVIEW_REPORT_ENABLE", True)):
            return
        cooldown = max(5.0, float(getattr(self, "REVIEW_REPORT_WRITE_COOLDOWN_SECONDS", 90.0) or 0))
        offset_hours = float(getattr(self, "REVIEW_REPORT_TZ_OFFSET_HOURS", 0.0) or 0.0)
        today = (now + timedelta(hours=offset_hours)).date()
        for day_key, data in list(self._review_events.items()):
            if not data.get("dirty"):
                continue
            if not data.get("events"):
                continue
            day_date = _date.fromisoformat(day_key)
            last_write: Optional[datetime] = data.get("last_write")
            should_write = False
            if day_date < today:
                should_write = True
            elif bool(getattr(self, "REVIEW_REPORT_LIVE_UPDATE", True)):
                if day_key == current_day_key:
                    if last_write is None or (now - last_write).total_seconds() >= cooldown:
                        should_write = True
                elif day_date > today:
                    should_write = True
            if should_write:
                self._review_write_report(day_key, data, now)
                data["dirty"] = False
                data["last_write"] = now
                data["written"] = True
        prune_before = today - timedelta(days=7)
        for day_key, data in list(self._review_events.items()):
            if not data.get("written"):
                continue
            day_date = _date.fromisoformat(day_key)
            if day_date < prune_before:
                self._review_events.pop(day_key, None)

    def _review_write_report(self, day_key: str, data: Dict[str, Any], now: datetime) -> None:
        events: List[Dict[str, Any]] = list(data.get("events", []))
        if not events:
            return
        events.sort(key=lambda e: e.get("timestamp", ""))
        day_date = _date.fromisoformat(day_key)
        total = len(events)
        stage_counts = data.get("stage_counts", {})
        stage_verdict_counts = data.get("stage_verdict_counts", {})
        verdict_counts = data.get("verdict_counts", {})
        pair_counts = data.get("pair_counts", {})
        direction_counts = data.get("direction_counts", {})
        direction_blocks = data.get("direction_blocks", {})
        reject_counts = data.get("reject_counts", {})
        elastic_events = data.get("elastic_events", [])
        review_state = getattr(self, "_review_state", None)
        guard_snapshot: Optional[Dict[str, Any]] = None
        if isinstance(review_state, dict):
            snap_candidate = review_state.get("directional_guard")
            if isinstance(snap_candidate, dict) and snap_candidate:
                guard_snapshot = snap_candidate
        timeline_limit = max(1, int(getattr(self, "REVIEW_REPORT_MAX_TIMELINE", 120)))
        timeline = events[-timeline_limit:]
        lines: List[str] = []
        lines.append(f"# ReflexivityStrategy 日志复盘（教学版） - {day_key}")
        lines.append("")
        bot_label = data.get("bot_label") or self._review_bot_label or getattr(self, "REVIEW_REPORT_BOT_LABEL", None)
        if bot_label:
            lines.append(f"> 当前机器人：{bot_label}")
        offset_hours = float(getattr(self, "REVIEW_REPORT_TZ_OFFSET_HOURS", 0.0) or 0.0)
        offset_td = timedelta(hours=offset_hours)
        local_label = "UTC"
        local_label_cn = "UTC"
        if math.isclose(offset_hours, 0.0, abs_tol=1e-9):
            lines.append("> 时间列基于 UTC；若需改用本地时区，可覆写 REVIEW_REPORT_TZ_OFFSET_HOURS（示例：设为 8 表示北京时间）。")
            local_header = "本地(UTC)时间"
        else:
            sign = "+" if offset_hours >= 0 else "-"
            abs_val = abs(offset_hours)
            abs_txt = f"{int(abs_val)}" if math.isclose(abs_val, round(abs_val), abs_tol=1e-9) else f"{abs_val:g}"
            local_label = f"UTC{sign}{abs_txt}"
            lines.append(
                f"> 时间列同时列出 UTC 与 {local_label}；可在 REVIEW_REPORT_TZ_OFFSET_HOURS 中调整偏移。"
            )
            if math.isclose(abs_val, 8.0, abs_tol=1e-6):
                local_label_cn = "北京时间"
            else:
                local_label_cn = local_label
            local_header = f"{local_label} 时间"
        if math.isclose(offset_hours, 0.0, abs_tol=1e-9):
            local_label_cn = "UTC"
        lines.append("")
        lines.append("")
        lines.append("## 今日概览")
        lines.append(f"- 记录总数：{total} 条")
        if bot_label:
            lines.append(f"- 机器人标识：{bot_label}")
        if verdict_counts:
            verdict_line = " / ".join(
                f"{label}×{verdict_counts[label]}" for label in sorted(verdict_counts.keys(), key=lambda x: (-verdict_counts[x], x))
            )
            lines.append(f"- 判定分布：{verdict_line}")
        if pair_counts:
            top_pairs = sorted(pair_counts.items(), key=lambda kv: (-kv[1], kv[0]))[:5]
            pair_line = ", ".join(f"{pair}×{count}" for pair, count in top_pairs)
            lines.append(f"- 触发频次 Top：{pair_line}")
        if stage_counts:
            allow_set = {"放行", "执行", "调整", "重置", "触发", "复核"}
            block_set = {"拦截", "拒绝", "搁置"}
            lines.append("- 各环节通过/拦截统计：")
            for stage, count in sorted(stage_counts.items(), key=lambda kv: (-kv[1], kv[0])):
                allow_cnt = sum(stage_verdict_counts.get(f"{stage}::{v}", 0) for v in allow_set)
                block_cnt = sum(stage_verdict_counts.get(f"{stage}::{v}", 0) for v in block_set)
                other_cnt = count - allow_cnt - block_cnt
                summary = f"  - {stage}：放行 {allow_cnt} / 拦截 {block_cnt}"
                if other_cnt > 0:
                    summary += f" / 其它 {other_cnt}"
                lines.append(summary)

        if direction_counts or direction_blocks:
            long_allow = int(direction_counts.get("long", 0) or 0)
            short_allow = int(direction_counts.get("short", 0) or 0)
            long_block = int(direction_blocks.get("long", 0) or 0)
            short_block = int(direction_blocks.get("short", 0) or 0)
            lines.append("")
            lines.append("### 多空方向统计")
            lines.append("")
            lines.append("| 方向 | 放行 | 拦截 |")
            lines.append("| --- | ---: | ---: |")
            lines.append(f"| 多单 | {long_allow} | {long_block} |")
            lines.append(f"| 空单 | {short_allow} | {short_block} |")
            lines.append("")
            if long_allow > 0:
                ratio_val = short_allow / long_allow
                lines.append(f"- 空/多放行比 ≈ {ratio_val:.2f}")
            elif short_allow > 0:
                lines.append("- 空/多放行比：今日未放行多单，请重点审查空头闸门。")
            else:
                lines.append("- 今日未放行空单。")

        stoploss_counter: Dict[Tuple[str, str], int] = defaultdict(int)
        stoploss_samples: Dict[Tuple[str, str], Dict[str, Any]] = {}
        stoploss_records: List[Dict[str, Any]] = []
        entry_quality_records: List[Dict[str, Any]] = []
        pair_state_snapshot = getattr(self, "_pair_state", {})
        if isinstance(pair_state_snapshot, dict):
            for pair_name, state in pair_state_snapshot.items():
                if not isinstance(state, dict):
                    continue
                profiles = state.get("trade_profiles") if isinstance(state, dict) else None
                if isinstance(profiles, dict):
                    for profile in profiles.values():
                        if not isinstance(profile, dict):
                            continue
                        events_log = profile.get("stoploss_events")
                        if isinstance(events_log, list):
                            for event in events_log:
                                if not isinstance(event, dict):
                                    continue
                                kind_txt = str(event.get("kind") or "").lower()
                                if kind_txt != "close":
                                    continue
                                ts_val = event.get("ts") or event.get("timestamp")
                                event_dt: Optional[datetime]
                                if isinstance(ts_val, datetime):
                                    event_dt = ts_val if ts_val.tzinfo else ts_val.replace(tzinfo=timezone.utc)
                                elif isinstance(ts_val, str):
                                    try:
                                        event_dt = datetime.fromisoformat(ts_val)
                                    except Exception:
                                        event_dt = None
                                else:
                                    event_dt = None
                                if event_dt is None:
                                    continue
                                if event_dt.tzinfo is None:
                                    event_dt = event_dt.replace(tzinfo=timezone.utc)
                                if event_dt.date() != day_date:
                                    continue
                                label = str(event.get("label") or event.get("tag") or "unknown")
                                prev_label = str(event.get("prev_label") or "").strip() or "-"
                                key = (label, prev_label)
                                stoploss_counter[key] += 1
                                if key not in stoploss_samples:
                                    sample: Dict[str, Any] = {}
                                    sample["tag"] = event.get("tag")
                                    prev_floor_val = event.get("prev_floor")
                                    if prev_floor_val is None:
                                        prev_floor_val = event.get("floor")
                                    sample["prev_floor"] = prev_floor_val
                                    context = event.get("context")
                                    if isinstance(context, dict) and context:
                                        sample["context"] = context
                                    stoploss_samples[key] = sample

                                record: Dict[str, Any] = {
                                    "pair": str(pair_name),
                                    "label": label,
                                    "prev_label": prev_label,
                                    "timestamp": event_dt.astimezone(timezone.utc).isoformat(),
                                    "status": "close",
                                }
                                tag_val = event.get("tag")
                                if tag_val is not None:
                                    record["tag"] = str(tag_val)
                                for field in ("floor", "prev_floor"):
                                    if field in event:
                                        try:
                                            record[field] = float(event[field])
                                        except (TypeError, ValueError):
                                            pass
                                context_data = event.get("context")
                                if isinstance(context_data, dict) and context_data:
                                    record["context"] = context_data
                                profile_side = str(profile.get("side") or "").lower()
                                if profile_side not in ("long", "short"):
                                    profile_side = str(state.get("last_dir") or "").lower()
                                if profile_side:
                                    record["side"] = profile_side
                                tier_txt = str(profile.get("tier", "base") or "base")
                                record["quality_tier"] = tier_txt.lower()
                                basis_pct = self._profile_risk_basis_pct(profile)
                                if basis_pct > 0:
                                    record["risk_basis_pct"] = round(basis_pct, 6)
                                realized_ctx = event.get("realized_r")
                                if realized_ctx is not None:
                                    try:
                                        record["realized_r"] = float(realized_ctx)
                                    except (TypeError, ValueError):
                                        pass
                                for key_name in ("quality_score", "quality_need", "quality_ratio"):
                                    try:
                                        val = float(profile.get(key_name, float("nan")))
                                    except (TypeError, ValueError):
                                        continue
                                    if np.isfinite(val):
                                        record[key_name] = round(val, 6)
                                stoploss_records.append(record)

                        entry_record: Dict[str, Any] = {
                            "pair": str(pair_name),
                            "status": "open",
                        }
                        profile_side = str(profile.get("side") or "").lower()
                        if profile_side not in ("long", "short"):
                            profile_side = str(state.get("last_dir") or "").lower()
                        if profile_side:
                            entry_record["side"] = profile_side
                        tier_txt = str(profile.get("tier", "base") or "base")
                        entry_record["quality_tier"] = tier_txt.lower()
                        for key_name in ("quality_score", "quality_need", "quality_ratio"):
                            try:
                                val = float(profile.get(key_name, float("nan")))
                            except (TypeError, ValueError):
                                continue
                            if np.isfinite(val):
                                entry_record[key_name] = round(val, 6)
                        basis_pct = self._profile_risk_basis_pct(profile)
                        if basis_pct > 0:
                            entry_record["risk_basis_pct"] = round(basis_pct, 6)
                        opened_raw = profile.get("opened")
                        opened_dt = self._to_utc_datetime(opened_raw)
                        if opened_dt:
                            entry_record["opened_at"] = opened_dt.isoformat()
                            entry_record["opened_same_day"] = bool(opened_dt.date() == day_date)
                        for extra_key in ("entry_notional", "entry_cap_usdt", "entry_target_notional", "entry_frontload_ratio"):
                            try:
                                extra_val = float(profile.get(extra_key, float("nan")))
                            except (TypeError, ValueError):
                                continue
                            if np.isfinite(extra_val):
                                entry_record[extra_key] = round(extra_val, 6)
                        entry_quality_records.append(entry_record)

                pending_snap = state.get("pending_entry_snapshot")
                if isinstance(pending_snap, dict) and pending_snap:
                    pending_record: Dict[str, Any] = {
                        "pair": str(pair_name),
                        "status": "pending",
                    }
                    snap_side = str(pending_snap.get("side") or state.get("last_dir") or "").lower()
                    if snap_side:
                        pending_record["side"] = snap_side
                    for key_name in ("entry_quality", "entry_quality_need"):
                        try:
                            val = float(pending_snap.get(key_name, float("nan")))
                        except (TypeError, ValueError):
                            continue
                        if np.isfinite(val):
                            pending_record[key_name] = round(val, 6)
                    need_val = pending_record.get("entry_quality_need")
                    score_val = pending_record.get("entry_quality")
                    if isinstance(need_val, float) and need_val > 0 and isinstance(score_val, float):
                        pending_record["quality_ratio"] = round(score_val / need_val, 6)
                    snap_time = self._to_utc_datetime(pending_snap.get("time"))
                    if snap_time:
                        pending_record["time"] = snap_time.isoformat()
                        pending_record["opened_same_day"] = bool(snap_time.date() == day_date)
                    entry_quality_records.append(pending_record)

        es_alpha = float(getattr(self, "EXPECTED_SHORTFALL_ALPHA", 0.15) or 0.15)
        es_window = max(1, int(getattr(self, "EXPECTED_SHORTFALL_WINDOW", 20) or 20))
        es_min_count = max(1, int(getattr(self, "EXPECTED_SHORTFALL_MIN_COUNT", 8) or 1))
        realized_values = []
        for rec in stoploss_records:
            if str(rec.get("status")) != "close":
                continue
            val = rec.get("realized_r")
            if val is None:
                continue
            try:
                num = float(val)
            except (TypeError, ValueError):
                continue
            if np.isfinite(num):
                realized_values.append(num)

        tail_metrics: Dict[str, Any] = {}
        rolling_metrics: Dict[str, Any] = {}
        if len(realized_values) >= es_min_count:
            arr = np.asarray(realized_values, dtype=float)
            arr = arr[np.isfinite(arr)]
            if arr.size >= es_min_count:
                try:
                    var_val = float(np.quantile(arr, es_alpha))
                except Exception:
                    var_val = float(arr.min())
                tail_vals = arr[arr <= var_val + 1e-12]
                if tail_vals.size == 0:
                    tail_vals = arr
                cvar_val = float(np.mean(tail_vals))
                tail_metrics = {
                    "alpha": float(es_alpha),
                    "var": var_val,
                    "cvar": cvar_val,
                    "count": int(arr.size),
                    "min": float(arr.min()),
                    "max": float(arr.max()),
                }

                review_state = getattr(self, "_review_state", None)
                if not isinstance(review_state, dict):
                    review_state = {}
                    self._review_state = review_state
                tail_state = review_state.setdefault("risk_tail", {})
                daily_records = tail_state.setdefault("daily", [])
                daily_records.append({"day": day_key, "values": realized_values, "metrics": tail_metrics})
                if len(daily_records) > es_window:
                    tail_state["daily"] = daily_records[-es_window:]
                    daily_records = tail_state["daily"]
                combined_values: List[float] = []
                for item in daily_records:
                    vals = item.get("values", [])
                    if isinstance(vals, list):
                        for candidate in vals:
                            try:
                                candidate_val = float(candidate)
                            except (TypeError, ValueError):
                                continue
                            if np.isfinite(candidate_val):
                                combined_values.append(candidate_val)
                if len(combined_values) >= es_min_count:
                    arr_roll = np.asarray(combined_values, dtype=float)
                    try:
                        var_roll = float(np.quantile(arr_roll, es_alpha))
                    except Exception:
                        var_roll = float(arr_roll.min())
                    tail_roll = arr_roll[arr_roll <= var_roll + 1e-12]
                    if tail_roll.size == 0:
                        tail_roll = arr_roll
                    cvar_roll = float(np.mean(tail_roll))
                    rolling_metrics = {
                        "alpha": float(es_alpha),
                        "var": var_roll,
                        "cvar": cvar_roll,
                        "count": int(arr_roll.size),
                        "days": len(daily_records),
                    }
                    tail_state["rolling"] = dict(rolling_metrics)
                tail_state["latest"] = {"day": day_key, **tail_metrics}

        stoploss_summary_data: List[Dict[str, Any]] = []
        for (label, prev_label), count in sorted(
            stoploss_counter.items(), key=lambda kv: (-kv[1], kv[0][0], kv[0][1])
        ):
            summary_entry: Dict[str, Any] = {
                "label": label,
                "prev_label": prev_label,
                "count": count,
            }
            sample_map = stoploss_samples.get((label, prev_label))
            if isinstance(sample_map, dict) and sample_map:
                summary_entry["sample"] = sample_map
            stoploss_summary_data.append(summary_entry)

        if tail_metrics:
            lines.append("")
            lines.append("## 尾部风险（Expected Shortfall）")
            lines.append(
                "- 日内样本：{cnt}，VaR(α={alpha:.2f})={var:.3f}R，ES={cvar:.3f}R".format(
                    cnt=tail_metrics.get("count", len(realized_values)),
                    alpha=tail_metrics.get("alpha", es_alpha),
                    var=tail_metrics.get("var", 0.0),
                    cvar=tail_metrics.get("cvar", 0.0),
                )
            )
            if rolling_metrics:
                lines.append(
                    "- 滚动窗口（近 {days} 日）样本 {count}，VaR={var:.3f}R，ES={cvar:.3f}R".format(
                        days=rolling_metrics.get("days", es_window),
                        count=rolling_metrics.get("count", 0),
                        var=rolling_metrics.get("var", 0.0),
                        cvar=rolling_metrics.get("cvar", 0.0),
                    )
                )
        elif realized_values and len(realized_values) < es_min_count:
            lines.append("")
            lines.append("## 尾部风险（Expected Shortfall）")
            lines.append(
                f"- 日内仅收集到 {len(realized_values)} 条 R 倍数样本，未达到 ES 最小样本 {es_min_count} 条，暂不计算 VaR/ES"
            )

        stoploss_total = sum(stoploss_counter.values())
        lines.append("")
        lines.append("### 止损分类统计")
        lines.append("")
        if stoploss_total > 0:
            lines.append("| 结案事件 | 最近地板来源 | 次数 | 示例 |")
            lines.append("| --- | --- | ---: | --- |")
            top_entries = stoploss_summary_data[:8]
            for summary_entry in top_entries:
                label = summary_entry.get("label", "unknown")
                prev_label = summary_entry.get("prev_label", "-")
                count = int(summary_entry.get("count", 0))
                sample = summary_entry.get("sample", {})
                snippet_parts: List[str] = []
                prev_floor_val = sample.get("prev_floor") if isinstance(sample, dict) else None
                try:
                    prev_floor_float = float(prev_floor_val)
                except (TypeError, ValueError):
                    prev_floor_float = None
                if prev_floor_float is not None and np.isfinite(prev_floor_float):
                    snippet_parts.append(f"floor≈{prev_floor_float:.4f}")
                tag_val = sample.get("tag") if isinstance(sample, dict) else None
                if tag_val and str(tag_val) != label:
                    snippet_parts.append(f"tag={tag_val}")
                context_map = sample.get("context") if isinstance(sample, dict) else None
                if isinstance(context_map, dict) and context_map:
                    ctx_items = list(context_map.items())[:3]
                    ctx_str = ", ".join(f"{k}={self._review_value_to_str(v)}" for k, v in ctx_items)
                    snippet_parts.append(ctx_str)
                snippet = "；".join(snippet_parts) if snippet_parts else "—"
                lines.append(f"| {label} | {prev_label} | {count} | {snippet} |")
        else:
            lines.append("今日无止损触发记录。")

        def _fmt_local(dt: Optional[datetime]) -> str:
            if dt is None:
                return "--:--"
            try:
                return (dt + offset_td).strftime("%H:%M:%S")
            except Exception:
                return "--:--"

        def _fmt_guard_time(ts_value: Any) -> str:
            dt = self._to_utc_datetime(ts_value)
            if dt is None:
                try:
                    if isinstance(ts_value, str):
                        dt = datetime.fromisoformat(ts_value)
                        if dt.tzinfo is None:
                            dt = dt.replace(tzinfo=timezone.utc)
                except Exception:
                    dt = None
            if dt is None:
                return "--:--"
            return f"{_fmt_local(dt)} / {dt.astimezone(timezone.utc).strftime('%H:%M:%S')} UTC"

        if guard_snapshot:
            hist = guard_snapshot.get("histogram") if isinstance(guard_snapshot, dict) else {}
            lines.append("")
            lines.append("#### 空单配额守卫快照")
            lines.append("")
            lines.append("| 指标 | 数值 |")
            lines.append("| --- | --- |")
            long_hist = hist.get("long") if isinstance(hist, dict) else None
            short_hist = hist.get("short") if isinstance(hist, dict) else None
            quota_hist = hist.get("quota") if isinstance(hist, dict) else None
            lookback_hist = hist.get("lookback_min") if isinstance(hist, dict) else None
            resume_hist = hist.get("resume_at") if isinstance(hist, dict) else None
            resume_txt = _fmt_guard_time(resume_hist) if resume_hist else "--"
            lines.append(f"| 24h 多单 | {long_hist if long_hist is not None else '--'} |")
            lines.append(f"| 24h 空单 | {short_hist if short_hist is not None else '--'} |")
            lines.append(f"| 配额 | {quota_hist if quota_hist is not None else '--'} |")
            lines.append(f"| 窗口(分钟) | {lookback_hist if lookback_hist is not None else '--'} |")
            lines.append(f"| 预计恢复 | {resume_txt} |")
            last_block = guard_snapshot.get("last_block") if isinstance(guard_snapshot, dict) else None
            last_allow = guard_snapshot.get("last_allow") if isinstance(guard_snapshot, dict) else None
            if isinstance(last_block, dict):
                lines.append(
                    f"- 最近拦截：{last_block.get('reason', '—')} @ {_fmt_guard_time(last_block.get('timestamp'))}"
                )
            if isinstance(last_allow, dict):
                lines.append(
                    f"- 最近放行：{last_allow.get('pair', '—')} {_fmt_guard_time(last_allow.get('timestamp'))}"
                )

        if reject_counts:
            top_reject = sorted(reject_counts.items(), key=lambda kv: (-kv[1], kv[0]))[:3]
            tips = "; ".join(f"{reason}×{cnt}" for reason, cnt in top_reject)
            lines.append(f"- 今日主要拦截集中：{tips}")

        if reject_counts:
            lines.append("")
            lines.append("## 被拒绝/搁置信号 Top 列表")
            for idx, (reason_key, cnt) in enumerate(sorted(reject_counts.items(), key=lambda kv: (-kv[1], kv[0]))[:10], start=1):
                lines.append(f"{idx}. {reason_key} —— {cnt} 次")

        if elastic_events:
            level_names = {"major": "重大", "medium": "中等", "minor": "轻微"}
            lines.append("")
            lines.append("## 弹性止盈评分事件（按严重度分组）")
            for level in ("major", "medium", "minor"):
                level_list = [ev for ev in elastic_events if str(ev.get("extra", {}).get("level")) == level]
                if not level_list:
                    continue
                lines.append(f"### {level_names.get(level, level)}事件")
                for ev in level_list:
                    utc_dt = self._to_utc_datetime(ev.get("timestamp"))
                    utc_txt = utc_dt.strftime("%H:%M:%S") if utc_dt else "--:--"
                    local_txt = _fmt_local(utc_dt)
                    extra = ev.get("extra", {})
                    highlight = []
                    for key in (
                        "score", "threshold", "ratio", "remain",
                        "need_major_events", "need_medium_events", "need_minor_events",
                        "elastic_score", "elastic_need", "fastpath_ratio", "fastpath_level",
                        "fastpath_blocked",
                    ):
                        if key in extra:
                            highlight.append(f"{key}={self._review_value_to_str(extra[key])}")
                    if extra.get("elastic_events"):
                        seq = extra.get("elastic_events")
                        if isinstance(seq, list):
                            tags = [f"{item.get('tag', '?')}({item.get('score', '-')})" for item in seq]
                            highlight.append("事件序列=" + " → ".join(tags))
                    highlight_txt = "；".join(highlight) if highlight else "-"
                    lines.append(
                        f"- {utc_txt} UTC / {local_txt} {local_label_cn}：{ev['pair']} {ev['side']} 判定 {ev['verdict']} —— {ev['reason']} | {highlight_txt}"
                    )

        lines.append("")
        lines.append("## 高优先级时间线（最近事件）")
        lines.append(f"| UTC时间 | {local_header} | 机器人 | 交易对 | 方向 | 阶段 | 判定 | 重点字段 | 理由 |")
        lines.append("| --- | --- | --- | --- | --- | --- | --- | --- | --- |")
        for ev in timeline:
            utc_dt = self._to_utc_datetime(ev.get("timestamp"))
            utc_txt = utc_dt.strftime("%H:%M:%S") if utc_dt else "--:--"
            local_txt = _fmt_local(utc_dt)
            highlights = ev.get("highlights", [])
            highlight_txt = "；".join(highlights) if highlights else "-"
            reason_txt = str(ev.get("reason", "")).replace("|", "／")
            bot_txt = ev.get("bot") or bot_label or "-"
            lines.append(
                f"| {utc_txt} | {local_txt} | {bot_txt} | {ev.get('pair')} | {ev.get('side')} | {ev.get('stage')} | {ev.get('verdict')} | {highlight_txt} | {reason_txt} |"
            )

        sample = timeline[-5:]
        if sample:
            lines.append("")
            lines.append("## 附录：最近事件原始字段（截取 5 条）")
            for ev in sample:
                lines.append(f"- {ev.get('stage')} @ {ev.get('timestamp')}")
                lines.append("  ```json")
                try:
                    lines.append("  " + json.dumps(ev, ensure_ascii=False, indent=2).replace("\n", "\n  "))
                except TypeError:
                    lines.append("  " + str(ev))
                lines.append("  ```")

        default_review_dir = getattr(self, "REVIEW_REPORT_DIR", "docs/review_reports")
        split_markdown = bool(getattr(self, "REVIEW_REPORT_SPLIT_BY_BOT", False))
        markdown_host_root = getattr(self, "REVIEW_REPORT_HOST_ROOT", None)
        out_dir, host_review_dir = self._review_resolve_output_bundle(
            default_review_dir,
            "docs/review_reports",
            split_by_bot=split_markdown,
            bot_label=bot_label,
            host_override=markdown_host_root,
        )
        try:
            out_dir.mkdir(parents=True, exist_ok=True)
        except Exception as exc:
            logger.warning("复盘报告目录创建失败：%s", exc)
            return

        filename = f"{getattr(self, 'REVIEW_REPORT_PREFIX', 'daily_review_')}{day_key}.md"
        path = out_dir / filename
        host_review_path: Optional[Path] = None
        if host_review_dir and host_review_dir != out_dir:
            host_review_path = host_review_dir / filename
        try:
            with open(path, "w", encoding="utf-8") as fh:
                fh.write("\n".join(lines))
        except Exception as exc:
            logger.warning("复盘报告写入失败：%s", exc)
        else:
            host_note = ""
            if host_review_path and host_review_path != path:
                host_note = f"（宿主机：{host_review_path}）"
            logger.info("复盘 Markdown 已写入：%s%s", path, host_note)

        export_json = bool(getattr(self, "REVIEW_REPORT_EXPORT_JSON", False))
        export_csv = bool(getattr(self, "REVIEW_REPORT_EXPORT_CSV", False))
        export_split_override = getattr(self, "REVIEW_REPORT_EXPORT_SPLIT_BY_BOT", None)
        if export_split_override is None:
            export_split_override = split_markdown
        review_state_split_override = getattr(self, "REVIEW_STATE_SPLIT_BY_BOT", None)
        if review_state_split_override is None:
            review_state_split_override = export_split_override
        if export_json or export_csv:
            analytics_host_root = getattr(self, "REVIEW_REPORT_EXPORT_HOST_ROOT", None)
            if not analytics_host_root:
                analytics_host_root = markdown_host_root
            analytics_dir, host_analytics_dir = self._review_resolve_output_bundle(
                getattr(self, "REVIEW_REPORT_EXPORT_DIR", "docs/review_reports/analytics"),
                "docs/review_reports/analytics",
                split_by_bot=bool(export_split_override),
                bot_label=bot_label,
                host_override=analytics_host_root,
                host_fallback=markdown_host_root,
            )
            try:
                analytics_dir.mkdir(parents=True, exist_ok=True)
            except Exception as exc:
                logger.warning("复盘结构化导出目录创建失败：%s", exc)
            else:
                def _sanitize_review_state(value: Any, depth: int = 0) -> Any:
                    if depth > 6:
                        return str(value)
                    if value is None:
                        return None
                    if isinstance(value, (str, int, bool)):
                        return value
                    if isinstance(value, float):
                        return float(value) if np.isfinite(value) else None
                    if isinstance(value, np.generic):  # type: ignore[attr-defined]
                        try:
                            return _sanitize_review_state(value.item(), depth + 1)
                        except Exception:
                            return None
                    if isinstance(value, dict):
                        sanitized_dict: Dict[str, Any] = {}
                        for key, val in value.items():
                            sanitized_key = str(key)
                            sanitized_dict[sanitized_key] = _sanitize_review_state(val, depth + 1)
                        return sanitized_dict
                    if isinstance(value, (list, tuple, set)):
                        return [_sanitize_review_state(item, depth + 1) for item in value]
                    if isinstance(value, datetime):
                        val = value
                        if val.tzinfo is None:
                            val = val.replace(tzinfo=timezone.utc)
                        return val.astimezone(timezone.utc).isoformat()
                    if isinstance(value, Path):
                        return str(value)
                    return str(value)

                generated_dt = now if isinstance(now, datetime) else datetime.now(timezone.utc)
                if generated_dt.tzinfo is None:
                    generated_dt = generated_dt.replace(tzinfo=timezone.utc)
                generated_iso = generated_dt.astimezone(timezone.utc).isoformat()
                analytics_payload = {
                    "day": day_key,
                    "generated_at": generated_iso,
                    "bot_label": bot_label,
                    "stoploss_summary": stoploss_summary_data,
                    "stoploss_events": stoploss_records,
                    "entry_quality": entry_quality_records,
                    "risk_tail": {
                        "daily": tail_metrics,
                        "rolling": rolling_metrics,
                        "sample_count": len(realized_values),
                        "alpha": es_alpha,
                        "window": es_window,
                        "min_count": es_min_count,
                    },
                }
                review_state_snapshot: Optional[Dict[str, Any]] = None
                review_state = getattr(self, "_review_state", None)
                if isinstance(review_state, dict) and review_state:
                    sanitized = _sanitize_review_state(review_state)
                    if isinstance(sanitized, dict) and sanitized:
                        review_state_snapshot = sanitized
                        analytics_payload["review_state"] = review_state_snapshot
                if direction_counts or direction_blocks:
                    analytics_payload["direction"] = {
                        "allowed": {k: int(v) for k, v in direction_counts.items()},
                        "blocked": {k: int(v) for k, v in direction_blocks.items()},
                    }
                guard_snapshot_payload: Optional[Dict[str, Any]] = None
                if guard_snapshot:
                    guard_snapshot_payload = _sanitize_review_state(guard_snapshot)
                if guard_snapshot_payload:
                    analytics_payload["directional_guard"] = guard_snapshot_payload
                if export_json:
                    json_path = analytics_dir / f"analytics_{day_key}.json"
                    host_json_path: Optional[Path] = None
                    if host_analytics_dir and host_analytics_dir != analytics_dir:
                        host_json_path = host_analytics_dir / f"analytics_{day_key}.json"
                    try:
                        with open(json_path, "w", encoding="utf-8") as fh_json:
                            json.dump(analytics_payload, fh_json, ensure_ascii=False, indent=2)
                    except Exception as exc:
                        logger.warning("复盘结构化 JSON 导出失败：%s", exc)
                    else:
                        host_note = ""
                        if host_json_path and host_json_path != json_path:
                            host_note = f"（宿主机：{host_json_path}）"
                        logger.info("复盘 JSON 已写入：%s%s", json_path, host_note)
                    if review_state_snapshot:
                        self._review_export_state_snapshot(
                            day_key,
                            review_state_snapshot,
                            bot_label=bot_label,
                            split_by_bot=bool(review_state_split_override),
                        )
                if export_csv:
                    csv_rows: List[Dict[str, Any]] = []
                    for summary_entry in stoploss_summary_data:
                        row: Dict[str, Any] = {
                            "record_type": "stoploss_summary",
                            "label": summary_entry.get("label", "unknown"),
                            "prev_label": summary_entry.get("prev_label", "-"),
                            "count": summary_entry.get("count", 0),
                        }
                        sample_map = summary_entry.get("sample") if isinstance(summary_entry, dict) else None
                        if isinstance(sample_map, dict):
                            for key, value in sample_map.items():
                                if isinstance(value, (dict, list)):
                                    row[f"sample_{key}"] = json.dumps(value, ensure_ascii=False)
                                else:
                                    row[f"sample_{key}"] = value
                        csv_rows.append(row)
                    for record in stoploss_records:
                        row = {"record_type": "stoploss_event"}
                        for key, value in record.items():
                            if isinstance(value, (dict, list)):
                                row[key] = json.dumps(value, ensure_ascii=False)
                            else:
                                row[key] = value
                        csv_rows.append(row)
                    for record in entry_quality_records:
                        row = {"record_type": "entry_quality"}
                        for key, value in record.items():
                            if isinstance(value, (dict, list)):
                                row[key] = json.dumps(value, ensure_ascii=False)
                            else:
                                row[key] = value
                        csv_rows.append(row)
                    if csv_rows:
                        fieldnames: List[str] = []
                        seen_fields: Set[str] = set()
                        for rec in csv_rows:
                            for key in rec.keys():
                                if key not in seen_fields:
                                    seen_fields.add(key)
                                    fieldnames.append(key)
                        csv_path = analytics_dir / f"analytics_{day_key}.csv"
                        host_csv_path: Optional[Path] = None
                        if host_analytics_dir and host_analytics_dir != analytics_dir:
                            host_csv_path = host_analytics_dir / f"analytics_{day_key}.csv"
                        try:
                            with open(csv_path, "w", encoding="utf-8", newline="") as csv_file:
                                writer = csv.DictWriter(csv_file, fieldnames=fieldnames)
                                writer.writeheader()
                                for rec in csv_rows:
                                    writer.writerow(rec)
                        except Exception as exc:
                            logger.warning("复盘结构化 CSV 导出失败：%s", exc)
                        else:
                            host_note = ""
                            if host_csv_path and host_csv_path != csv_path:
                                host_note = f"（宿主机：{host_csv_path}）"
                            logger.info("复盘 CSV 已写入：%s%s", csv_path, host_note)
        elif review_state_snapshot and bool(getattr(self, "REVIEW_STATE_EXPORT_STANDALONE", True)):
            self._review_export_state_snapshot(
                day_key,
                review_state_snapshot,
                bot_label=bot_label,
                split_by_bot=bool(review_state_split_override),
            )

    def _effective_account_leverage(
        self, profile: Optional[Dict[str, Any]] = None, pair: Optional[str] = None
    ) -> float:
        """教学提示：根据名义配置解析有效杠杆，回落到 DEFAULT_LEVERAGE 并套用上限。"""

        leverage_cap = getattr(self, "MAX_LEVERAGE_CAP", 0.0)

        if profile is None or not isinstance(profile, dict):
            try:
                profile, _, _ = self._resolve_notional_profile(pair)
            except Exception:
                profile = {}

        lev_raw: Any = None
        if isinstance(profile, dict):
            lev_raw = profile.get("leverage", None)

        if lev_raw is None:
            lev_raw = getattr(self, "DEFAULT_LEVERAGE", 1.0)

        try:
            leverage = float(lev_raw) if lev_raw is not None else 1.0
        except (TypeError, ValueError):
            leverage = float(getattr(self, "DEFAULT_LEVERAGE", 1.0) or 1.0)

        if not np.isfinite(leverage) or leverage <= 0:
            leverage = 1.0

        if (
            leverage_cap
            and np.isfinite(leverage_cap)
            and leverage_cap > 0
        ):
            leverage = min(leverage, float(leverage_cap))

        return max(1.0, leverage)

    def _min_margin_override(self, pair: str) -> Tuple[Optional[float], Optional[str]]:
        """教学提示：读取账户或逐币种覆写的最小保证金参数。"""

        override: Optional[float] = None
        source: Optional[str] = None

        try:
            pair_overrides = getattr(self, "_notional_pair_overrides", {}) or {}
            entry = pair_overrides.get(pair)
            if isinstance(entry, dict):
                val = self._safe_float(entry.get("min_margin_usdt"))
                if val and val > 0:
                    override = val
                    source = "pair"
        except Exception:
            override = None
            source = None

        if override is None:
            try:
                profile = getattr(self, "_notional_profile", {}) or {}
            except Exception:
                profile = {}
            if isinstance(profile, dict):
                val = self._safe_float(profile.get("min_margin_usdt"))
                if val and val > 0:
                    override = val
                    source = "account"

        return override, source

    def _min_stake_requirement(
        self,
        pair: str,
        price: Optional[float],
        leverage: Optional[float] = None,
    ) -> Tuple[Optional[float], Dict[str, Any]]:
        """教学提示：根据交易所精度估算最小下单金额（USDT），并附带元信息。"""

        market = self._market_info(pair)
        limits = (market or {}).get("limits", {}) or {}
        cost_limits = limits.get("cost", {}) or {}
        amount_limits = limits.get("amount", {}) or {}

        if leverage is None or leverage <= 0:
            leverage = self._effective_account_leverage(pair=pair)

        leverage = max(1.0, float(leverage))

        meta: Dict[str, Any] = {"leverage": round(leverage, 6)}

        min_cost = self._safe_float(cost_limits.get("min"))
        min_amount = self._safe_float(amount_limits.get("min"))
        contract_size_raw = self._safe_float((market or {}).get("contractSize"))
        is_contract_market = bool((market or {}).get("contract"))

        info = (market or {}).get("info") or {}
        quote_ccy = str((market or {}).get("quote") or "").upper()
        ct_val_ccy = str(info.get("ctValCcy") or "").upper()

        contract_size_base: Optional[float] = None
        contract_size_quote: Optional[float] = None

        if contract_size_raw and contract_size_raw > 0:
            if (
                is_contract_market
                and ct_val_ccy
                and quote_ccy
                and ct_val_ccy == quote_ccy
            ):
                # OKX 等线性合约会返回 quote 计价的合约面值（例如 10 USDT）。
                # 需要根据当前价格换算为基础币数量，才能与 amount 张数
                # 一起得到真实名义。
                contract_size_quote = float(contract_size_raw)
                if price and price > 0:
                    contract_size_base = contract_size_quote / float(price)
            else:
                contract_size_base = float(contract_size_raw)

        if contract_size_base and contract_size_base > 0:
            meta["contract_size"] = float(contract_size_base)
        elif contract_size_raw and contract_size_raw > 0:
            meta["contract_size"] = float(contract_size_raw)

        if contract_size_raw and contract_size_raw > 0:
            meta["contract_size_raw"] = float(contract_size_raw)

        if contract_size_quote is not None:
            meta["contract_size_quote"] = float(contract_size_quote)
            if ct_val_ccy:
                meta["contract_ct_val_ccy"] = ct_val_ccy

        # 对于合约市场，`amount` 通常代表“张数”。若交易所未返回 amount
        # 下限，则退回到 1 张起订；现货依旧按最小币量处理。
        if is_contract_market and min_amount is None:
            min_amount = 1.0
        elif not is_contract_market and contract_size_raw and contract_size_raw > 0 and min_amount is None:
            min_amount = contract_size_raw

        min_amount_notional: Optional[float] = None
        min_contracts: Optional[float] = None

        requirements: List[Dict[str, float]] = []

        if min_cost and min_cost > 0:
            margin = float(min_cost) / leverage
            requirements.append({
                "type": "cost_min",
                "margin": margin,
                "notional": float(min_cost),
            })
            meta["market_min_cost"] = float(min_cost)

        if min_amount and min_amount > 0 and price and price > 0:
            min_amount_f = float(min_amount)
            amount_units = min_amount_f
            contract_value_quote: Optional[float] = None
            if is_contract_market:
                min_contracts = min_amount_f
                if contract_size_base and contract_size_base > 0:
                    amount_units = min_amount_f * float(contract_size_base)
                elif contract_size_raw and contract_size_raw > 0:
                    amount_units = min_amount_f * float(contract_size_raw)
                if contract_size_quote is not None:
                    contract_value_quote = float(contract_size_quote)
            min_amount_notional = amount_units
            notional = amount_units * float(price)
            margin = notional / leverage
            requirement: Dict[str, float] = {
                "type": "amount_min",
                "margin": margin,
                "notional": notional,
                "min_amount": amount_units,
                "price_used": float(price),
            }
            if min_contracts is not None:
                requirement["contracts"] = float(min_contracts)
            if contract_size_base is not None:
                requirement["contract_value_base"] = float(contract_size_base)
            if contract_value_quote is not None:
                requirement["contract_value_quote"] = contract_value_quote
            requirements.append(requirement)

        need: Optional[float] = None
        if min_amount_notional is not None:
            meta["min_amount"] = float(min_amount_notional)
        if min_contracts is not None:
            meta["min_contracts"] = float(min_contracts)

        if requirements:
            chosen = max(requirements, key=lambda item: item.get("margin", 0.0))
            need = float(chosen.get("margin", 0.0))
            meta["source"] = chosen.get("type")
            meta_requirements: List[Dict[str, Any]] = []
            for req in requirements:
                entry: Dict[str, Any] = {
                    "type": req.get("type"),
                    "margin": round(float(req.get("margin", 0.0)), 6),
                    "notional": round(float(req.get("notional", 0.0)), 6),
                }
                for opt_key in ("min_amount", "contracts", "contract_value_base", "contract_value_quote"):
                    if req.get(opt_key) is not None:
                        try:
                            entry[opt_key] = round(float(req.get(opt_key, 0.0)), 6)
                        except (TypeError, ValueError):
                            entry[opt_key] = req.get(opt_key)
                meta_requirements.append(entry)
            meta["requirements"] = meta_requirements

        override_margin, override_source = self._min_margin_override(pair)
        if override_margin and override_margin > 0:
            meta["override_margin"] = round(float(override_margin), 6)
            if override_source:
                meta["override_source"] = override_source
            if need is None or need <= 0:
                need = float(override_margin)
                meta["source"] = "override"
            else:
                baseline = need
                if override_margin < need - 1e-9:
                    meta["override_clamped"] = True
                    if not self._min_margin_override_log.get(pair):
                        logger.warning(
                            "%s 的 min_margin_usdt=%.6f 低于交易所推导的最小保证金 %.6f，已按覆写值执行，实际下单请留意交易所约束。",
                            pair,
                            float(override_margin),
                            baseline,
                        )
                        self._min_margin_override_log[pair] = True
                need = float(override_margin)
                meta["source"] = "override"
                meta["baseline_margin"] = round(float(baseline), 6)

        return need, meta

    def _entry_guard_status_sanitize_value(self, value: Any) -> Any:
        """把入场守卫的诊断信息压缩成 JSON 友好的格式，避免复盘与日志刷屏。"""
        if value is None:
            return None
        if isinstance(value, (str, int, bool)):
            return value
        if isinstance(value, float):
            if np.isfinite(value):
                return round(float(value), 6)
            return "nan"
        if isinstance(value, datetime):
            return value.astimezone(timezone.utc).isoformat()
        if isinstance(value, pd.Timestamp):
            return value.to_pydatetime().astimezone(timezone.utc).isoformat()
        if isinstance(value, (list, tuple, set)):
            return [self._entry_guard_status_sanitize_value(v) for v in list(value)[:6]]
        if isinstance(value, dict):
            sanitized: Dict[str, Any] = {}
            for idx, (key, val) in enumerate(value.items()):
                if idx >= 12:
                    break
                sanitized[str(key)] = self._entry_guard_status_sanitize_value(val)
            return sanitized
        try:
            return round(float(value), 6)
        except Exception:
            return str(value)

    def _entry_guard_review_update(self) -> None:
        state = getattr(self, "_review_state", None)
        if not isinstance(state, dict):
            return
        snapshot: Dict[str, Dict[str, Any]] = {}
        for guard, mapping in self._entry_guard_status.items():
            if not mapping:
                continue
            snapshot[guard] = {pair: dict(payload) for pair, payload in mapping.items()}
        if snapshot:
            state["entry_readiness"] = snapshot
        else:
            state.pop("entry_readiness", None)

    def _entry_guard_status_record(
        self,
        guard: str,
        pair: str,
        ok: bool,
        reason: Optional[str],
        extra: Optional[Dict[str, Any]],
        resume_at: Optional[datetime],
        now: Optional[datetime],
    ) -> None:
        if not guard or not pair:
            return
        now_dt = now or self._utc_now()
        status_map = self._entry_guard_status.setdefault(guard, {})

        sanitized_extra: Optional[Dict[str, Any]] = None
        if isinstance(extra, dict) and extra:
            sanitized_extra = {}
            for key, value in extra.items():
                sanitized_extra[str(key)] = self._entry_guard_status_sanitize_value(value)

        resume_iso: Optional[str] = None
        if resume_at is not None:
            try:
                resume_iso = resume_at.astimezone(timezone.utc).isoformat()
            except Exception:
                resume_iso = None
        elif isinstance(extra, dict) and extra.get("resume_at") is not None:
            parsed = self._to_utc_datetime(extra.get("resume_at"))
            if parsed is not None:
                resume_iso = parsed.astimezone(timezone.utc).isoformat()

        entry: Optional[Dict[str, Any]]
        if ok:
            entry = None
        else:
            entry = {
                "reason": str(reason or ""),
                "ts": now_dt.isoformat(),
            }
            if resume_iso:
                entry["resume_at"] = resume_iso
            if sanitized_extra:
                entry["details"] = sanitized_extra

        previous = status_map.get(pair)
        changed = False
        if entry is None:
            if pair in status_map:
                status_map.pop(pair, None)
                changed = True
        else:
            if previous != entry:
                status_map[pair] = entry
                changed = True

        if not changed:
            return

        guard_label = {"data": "数据刷新", "balance": "保证金"}.get(guard, guard)
        if entry is None:
            logger.info(f"[入场体检] {pair} {guard_label}守卫已恢复正常")
        else:
            msg = f"[入场体检] {pair} {guard_label}守卫触发：{entry.get('reason') or guard_label}"
            resume_txt = entry.get("resume_at")
            if resume_txt:
                msg += f"（预计恢复 {resume_txt}）"
            details = entry.get("details")
            if isinstance(details, dict) and details:
                detail_txt = ", ".join(f"{k}={v}" for k, v in details.items())
                msg += f" | {detail_txt}"
            logger.warning(msg)

        self._entry_guard_review_update()

    def _entry_signal_queue(self, pair: Optional[str]) -> List[Dict[str, Any]]:
        if not pair:
            return []
        st = self._pair_state.setdefault(pair, {})
        queue = st.get("entry_signal_queue")
        if not isinstance(queue, list):
            queue = []
        st["entry_signal_queue"] = queue
        return queue

    def _entry_signal_track(
        self,
        pair: Optional[str],
        side: str,
        ts_raw: Any,
        tag: Optional[str],
        price: Optional[Any],
        *,
        fallback_ts: Optional[Any] = None,
    ) -> None:
        if not pair or side not in ("long", "short"):
            return
        ts = self._to_utc_datetime(ts_raw)
        if ts is not None and getattr(ts, "year", 0) < 2000:
            ts = None
        if ts is None and fallback_ts is not None:
            ts = self._to_utc_datetime(fallback_ts)
        if ts is None:
            ts = self._utc_now()
        queue = self._entry_signal_queue(pair)
        key = f"{side}:{ts.isoformat()}"
        if any(sig.get("key") == key for sig in queue):
            return
        entry: Dict[str, Any] = {
            "side": side,
            "ts": ts,
            "key": key,
        }
        tag_txt = (str(tag).strip() if isinstance(tag, str) else "")
        if tag_txt:
            entry["tag"] = tag_txt
        price_val = self._safe_float(price)
        if price_val is not None and np.isfinite(price_val):
            entry["price"] = price_val
        queue.append(entry)
        limit = max(4, int(getattr(self, "ENTRY_SIGNAL_QUEUE_LIMIT", 12) or 12))
        if len(queue) > limit:
            queue[:] = queue[-limit:]

    def _entry_signal_pending_hint(self, pair: Optional[str]) -> Dict[str, Any]:
        hint: Dict[str, Any] = {}
        if not pair:
            return hint

        pair_state = {}
        try:
            pair_state = self._pair_state.get(pair, {})  # type: ignore[attr-defined]
        except Exception:
            pair_state = {}
        block_ctx = pair_state.get("last_entry_block") if isinstance(pair_state, dict) else None

        max_open: Optional[int] = None
        try:
            cfg_val = getattr(self, "max_open_trades", None)
            if cfg_val is not None:
                max_open = int(cfg_val)
        except Exception:
            max_open = None
        if max_open is None:
            try:
                cfg_val = ((self.config or {}).get("max_open_trades")) if isinstance(self.config, dict) else None
                if cfg_val is not None:
                    max_open = int(cfg_val)
            except Exception:
                max_open = None

        portfolio: Dict[str, Any] = {}
        try:
            portfolio = self._portfolio_snapshot()
        except Exception:
            portfolio = {}
        open_count = int(portfolio.get("open_count", 0) or 0)

        if max_open is not None and max_open > 0:
            hint["open_trades"] = open_count
            hint["max_open_trades"] = max_open
            if open_count >= max_open:
                hint["hint"] = "max_open_trades_full"
                return hint

        if "hint" not in hint:
            hint["hint"] = "freqtrade 未触发终审，通常是 pairlock/max_open_trades/余额冷静期"

        if isinstance(block_ctx, dict):
            reason_txt = str(block_ctx.get("reason") or "").strip()
            block_time = block_ctx.get("time")
            extra = block_ctx.get("extra") if isinstance(block_ctx.get("extra"), dict) else None
            if reason_txt:
                hint.setdefault("last_block_reason", reason_txt)
            if isinstance(block_time, datetime):
                hint.setdefault("last_block_time", block_time.isoformat())
            if extra:
                if "cooldown_need" in extra or "cooldown_done" in extra:
                    hint["hint"] = "entry_cooldown_active"
                    hint.setdefault("cooldown_need", extra.get("cooldown_need"))
                    hint.setdefault("cooldown_done", extra.get("cooldown_done"))
                hint.setdefault("last_block_extra", extra)
            elif reason_txt and "冷静期" in reason_txt and hint.get("hint"):
                hint["hint"] = "entry_cooldown_active"
        return hint

    def _entry_signal_history_state(self, pair: Optional[str]) -> "OrderedDict[str, Dict[str, Any]]":
        if not pair:
            return OrderedDict()
        st = self._pair_state.setdefault(pair, {})
        history_raw = st.get("entry_signal_history")
        if isinstance(history_raw, OrderedDict):
            history = history_raw
        elif isinstance(history_raw, dict):
            history = OrderedDict(history_raw.items())
        else:
            history = OrderedDict()
        cleaned: "OrderedDict[str, Dict[str, Any]]" = OrderedDict()
        for key, entry in history.items():
            entry_dict = entry if isinstance(entry, dict) else {}
            ts_val = entry_dict.get("ts", key)
            ts = self._to_utc_datetime(ts_val)
            if ts is None:
                continue
            cleaned[key] = {
                "ts": ts,
                "long": bool(entry_dict.get("long")),
                "short": bool(entry_dict.get("short")),
            }
        # 重新按时间排序，确保 popitem(last=False) 始终移除最旧记录
        ordered = OrderedDict(sorted(cleaned.items(), key=lambda item: item[1]["ts"]))
        st["entry_signal_history"] = ordered
        return ordered

    def _entry_signal_history_prune(self, pair: Optional[str], df: DataFrame) -> None:
        if not pair or df.empty:
            return
        history = self._entry_signal_history_state(pair)
        if not history:
            return
        idx = df.index
        try:
            idx_min = pd.Timestamp(idx.min())
        except Exception:
            idx_min = None
        pad_minutes = max(1.0, float(self._tf_minutes()) * 10.0)
        cutoff = None
        if idx_min is not None:
            if idx_min.tzinfo is None:
                idx_min = idx_min.tz_localize(timezone.utc)
            else:
                idx_min = idx_min.tz_convert(timezone.utc)
            cutoff = idx_min - pd.Timedelta(minutes=pad_minutes)
        for key, entry in list(history.items()):
            ts = entry.get("ts")
            if cutoff is not None and isinstance(ts, datetime) and ts < cutoff:
                history.pop(key, None)
        limit = max(120, int(getattr(self, "ENTRY_SIGNAL_HISTORY_MAX_ENTRIES", 960) or 960))
        while len(history) > limit:
            history.popitem(last=False)

    def _entry_signal_history_replay(self, df: DataFrame, pair: Optional[str]) -> None:
        if not pair or df.empty:
            return
        history = self._entry_signal_history_state(pair)
        if not history:
            return
        freeze = int(getattr(self, "ENTRY_SIGNAL_FREEZE_BARS", 5) or 5)
        freeze = max(1, freeze)
        idx = df.index
        stable_len = len(idx) - freeze
        if stable_len <= 0:
            return
        stable_labels = set(idx[:stable_len])
        for entry in history.values():
            ts = entry.get("ts")
            if ts is None:
                continue
            idx_label = self._entry_block_index_lookup(df, {"time": ts})
            if idx_label is None or idx_label not in stable_labels:
                continue
            if entry.get("long"):
                df.loc[idx_label, "enter_long"] = 1
                df.loc[idx_label, "sig_long_cand"] = 1
            if entry.get("short"):
                df.loc[idx_label, "enter_short"] = 1
                df.loc[idx_label, "sig_short_cand"] = 1

    def _entry_signal_history_capture(self, df: DataFrame, pair: Optional[str]) -> None:
        if not pair or df.empty:
            return
        history = self._entry_signal_history_state(pair)
        idx = df.index
        capture_span = int(getattr(self, "ENTRY_SIGNAL_HISTORY_CAPTURE_BARS", 720) or 720)
        capture_span = max(60, capture_span)
        start = max(0, len(idx) - capture_span)
        capture_index = idx[start:]
        for label in capture_index:
            try:
                ts = pd.Timestamp(label)
            except Exception:
                continue
            if ts.tzinfo is None:
                ts_utc = ts.tz_localize(timezone.utc)
            else:
                ts_utc = ts.tz_convert(timezone.utc)
            long_flag = int(df.loc[label, "enter_long"] == 1)
            short_flag = int(df.loc[label, "enter_short"] == 1)
            if not long_flag and not short_flag:
                continue
            key = ts_utc.isoformat()
            entry = history.get(key)
            if not isinstance(entry, dict):
                entry = {"ts": ts_utc, "long": False, "short": False}
                history[key] = entry
            entry["ts"] = ts_utc
            if long_flag:
                entry["long"] = True
            if short_flag:
                entry["short"] = True
        self._entry_signal_history_prune(pair, df)

    def _entry_block_index_lookup(self, df: DataFrame, block_ctx: Dict[str, Any]) -> Optional[Any]:
        idx_key = block_ctx.get("row_index")
        if idx_key is not None and idx_key in df.index:
            return idx_key
        block_time = self._to_utc_datetime(block_ctx.get("time"))
        if block_time is None or df.empty:
            return None
        try:
            idx_dt = pd.DatetimeIndex(df.index)
        except Exception:
            return None
        target = pd.Timestamp(block_time)
        if idx_dt.tz is None:
            if target.tzinfo is not None:
                target = target.tz_localize(None)
        else:
            if target.tzinfo is None:
                target = target.tz_localize(idx_dt.tz)
            else:
                target = target.tz_convert(idx_dt.tz)
        tolerance_min = float(getattr(self, "ENTRY_BLOCK_MARK_TOLERANCE_MINUTES", 0.0) or 0.0)
        if tolerance_min <= 0:
            tolerance_min = max(1.0, self._tf_minutes() * 0.6)
        tolerance = pd.Timedelta(minutes=tolerance_min)
        try:
            deltas = (idx_dt - target).abs()
        except Exception:
            return None
        if deltas.empty:
            return None
        min_delta = deltas.min()
        if pd.isna(min_delta) or min_delta > tolerance:
            return None
        nearest_pos = int(deltas.argmin())
        if nearest_pos < 0 or nearest_pos >= len(df.index):
            return None
        return df.index[nearest_pos]

    def _apply_entry_block_overlay(self, df: DataFrame, pair: Optional[str]) -> None:
        if not pair or df.empty:
            return
        st = self._pair_state.get(pair)
        if not isinstance(st, dict):
            return
        block_ctx = st.get("last_entry_block")
        if not isinstance(block_ctx, dict):
            return
        side = str(block_ctx.get("side") or "").lower()
        if side not in ("long", "short"):
            return
        idx_label = self._entry_block_index_lookup(df, block_ctx)
        if idx_label is None:
            return
        col = "entry_block_long" if side == "long" else "entry_block_short"
        try:
            df.loc[idx_label, col] = 1
        except Exception:
            return
        if bool(getattr(self, "ENTRY_BLOCK_HIDE_SIGNALS", True)):
            enter_col = f"enter_{side}"
            try:
                df.loc[idx_label, enter_col] = 0
            except Exception:
                pass
            try:
                df.loc[idx_label, "enter_tag"] = ""
            except Exception:
                pass

    def _entry_signal_latency_thresholds(self) -> Tuple[float, float]:
        warn = float(getattr(self, "ENTRY_EXECUTION_LATENCY_WARN_SEC", 0.0) or 0.0)
        alert = float(getattr(self, "ENTRY_EXECUTION_LATENCY_ALERT_SEC", 0.0) or 0.0)
        if warn <= 0:
            warn = 75.0
        if alert <= 0 or alert < warn:
            alert = max(warn * 1.5, warn + 45.0)
        warn = max(5.0, warn)
        alert = max(warn, alert)
        return warn, alert

    def _entry_signal_latency_log(
        self,
        pair: Optional[str],
        side: str,
        sig_ts: Optional[datetime],
        executed_at: Optional[datetime],
        latency_sec: Optional[float],
        *,
        queue_size: Optional[int] = None,
    ) -> None:
        if not pair or side not in ("long", "short"):
            return
        if latency_sec is None:
            return
        warn, alert = self._entry_signal_latency_thresholds()
        if latency_sec < warn:
            return
        info: Dict[str, Any] = {
            "latency_sec": round(latency_sec, 3),
            "warn_sec": round(warn, 3),
            "alert_sec": round(alert, 3),
        }
        if queue_size is not None:
            info["queue_size"] = int(queue_size)
        if sig_ts is not None:
            info["signal_time"] = sig_ts.isoformat()
        if executed_at is not None:
            info["executed_at"] = executed_at.isoformat()
        pending_hint = self._entry_signal_pending_hint(pair)
        for key, value in pending_hint.items():
            info.setdefault(key, value)
        if latency_sec >= alert:
            reason = "候选信号执行严重延迟"
        else:
            reason = "候选信号执行延迟"
        self._log_decision("入场体检", pair, side, "延迟", reason, info)

    def _entry_fill_slippage_log(
        self,
        pair: Optional[str],
        side: Optional[str],
        pending_snap: Optional[Dict[str, Any]],
        fill_price: Optional[float],
        fill_ts: Optional[datetime],
    ) -> None:
        if not pair or pending_snap is None:
            return
        price_signal = self._safe_float(pending_snap.get("entry_signal_price"))
        if price_signal is None or price_signal <= 0:
            return
        price_fill = self._safe_float(fill_price)
        if price_fill is None or price_fill <= 0:
            return
        slippage = (price_fill - price_signal) / price_signal
        slip_abs = abs(slippage)
        self._record_slippage_sample(pair, slippage, fill_ts)
        warn = float(getattr(self, "ENTRY_SLIPPAGE_WARN_PCT", 0.0) or 0.0)
        alert = float(getattr(self, "ENTRY_SLIPPAGE_ALERT_PCT", 0.0) or 0.0)
        if warn <= 0:
            warn = 0.0008
        if alert <= 0 or alert < warn:
            alert = max(warn * 1.6, warn + 0.0003)
        if slip_abs < warn:
            return
        sig_dt = self._to_utc_datetime(pending_snap.get("entry_signal_dt") or pending_snap.get("time"))
        lat_sec: Optional[float] = None
        if sig_dt is not None and fill_ts is not None:
            lat_sec = max(0.0, (fill_ts - sig_dt).total_seconds())
        info: Dict[str, Any] = {
            "signal_price": round(price_signal, 6),
            "fill_price": round(price_fill, 6),
            "slippage_pct": round(slippage, 6),
            "slippage_bps": round(slip_abs * 10000.0, 3),
            "warn_pct": round(warn, 6),
            "alert_pct": round(alert, 6),
        }
        if lat_sec is not None:
            info["signal_to_fill_sec"] = round(lat_sec, 3)
        if sig_dt is not None:
            info["signal_time"] = sig_dt.isoformat()
        if fill_ts is not None:
            info["fill_time"] = fill_ts.isoformat()
        pending_hint = self._entry_signal_pending_hint(pair)
        for key, value in pending_hint.items():
            info.setdefault(key, value)
        log_side = side or str(pending_snap.get("side") or "long")
        if slip_abs >= alert:
            reason = "实际成交滑点超过严重阈值"
        else:
            reason = "实际成交滑点偏高"
        self._log_decision("入场体检", pair, log_side, "滑点", reason, info)

    def _record_slippage_sample(
        self, pair: Optional[str], slippage: Optional[float], fill_ts: Optional[datetime]
    ) -> None:
        if not pair or slippage is None or not np.isfinite(slippage):
            return
        st = self._pair_state.setdefault(pair, {})
        slip_state = st.setdefault("slippage_state", {})
        samples: List[Dict[str, Any]] = slip_state.setdefault("samples", []) if isinstance(slip_state, dict) else []
        now_ts = fill_ts if isinstance(fill_ts, datetime) else datetime.now(timezone.utc)
        try:
            samples.append({"abs_pct": abs(float(slippage)), "ts": now_ts})
        except Exception:
            return
        cfg = self._pair_cfg(pair)
        window = int(cfg.get("execution_slippage", {}).get("window", getattr(self, "EXECUTION_SLIPPAGE_WINDOW", 14)) or getattr(self, "EXECUTION_SLIPPAGE_WINDOW", 14))
        if window > 0 and len(samples) > window:
            samples[:] = samples[-window:]
        abs_vals = [self._safe_float(s.get("abs_pct")) or 0.0 for s in samples]
        slip_state["mean_abs"] = float(np.mean(abs_vals)) if abs_vals else 0.0
        slip_state["max_abs"] = float(np.max(abs_vals)) if abs_vals else 0.0
        slip_state["window"] = window
        slip_state["last_ts"] = now_ts

    def _slippage_guard_snapshot(self, pair: str) -> Dict[str, Any]:
        state = self._pair_state.setdefault(pair, {})
        slip_state = state.get("slippage_state") if isinstance(state, dict) else None
        samples = slip_state.get("samples") if isinstance(slip_state, dict) else None
        if not isinstance(samples, list) or not samples:
            return {"active": False, "stats": {}}

        cfg = self._pair_cfg(pair)
        slip_cfg = cfg.get("execution_slippage", {}) if isinstance(cfg, dict) else {}
        window = int(slip_cfg.get("window", getattr(self, "EXECUTION_SLIPPAGE_WINDOW", 14)) or getattr(self, "EXECUTION_SLIPPAGE_WINDOW", 14))
        tighten_bps = float(slip_cfg.get("tighten_bps", getattr(self, "EXECUTION_SLIPPAGE_TIGHTEN_BPS", 18.0)) or getattr(self, "EXECUTION_SLIPPAGE_TIGHTEN_BPS", 18.0))
        severe_bps = float(slip_cfg.get("severe_bps", getattr(self, "EXECUTION_SLIPPAGE_SEVERE_BPS", 32.0)) or getattr(self, "EXECUTION_SLIPPAGE_SEVERE_BPS", 32.0))
        tighten = max(0.0, tighten_bps) / 10000.0
        severe = max(severe_bps, tighten_bps) / 10000.0
        recent = samples[-window:] if window > 0 else list(samples)
        abs_vals = [self._safe_float(s.get("abs_pct")) or 0.0 for s in recent]
        mean_abs = float(np.mean(abs_vals)) if abs_vals else 0.0
        max_abs = float(np.max(abs_vals)) if abs_vals else 0.0

        severity = None
        if max_abs >= severe:
            severity = "severe"
        elif max_abs >= tighten or mean_abs >= tighten:
            severity = "tight"

        risk_scale = float(slip_cfg.get("risk_scale", getattr(self, "EXECUTION_SLIPPAGE_RISK_SCALE", 0.92)))
        risk_scale_severe = float(slip_cfg.get("risk_scale_severe", getattr(self, "EXECUTION_SLIPPAGE_SEVERE_RISK_SCALE", 0.86)))
        cost_boost = float(slip_cfg.get("cost_boost", getattr(self, "EXECUTION_SLIPPAGE_COST_BOOST", 1.05)))
        cost_boost_severe = float(slip_cfg.get("cost_boost_severe", getattr(self, "EXECUTION_SLIPPAGE_SEVERE_COST_BOOST", 1.12)))
        cap_share = float(slip_cfg.get("cap_share", getattr(self, "EXECUTION_SLIPPAGE_CAP_SHARE", 0.82)))
        cap_share_severe = float(slip_cfg.get("cap_share_severe", getattr(self, "EXECUTION_SLIPPAGE_SEVERE_CAP_SHARE", 0.72)))

        guard: Dict[str, Any] = {
            "active": severity is not None,
            "severity": severity,
            "stats": {
                "window": window,
                "mean_abs": mean_abs,
                "max_abs": max_abs,
                "tighten_bps": tighten_bps,
                "severe_bps": severe_bps,
            },
        }
        if severity == "severe":
            guard.update(
                {
                    "risk_scale": risk_scale_severe,
                    "cost_boost": cost_boost_severe,
                    "cap_share": cap_share_severe,
                }
            )
        elif severity == "tight":
            guard.update(
                {
                    "risk_scale": risk_scale,
                    "cost_boost": cost_boost,
                    "cap_share": cap_share,
                }
            )
        return guard

    def _entry_signal_consume(
        self,
        pair: Optional[str],
        side: str,
        ts_raw: Optional[Any],
        executed_at: Optional[Any] = None,
    ) -> None:
        if not pair or side not in ("long", "short"):
            return
        st = self._pair_state.get(pair)
        if not isinstance(st, dict):
            return
        queue = st.get("entry_signal_queue")
        if not isinstance(queue, list) or not queue:
            return
        target_ts = self._to_utc_datetime(ts_raw)
        exec_dt = self._to_utc_datetime(executed_at)
        if exec_dt is None:
            exec_dt = self._utc_now()
        tolerance_sec = max(60.0, self._tf_minutes() * 60.0)
        keep: List[Dict[str, Any]] = []
        consumed = False
        latency_logged = False
        queue_size = len(queue)
        for sig in queue:
            sig_side = sig.get("side")
            sig_ts = self._to_utc_datetime(sig.get("ts")) if sig.get("ts") is not None else None
            if sig_ts is not None and getattr(sig_ts, "year", 0) < 2000:
                sig_ts = None
            if not consumed and sig_side == side:
                match = False
                if target_ts is not None and sig_ts is not None:
                    delta = abs((target_ts - sig_ts).total_seconds())
                    if delta <= tolerance_sec:
                        match = True
                elif target_ts is None:
                    match = True
                if match:
                    consumed = True
                    if not latency_logged:
                        latency_sec = None
                        if exec_dt is not None and sig_ts is not None:
                            latency_sec = abs((exec_dt - sig_ts).total_seconds())
                        log_side = sig_side if sig_side in ("long", "short") else side
                        self._entry_signal_latency_log(
                            pair,
                            log_side,
                            sig_ts,
                            exec_dt,
                            latency_sec,
                            queue_size=queue_size,
                        )
                        latency_logged = True
                    continue
            keep.append(sig)
        if consumed:
            st["entry_signal_queue"] = keep

    def _sweep_pending_entry_signals(
        self,
        pair: Optional[str],
        now: Optional[datetime] = None,
    ) -> None:
        if not pair:
            return
        st = self._pair_state.get(pair)
        if not isinstance(st, dict):
            return
        queue = st.get("entry_signal_queue")
        if not isinstance(queue, list) or not queue:
            return
        now_dt = self._utc_now(now)
        tf_minutes = max(1.0, float(getattr(self, "_current_tf_minutes", self._tf_minutes())))
        stale_cfg = float(getattr(self, "ENTRY_SIGNAL_STALE_MINUTES", 0.0) or 0.0)
        if stale_cfg <= 0:
            stale_minutes = max(3.0, tf_minutes * 2.4)
        else:
            stale_minutes = max(1.0, stale_cfg)
        keep: List[Dict[str, Any]] = []
        for sig in queue:
            sig_ts = self._to_utc_datetime(sig.get("ts")) if sig.get("ts") is not None else None
            if sig_ts is not None and getattr(sig_ts, "year", 0) < 2000:
                sig_ts = None
            if sig_ts is None:
                continue
            age_min = max(0.0, (now_dt - sig_ts).total_seconds() / 60.0)
            if age_min < stale_minutes:
                keep.append(sig)
                continue
            info: Dict[str, Any] = {
                "signal_time": sig_ts.isoformat(),
                "age_min": round(age_min, 3),
                "stale_min": round(stale_minutes, 3),
            }
            if sig.get("tag"):
                info["enter_tag"] = sig.get("tag")
            price_val = self._safe_float(sig.get("price"))
            if price_val is not None and np.isfinite(price_val):
                info["signal_price"] = round(price_val, 6)
            pending_hint = self._entry_signal_pending_hint(pair)
            if pending_hint:
                for key, value in pending_hint.items():
                    info.setdefault(key, value)
            self._log_decision(
                "入场体检",
                pair,
                sig.get("side"),
                "候选未执行",
                "候选信号超过等待窗口仍未下单，建议检查 freqtrade 是否锁对或名额已满",
                info,
            )
        st["entry_signal_queue"] = keep

    def _ensure_data_fresh(
        self,
        pair: str,
        now: datetime,
        df: Optional[DataFrame] = None,
        current_time: Optional[datetime] = None,
        row_ts: Optional[datetime] = None,
    ) -> Tuple[bool, Optional[str], Optional[Dict[str, Any]]]:
        """教学提示：K 线过旧时暂停终审，避免 create_trade 在历史未更新时硬开仓。"""
        threshold = max(1.0, float(getattr(self, "DATA_STALE_THRESHOLD_MINUTES", 20)))
        recheck = max(1.0, float(getattr(self, "DATA_STALE_RECHECK_MINUTES", 5)))
        log_cd = max(1.0, float(getattr(self, "DATA_STALE_LOG_COOLDOWN_MINUTES", 30)))

        if df is None:
            try:
                df, _ = self.dp.get_analyzed_dataframe(pair, self.timeframe)
            except Exception:
                df = None

        row_dt: Optional[datetime] = None
        if row_ts is not None:
            row_dt = self._to_utc_datetime(row_ts)

        current_dt: Optional[datetime] = None
        if current_time is not None:
            current_dt = self._to_utc_datetime(current_time)

        until = self._data_stale_until.get(pair)

        def _finish(ok: bool, reason: Optional[str], extra: Optional[Dict[str, Any]]):
            resume_dt: Optional[datetime] = None
            if not ok:
                resume_dt = self._data_stale_until.get(pair)
                if isinstance(extra, dict) and extra.get("resume_at") is not None:
                    parsed = self._to_utc_datetime(extra.get("resume_at"))
                    if parsed is not None:
                        resume_dt = parsed
            self._entry_guard_status_record("data", pair, ok, reason, extra, resume_dt, now)
            return ok, reason, extra

        last_dt: Optional[datetime] = None
        raw_last_dt: Optional[datetime] = None
        age_now: Optional[float] = None
        age_metrics: Dict[str, float] = {}
        age_candidates: List[float] = []
        last_dt_source: Optional[str] = None
        if df is not None and not df.empty:
            last_idx = df.index[-1]
            raw_last_dt = self._to_utc_datetime(last_idx)
            if raw_last_dt is not None and raw_last_dt.year >= 2000:
                last_dt = raw_last_dt
                last_dt_source = "dataframe"
            elif row_dt is not None and row_dt.year >= 2000:
                last_dt = row_dt
                last_dt_source = "row_ts_fallback"
            elif current_dt is not None and current_dt.year >= 2000:
                last_dt = current_dt
                last_dt_source = "current_time_fallback"
            if last_dt is None:
                return _finish(False, "无法解析最新 K 线时间", None)

            age_now = max(0.0, (now - last_dt).total_seconds() / 60.0)
            age_candidates.append(age_now)
            age_metrics["age_runtime_min"] = round(age_now, 4)

            if row_dt is not None:
                age_from_row = max(0.0, (now - row_dt).total_seconds() / 60.0)
                age_candidates.append(age_from_row)
                age_metrics["age_from_row_min"] = round(age_from_row, 4)

            if current_dt is not None:
                age_from_current = max(0.0, (current_dt - last_dt).total_seconds() / 60.0)
                age_candidates.append(age_from_current)
                age_metrics["age_from_current_min"] = round(age_from_current, 4)

            effective_age: Optional[float] = None
            if age_candidates:
                effective_age = max(age_candidates)
            if effective_age is not None and effective_age <= threshold:
                self._data_stale_until.pop(pair, None)
                self._data_stale_last_log.pop(pair, None)
                return _finish(True, None, None)
            if effective_age is not None:
                age_metrics["effective_age_max"] = round(effective_age, 4)
            if last_dt_source:
                age_metrics["last_candle_source"] = last_dt_source
            if raw_last_dt is not None and last_dt_source != "dataframe":
                age_metrics["last_candle_raw_df"] = raw_last_dt.isoformat()

        stale_extra: Dict[str, Any] = {}
        if last_dt is not None and age_now is not None:
            stale_extra.update({
                "last_candle": last_dt.isoformat(),
                "age_minutes": round(age_now, 2),
            })
        if age_metrics:
            stale_extra.update(age_metrics)

        stale_extra.setdefault("threshold_min", round(threshold, 4))
        stale_extra.setdefault("recheck_min", round(recheck, 4))
        tf_minutes = float(getattr(self, "_current_tf_minutes", self._tf_minutes()))
        stale_extra.setdefault("timeframe_min", round(tf_minutes, 4))

        if df is None or df.empty:
            if until and now < until:
                extra = {"resume_at": until.isoformat()}
                extra.update(stale_extra)
                last_log = self._data_stale_last_log.get(pair)
                if last_log is None or (now - last_log) >= timedelta(minutes=log_cd):
                    self._data_stale_last_log[pair] = now
                    return _finish(False, "K线数据延迟，等待刷新", extra)
                return _finish(False, None, extra)
            return _finish(False, "数据帧为空，暂缓下单", None)

        if until is None or now >= until:
            self._data_stale_until[pair] = now + timedelta(minutes=recheck)
            self._data_stale_last_log[pair] = now
            stale_extra.update({"recheck_in_min": recheck})
            return _finish(False, "K线数据延迟，等待刷新", stale_extra)

        extra = {"resume_at": until.isoformat()}
        extra.update(stale_extra)
        last_log = self._data_stale_last_log.get(pair)
        if last_log is None or (now - last_log) >= timedelta(minutes=log_cd):
            self._data_stale_last_log[pair] = now
            return _finish(False, "K线数据延迟，等待刷新", extra)
        return _finish(False, None, extra)

    def _ensure_min_stake_balance(self, pair: str, now: datetime, price: Optional[float]) -> Tuple[bool, Optional[str], Optional[Dict[str, Any]]]:
        """教学提示：余额低于最小下单量时暂缓终审，减少反复 Minimum stake 告警。"""
        cooldown = max(1.0, float(getattr(self, "LOW_BALANCE_SKIP_MINUTES", 12)))
        log_cd = max(1.0, float(getattr(self, "LOW_BALANCE_LOG_COOLDOWN_MINUTES", 30)))

        until = self._low_balance_until.get(pair)

        def _finish(ok: bool, reason: Optional[str], extra: Optional[Dict[str, Any]]):
            resume_dt: Optional[datetime] = None
            if not ok:
                resume_dt = self._low_balance_until.get(pair)
                if isinstance(extra, dict) and extra.get("resume_at") is not None:
                    parsed = self._to_utc_datetime(extra.get("resume_at"))
                    if parsed is not None:
                        resume_dt = parsed
            self._entry_guard_status_record("balance", pair, ok, reason, extra, resume_dt, now)
            return ok, reason, extra

        if until and now < until:
            extra = {"resume_at": until.isoformat()}
            last_log = self._low_balance_last_log.get(pair)
            if last_log is None or (now - last_log) >= timedelta(minutes=log_cd):
                self._low_balance_last_log[pair] = now
                return _finish(False, "保证金不足最小下单量，等待冷静期", extra)
            return _finish(False, None, extra)

        profile_raw, free_float, _ = self._resolve_notional_profile(pair)
        profile = profile_raw if isinstance(profile_raw, dict) else {}
        leverage = self._effective_account_leverage(profile, pair)

        need, need_meta = self._min_stake_requirement(pair, price, leverage=leverage)
        if need_meta:
            leverage = float(need_meta.get("leverage", leverage) or leverage)

        if need is None or need <= 0:
            self._low_balance_until.pop(pair, None)
            self._low_balance_last_log.pop(pair, None)
            return _finish(True, None, None)

        need_margin = need
        need_notional: Optional[float] = None
        if need_margin is not None and need_margin > 0 and leverage > 0:
            need_notional = need_margin * leverage

        if free_float is None or not np.isfinite(free_float):
            return _finish(True, None, None)

        reserve_ratio = min(max(float(profile.get("reserve_ratio", 0.0) or 0.0), 0.0), 0.95)
        reserve_static = max(0.0, float(profile.get("reserve_static", 0.0) or 0.0))
        ratio_reserve_amt = max(0.0, free_float * reserve_ratio)
        reserve_amt = ratio_reserve_amt + reserve_static
        usable = max(0.0, free_float - reserve_amt)
        tol = 1e-9

        if usable + tol >= need:
            info: Dict[str, Any] = {"reserve_mode": "none"}
            if free_float is not None and np.isfinite(free_float):
                info["available"] = round(float(free_float), 6)
            info["usable_after_reserve"] = round(float(usable), 6)
            info["min_required"] = round(float(need), 6)
            info["need_margin"] = round(float(need_margin), 6)
            if need_notional is not None and np.isfinite(need_notional):
                info["need_notional"] = round(float(need_notional), 6)
            info["reserve_gap"] = 0.0
            if reserve_amt > 0:
                info["reserve_buffer"] = round(float(reserve_amt), 6)
            info["reserve_tap_frac"] = 0.0
            if need_meta:
                info["min_requirement"] = need_meta
            self._low_balance_until.pop(pair, None)
            self._low_balance_last_log.pop(pair, None)
            return _finish(True, None, info)

        relax_enable = bool(getattr(self, "LOW_BALANCE_ALLOW_RESERVE_TAP", False))
        relax_frac = float(getattr(self, "LOW_BALANCE_RESERVE_TAP_FRAC", 0.0) or 0.0)
        if relax_frac < 0:
            relax_frac = 0.0
        if relax_frac > 1:
            relax_frac = 1.0

        if relax_enable and free_float + tol >= need and reserve_amt > tol:
            gap = need - usable
            if gap > tol:
                borrow_cap = reserve_amt * relax_frac
                if borrow_cap + tol >= gap:
                    info = {
                        "available": round(free_float, 6),
                        "usable_after_reserve": round(usable, 6),
                        "min_required": round(need, 6),
                        "need_margin": round(need_margin, 6),
                        "need_notional": round(need_notional, 6) if need_notional is not None else None,
                        "reserve_gap": round(gap, 6),
                        "reserve_buffer": round(max(0.0, reserve_amt - gap), 6),
                        "reserve_tap_frac": round(relax_frac, 4),
                        "reserve_mode": "buffer",
                    }
                    if need_meta:
                        info.setdefault("min_requirement", need_meta)
                    self._low_balance_until.pop(pair, None)
                    self._low_balance_last_log.pop(pair, None)
                    return _finish(True, "reserve_tap", info)

                if reserve_amt + tol >= gap:
                    ratio_used = min(gap, max(0.0, ratio_reserve_amt))
                    static_used = max(0.0, gap - ratio_used)
                    info = {
                        "available": round(free_float, 6),
                        "usable_after_reserve": round(usable, 6),
                        "min_required": round(need, 6),
                        "need_margin": round(need_margin, 6),
                        "need_notional": round(need_notional, 6) if need_notional is not None else None,
                        "reserve_gap": round(gap, 6),
                        "reserve_buffer": round(max(0.0, reserve_amt - gap), 6),
                        "reserve_tap_frac": 1.0,
                        "reserve_mode": "full",
                        "reserve_ratio_used": round(ratio_used, 6),
                        "reserve_static_used": round(static_used, 6),
                    }
                    if need_meta:
                        info.setdefault("min_requirement", need_meta)
                    self._low_balance_until.pop(pair, None)
                    self._low_balance_last_log.pop(pair, None)
                    return _finish(True, "reserve_tap", info)

        self._low_balance_until[pair] = now + timedelta(minutes=cooldown)
        self._low_balance_last_log[pair] = now
        extra = {
            "resume_at": self._low_balance_until[pair].isoformat(),
            "available": round(free_float, 6),
            "usable_after_reserve": round(usable, 6),
            "min_required": round(need, 6),
            "need_margin": round(need_margin, 6),
            "need_notional": round(need_notional, 6) if need_notional is not None else None,
            "reserve_buffer": round(reserve_amt, 6),
            "reserve_gap": round(need - usable, 6),
            "cooldown_min": cooldown,
        }
        if need_meta:
            extra.setdefault("min_requirement", need_meta)
        return _finish(False, "保证金不足最小下单量，等待冷静期", extra)

    def _amount_to_precision(self, pair: str, amount: float) -> Optional[float]:
        """教学提示：调用交易所接口做 amount_to_precision，避免我们手工计算步进时出现偏差。"""
        try:
            exchange = getattr(self, "exchange", None)
            if exchange is None:
                return None
            precise = exchange.amount_to_precision(pair, amount)
        except Exception:
            return None
        try:
            return float(precise)
        except (TypeError, ValueError):
            return None

    def _market_info(self, pair: str) -> Dict[str, Any]:
        """教学提示：优先从 exchange 获取期货/永续的精度，再回退到 data provider。"""
        market: Dict[str, Any] = {}
        exchange = getattr(self, "exchange", None)
        if exchange is not None:
            try:
                mk = exchange.market(pair)  # type: ignore[attr-defined]
                if isinstance(mk, dict):
                    market = mk
            except Exception:
                market = {}
        if not market:
            dp = getattr(self, "dp", None)
            if dp is not None:
                try:
                    mk = dp.market(pair)  # type: ignore[attr-defined]
                    if isinstance(mk, dict):
                        market = mk
                except Exception:
                    market = {}
        return market or {}

    def _normalize_partial_exit(self, pair: str, amount: float, price: float,
                                position_amount: float, tag: str = "") -> Tuple[Optional[float], Dict[str, Any]]:
        """教学提示：将部分减仓数量对齐交易所最小下单量/步进，防止出现“Wanted to exit... amount 0”日志。"""
        meta: Dict[str, Any] = {
            "tag": tag,
        }
        amt = float(abs(amount))
        pos_amt = float(max(0.0, position_amount))
        pos_amt_orig = pos_amt
        pos_precise = self._amount_to_precision(pair, pos_amt)
        if pos_precise is not None and pos_precise > 0:
            meta["precision_position"] = pos_precise
        meta["attempt_amount"] = amt
        meta["position_amount"] = pos_amt_orig
        if pos_amt <= 0:
            meta["limit_reason"] = "no_position"
            return None, meta
        if amt > pos_amt:
            amt = pos_amt
        runner_guard: Optional[float] = None
        tol = 1e-12
        partial_request = amt < pos_amt - 1e-9
        if partial_request:
            try:
                runner_frac = float(
                    (self._pair_cfg(pair) or {}).get(
                        "runner_min_frac", getattr(self, "RUNNER_MIN_FRAC", 0.0)
                    )
                    or 0.0
                )
            except (TypeError, ValueError):
                runner_frac = float(getattr(self, "RUNNER_MIN_FRAC", 0.0) or 0.0)
            runner_frac = float(max(0.0, min(1.0, runner_frac)))
            if runner_frac > 0.0 and runner_frac < 1.0:
                min_runner_amt = pos_amt * runner_frac
                max_trim_amt = max(0.0, pos_amt - min_runner_amt)
                meta["runner_min_frac"] = runner_frac
                meta["runner_min_position"] = min_runner_amt
                runner_guard = max_trim_amt
                if max_trim_amt <= 0:
                    meta["limit_reason"] = "runner_protected"
                    return None, meta
                if amt > max_trim_amt:
                    amt = max_trim_amt
                    meta["runner_clamped"] = True
        market = self._market_info(pair)
        limits = (market or {}).get("limits", {}) or {}
        amount_limits = limits.get("amount", {}) or {}
        min_amt = amount_limits.get("min")
        step_amt = amount_limits.get("step")
        precision = (market or {}).get("precision", {}) or {}
        if min_amt is not None:
            try:
                min_amt_f = float(min_amt)
            except (TypeError, ValueError):
                min_amt_f = 0.0
            meta["min_amount"] = min_amt_f if min_amt_f > 0 else None
        else:
            min_amt_f = 0.0
        if step_amt is not None:
            try:
                step_amt_f = float(step_amt)
            except (TypeError, ValueError):
                step_amt_f = 0.0
            meta["amount_step"] = step_amt_f if step_amt_f > 0 else None
        else:
            step_amt_f = 0.0
        if isinstance(precision, dict):
            prec_raw = precision.get("amount")
            try:
                prec_val = float(prec_raw) if prec_raw is not None else None
            except Exception:
                prec_val = None
            if (step_amt_f <= 0) and (prec_val is not None) and prec_val >= 0:
                try:
                    guess = 10.0 ** (-int(prec_val))
                except Exception:
                    guess = 0.0
                if guess > 0:
                    step_amt_f = guess
                    meta["amount_step"] = step_amt_f
        try:
            contract_size = float((market or {}).get("contractSize", 0.0) or 0.0)
        except Exception:
            contract_size = 0.0
        if contract_size > 0:
            meta["contract_size"] = contract_size
            if step_amt_f <= 0:
                step_amt_f = contract_size
            else:
                step_amt_f = max(step_amt_f, contract_size)
            if min_amt_f <= 0:
                min_amt_f = contract_size
        if step_amt_f > 0:
            try:
                step_dec = Decimal(str(step_amt_f))
                amt_dec = Decimal(str(amt))
                steps = (amt_dec / step_dec).to_integral_value(rounding=ROUND_DOWN)
                amt = float(steps * step_dec)
            except (InvalidOperation, ValueError):
                amt = math.floor(amt / step_amt_f) * step_amt_f
        if amt > pos_amt:
            amt = pos_amt
        if step_amt_f > 0:
            tol = max(tol, step_amt_f * 1e-6)
        elif min_amt_f > 0:
            tol = max(tol, min_amt_f * 1e-6)

        effective_pos_amt = pos_amt
        if pos_precise is not None and pos_precise > 0:
            effective_pos_amt = max(effective_pos_amt, pos_precise)

        effective_min_amt = min_amt_f
        if effective_min_amt > 0 and pos_amt > 0 and effective_min_amt > max(1.0, pos_amt * 4.0):
            meta["min_amount_suspect"] = True
            effective_min_amt = 0.0

        if effective_min_amt > 0 and (amt + tol) < effective_min_amt:
            # 若部分减仓低于最小下单量，尝试放大到最小量或一键平仓，避免错失止盈。
            if (effective_pos_amt + tol) >= effective_min_amt:
                try:
                    if step_amt_f > 0:
                        step_dec = Decimal(str(step_amt_f))
                        min_dec = Decimal(str(effective_min_amt))
                        pos_dec = Decimal(str(effective_pos_amt))
                        min_steps = (min_dec / step_dec).to_integral_value(rounding=ROUND_CEILING)
                        alt_dec = step_dec * min_steps
                        if alt_dec > pos_dec:
                            alt_dec = pos_dec
                        alt_amt = float(alt_dec)
                    else:
                        alt_amt = min(effective_pos_amt, effective_min_amt)
                except (InvalidOperation, ValueError):
                    alt_amt = min(effective_pos_amt, effective_min_amt)

                # 若放大后的剩余头寸不足最小量，则直接清仓，避免遗留尘量。
                if effective_pos_amt - alt_amt > 0 and effective_min_amt > 0 and (effective_pos_amt - alt_amt) < effective_min_amt:
                    alt_amt = effective_pos_amt

                if alt_amt > 0:
                    amt = alt_amt
                    meta["fallback_mode"] = "min_amount"
                    meta["effective_position_amount"] = amt
                else:
                    meta["limit_reason"] = "below_min_amount"
                    return None, meta
            else:
                # 账户内真实持仓已低于交易所标称最小量时，尝试直接用全部头寸报单，
                # 若精度检查仍可得到正数则允许“尘量强平”，避免被困在尘仓里。
                precise_pos_amt = pos_precise or self._amount_to_precision(pair, pos_amt)
                if (precise_pos_amt is None or precise_pos_amt <= 0) and step_amt_f > 0:
                    try:
                        step_dec = Decimal(str(step_amt_f))
                        pos_dec = Decimal(str(pos_amt))
                        ceil_steps = (pos_dec / step_dec).to_integral_value(rounding=ROUND_CEILING)
                        alt_amt = float(min(pos_dec, step_dec * ceil_steps))
                    except (InvalidOperation, ValueError):
                        alt_amt = pos_amt
                    if alt_amt > pos_amt:
                        alt_amt = pos_amt
                    precise_pos_amt = self._amount_to_precision(pair, alt_amt)
                    if precise_pos_amt is not None and precise_pos_amt > 0:
                        pos_amt = alt_amt
                        meta["effective_position_amount"] = pos_amt
                if precise_pos_amt is not None and precise_pos_amt > 0:
                    amt = pos_amt
                    meta["fallback_mode"] = "dust_full_close"
                    meta["precision_amount"] = precise_pos_amt
                else:
                    amt = pos_amt
                    meta["fallback_mode"] = "dust_attempt"
                    meta["effective_position_amount"] = pos_amt
        pos_amt_effective = float(meta.get("effective_position_amount", pos_amt))

        cost_limits = limits.get("cost", {}) or {}
        min_cost = cost_limits.get("min")
        if min_cost is not None:
            try:
                min_cost_f = float(min_cost)
            except (TypeError, ValueError):
                min_cost_f = 0.0
            meta["min_cost"] = min_cost_f if min_cost_f > 0 else None
        else:
            min_cost_f = 0.0
        if min_cost_f > 0 and price > 0:
            notional = amt * price
            meta["notional"] = notional
            if notional < min_cost_f:
                if (pos_amt_effective * price) >= (min_cost_f * 0.25):
                    meta["min_cost_suspect"] = True
                else:
                    meta["limit_reason"] = "below_min_cost"
                    return None, meta
        precise_amt = self._amount_to_precision(pair, abs(amt))
        if precise_amt is not None:
            meta["precision_amount"] = precise_amt
            if precise_amt <= 0:
                fallback_mode = meta.get("fallback_mode")
                fallback_candidates: List[float] = []
                if effective_min_amt > 0:
                    fallback_candidates.append(effective_min_amt)
                if step_amt_f > 0:
                    try:
                        step_dec = Decimal(str(step_amt_f))
                        amt_dec = Decimal(str(amt))
                        alt_steps = (amt_dec / step_dec).to_integral_value(rounding=ROUND_CEILING)
                        fallback_candidates.append(float(step_dec * alt_steps))
                    except (InvalidOperation, ValueError):
                        fallback_candidates.append(step_amt_f)
                fallback_candidates.append(pos_amt_effective)
                fallback_amt: Optional[float] = None
                for cand in fallback_candidates:
                    cand = float(max(0.0, min(cand, pos_amt_effective)))
                    if cand <= 0:
                        continue
                    cand_precise = self._amount_to_precision(pair, cand)
                    if cand_precise is None or cand_precise <= 0:
                        continue
                    fallback_amt = cand
                    meta["precision_amount"] = cand_precise
                    if not fallback_mode:
                        meta["fallback_mode"] = "precision_upscale"
                    break
                if fallback_amt is None:
                    meta["limit_reason"] = "precision_zero"
                    return None, meta
                amt = fallback_amt
                precise_amt = self._amount_to_precision(pair, abs(amt))
                if precise_amt is not None and precise_amt > 0:
                    meta["precision_amount"] = precise_amt
                else:
                    precise_amt = None
        if runner_guard is not None and amt > runner_guard + tol:
            meta["limit_reason"] = "runner_protected"
            meta["runner_guard"] = runner_guard
            meta["normalized_candidate"] = amt
            return None, meta
        if amt <= 0:
            meta["limit_reason"] = "zero_after_round"
            return None, meta
        normalized_base = precise_amt if precise_amt is not None and precise_amt > 0 else amt
        normalized = math.copysign(normalized_base, amount)
        meta["normalized_amount"] = abs(normalized)
        return normalized, meta

    @property
    def exchange_name(self) -> str:
        """教学提示：识别当前配置使用的交易所，用于信号校准。"""
        cache = getattr(self, "_exchange_name_cache", None)
        if cache is not None:
            return cache
        name = ""
        try:
            name = str(((self.config or {}).get("exchange") or {}).get("name", "")).lower()
        except Exception:
            name = ""
        self._exchange_name_cache = name
        return name

    @property
    def base_pairs(self) -> List[str]:
        """教学提示：返回参考用的“市场广度”币对列表，优先使用配置里的白名单。"""
        try:
            wl = ((self.config or {}).get("exchange") or {}).get("pair_whitelist", None)
            if wl:
                return list(wl)
        except Exception:
            pass

        return list(self.fallback_pairs)

    def _pair_cfg(self, pair: str) -> Dict[str, Any]:
        """教学提示：合并默认 per-pair 配置与 freqtrade 配置文件里的覆盖值。"""
        try:
            po_cfg = ((self.config or {}).get("pair_overrides")) or {}
        except Exception:
            po_cfg = {}
        base = {**self.pair_overrides.get(pair, {}), **po_cfg.get(pair, {})}
        return self._exit_tuning_merge_cfg(base, pair)

    def _validate_static_params(self) -> None:
        """教学提示：对关键参数做一次静态体检，发现冲突时在日志给出易懂警示。"""
        try:
            narrow = float(getattr(self, "CHANNEL_NARROW_MAX", 0.0))
            wide = float(getattr(self, "CHANNEL_WIDE_MIN", 0.0))
            if narrow >= wide and wide > 0:
                msg = (
                    f"CHANNEL_NARROW_MAX({narrow:.4f}) 不应大于或等于 CHANNEL_WIDE_MIN({wide:.4f})，"
                    "已按 freqtrade 推荐维持‘窄趋势 < 宽震荡’的分层。"
                )
                logger.warning(msg)

            legs = tuple(getattr(self, "ICEBERG_LEGS", ()))
            max_adds = max(0, int(getattr(self, "max_entry_position_adjustment", 0)))
            if len(legs) < max_adds + 1:
                msg = (
                    f"ICEBERG_LEGS 长度 {len(legs)} < max_entry_position_adjustment + 1 ({max_adds + 1})，"
                    "请补足加仓腿或下调 max_entry_position_adjustment。"
                )
                logger.warning(msg)

            lock_share = float(getattr(self, "PERF_DRAW_LOCK_SHARE", 0.0))
            if not (0.0 < lock_share <= 1.0):
                logger.warning(
                    "PERF_DRAW_LOCK_SHARE=%.3f 不在 (0,1] 区间，回撤期锁盈比例应控制在 0~1。",
                    lock_share
                )

            default_near = float(getattr(self, "SCALE_OUT_NEAR_FRAC", 0.0) or 0.0)
            default_exhaust = float(getattr(self, "SCALE_OUT_EXHAUST_FRAC", 0.0) or 0.0)
            default_runner = float(getattr(self, "RUNNER_MIN_FRAC", 0.0) or 0.0)

            def _check_fractions(
                label: str,
                near: float,
                exhaust: float,
                runner: float,
                target: Optional[Dict[str, Any]] = None,
            ) -> float:
                tol = 1e-9
                for key, value in (
                    ("scale_out_near_frac", near),
                    ("scale_out_exhaust_frac", exhaust),
                    ("runner_min_frac", runner),
                ):
                    if value < -tol or value > 1.0 + tol:
                        logger.warning(
                            "%s 的 %s=%.3f 超出 [0,1]，请检查分段减仓配置。",
                            label,
                            key,
                            value,
                        )
                remainder = 1.0 - max(0.0, near) - max(0.0, exhaust)
                if remainder < -tol:
                    logger.warning(
                        "%s 的 scale_out_near_frac + scale_out_exhaust_frac=%.3f 超出 1.0，减仓系数冲突。",
                        label,
                        near + exhaust,
                    )
                elif runner > remainder + tol:
                    capped_runner = max(remainder, 0.0)
                    logger.warning(
                        "%s 的 runner_min_frac=%.3f 高于剩余 %.3f，可能导致部分减仓报单被拒绝。",
                        label,
                        runner,
                        max(remainder, 0.0),
                    )
                    if target is not None:
                        target["runner_min_frac"] = capped_runner
                    runner = capped_runner

                return max(runner, 0.0)

            default_runner = _check_fractions(
                "默认参数", default_near, default_exhaust, default_runner, None
            )

            pair_cfgs: Dict[str, Dict[str, Any]] = {}
            try:
                for pair, cfg in (self.pair_overrides or {}).items():
                    if isinstance(cfg, dict):
                        pair_cfgs[pair] = dict(cfg)
            except Exception:
                pair_cfgs = {}
            try:
                config_pairs = ((self.config or {}).get("pair_overrides")) or {}
            except Exception:
                config_pairs = {}
            if isinstance(config_pairs, dict):
                for pair, override in config_pairs.items():
                    if not isinstance(override, dict):
                        continue
                    merged = pair_cfgs.setdefault(pair, {})
                    merged.update(override)
            for pair, cfg in pair_cfgs.items():
                if not isinstance(cfg, dict):
                    continue
                near = float(cfg.get("scale_out_near_frac", default_near) or 0.0)
                exhaust = float(cfg.get("scale_out_exhaust_frac", default_exhaust) or 0.0)
                runner = float(cfg.get("runner_min_frac", default_runner) or 0.0)
                runner = _check_fractions(pair, near, exhaust, runner, cfg)

            def _to_float(val: Any) -> Optional[float]:
                if val is None:
                    return None
                try:
                    return float(val)
                except (TypeError, ValueError):
                    return None

            def _check_exit_priority(label: str, cfg: Dict[str, Any]) -> None:
                tol = 1e-9
                min_profit = _to_float(cfg.get("min_profit_exit"))
                near_mult = _to_float(cfg.get("near_exit_mult"))
                near_alt = _to_float(cfg.get("near_exit_alt"))
                pb_gate = _to_float(cfg.get("pb_min_profit_gate"))
                if min_profit is not None and min_profit <= tol:
                    logger.warning(
                        "%s 的 min_profit_exit=%.4f <= 0，near-exit 与小回调释放将失去盈利优先级。",
                        label,
                        float(min_profit),
                    )
                if near_mult is not None:
                    if near_mult <= tol:
                        logger.warning(
                            "%s 的 near_exit_mult=%.4f <= 0，near-exit 判定会提前失效。",
                            label,
                            float(near_mult),
                        )
                    elif near_mult > 1.2 + tol:
                        logger.warning(
                            "%s 的 near_exit_mult=%.4f 远高于 1.0，near-exit 触发将明显滞后于 min_profit_exit。",
                            label,
                            float(near_mult),
                        )
                if near_alt is not None and near_alt <= tol:
                    logger.warning(
                        "%s 的 near_exit_alt=%.4f <= 0，将无法在小浮盈阶段提供兜底触发。",
                        label,
                        float(near_alt),
                    )
                if (
                    min_profit is not None
                    and min_profit > tol
                    and pb_gate is not None
                    and pb_gate >= min_profit - tol
                ):
                    logger.warning(
                        "%s 的 pb_min_profit_gate=%.4f 未低于 min_profit_exit=%.4f，小回调释放将与 near-exit 抢占同一优先级。",
                        label,
                        float(pb_gate),
                        float(min_profit),
                    )

            def _check_expectation_priority(label: str, cfg: Dict[str, Any]) -> None:
                tol = 1e-9
                enable = cfg.get("expectation_guard_enable", getattr(self, "EXPECTATION_GUARD_ENABLE", False))
                if not bool(enable):
                    return
                has_target = "expectation_target_r" in cfg
                has_release = "expectation_release_r" in cfg
                has_floor = "expectation_release_floor_r" in cfg
                has_floor_max = "expectation_floor_max_r" in cfg
                has_floor_escalate = "expectation_floor_escalate_at_r" in cfg
                has_floor_pad = "expectation_floor_escalate_pad_r" in cfg
                has_time_minutes = "expectation_time_escalate_minutes" in cfg
                has_time_target = "expectation_time_escalate_target_r" in cfg
                has_time_min = "expectation_time_escalate_min_r" in cfg
                has_time_pad = "expectation_time_escalate_pad_r" in cfg
                has_drawdown = "expectation_drawdown_r" in cfg
                has_relax = "expectation_relax_minutes" in cfg

                target_r = _to_float(cfg.get("expectation_target_r"))
                if target_r is None and not has_target:
                    target_r = _to_float(getattr(self, "EXPECTATION_TARGET_R", None))

                release_r = _to_float(cfg.get("expectation_release_r"))
                if release_r is None and not has_release:
                    release_r = _to_float(getattr(self, "EXPECTATION_RELEASE_R", None))

                floor_r = _to_float(cfg.get("expectation_release_floor_r"))
                if floor_r is None and not has_floor:
                    floor_r = _to_float(getattr(self, "EXPECTATION_RELEASE_FLOOR_R", None))

                floor_max_r = _to_float(cfg.get("expectation_floor_max_r"))
                if floor_max_r is None and not has_floor_max:
                    floor_max_r = _to_float(getattr(self, "EXPECTATION_FLOOR_MAX_R", None))

                floor_escalate_at_r = _to_float(cfg.get("expectation_floor_escalate_at_r"))
                if floor_escalate_at_r is None and not has_floor_escalate:
                    floor_escalate_at_r = _to_float(getattr(self, "EXPECTATION_FLOOR_ESCALATE_AT_R", None))

                floor_escalate_pad_r = _to_float(cfg.get("expectation_floor_escalate_pad_r"))
                if floor_escalate_pad_r is None and not has_floor_pad:
                    floor_escalate_pad_r = _to_float(getattr(self, "EXPECTATION_FLOOR_ESCALATE_PAD_R", None))

                time_escalate_minutes = _to_float(cfg.get("expectation_time_escalate_minutes"))
                if time_escalate_minutes is None and not has_time_minutes:
                    time_escalate_minutes = _to_float(getattr(self, "EXPECTATION_TIME_ESCALATE_MINUTES", None))

                time_escalate_target_r = _to_float(cfg.get("expectation_time_escalate_target_r"))
                if time_escalate_target_r is None and not has_time_target:
                    time_escalate_target_r = _to_float(getattr(self, "EXPECTATION_TIME_ESCALATE_TARGET_R", None))

                time_escalate_min_r = _to_float(cfg.get("expectation_time_escalate_min_r"))
                if time_escalate_min_r is None and not has_time_min:
                    time_escalate_min_r = _to_float(getattr(self, "EXPECTATION_TIME_ESCALATE_MIN_R", None))

                time_escalate_pad_r = _to_float(cfg.get("expectation_time_escalate_pad_r"))
                if time_escalate_pad_r is None and not has_time_pad:
                    time_escalate_pad_r = _to_float(getattr(self, "EXPECTATION_TIME_ESCALATE_PAD_R", None))

                drawdown_r = _to_float(cfg.get("expectation_drawdown_r"))
                if drawdown_r is None and not has_drawdown:
                    drawdown_r = _to_float(getattr(self, "EXPECTATION_DRAWDOWN_R", None))

                relax_minutes = _to_float(cfg.get("expectation_relax_minutes"))
                if relax_minutes is None and not has_relax:
                    relax_minutes = _to_float(getattr(self, "EXPECTATION_RELAX_MINUTES", None))

                if target_r is None or target_r <= tol:
                    logger.warning(
                        "%s 启用了 expectation_guard 但 expectation_target_r=%.3f 无效，将导致守卫优先级缺失。",
                        label,
                        float(target_r or 0.0),
                    )
                    target_r = None
                if release_r is not None and release_r <= tol:
                    logger.warning(
                        "%s 的 expectation_release_r=%.3f <= 0，守卫将无法在达到目标前提供回撤豁免。",
                        label,
                        float(release_r or 0.0),
                    )
                if drawdown_r is not None and drawdown_r < -tol:
                    logger.warning(
                        "%s 的 expectation_drawdown_r=%.3f 为负值，将被忽略。",
                        label,
                        float(drawdown_r),
                    )
                    if floor_r is not None:
                        if floor_r <= tol:
                            logger.warning(
                                "%s 的 expectation_release_floor_r=%.3f ≤ 0，将无法为旧版 0.5R≈0.338R 的早退提供保障。",
                                label,
                                float(floor_r or 0.0),
                            )
                            floor_r = None
                        elif release_r is not None and release_r > tol and floor_r - release_r > tol:
                            logger.warning(
                                "%s 的 expectation_release_floor_r=%.3f 高于 release_r=%.3f，将被自动压回 release_r。",
                                label,
                                float(floor_r),
                                float(release_r),
                            )
                            if isinstance(cfg, dict):
                                floor_r = release_r
                                cfg["expectation_release_floor_r"] = floor_r
                        if floor_max_r is not None and floor_max_r > tol and floor_r - floor_max_r > tol:
                            logger.warning(
                                "%s 的 expectation_release_floor_r=%.3f 已超过 floor_max_r=%.3f，将以 floor_max_r 为准。",
                                label,
                            float(floor_r),
                            float(floor_max_r),
                        )
                if (
                    drawdown_r is not None
                    and drawdown_r > tol
                    and release_r is not None
                ):
                    if release_r <= tol:
                        logger.warning(
                            "%s 的 expectation_drawdown_r=%.3f > 0 但 release_r=%.3f，守卫缺乏有效回撤窗口。",
                            label,
                            float(drawdown_r),
                            float(release_r or 0.0),
                        )
                    else:
                        anchor_desc = "release"
                        if target_r is not None and target_r > tol and release_r >= target_r - tol:
                            max_draw = max(release_r - target_r, 0.0)
                            anchor_desc = "release-target"
                        else:
                            max_draw = release_r
                        if max_draw <= tol:
                            logger.warning(
                                "%s 的 expectation_drawdown_r=%.3f 但 %s 留白≈%.3fR，将导致守卫触发条件退化。",
                                label,
                                float(drawdown_r),
                                anchor_desc,
                                float(max_draw),
                            )
                        elif drawdown_r - max_draw > tol:
                            logger.warning(
                                "%s 的 expectation_drawdown_r=%.3f 超出 %s=%.3f，将被自动削减。",
                                label,
                                float(drawdown_r),
                                anchor_desc,
                                float(max_draw),
                            )
                            if isinstance(cfg, dict):
                                drawdown_r = max_draw
                                cfg["expectation_drawdown_r"] = drawdown_r
                        if (
                            floor_r is not None
                            and release_r is not None
                            and release_r > tol
                            and drawdown_r is not None
                        ):
                            effective_floor = release_r - max(drawdown_r, 0.0)
                            if effective_floor + tol < floor_r:
                                logger.warning(
                                    "%s 的 expectation_drawdown_r=%.3f 会让释放后仅剩 %.3fR < floor 底线 %.3fR，请同步调低 drawdown。",
                                    label,
                                    float(drawdown_r),
                                    float(effective_floor),
                                    float(floor_r),
                                )
                                suggested_drawdown = max(release_r - floor_r, 0.0)
                                if isinstance(cfg, dict) and suggested_drawdown < drawdown_r - tol:
                                    cfg["expectation_drawdown_r"] = suggested_drawdown
                                    drawdown_r = suggested_drawdown
                if floor_max_r is not None and floor_max_r <= tol:
                    logger.warning(
                        "%s 的 expectation_floor_max_r=%.3f ≤ 0，将无法在浮盈 ≥1R 时抬高锁盈地板。",
                        label,
                        float(floor_max_r or 0.0),
                    )
                if floor_escalate_at_r is not None and floor_escalate_at_r < 0:
                    logger.warning(
                        "%s 的 expectation_floor_escalate_at_r=%.3f < 0，将退化为默认阈值。",
                        label,
                        float(floor_escalate_at_r or 0.0),
                    )
                if (
                    floor_escalate_at_r is not None
                    and floor_r is not None
                    and floor_escalate_at_r + tol < floor_r
                ):
                    logger.warning(
                        "%s 的 floor_escalate_at_r=%.3f 低于 floor_r=%.3f，守卫将立即尝试抬升至 1R。",
                        label,
                        float(floor_escalate_at_r),
                        float(floor_r),
                    )
                if floor_escalate_pad_r is not None and floor_escalate_pad_r < -tol:
                    logger.warning(
                        "%s 的 expectation_floor_escalate_pad_r=%.3f < 0，将被截断为 0。",
                        label,
                        float(floor_escalate_pad_r),
                    )
                if time_escalate_minutes is not None and time_escalate_minutes < -tol:
                    logger.warning(
                        "%s 的 expectation_time_escalate_minutes=%.3f 为负值，将不会触发时间锁盈。",
                        label,
                        float(time_escalate_minutes),
                    )
                if time_escalate_target_r is not None and time_escalate_target_r <= tol:
                    logger.warning(
                        "%s 的 expectation_time_escalate_target_r=%.3f ≤ 0，时间锁盈将无法抬升地板。",
                        label,
                        float(time_escalate_target_r or 0.0),
                    )
                if time_escalate_min_r is not None and time_escalate_min_r < -tol:
                    logger.warning(
                        "%s 的 expectation_time_escalate_min_r=%.3f < 0，将按 0 处理。",
                        label,
                        float(time_escalate_min_r),
                    )
                if (
                    time_escalate_target_r is not None
                    and floor_max_r is not None
                    and floor_max_r > tol
                    and time_escalate_target_r - floor_max_r > tol
                ):
                    logger.warning(
                        "%s 的 time_escalate_target_r=%.3f 超过 floor_max_r=%.3f，将被压回上限。",
                        label,
                        float(time_escalate_target_r),
                        float(floor_max_r),
                    )
                if relax_minutes is not None and relax_minutes < -tol:
                    logger.warning(
                        "%s 的 expectation_relax_minutes=%.3f 为负值，已失去定时降级的优先级含义。",
                        label,
                        float(relax_minutes),
                    )

            _check_expectation_priority(
                "默认参数",
                {
                    "expectation_guard_enable": getattr(self, "EXPECTATION_GUARD_ENABLE", False),
                    "expectation_target_r": getattr(self, "EXPECTATION_TARGET_R", 0.0),
                    "expectation_release_r": getattr(self, "EXPECTATION_RELEASE_R", 0.0),
                    "expectation_release_floor_r": getattr(self, "EXPECTATION_RELEASE_FLOOR_R", 0.0),
                    "expectation_floor_max_r": getattr(self, "EXPECTATION_FLOOR_MAX_R", 0.0),
                    "expectation_floor_escalate_at_r": getattr(self, "EXPECTATION_FLOOR_ESCALATE_AT_R", 0.0),
                    "expectation_floor_escalate_pad_r": getattr(self, "EXPECTATION_FLOOR_ESCALATE_PAD_R", 0.0),
                    "expectation_time_escalate_minutes": getattr(self, "EXPECTATION_TIME_ESCALATE_MINUTES", 0.0),
                    "expectation_time_escalate_target_r": getattr(self, "EXPECTATION_TIME_ESCALATE_TARGET_R", 0.0),
                    "expectation_time_escalate_min_r": getattr(self, "EXPECTATION_TIME_ESCALATE_MIN_R", 0.0),
                    "expectation_time_escalate_pad_r": getattr(self, "EXPECTATION_TIME_ESCALATE_PAD_R", 0.0),
                    "expectation_drawdown_r": getattr(self, "EXPECTATION_DRAWDOWN_R", 0.0),
                    "expectation_relax_minutes": getattr(self, "EXPECTATION_RELAX_MINUTES", 0.0),
                },
            )

            for pair, cfg in pair_cfgs.items():
                if not isinstance(cfg, dict):
                    continue
                _check_exit_priority(pair, cfg)
                _check_expectation_priority(pair, cfg)
        except Exception:
            logger.warning("参数体检过程中出现异常，建议复查策略配置。")
        try:
            for ev in self._macro_event_schedule():
                if not isinstance(ev, dict):
                    continue
                if not ev.get("start"):
                    logger.warning("宏观事件 %s 缺少 start 字段，事件守护将被忽略。", ev)
                elif self._parse_event_time(ev.get("start")) is None:
                    logger.warning("宏观事件 %s 的 start 无法解析为时间，请使用 ISO 字符串或时间戳。", ev)
                if ev.get("end") and self._parse_event_time(ev.get("end")) is None:
                    logger.warning("宏观事件 %s 的 end 无法解析为时间，将 fallback 到 duration/默认 60 分钟。", ev)
        except Exception:
            logger.warning("宏观事件配置解析失败，已忽略事件守护。")

    def _build_exchange_profile(self) -> Dict[str, Any]:
        """教学提示：合并默认/交易所/配置覆写的信号校准参数。"""
        profile: Dict[str, Any] = {}
        try:
            raw = getattr(self, "EXCHANGE_SIGNAL_PROFILE", {}) or {}
            default = raw.get("default", {}) if isinstance(raw, dict) else {}
            if isinstance(default, dict):
                profile.update(default)
            name = self.exchange_name
            if name and isinstance(raw, dict):
                custom = raw.get(name, {})
                if isinstance(custom, dict):
                    profile.update(custom)
        except Exception:
            profile = {}

        try:
            sp = ((self.config or {}).get("strategy_parameters")) or {}
            override = sp.get("exchange_profile_override", None)
            if isinstance(override, dict):
                profile.update(override)
        except Exception:
            pass

        return profile

    def _profile_val(self, key: str, default: Any = None) -> Any:
        """教学提示：统一读取交易所校准参数，未设置时返回默认值。"""
        prof = getattr(self, "_exchange_profile", {}) or {}
        return prof.get(key, default)

    def _resolve_notional_profile(
        self, pair: Optional[str] = None
    ) -> Tuple[Dict[str, Any], Optional[float], Optional[float]]:
        """教学提示：合并名义资金默认值与余额分层覆写，返回有效配置与余额浮点值。"""
        profile_raw = getattr(self, "_notional_profile", {}) or {}
        if not isinstance(profile_raw, dict):
            return {}, None, None

        profile = dict(profile_raw)
        if pair:
            pair_overrides = getattr(self, "_notional_pair_overrides", {}) or {}
            override = pair_overrides.get(pair)
            if isinstance(override, dict):
                profile.update(override)
        wallets = getattr(self, "wallets", None)
        stake_currency = getattr(self, "stake_currency", "USDT")

        free_amt: Any = None
        total_amt: Any = None
        if wallets is not None:
            try:
                free_amt = wallets.get_free(stake_currency)
            except Exception:
                free_amt = None
            try:
                total_amt = wallets.get_total(stake_currency)
            except Exception:
                total_amt = None

        def _to_float(value: Any) -> Optional[float]:
            try:
                if value is None:
                    return None
                res = float(value)
                if not np.isfinite(res):
                    return None
                return res
            except (TypeError, ValueError):
                return None

        free_float = _to_float(free_amt)
        total_float = _to_float(total_amt)

        tiers = profile.get("balance_tiers", None)
        tier_source = total_float if total_float is not None else free_float
        profile["_balance_source"] = tier_source
        applied_tier_label: Optional[str] = None
        applied_tier_bound: Optional[float] = None
        if isinstance(tiers, (list, tuple)) and tier_source is not None:
            for tier in tiers:
                if not isinstance(tier, dict):
                    continue
                max_total = _to_float(tier.get("max_total", None))
                if max_total is None:
                    continue
                if tier_source <= max_total + 1e-9:
                    for key, value in tier.items():
                        if key in {"max_total", "label"}:
                            continue
                        profile[key] = value
                    applied_tier_label = str(tier.get("label") or f"<= {max_total}")
                    applied_tier_bound = max_total
                    break

        if applied_tier_label:
            profile["_balance_tier_label"] = applied_tier_label
        if applied_tier_bound is not None:
            profile["_balance_tier_max_total"] = applied_tier_bound

        return profile, free_float, total_float

    def _usable_balance_amount(self, profile: Mapping[str, Any], amount: Optional[float]) -> float:
        """根据预留参数计算可用余额，供名义上限与加仓上限共用。"""
        try:
            val = float(amount) if amount is not None else 0.0
        except (TypeError, ValueError):
            val = 0.0
        reserve_ratio = min(max(float(profile.get("reserve_ratio", 0.0) or 0.0), 0.0), 0.95)
        reserve_static = max(0.0, float(profile.get("reserve_static", 0.0) or 0.0))
        usable = val - (val * reserve_ratio + reserve_static)
        return max(0.0, usable)

    def _account_notional_cap(self, pair: str) -> float:
        """教学提示：根据账户余额、手续费预留与分层占比动态计算名义资金上限。"""
        base_cap = float(self._pair_cfg(pair).get("max_notional_usdt", self.NOTIONAL_CAP_USDT))
        profile, free_float, total_float = self._resolve_notional_profile(pair)
        if not profile or not bool(profile.get("enable", True)):
            return base_cap

        def _usable_amount(amount: Optional[float]) -> float:
            return self._usable_balance_amount(profile, amount)

        leverage = max(1.0, float(profile.get("leverage", self.DEFAULT_LEVERAGE) or self.DEFAULT_LEVERAGE))
        leverage_cap = getattr(self, "MAX_LEVERAGE_CAP", 0.0)
        if leverage_cap and np.isfinite(leverage_cap) and leverage_cap > 0:
            leverage = min(leverage, leverage_cap)
        buffer = float(profile.get("buffer", 1.0) or 1.0)
        buffer = min(max(buffer, 0.0), 1.0)
        total_ratio = float(profile.get("total_ratio", 0.0) or 0.0)
        free_ratio = float(profile.get("free_ratio", 0.0) or 0.0)
        reserve_ratio = min(max(float(profile.get("reserve_ratio", 0.0) or 0.0), 0.0), 0.95)
        reserve_static = max(0.0, float(profile.get("reserve_static", 0.0) or 0.0))
        min_cap_base = float(profile.get("min_cap", 0.0) or 0.0)
        min_cap_ratio = float(profile.get("min_cap_ratio", 0.0) or 0.0)
        max_cap = float(profile.get("max_cap", 0.0) or 0.0)

        def _usable_amount(amount: Optional[float]) -> float:
            if amount is None or amount <= 0:
                return 0.0
            reserve = amount * reserve_ratio + reserve_static
            return max(0.0, amount - reserve)

        usable_free = _usable_amount(free_float)
        usable_total = _usable_amount(total_float)

        cap_candidates: List[Tuple[str, float]] = []
        if np.isfinite(base_cap) and base_cap > 0:
            cap_candidates.append(("pair_base", base_cap))

        free_cap_full: Optional[float] = None
        total_cap_full: Optional[float] = None

        if leverage > 0:
            if usable_free > 0:
                free_cap_full = usable_free * leverage * buffer
                if free_cap_full > 0:
                    cap_candidates.append(("free_full", free_cap_full))
                if free_ratio > 0 and free_float is not None:
                    ratio_cap = min(usable_free, max(0.0, free_float * free_ratio)) * leverage * buffer
                    if ratio_cap > 0:
                        cap_candidates.append(("free_ratio", ratio_cap))
                elif free_cap_full > 0:
                    cap_candidates.append(("free_buffer", free_cap_full))

            if usable_total > 0 and total_ratio > 0 and total_float is not None:
                ratio_amt = max(0.0, total_float * total_ratio)
                total_cap_full = min(usable_total, ratio_amt) * leverage * buffer
                if total_cap_full > 0:
                    cap_candidates.append(("total_ratio", total_cap_full))

        # [CODEX-NEW] 名义上限分层：平衡档与 per-pair ceiling 支持高杠杆小余额的更严上限。
        pair_caps = profile.get("pair_notional_caps") if isinstance(profile, dict) else None
        if isinstance(pair_caps, dict):
            specific_cap = self._safe_float(pair_caps.get(pair))
            default_cap = self._safe_float(pair_caps.get("default"))
            if specific_cap and specific_cap > 0:
                cap_candidates.append(("pair_cap", float(specific_cap)))
            elif default_cap and default_cap > 0:
                cap_candidates.append(("pair_cap_default", float(default_cap)))

        pair_tier_caps = profile.get("pair_balance_caps") if isinstance(profile, dict) else None
        tier_source = profile.get("_balance_source") if isinstance(profile, dict) else None
        balance_tier_label = str(profile.get("_balance_tier_label", "")) if isinstance(profile, dict) else ""
        balance_tier_bound = self._safe_float(profile.get("_balance_tier_max_total", None))
        if isinstance(pair_tier_caps, (list, tuple)) and tier_source is not None:
            for tier_cfg in pair_tier_caps:
                if not isinstance(tier_cfg, dict):
                    continue
                max_total = self._safe_float(tier_cfg.get("max_total"))
                if max_total is None:
                    continue
                if tier_source <= max_total + 1e-9:
                    label = str(tier_cfg.get("label") or f"<= {max_total}")
                    caps_cfg = tier_cfg.get("caps") if isinstance(tier_cfg.get("caps"), dict) else {}
                    specific = self._safe_float(caps_cfg.get(pair)) if isinstance(caps_cfg, dict) else None
                    default = self._safe_float(caps_cfg.get("default")) if isinstance(caps_cfg, dict) else None
                    cap_val = specific if specific and specific > 0 else (default if default and default > 0 else None)
                    if cap_val:
                        cap_candidates.append((f"pair_tier_{label}", float(cap_val)))
                        balance_tier_label = label or balance_tier_label
                        balance_tier_bound = max_total
                    break

        slip_guard = self._slippage_guard_snapshot(pair)
        if slip_guard.get("active"):
            cap_share = self._safe_float(slip_guard.get("cap_share"))
            if cap_share is not None and cap_share > 0:
                cap_candidates.append(("slippage_cap", float(base_cap * cap_share)))

        cap_source = "pair_base"
        cap = base_cap
        try:
            valid_caps = [(src, c) for src, c in cap_candidates if np.isfinite(c) and c > 0]
            if valid_caps:
                chosen = min(valid_caps, key=lambda item: item[1])
                cap = chosen[1]
                cap_source = chosen[0]
        except Exception:
            cap = base_cap
            cap_source = "pair_base"

        dynamic_min = max(0.0, min_cap_base)
        ratio_source = usable_total if usable_total > 0 else usable_free
        if (ratio_source is None or ratio_source <= 0) and total_float is not None and total_float > 0:
            ratio_source = total_float
        if min_cap_ratio > 0 and ratio_source is not None and ratio_source > 0 and leverage > 0:
            dynamic_min = max(dynamic_min, ratio_source * leverage * buffer * min_cap_ratio)
        if free_cap_full is not None and free_cap_full > 0:
            dynamic_min = min(dynamic_min, free_cap_full)

        if dynamic_min > 0:
            cap = max(cap, dynamic_min)
        if max_cap > 0:
            cap = min(cap, max_cap)

        trace = {
            "pair": pair,
            "balance_tier": balance_tier_label or None,
            "balance_tier_max_total": balance_tier_bound,
            "balance_source": tier_source,
            "cap_candidates": [{"source": src, "cap": float(val)} for src, val in cap_candidates if np.isfinite(val) and val > 0],
            "chosen_source": cap_source,
            "cap_after_min_max": cap,
            "dynamic_min": dynamic_min,
            "max_cap": max_cap if max_cap > 0 else None,
            "free_balance": free_float,
            "total_balance": total_float,
            "leverage": leverage,
        }
        if slip_guard.get("active"):
            trace["slippage_guard"] = {
                "severity": slip_guard.get("severity"),
                "mean_abs": slip_guard.get("stats", {}).get("mean_abs"),
                "max_abs": slip_guard.get("stats", {}).get("max_abs"),
                "cap_share": slip_guard.get("cap_share"),
            }

        try:
            st = getattr(self, "_pair_state", {})
            if not isinstance(st, dict):
                st = {}
                self._pair_state = st
            entry = st.setdefault(pair, {})
            prev_trace = entry.get("notional_cap_trace")
            entry["notional_cap_trace"] = trace
            if prev_trace != trace:
                summary = ", ".join(f"{c['source']}={c['cap']:.2f}" for c in trace["cap_candidates"])
                logger.info(
                    "[名义上限] %s cap=%.2f 源=%s 动态下限=%.2f 上限=%s | 候选=%s",
                    pair,
                    cap,
                    cap_source,
                    dynamic_min,
                    max_cap if max_cap > 0 else "∞",
                    summary or "none",
                )
        except Exception:
            pass

        return cap

    def _normalize_iceberg_legs(self, legs: Any) -> Tuple[float, ...]:
        """教学提示：把自定义分批占比规范化为正比例并归一化。"""
        if legs is None:
            return tuple()
        if isinstance(legs, dict):
            iterable = legs.values()
        else:
            iterable = legs

        normalized: List[float] = []
        for value in iterable:
            try:
                f_val = float(value)
            except (TypeError, ValueError):
                continue
            if not np.isfinite(f_val) or f_val <= 0:
                continue
            normalized.append(f_val)

        if not normalized:
            return tuple()

        total = float(np.sum(normalized))
        if not np.isfinite(total) or total <= 0:
            return tuple()

        return tuple(f_val / total for f_val in normalized)

    def _classify_iceberg_leg_structure(self, legs: Any) -> Dict[str, Any]:
        """教学提示：辨识分批占比是否呈现“首腿大、次腿缩”的 N 字结构。"""

        normalized = self._normalize_iceberg_legs(legs)
        if not normalized:
            return {}

        first = float(normalized[0]) if normalized else 0.0
        second = float(normalized[1]) if len(normalized) > 1 else 0.0
        tail = float(sum(normalized[2:])) if len(normalized) > 2 else 0.0

        try:
            ratio_12 = first / second if second > 0 else float("inf")
        except ZeroDivisionError:
            ratio_12 = float("inf")

        descending = all(normalized[idx] >= normalized[idx + 1] - 1e-9 for idx in range(len(normalized) - 1))
        frontload = first >= 0.35
        second_ok = second >= 0.10 if len(normalized) > 1 else True
        n_candidate = descending and frontload and second_ok and (ratio_12 >= 1.2 or len(normalized) == 1)

        structure = "n_shape" if n_candidate else ("frontload" if frontload else "balanced")
        dominance = first - second if len(normalized) > 1 else first

        info: Dict[str, Any] = {
            "structure": structure,
            "descending": bool(descending),
            "frontload": round(first, 6),
            "second": round(second, 6) if len(normalized) > 1 else 0.0,
            "tail": round(tail, 6),
            "dominance": round(dominance, 6),
            "n_candidate": bool(n_candidate),
        }

        if np.isfinite(ratio_12):
            info["ratio_12"] = round(float(ratio_12), 3)

        return info

    def _position_tier(self, pair: Optional[str] = None) -> Dict[str, Any]:
        """教学提示：依据账户余额/覆写选择当前应适用的仓位分层档位。"""
        schedule = tuple(getattr(self, "POSITION_TIER_SCHEDULE", ()))
        if not schedule:
            return {}

        def _match_label(label: Any) -> Optional[Dict[str, Any]]:
            if label is None:
                return None
            label_txt = str(label).strip().lower()
            if not label_txt:
                return None
            for entry in schedule:
                if not isinstance(entry, dict):
                    continue
                if str(entry.get("label", "")).strip().lower() == label_txt:
                    return entry
            return None

        overrides: List[Dict[str, Any]] = []
        label_override: Optional[str] = None

        try:
            sp = ((self.config or {}).get("strategy_parameters")) or {}
            sp_override = sp.get("position_tier_override")
            if isinstance(sp_override, dict):
                overrides.append(sp_override)
                if sp_override.get("label") is not None:
                    label_override = str(sp_override.get("label"))
        except Exception:
            sp_override = None

        pair_cfg: Dict[str, Any] = {}
        if pair is not None:
            try:
                pair_cfg = self._pair_cfg(pair)
            except Exception:
                pair_cfg = {}
            pair_label = pair_cfg.get("position_tier_label")
            if pair_label is not None:
                label_override = str(pair_label)
            cfg_override = pair_cfg.get("position_tier_override")
            if isinstance(cfg_override, dict):
                overrides.append(cfg_override)

        selected: Optional[Dict[str, Any]] = _match_label(label_override)

        profile, free_float, total_float = self._resolve_notional_profile(pair)
        _ = free_float  # 占位防未使用警告
        balance_source = None
        if isinstance(overrides, list):
            for src in overrides:
                if isinstance(src, dict) and src.get("balance_total") is not None:
                    try:
                        balance_source = float(src.get("balance_total"))
                    except (TypeError, ValueError):
                        balance_source = None
        if balance_source is None:
            balance_source = total_float

        if selected is None and balance_source is not None and np.isfinite(balance_source):
            for entry in schedule:
                if not isinstance(entry, dict):
                    continue
                max_total = entry.get("max_total")
                if max_total is None:
                    continue
                try:
                    max_total_val = float(max_total)
                except (TypeError, ValueError):
                    continue
                if not np.isfinite(max_total_val):
                    continue
                if balance_source <= max_total_val + 1e-9:
                    selected = entry
                    break

        if selected is None:
            for entry in reversed(schedule):
                if isinstance(entry, dict):
                    selected = entry
                    break

        final: Dict[str, Any] = dict(selected or {})
        final.setdefault("balance_total", balance_source)
        if selected is None and label_override is not None:
            final.setdefault("label", label_override)

        for override in overrides:
            if not isinstance(override, dict):
                continue
            for key, value in override.items():
                if key in {"label", "max_total", "balance_total"}:
                    continue
                final[key] = value

        if "label" not in final and selected is not None:
            final["label"] = selected.get("label")

        return final

    def _iceberg_config(self, pair: str) -> Dict[str, Any]:
        """教学提示：结合分层/覆写生成当前币种的分批参数。"""

        def _to_float(value: Any, default: float) -> float:
            try:
                f_val = float(value)
            except (TypeError, ValueError):
                return default
            if not np.isfinite(f_val):
                return default
            return f_val

        def _to_int(value: Any, default: int) -> int:
            try:
                i_val = int(value)
            except (TypeError, ValueError):
                return default
            return i_val

        tier = self._position_tier(pair)
        pair_cfg: Dict[str, Any] = {}
        try:
            pair_cfg = self._pair_cfg(pair)
        except Exception:
            pair_cfg = {}

        config: Dict[str, Any] = {
            "tier_label": tier.get("label") if isinstance(tier, dict) else None,
            "balance_total": tier.get("balance_total") if isinstance(tier, dict) else None,
        }

        legs_source = pair_cfg.get("iceberg_legs")
        if legs_source is None and isinstance(tier, dict):
            legs_source = tier.get("iceberg_legs")
        if legs_source is None:
            legs_source = getattr(self, "ICEBERG_LEGS", ())
        legs = self._normalize_iceberg_legs(legs_source)
        if not legs:
            legs = self._normalize_iceberg_legs(getattr(self, "ICEBERG_LEGS", ()))
        config["legs"] = legs

        base_max_adds = int(getattr(self, "max_entry_position_adjustment", 0) or 0)
        tier_max_adds = tier.get("max_entry_position_adjustment") if isinstance(tier, dict) else None
        cfg_max_adds = pair_cfg.get("max_entry_position_adjustment")
        max_adds = base_max_adds
        if tier_max_adds is not None:
            max_adds = _to_int(tier_max_adds, max_adds)
        if cfg_max_adds is not None:
            max_adds = _to_int(cfg_max_adds, max_adds)
        if legs:
            max_adds = max(0, min(max_adds, len(legs) - 1))
        else:
            max_adds = 0
        config["max_adds"] = max_adds

        base_min_pull = float(getattr(self, "ICEBERG_MIN_PULLBACK_ATR", 0.0) or 0.0)
        base_cooldown = int(getattr(self, "ICEBERG_COOLDOWN_BARS", 0) or 0)
        base_fast_cool = int(getattr(self, "ICEBERG_FASTLANE_COOLOFF", 0) or 0)
        base_slow_cool = int(getattr(self, "ICEBERG_SLOWLANE_COOLOFF", 0) or 0)

        config["min_pullback_atr"] = _to_float(
            pair_cfg.get("iceberg_min_pullback_atr",
                         tier.get("iceberg_min_pullback_atr") if isinstance(tier, dict) else None),
            base_min_pull,
        )
        config["cooldown_bars"] = max(
            0,
            _to_int(
                pair_cfg.get("iceberg_cooldown_bars",
                             tier.get("iceberg_cooldown_bars") if isinstance(tier, dict) else None),
                base_cooldown,
            ),
        )
        config["fastlane_cooloff"] = max(
            0,
            _to_int(
                pair_cfg.get("iceberg_fastlane_cooloff",
                             tier.get("iceberg_fastlane_cooloff") if isinstance(tier, dict) else None),
                base_fast_cool,
            ),
        )
        config["slowlane_cooloff"] = max(
            0,
            _to_int(
                pair_cfg.get("iceberg_slowlane_cooloff",
                             tier.get("iceberg_slowlane_cooloff") if isinstance(tier, dict) else None),
                base_slow_cool,
            ),
        )

        base_front_min = float(getattr(self, "ENTRY_FRONTLOAD_MIN", 0.0) or 0.0)
        base_front_max = float(getattr(self, "ENTRY_FRONTLOAD_MAX", 1.0) or 1.0)
        front_min_raw = pair_cfg.get("entry_frontload_min",
                                     tier.get("entry_frontload_min") if isinstance(tier, dict) else None)
        front_max_raw = pair_cfg.get("entry_frontload_max",
                                     tier.get("entry_frontload_max") if isinstance(tier, dict) else None)
        config["frontload_min"] = max(0.0, _to_float(front_min_raw, base_front_min))
        config["frontload_max"] = max(config["frontload_min"], _to_float(front_max_raw, base_front_max))
        hard_cap_raw = pair_cfg.get("entry_frontload_hard_cap",
                                    tier.get("entry_frontload_hard_cap") if isinstance(tier, dict) else None)
        config["frontload_hard_cap"] = max(0.0, _to_float(hard_cap_raw, 0.0))

        base_def_dd = float(getattr(self, "DEF_ADD_MIN_DD_ATR", 0.0) or 0.0)
        config["def_add_min_dd_atr"] = _to_float(
            pair_cfg.get("def_add_min_dd_atr",
                         tier.get("def_add_min_dd_atr") if isinstance(tier, dict) else None),
            base_def_dd,
        )
        base_def_frac = float(getattr(self, "DEF_ADD_LEG_FRAC", 0.0) or 0.0)
        config["def_add_leg_frac"] = _to_float(
            pair_cfg.get("def_add_leg_frac",
                         tier.get("def_add_leg_frac") if isinstance(tier, dict) else None),
            base_def_frac,
        )

        return config

    def _iceberg_legs(self, pair: str) -> Tuple[float, ...]:
        """教学提示：读取当前币种应使用的分批占比。"""
        cfg = self._iceberg_config(pair)
        legs = cfg.get("legs")
        return tuple(legs) if isinstance(legs, (list, tuple)) else tuple()

    def _entry_frontload_ratio(self, pair: str, side: str,
                               snapshot: Optional[Dict[str, Any]]) -> float:
        """教学提示：根据入场快慢车道/多周期强度，动态放大首单仓位占比。"""
        iceberg_cfg = self._iceberg_config(pair)
        legs = tuple(iceberg_cfg.get("legs", ()))
        base = float(legs[0]) if legs else 0.3
        front_min = float(iceberg_cfg.get("frontload_min", base) or base)
        front_max = float(iceberg_cfg.get("frontload_max", 1.0) or 1.0)
        front_min = max(0.0, front_min)
        front_max = max(front_min, front_max)
        ratio = max(base, front_min)

        if isinstance(snapshot, dict) and snapshot:
            align_val = float(snapshot.get("align", 0.0) or 0.0)
            fast_lane = bool(int(snapshot.get("fast_lane", 0) or 0))
            slow_lane = bool(int(snapshot.get("slow_lane", 0) or 0))
            narrow = bool(int(snapshot.get("channel_narrow", 0) or 0))
            drive = bool(int(snapshot.get("htf_drive", 0) or 0))
            vol_any = int(snapshot.get("vol_any", 0) or 0)
            priority_prefer = snapshot.get("priority_prefer")
            priority_conf = float(snapshot.get("priority_conf", 0.0) or 0.0)
            portfolio_fragile = bool(int(snapshot.get("portfolio_fragile", 0) or 0))
            panic_guard = int(snapshot.get("panic_guard", 0) or 0)
            blowoff_guard = int(snapshot.get("blowoff_guard", 0) or 0)
            darkside_active = int(snapshot.get("darkside_active", 0) or 0)
            darkside_pass = int(snapshot.get("darkside_pass", 0) or 0)

            align_thr = float(getattr(self, "ENTRY_FRONTLOAD_ALIGN_THRESHOLD", 0.0) or 0.0)
            align_scale = float(getattr(self, "ENTRY_FRONTLOAD_ALIGN_SCALE", 0.0) or 0.0)
            align_cap = float(getattr(self, "ENTRY_FRONTLOAD_ALIGN_CAP", 0.0) or 0.0)
            if align_thr > 0 and align_scale > 0 and align_cap > 0:
                align_pass = ((side == "long" and align_val >= align_thr) or
                              (side == "short" and align_val <= -align_thr))
                if align_pass:
                    align_bonus = max(0.0, abs(align_val) - align_thr) * align_scale
                    ratio += min(align_cap, align_bonus)

            if fast_lane and vol_any >= 1:
                ratio += float(getattr(self, "ENTRY_FRONTLOAD_FASTLANE_BONUS", 0.0) or 0.0)
            if slow_lane:
                ratio += float(getattr(self, "ENTRY_FRONTLOAD_SLOWLANE_BONUS", 0.0) or 0.0)
            if narrow:
                ratio += float(getattr(self, "ENTRY_FRONTLOAD_NARROW_BONUS", 0.0) or 0.0)
            if drive:
                ratio += float(getattr(self, "ENTRY_FRONTLOAD_DRIVE_BONUS", 0.0) or 0.0)

            if isinstance(priority_prefer, str) and priority_prefer.lower() == str(side).lower():
                bonus = float(getattr(self, "ENTRY_FRONTLOAD_PRIORITY_BONUS", 0.0) or 0.0)
                scale = float(getattr(self, "ENTRY_FRONTLOAD_PRIORITY_SCALE", 0.0) or 0.0)
                if bonus > 0 and scale > 0:
                    ratio += bonus * min(1.0, max(0.0, priority_conf) / scale)

            if portfolio_fragile:
                ratio -= float(getattr(self, "ENTRY_FRONTLOAD_FRAGILE_PENALTY", 0.0) or 0.0)

            extreme_penalty = float(getattr(self, "ENTRY_FRONTLOAD_EXTREME_PENALTY", 1.0) or 1.0)
            if 0.0 < extreme_penalty < 1.0:
                if (side == "long" and blowoff_guard >= 1) or (side == "short" and panic_guard >= 1):
                    ratio *= extreme_penalty

            if darkside_pass >= 1:
                pass_penalty = float(getattr(self, "ENTRY_FRONTLOAD_DARKSIDE_PASS_PENALTY", 1.0) or 1.0)
                if 0.0 < pass_penalty < 1.0:
                    ratio *= pass_penalty
            elif darkside_active >= 1:
                active_penalty = float(getattr(self, "ENTRY_FRONTLOAD_DARKSIDE_ACTIVE_PENALTY", 1.0) or 1.0)
                if 0.0 < active_penalty < 1.0:
                    ratio *= active_penalty

            style_frontload = float(snapshot.get("style_frontload_mult", 1.0) or 1.0)
            if style_frontload != 1.0 and style_frontload > 0:
                ratio *= style_frontload

        ratio = max(front_min, ratio)
        ratio = min(front_max, ratio)

        hard_cap = float(iceberg_cfg.get("frontload_hard_cap", 0.0) or 0.0)
        if hard_cap <= 0.0 and legs:
            hard_cap = float(np.sum(legs[:2])) if len(legs) >= 2 else float(legs[0])
        if hard_cap > 0.0:
            ratio = min(ratio, hard_cap)

        ratio = max(0.0, min(1.0, ratio))
        return float(ratio)

    # -------------------- 热榜白名单 --------------------
    def _current_whitelist(self) -> List[str]:
        """教学提示：读取 freqtrade 当前白名单，供热榜功能过滤候选。"""
        pairs: List[str] = []
        dp = getattr(self, "dp", None)
        if dp is not None:
            try:
                wl_func = getattr(dp, "current_whitelist", None)
                if callable(wl_func):
                    res = wl_func()
                    if isinstance(res, (list, tuple, set)):
                        pairs = list(res)
            except Exception:
                pairs = []
            if not pairs:
                try:
                    pairlists = getattr(dp, "pairlists", None)
                    wl = getattr(pairlists, "whitelist", None) if pairlists else None
                    if isinstance(wl, (list, tuple, set)):
                        pairs = list(wl)
                except Exception:
                    pairs = []
        if not pairs:
            try:
                exch = (self.config or {}).get("exchange", {}) if isinstance(self.config, dict) else {}
                wl_cfg = exch.get("pair_whitelist", [])
                if isinstance(wl_cfg, (list, tuple, set)):
                    pairs = list(wl_cfg)
            except Exception:
                pairs = []
        if not pairs:
            preset = getattr(self, "PAIR_POOL_PRESET", tuple())
            if preset:
                pairs = list(preset)
        if not pairs:
            return []
        seen: Dict[str, bool] = {}
        ordered: List[str] = []
        for item in pairs:
            if not isinstance(item, str):
                continue
            if item in seen:
                continue
            seen[item] = True
            ordered.append(item)
        if not ordered:
            preset = getattr(self, "PAIR_POOL_PRESET", tuple())
            for item in preset:
                if not isinstance(item, str):
                    continue
                if item in seen:
                    continue
                seen[item] = True
                ordered.append(item)
        return ordered

    def _dynamic_pairlist_profile(self, now: Optional[datetime] = None) -> Dict[str, Any]:
        """教学提示：根据 24h 涨幅与成交额自动挑选交易所热度榜，供机器人切换标的。"""
        forced_off = bool(getattr(self, "DYNAMIC_PAIRLIST_FORCE_DISABLE", False))
        enabled = bool(getattr(self, "DYNAMIC_PAIRLIST_ENABLE", False)) and not forced_off
        now_dt = self._utc_now(now)
        if forced_off:
            profile = {
                "active": False,
                "pairs": [],
                "ts": now_dt,
                "fallback": "allow",
                "fallback_source": "force_disable",
                "source": "disabled",
            }
            self._dynamic_pairlist_cache = profile
            return profile
        if not enabled:
            profile = {
                "active": False,
                "pairs": [],
                "ts": now_dt,
                "fallback": "allow",
                "fallback_source": "manual_disable" if forced_off else None,
            }
            self._dynamic_pairlist_cache = profile
            return profile

        refresh = max(5, int(getattr(self, "DYNAMIC_PAIRLIST_REFRESH_MINUTES", 30) or 30))
        cached = getattr(self, "_dynamic_pairlist_cache", {}) or {}
        cached_ts = self._to_utc_datetime(cached.get("ts")) if cached else None
        if cached and cached_ts is not None:
            age = (now_dt - cached_ts).total_seconds() / 60.0
            if age < refresh and cached.get("active"):
                return cached

        exchange = getattr(self, "exchange", None) or getattr(getattr(self, "dp", None), "exchange", None)
        result: Dict[str, Any] = {"active": True, "pairs": [], "ts": now_dt, "source": getattr(self, "DYNAMIC_PAIRLIST_SOURCE", "gainers")}
        if exchange is None:
            result["error"] = "no_exchange"
            self._dynamic_pairlist_cache = result
            return result

        try:
            tickers = exchange.fetch_tickers()  # type: ignore[attr-defined]
        except Exception as exc:
            level = getattr(logging, str(getattr(self, "DYNAMIC_PAIRLIST_LOG_LEVEL", "info")).upper(), logging.INFO)
            logger.log(level, "[动态热榜] 获取 ticker 失败：%s", exc)
            result.update({
                "active": False,
                "pairs": [],
                "fallback": "allow",
                "fallback_source": "fetch_error",
                "error": str(exc),
            })
            self._dynamic_pairlist_cache = result
            return result

        respect = bool(getattr(self, "DYNAMIC_PAIRLIST_RESPECT_WHITELIST", True))
        whitelist_ordered: List[str] = self._current_whitelist() if respect else []
        whitelist = set(whitelist_ordered) if respect else set()
        min_change = float(getattr(self, "DYNAMIC_PAIRLIST_MIN_CHANGE", 0.0) or 0.0)
        min_quote = float(getattr(self, "DYNAMIC_PAIRLIST_MIN_QUOTE", 0.0) or 0.0)
        limit = max(1, int(getattr(self, "DYNAMIC_PAIRLIST_LIMIT", 6) or 6))

        records: List[Tuple[float, str]] = []
        metrics: Dict[str, Dict[str, Any]] = {}

        def _score_entry(name: str, info: Dict[str, Any]) -> Optional[Tuple[float, Dict[str, float]]]:
            if respect and whitelist and name not in whitelist:
                return None
            symbol = str(name or "")
            if not symbol:
                return None
            if symbol.endswith(":USDT") or symbol.endswith("/USDT"):
                pass
            else:
                return None
            raw: Dict[str, Any] = (info or {})
            change = self._safe_float(raw.get("percentage"))
            if change is None:
                # Gate/OKX/Binance 等常见交易所会把涨幅写在 info["chg"] 或 "change" 字段
                change = self._safe_float((raw.get("info", {}) or {}).get("chg"))
            if change is None:
                change = self._safe_float(raw.get("change"))
            if change is None:
                # 当 ticker 仅给出 last/open 时，手动换算 24h 百分比涨幅
                last_price = self._safe_float(raw.get("last"))
                open_price = self._safe_float(raw.get("open"))
                if last_price is not None and open_price is not None and open_price != 0:
                    change = (last_price - open_price) / abs(open_price) * 100.0
            if change is None:
                return None
            quote_vol = self._safe_float(raw.get("quoteVolume"))
            if quote_vol is None:
                info_block = (raw.get("info", {}) or {})
                for key in ("volCcy24h", "quoteVol", "usdVol", "quoteVolume24h"):
                    quote_vol = self._safe_float(info_block.get(key))
                    if quote_vol is not None:
                        break
            if quote_vol is None:
                base_vol = self._safe_float(raw.get("baseVolume"))
                if base_vol is None:
                    base_vol = self._safe_float((raw.get("info", {}) or {}).get("vol"))
                if base_vol is not None:
                    price_for_est = self._safe_float(raw.get("last"))
                    if price_for_est is None:
                        price_for_est = self._safe_float((raw.get("info", {}) or {}).get("last"))
                    if price_for_est is not None:
                        quote_vol = base_vol * price_for_est
            if quote_vol is None:
                return None
            if quote_vol <= 0:
                return None
            if abs(change) < min_change:
                return None
            if quote_vol < min_quote:
                return None
            score = abs(change) * math.log1p(max(0.0, quote_vol))
            details = {
                "change": float(change),
                "quote_volume": float(quote_vol),
                "change_source": "percentage" if raw.get("percentage") is not None else "fallback",
            }
            return score, details

        for name, info in (tickers or {}).items():
            if not isinstance(name, str):
                continue
            if not isinstance(info, dict):
                continue
            scored = _score_entry(name, info)
            if scored is None:
                continue
            score, detail = scored
            metrics[name] = detail
            records.append((score, name))

        records.sort(key=lambda x: x[0], reverse=True)
        selected = [name for _, name in records[:limit]]

        fallback_mode = str(getattr(self, "DYNAMIC_PAIRLIST_FALLBACK", "allow") or "allow").lower()
        fallback_pairs: List[str] = []
        fallback_source: Optional[str] = None
        if whitelist_ordered:
            fallback_pairs = whitelist_ordered[:limit]
            fallback_source = "whitelist"
        else:
            preset = getattr(self, "PAIR_POOL_PRESET", tuple()) or tuple()
            preset_list = [item for item in preset if isinstance(item, str)]
            if preset_list:
                fallback_pairs = preset_list[:limit]
                fallback_source = "preset"
        if not selected:
            if fallback_mode == "whitelist":
                if fallback_pairs:
                    selected = list(fallback_pairs)
                    result["fallback"] = "whitelist"
                    if fallback_source:
                        result["fallback_source"] = fallback_source
                else:
                    result["active"] = False
                    result["fallback"] = "allow"
                    result["fallback_source"] = "whitelist_empty"
            elif fallback_mode == "allow":
                result["active"] = False
                result["fallback"] = "allow"
            else:
                result["fallback"] = "none"
        result.update({
            "pairs": selected,
            "metrics": metrics,
            "total_candidates": len(records),
            "whitelist_size": len(whitelist) if respect else None,
        })

        prev_pairs = set(cached.get("pairs", [])) if isinstance(cached, dict) else set()
        if selected and set(selected) != prev_pairs:
            level = getattr(logging, str(getattr(self, "DYNAMIC_PAIRLIST_LOG_LEVEL", "info")).upper(), logging.INFO)
            logger.log(level, "[动态热榜] %s 更新：%s", result.get("source", "hotlist"), ", ".join(selected))

        self._dynamic_pairlist_cache = result
        return result

    def _dynamic_pair_guard(self, pair: str, now: datetime,
                             session_ctx: Optional[Dict[str, Any]] = None) -> Tuple[bool, Dict[str, Any]]:
        """教学提示：检查当前币是否在动态热榜，返回是否允许继续执行和日志字段。"""
        profile = self._dynamic_pairlist_profile(now)
        info: Dict[str, Any] = {
            "dynamic_active": bool(profile.get("active", False)),
            "dynamic_mode": str(getattr(self, "DYNAMIC_PAIRLIST_MODE", "focus")),
            "dynamic_source": profile.get("source", "gainers"),
            "dynamic_pairs": list(profile.get("pairs", [])),
            "dynamic_fallback": profile.get("fallback"),
            "dynamic_fallback_source": profile.get("fallback_source"),
        }
        if not bool(profile.get("active", False)):
            fallback = str(profile.get("fallback")) if profile.get("fallback") is not None else None
            if fallback == "allow":
                fb_src = str(profile.get("fallback_source") or "")
                if fb_src:
                    info["dynamic_reason"] = f"fallback_allow_{fb_src}"
                else:
                    info["dynamic_reason"] = "fallback_allow"
            return True, info

        mode = str(getattr(self, "DYNAMIC_PAIRLIST_MODE", "focus")).lower()
        allow_held = bool(getattr(self, "DYNAMIC_PAIRLIST_ALLOW_HELD", True))
        if allow_held:
            st = self._pair_state.setdefault(pair, {})
            if st.get("has_open_trade"):
                info["dynamic_reason"] = "held_position"
                info["dynamic_metric"] = (profile.get("metrics", {}) or {}).get(pair)
                return True, info

        hot_pairs = set(profile.get("pairs", []))
        metrics = profile.get("metrics", {}) or {}

        if info.get("dynamic_fallback") == "whitelist":
            info["dynamic_reason"] = "fallback_whitelist"
            info["dynamic_metric"] = metrics.get(pair)
            if not hot_pairs or pair in hot_pairs:
                return True, info
            info["dynamic_reason"] = "fallback_whitelist_not_listed"
            return False, info

        if mode == "focus":
            if pair in hot_pairs:
                info["dynamic_reason"] = "in_hotlist"
                info["dynamic_metric"] = metrics.get(pair)
                return True, info
            info["dynamic_reason"] = "not_in_hotlist"
            info["dynamic_metric"] = metrics.get(pair)
            return False, info

        if mode == "prefer":
            info["dynamic_metric"] = metrics.get(pair)
            if pair in hot_pairs:
                info["dynamic_reason"] = "prefer_hotlist"
                return True, info
            info["dynamic_reason"] = "prefer_penalty"
            info["dynamic_penalty"] = True
            return True, info

        info["dynamic_reason"] = "mode_off"
        return True, info

    def _build_account_notional_profile(self) -> Dict[str, Any]:
        """教学提示：针对不同交易所/账号合并名义资金管理的默认值与覆写。"""
        profile: Dict[str, Any] = {}
        pair_overrides: Dict[str, Dict[str, Any]] = {}

        try:
            raw = getattr(self, "ACCOUNT_NOTIONAL_PROFILE", {}) or {}
            default = raw.get("default", {}) if isinstance(raw, dict) else {}
            if isinstance(default, dict):
                profile.update(default)
            name = self.exchange_name
            if name and isinstance(raw, dict):
                custom = raw.get(name, {})
                if isinstance(custom, dict):
                    profile.update(custom)
        except Exception:
            profile = {}

        try:
            sp = ((self.config or {}).get("strategy_parameters")) or {}
            override = sp.get("account_notional_override", None)
            if isinstance(override, dict):
                profile.update(override)
        except Exception:
            pass

        def _collect_pair_overrides(source: Any) -> None:
            if not isinstance(source, dict):
                return
            for pair_key, cfg in source.items():
                if not isinstance(pair_key, str) or not isinstance(cfg, dict):
                    continue
                acct_override = cfg.get("account_notional_override")
                if isinstance(acct_override, dict) and acct_override:
                    entry = pair_overrides.setdefault(pair_key, {})
                    entry.update(acct_override)

        try:
            _collect_pair_overrides(getattr(self, "pair_overrides", {}) or {})
        except Exception:
            pass
        try:
            cfg_pairs = ((self.config or {}).get("pair_overrides")) or {}
        except Exception:
            cfg_pairs = {}
        _collect_pair_overrides(cfg_pairs)

        self._notional_pair_overrides = pair_overrides

        return profile

    def _audit_feature_conflicts(self) -> Dict[str, Any]:
        """教学提示：初始化时审计新旧功能是否存在明显冲突，并输出易懂提示。"""
        report: Dict[str, Any] = {"warnings": [], "notes": [], "conflicts": [], "sections": {}}

        def warn(msg: str) -> None:
            report["warnings"].append(msg)

        def note(msg: str) -> None:
            report["notes"].append(msg)

        def conflict(msg: str) -> None:
            report["conflicts"].append(msg)
            warn(msg)

        sections: Dict[str, Dict[str, Any]] = report["sections"]

        try:
            entry_section: Dict[str, Any] = {
                "quiet_mode": bool(getattr(self, "QUIET_MODE", True)),
                "channel_pivot": bool(getattr(self, "CHANNEL_PIVOT_ENABLE", True)),
                "darkside": bool(getattr(self, "DARKSIDE_ENTRY_ENABLE", True)),
                "entry_quality": bool(getattr(self, "ENTRY_QUALITY_ENABLE", True)),
            }
            sections["entry"] = entry_section

            exit_section: Dict[str, Any] = {
                "strict_giveback": bool(getattr(self, "STRICT_GIVEBACK_ENABLE", True)),
                "expectation_guard": bool(getattr(self, "EXPECTATION_GUARD_ENABLE", True)),
                "measured_move": bool(getattr(self, "MEASURED_MOVE_ENABLE", True)),
                "measured_move_super": bool(getattr(self, "MEASURED_MOVE_SUPER_ENABLE", False)),
                "small_target": bool(getattr(self, "SMALL_TARGET_ENABLE", True)),
            }
            sections["exit"] = exit_section

            stop_section: Dict[str, Any] = {
                "custom_stoploss": bool(getattr(self, "use_custom_stoploss", True)),
                "kel_buffer": bool(getattr(self, "STOPLOSS_KEL_BUFFER_ENABLE", True)),
                "kel_expand": bool(getattr(self, "STOPLOSS_KEL_BUFFER_EXPAND_FALLBACK", True)),
                "context": bool(getattr(self, "STOPLOSS_CONTEXT_ENABLE", True)),
            }
            sections["stop"] = stop_section

            flash_section: Dict[str, Any] = {
                "flash_guard": bool(getattr(self, "FLASH_VOL_GUARD_ENABLE", True)),
                "flash_relax": bool(getattr(self, "FLASH_VOL_GUARD_RELAX_ENABLE", True)),
            }
            sections["flash"] = flash_section

            priority_section: Dict[str, Any] = {
                "side_priority": bool(getattr(self, "SIDE_PRIORITY_ENABLE", True)),
                "frontload_priority_bonus": float(getattr(self, "ENTRY_FRONTLOAD_PRIORITY_BONUS", 0.0) or 0.0),
                "entry_priority_weight": float(getattr(self, "ENTRY_QUALITY_PRIORITY_WEIGHT", self.ENTRY_QUALITY_PRIORITY_WEIGHT) or 0.0),
            }
            sections["priority"] = priority_section

            if exit_section["measured_move_super"] and not exit_section["measured_move"]:
                conflict("已启用 2R 超级趋势但关闭 MEASURED_MOVE_ENABLE，目标升阶缺乏基础量度守卫。")

            if exit_section["measured_move_super"] and not exit_section["expectation_guard"]:
                warn("已启用 2R 超级趋势但关闭 EXPECTATION_GUARD，会降低超趋势放行质量，请确认风险偏好。")

            if not exit_section["strict_giveback"] and not exit_section["small_target"]:
                conflict("已同时关闭 STRICT_GIVEBACK 与 SMALL_TARGET，盈利单将缺少锁盈地板。")

            if flash_section["flash_relax"] and not flash_section["flash_guard"]:
                warn("已关闭 FLASH_VOL_GUARD 但保留放宽参数，建议同时关闭 FLASH_VOL_GUARD_RELAX_ENABLE 或重新启用守卫。")

            if stop_section["kel_expand"] and not stop_section["kel_buffer"]:
                warn("已禁用 Keltner 止损隐藏却启用 STOPLOSS_KEL_BUFFER_EXPAND_FALLBACK，设置将被忽略，建议二者同步。")

            if not priority_section["side_priority"] and (
                priority_section["frontload_priority_bonus"] > 0.0
                or priority_section["entry_priority_weight"] > 0.0
            ):
                warn("SIDE_PRIORITY_ENABLE=False 但仍配置优先级加成，建议关闭相关 bonus 或重新启用 side priority。")

            if not entry_section["channel_pivot"] and bool(getattr(self, "ALLOW_FLIP", True)):
                warn("CHANNEL_PIVOT_ENABLE=False 且允许反手，突破后立即翻向可能失去冷静期，确认是否为预期。")

            if not bool(getattr(self, "use_custom_stoploss", True)):
                warn("已关闭 use_custom_stoploss，自适应动态止损与小目标锁盈将失效，建议保持开启。")

            if not bool(getattr(self, "position_adjustment_enable", False)) and int(getattr(self, "max_entry_position_adjustment", 0)) > 0:
                warn("max_entry_position_adjustment > 0 但未启用 position_adjustment_enable，浮盈加仓/防守均价将无法生效。")

            legs = tuple(getattr(self, "ICEBERG_LEGS", ()))
            if legs and any(l <= 0 for l in legs):
                warn("ICEBERG_LEGS 包含非正数，可能导致加仓占比计算异常，请仅使用正数比例。")

            if float(getattr(self, "PANIC_WICK_SHARE", 0.0)) <= 0.0 or float(getattr(self, "PANIC_WICK_SHARE", 0.0)) >= 1.0:
                warn("PANIC_WICK_SHARE 应处于 0~1 之间，用于衡量下影线占比，当前设置无效。")

            if float(getattr(self, "BLOWOFF_WICK_SHARE", 0.0)) <= 0.0 or float(getattr(self, "BLOWOFF_WICK_SHARE", 0.0)) >= 1.0:
                warn("BLOWOFF_WICK_SHARE 应处于 0~1 之间，用于衡量上影线占比，当前设置无效。")

            if int(getattr(self, "PANIC_GUARD_BARS", 0)) < 1:
                warn("PANIC_GUARD_BARS 至少为 1 根，否则无法阻断爆插后的反向追空。")

            if int(getattr(self, "BLOWOFF_GUARD_BARS", 0)) < 1:
                warn("BLOWOFF_GUARD_BARS 至少为 1 根，否则无法阻断瀑布前夕的盲目追多。")

            if int(getattr(self, "REFLEXIVE_WINDOW", 0)) < 2:
                warn("REFLEXIVE_WINDOW 过小，无法形成有效的反身性能量均值，建议≥2。")

            if int(getattr(self, "REFLEXIVE_GUARD_BARS", 0)) < 1:
                warn("REFLEXIVE_GUARD_BARS 至少为 1 根，否则能量塌陷冷静期无法生效。")

            if float(getattr(self, "REFLEXIVE_PEAK_THR", 0.0)) <= 0.0 or float(getattr(self, "REFLEXIVE_PERCEPTION_MIN", 0.0)) <= 0.0:
                warn("反身性阈值需为正数，确保能量塌陷检测可用。")

            stop_base = float(getattr(self, "STOPLOSS_ATR_BASE", 0.0))
            if stop_base <= 0.0:
                warn("STOPLOSS_ATR_BASE 需为正数，否则自适应动态止损无法计算基础宽度。")

            if float(getattr(self, "STOPLOSS_MIN_PCT", 0.0)) <= 0.0:
                warn("STOPLOSS_MIN_PCT 需为正数，用于限制止损最小宽度。")

            for attr in ("STOPLOSS_FAST_MULT", "STOPLOSS_NARROW_MULT", "STOPLOSS_ADD_DECAY", "STOPLOSS_TIME_TIGHTEN_EACH"):
                value = float(getattr(self, attr, 0.0))
                if value <= 0.0:
                    warn(f"{attr} 需为正数，当前设置会导致止损乘子无效。")
                elif value > 1.2:
                    note(f"{attr} 当前值 {value:.3f} 偏大，可能让止损过宽，建议复核是否符合预期。")

            if float(getattr(self, "STOPLOSS_PANIC_RELAX", 0.0)) < 1.0:
                warn("STOPLOSS_PANIC_RELAX 建议 ≥1，用于在底部爆插后放宽多单止损。")

            for attr in ("STOPLOSS_PANIC_TIGHT", "STOPLOSS_BLOWOFF_TIGHT", "STOPLOSS_MANIA_TIGHTEN"):
                value = float(getattr(self, attr, 0.0))
                if value <= 0.0 or value >= 1.0:
                    warn(f"{attr} 建议处于 0~1 区间，用于收紧极端护栏内的止损。")

            if bool(getattr(self, "PERFORMANCE_GUARD", True)):
                if int(getattr(self, "PERF_WINDOW", 0)) < 2:
                    warn("绩效调速开启时 PERF_WINDOW 至少为 2，才能计算近期收益节奏。")
                if int(getattr(self, "PERF_MAX_LOSS_STREAK", 0)) < 1:
                    warn("PERF_MAX_LOSS_STREAK 需 ≥1，才能正确判断连败刹车。")
            else:
                note("已关闭 PERFORMANCE_GUARD，盈亏节奏调速器不会参与入场/离场调节。")

            if not bool(getattr(self, "REFLEXIVE_EVENT_ENABLE", True)):
                note("已关闭宏观事件守护，FOMC/期权结算等窗口不会触发自动收紧。")

            if not bool(getattr(self, "LOG_DECISIONS", True)):
                note("LOG_DECISIONS 已关闭，WebUI 将无法记录放行/拒绝原因，建议仅在需要静默时关闭。")
        except Exception:
            logger.warning("功能冲突审计过程中出现异常，建议复查参数配置。")
            return report

        for msg in report["warnings"]:
            logger.warning("[功能冲突审计] %s", msg)

        if report["warnings"]:
            return report

        if report["notes"]:
            for msg in report["notes"]:
                logger.info("[功能冲突审计] %s", msg)
        else:
            logger.info("[功能冲突审计] 未发现新旧功能之间的明显冲突。")

        return report

    def _audit_directional_parity(self) -> Dict[str, List[str]]:
        """教学提示：检查多空逻辑是否保持对称，避免只实现单方向造成功能断层。"""
        report: Dict[str, List[str]] = {"warnings": [], "notes": []}

        def warn(msg: str) -> None:
            report["warnings"].append(msg)

        def note(msg: str) -> None:
            report["notes"].append(msg)

        try:
            def _check_range(name: str, rng: Any, label: str) -> None:
                if not isinstance(rng, (tuple, list)) or len(rng) != 2:
                    warn(f"{label} 区间 {name} 未定义为 (min, max) 结构，多空补票逻辑可能失效。")
                    return
                lo, hi = float(rng[0]), float(rng[1])
                if not (0.0 <= lo < hi <= 1.0):
                    warn(f"{label} 区间 {name}={rng} 超出 0~1 或上下界顺序错误，请检查多空补票位置。")

            _check_range("REENTRY_LONG_POS_RANGE", getattr(self, "REENTRY_LONG_POS_RANGE", None), "多单趋势补票")
            _check_range("REENTRY_SHORT_POS_RANGE", getattr(self, "REENTRY_SHORT_POS_RANGE", None), "空单趋势补票")

            rev_top = float(getattr(self, "REV_TOP_POS", 0.0))
            rev_bot = float(getattr(self, "REV_BOT_POS", 0.0))
            if not (0.0 <= rev_bot < rev_top <= 1.0):
                warn(f"反转位置 REV_BOT_POS={rev_bot:.3f}, REV_TOP_POS={rev_top:.3f} 不满足 0≤底<顶≤1，可能导致一侧反转基元缺失。")

            dist_base = float(getattr(self, "DIST_EMA_NEED", 0.0))
            dist_near = float(getattr(self, "DIST_EMA_NEAR_MIN", 0.0))
            if dist_base <= 0.0 or dist_near <= 0.0:
                warn("EMA 距离硬阈未正确设置，可能导致多空双方都被拒绝或放得过宽。")

            dist_short_bonus = float(getattr(self, "DIST_EMA_NEED_SHORT_BONUS", 0.0))
            dist_short_near = float(getattr(self, "DIST_EMA_NEAR_MIN_SHORT_BONUS", 0.0))
            if dist_short_bonus <= 0.0 or dist_short_near <= 0.0:
                warn("做空 EMA 距离乘子需为正，当前设置会让空单距离护栏失效。")
            elif dist_short_bonus < 1.0 or dist_short_near < 1.0:
                note("做空 EMA 距离乘子 <1，等同于放宽空单距离门槛，请确认是否符合风控预期。")

            panic_params = [
                float(getattr(self, "PANIC_PIERCE_ATR", 0.0)),
                float(getattr(self, "PANIC_REBOUND_ATR", 0.0)),
                float(getattr(self, "PANIC_SLOPE_DROP_ATR", 0.0)),
                float(getattr(self, "PANIC_SLOPE_REBOUND_ATR", 0.0)),
            ]
            panic_guard = int(getattr(self, "PANIC_GUARD_BARS", 0))
            panic_slope_guard = int(getattr(self, "PANIC_SLOPE_GUARD_BARS", 0))
            if panic_guard < 1 or panic_slope_guard < 1 or any(p <= 0.0 for p in panic_params):
                warn("爆插/连续瀑布护栏参数异常，可能在多单方向失去底部灾难性信号防守。")

            blowoff_params = [
                float(getattr(self, "BLOWOFF_PIERCE_ATR", 0.0)),
                float(getattr(self, "BLOWOFF_FADE_ATR", 0.0)),
                float(getattr(self, "BLOWOFF_WICK_SHARE", 0.0)),
            ]
            blowoff_guard = int(getattr(self, "BLOWOFF_GUARD_BARS", 0))
            if blowoff_guard < 1 or any(p <= 0.0 for p in blowoff_params):
                warn("瀑布前夕护栏参数异常，可能在空单方向失去顶部灾难性信号防守。")

            sl_panic_relax = float(getattr(self, "STOPLOSS_PANIC_RELAX", 0.0))
            sl_panic_tight = float(getattr(self, "STOPLOSS_PANIC_TIGHT", 0.0))
            sl_panic_slope = float(getattr(self, "STOPLOSS_PANIC_SLOPE_TIGHT", 0.0))
            sl_mania_tight = float(getattr(self, "STOPLOSS_MANIA_TIGHTEN", 0.0))
            sl_blowoff_tight = float(getattr(self, "STOPLOSS_BLOWOFF_TIGHT", 0.0))

            if sl_panic_relax <= 0.0 or sl_panic_tight <= 0.0 or sl_panic_slope <= 0.0:
                warn("爆插相关的止损乘子需为正数，才能在多单方向动态收紧/放宽止损。")
            if sl_mania_tight <= 0.0 or sl_blowoff_tight <= 0.0:
                warn("瀑布前夕相关的止损乘子需为正数，才能在空单方向动态收紧止损。")

            merged_overrides: Dict[str, Dict[str, Any]] = {}
            try:
                base_overrides = getattr(self, "pair_overrides", {}) or {}
                for pair, cfg in base_overrides.items():
                    if isinstance(cfg, dict):
                        merged_overrides.setdefault(pair, {}).update(cfg)
                cfg_overrides = ((self.config or {}).get("pair_overrides")) or {}
                if isinstance(cfg_overrides, dict):
                    for pair, cfg in cfg_overrides.items():
                        if isinstance(cfg, dict):
                            merged_overrides.setdefault(pair, {}).update(cfg)
            except Exception:
                merged_overrides = {}

            missing_long: List[str] = []
            missing_short: List[str] = []
            for pair, cfg in merged_overrides.items():
                if "strict_long_htf" in cfg and "strict_short_htf" not in cfg:
                    missing_short.append(pair)
                if "strict_short_htf" in cfg and "strict_long_htf" not in cfg:
                    missing_long.append(pair)

            if missing_long:
                note("以下币种仅设置了空头高周期约束，未显式声明多头：" + ", ".join(sorted(set(missing_long))))
            if missing_short:
                note("以下币种仅设置了多头高周期约束，未显式声明空头：" + ", ".join(sorted(set(missing_short))))

            long_pathways = [
                "趋势单：快/慢车道 + tri_bias_long + panic_guard 联动",  # noqa: E501
                "反转单：range_gate + REV_BOT_POS/REV_TOP_POS",          # noqa: E501
                "动能快单：fast_lane_long + vol_surge_any",               # noqa: E501
            ]
            short_pathways = [
                "趋势单：快/慢车道 + tri_bias_short + mania_guard 联动",  # noqa: E501
                "反转单：range_gate + REV_BOT_POS/REV_TOP_POS",           # noqa: E501
                "动能快单：fast_lane_short + vol_surge_any",              # noqa: E501
            ]
            note("多单护栏结构：" + "；".join(long_pathways))
            note("空单护栏结构：" + "；".join(short_pathways))

            if bool(getattr(self, "can_short", False)) and bool(getattr(self, "ALLOW_FLIP", True)):
                note("已启用 can_short + ALLOW_FLIP，确认多空均可持仓并支持顺势翻转。")
            elif not bool(getattr(self, "can_short", False)):
                warn("策略未开启 can_short，将无法执行空单方向的逻辑。")

            short_force_disable = bool(getattr(self, "DIRECTIONAL_SHORT_FORCE_DISABLE", False))
            short_ratio_enable = bool(getattr(self, "DIRECTIONAL_SHORT_RATIO_ENABLE", True))
            short_max_ratio = float(getattr(self, "DIRECTIONAL_SHORT_MAX_RATIO", 0.0) or 0.0)
            short_min_long = int(getattr(self, "DIRECTIONAL_SHORT_MIN_LONG", 0) or 0)
            short_lookback = float(getattr(self, "DIRECTIONAL_SHORT_LOOKBACK_MINUTES", 0.0) or 0.0)
            if short_force_disable:
                note("已临时关闭空单比例/数量守卫（DIRECTIONAL_SHORT_FORCE_DISABLE=True），所有空单将绕过配额与数量限制。")
            elif short_ratio_enable:
                if short_max_ratio <= 0.0:
                    warn("空单比例守卫已启用但 short_max_ratio<=0，无法根据多单配额限制做空频率。")
                else:
                    note(
                        "空单比例守卫启用：lookback≈{:.0f} 分钟、max_ratio≈{:.3f}、min_long={}".format(
                            short_lookback if short_lookback > 0 else 0.0,
                            short_max_ratio,
                            short_min_long,
                        )
                    )
                if short_lookback <= 0.0:
                    warn("空单比例守卫的 short_lookback_minutes<=0，将导致历史样本窗口无效。")
            else:
                note("已关闭空单比例守卫（DIRECTIONAL_SHORT_RATIO_ENABLE=False），空头频率将不再受多单计数约束。")

            short_open_enable = bool(getattr(self, "DIRECTIONAL_SHORT_OPEN_ENABLE", True))
            short_max_open = int(getattr(self, "DIRECTIONAL_SHORT_MAX_OPEN", 0) or 0)
            if short_force_disable:
                pass
            elif short_open_enable:
                if short_max_open <= 0:
                    warn("空单数量守卫已开启但 short_max_open<=0，同一时间的空头持仓数量不会受到限制。")
                else:
                    note(f"空单数量守卫启用：同一时间最多允许 {short_max_open} 笔空单。")
            else:
                note("空单数量守卫已关闭（DIRECTIONAL_SHORT_OPEN_ENABLE=False），默认恢复无限空单。")

            short_mania_override = bool(getattr(self, "DIRECTIONAL_SHORT_MANIA_OVERRIDE", True))
            short_price_floor = float(getattr(self, "DIRECTIONAL_SHORT_PRICE_OVERRIDE_FLOOR", 0.0) or 0.0)
            if not short_force_disable:
                if short_mania_override:
                    if not (0.0 <= short_price_floor <= 1.0):
                        warn("空单 mania 覆盖价位 short_price_override_floor 未落在 0~1，mania 车道将无法正确判断是否越界。")
                    else:
                        note(
                            "空单 mania 覆盖启用：价格分位≥{:.2f} 且处于 mania 车道时可越过比例配额。".format(
                                short_price_floor
                            )
                        )
                else:
                    note("已关闭空单 mania 覆盖（DIRECTIONAL_SHORT_MANIA_OVERRIDE=False），mania 车道将继续遵守比例配额。")

        except Exception:
            logger.warning("多空对称审计过程中出现异常，请复核参数定义。")
            return report

        for msg in report["warnings"]:
            logger.warning("[多空审计] %s", msg)

        for msg in report["notes"]:
            logger.info("[多空审计] %s", msg)

        return report

    def _directional_register_entry(
        self,
        side: str,
        when: Optional[datetime],
        settings: Optional[Dict[str, Any]] = None,
    ) -> None:
        """记录一次多/空放行，用于后续配额治理。"""

        hist = getattr(self, "_directional_entry_history", None)
        if not isinstance(hist, list):
            hist = []
            self._directional_entry_history = hist

        if not isinstance(when, datetime):
            when = self._utc_now()
        if when.tzinfo is None:
            when = when.replace(tzinfo=timezone.utc)

        lookback = float(getattr(self, "DIRECTIONAL_SHORT_LOOKBACK_MINUTES", 1440.0) or 1440.0)
        if isinstance(settings, dict):
            cfg_val = settings.get("short_lookback_minutes")
            try:
                lookback = max(lookback, float(cfg_val)) if cfg_val is not None else lookback
            except (TypeError, ValueError):
                pass
        lookback = max(1.0, lookback)
        cutoff = when - timedelta(minutes=lookback)

        pruned: List[Tuple[datetime, str]] = []
        for ts, s in hist:
            if not isinstance(ts, datetime):
                continue
            if ts.tzinfo is None:
                ts = ts.replace(tzinfo=timezone.utc)
            if ts >= cutoff:
                pruned.append((ts, s))
        pruned.append((when, side))
        self._directional_entry_history = pruned

    def _directional_short_guard(
        self,
        now: datetime,
        settings: Optional[Dict[str, Any]],
        *,
        mania_override: bool,
        price_position: float,
    ) -> Tuple[bool, Optional[str], Dict[str, Any]]:
        """根据近期多空放行比限制空单频率。"""

        if bool(getattr(self, "DIRECTIONAL_SHORT_FORCE_DISABLE", False)):
            return True, None, {"dir_short_force_disable": 1, "dir_short_fallback": "force_disable"}

        if not bool(getattr(self, "DIRECTIONAL_SHORT_RATIO_ENABLE", True)):
            return True, None, {}

        cfg: Dict[str, Any] = {
            "enable": True,
            "short_max_ratio": float(getattr(self, "DIRECTIONAL_SHORT_MAX_RATIO", 0.05) or 0.0),
            "short_lookback_minutes": float(getattr(self, "DIRECTIONAL_SHORT_LOOKBACK_MINUTES", 1440.0) or 1440.0),
            "short_min_long": int(getattr(self, "DIRECTIONAL_SHORT_MIN_LONG", 0) or 0),
            "short_mania_override": bool(getattr(self, "DIRECTIONAL_SHORT_MANIA_OVERRIDE", True)),
            "short_price_override_floor": float(getattr(self, "DIRECTIONAL_SHORT_PRICE_OVERRIDE_FLOOR", 0.86) or 0.0),
            "short_open_enable": bool(getattr(self, "DIRECTIONAL_SHORT_OPEN_ENABLE", True)),
            "short_max_open": int(getattr(self, "DIRECTIONAL_SHORT_MAX_OPEN", 0) or 0),
        }

        if isinstance(settings, dict):
            for key, cfg_key in (
                ("enable", "enable"),
                ("short_max_ratio", "short_max_ratio"),
                ("short_lookback_minutes", "short_lookback_minutes"),
                ("short_min_long", "short_min_long"),
                ("short_mania_override", "short_mania_override"),
                ("short_price_override_floor", "short_price_override_floor"),
                ("short_open_enable", "short_open_enable"),
                ("short_max_open", "short_max_open"),
            ):
                if key not in settings:
                    continue
                value = settings.get(key)
                try:
                    if key in {"enable", "short_mania_override", "short_open_enable"}:
                        cfg[cfg_key] = bool(value)
                    elif key in {"short_min_long", "short_max_open"}:
                        cfg[cfg_key] = int(max(0, int(value)))
                    else:
                        cfg[cfg_key] = float(value)
                except (TypeError, ValueError):
                    continue

        if not cfg.get("enable", True):
            return True, None, {}

        hist = getattr(self, "_directional_entry_history", [])
        now_ts = now if isinstance(now, datetime) else self._utc_now()
        if now_ts.tzinfo is None:
            now_ts = now_ts.replace(tzinfo=timezone.utc)

        lookback = max(1.0, float(cfg.get("short_lookback_minutes", 1440.0)))
        cutoff = now_ts - timedelta(minutes=lookback)

        long_count = 0
        short_count = 0
        earliest_short: Optional[datetime] = None
        pruned: List[Tuple[datetime, str]] = []
        for ts, s in hist:
            if not isinstance(ts, datetime):
                continue
            if ts.tzinfo is None:
                ts = ts.replace(tzinfo=timezone.utc)
            if ts < cutoff:
                continue
            pruned.append((ts, s))
            if s == "long":
                long_count += 1
            elif s == "short":
                short_count += 1
                if earliest_short is None or ts < earliest_short:
                    earliest_short = ts
        self._directional_entry_history = pruned

        max_ratio = max(0.0, float(cfg.get("short_max_ratio", 0.0)))
        min_long = max(0, int(cfg.get("short_min_long", 0)))
        info: Dict[str, Any] = {
            "dir_short_long_count": long_count,
            "dir_short_short_count": short_count,
            "dir_short_max_ratio": round(max_ratio, 4),
            "dir_short_min_long": min_long,
            "dir_short_lookback_min": round(lookback, 2),
        }
        if long_count > 0:
            info["dir_short_ratio"] = round(short_count / long_count, 4)

        price_val = float(price_position) if np.isfinite(price_position) else float("nan")
        if np.isfinite(price_val):
            info["dir_short_price_pos"] = round(price_val, 4)

        quota = 0
        if max_ratio > 0 and long_count >= min_long:
            quota = max(1, int(math.floor(long_count * max_ratio + 1e-9)))
        info["dir_short_quota"] = quota

        mania_allowed = False
        price_floor = float(cfg.get("short_price_override_floor", 0.0) or 0.0)
        mania_override_enabled = bool(cfg.get("short_mania_override", True))
        if mania_override_enabled:
            info["dir_short_override_price_floor"] = round(price_floor, 4)
            if mania_override:
                mania_allowed = np.isfinite(price_val) and price_val >= price_floor
                if mania_allowed:
                    info["dir_short_override"] = 1

        if not mania_allowed:
            if quota <= 0:
                info["dir_short_needed"] = max(0, min_long - long_count)
                return False, "空单比例守卫：等待多单累计", info

            if short_count >= quota:
                if earliest_short is not None:
                    resume_at = earliest_short + timedelta(minutes=lookback)
                    if resume_at.tzinfo is None:
                        resume_at = resume_at.replace(tzinfo=timezone.utc)
                    info["dir_short_resume_at"] = resume_at.isoformat()
                info["dir_short_block_reason"] = "quota"
                return False, "空单比例守卫：等待多单扩容或冷却", info

        open_limit_enabled = bool(cfg.get("short_open_enable", True))
        max_open = max(0, int(cfg.get("short_max_open", 0)))
        if open_limit_enabled and max_open > 0:
            traces = getattr(self, "_portfolio_traces", {})
            open_count = 0
            open_pairs: List[str] = []
            if isinstance(traces, dict):
                for trace in traces.values():
                    if not isinstance(trace, dict):
                        continue
                    if not bool(trace.get("is_short")):
                        continue
                    notional_val = float(trace.get("notional", 0.0) or 0.0)
                    if not np.isfinite(notional_val) or notional_val <= 0:
                        continue
                    open_count += 1
                    pair_name = trace.get("pair")
                    if isinstance(pair_name, str) and pair_name:
                        open_pairs.append(pair_name)
            info["dir_short_open_count"] = open_count
            info["dir_short_open_limit"] = max_open
            if open_pairs:
                info["dir_short_open_pairs"] = sorted(set(open_pairs))
            if open_count >= max_open:
                info["dir_short_block_reason"] = "open_limit"
                return False, "空单数量守卫：等待持仓释放", info

        return True, None, info

    def _tri_need_threshold(self) -> float:
        """教学提示：基础三锚需求结合交易所校准后的阈值。"""
        base = 1.0 - float(self.GLOBAL_SOFTLOCK_STRICTNESS)
        mult = float(self._profile_val("tri_need_mult", 1.0) or 1.0)
        return float(np.clip(base * mult, 0.0, 1.0))

    @staticmethod
    def _timeframe_to_minutes(tf_raw: str, fallback: float = 5.0) -> float:
        """教学提示：把任意 timeframe 字符串换算成分钟数（支持 m/h/d/w）。"""
        if not tf_raw:
            return float(fallback)
        tf_raw = str(tf_raw).strip().lower()
        if not tf_raw:
            return float(fallback)
        unit = tf_raw[-1]
        value_str = tf_raw[:-1]
        try:
            value = float(value_str)
        except (TypeError, ValueError):
            return float(fallback)

        if unit == "m":
            minutes = value
        elif unit == "h":
            minutes = value * 60.0
        elif unit == "d":
            minutes = value * 1440.0
        elif unit == "w":
            minutes = value * 10080.0
        else:
            minutes = float(fallback)
        if minutes <= 0:
            return float(fallback)
        return float(minutes)

    def _tf_minutes(self) -> int:
        """教学提示：把当前 timeframe（如 5m/30m/1h/1d）换算成“多少分钟一根 K”。"""
        fallback = float(getattr(self, "BASE_TIMEFRAME_MINUTES", 5.0) or 5.0)
        minutes = self._timeframe_to_minutes(str(getattr(self, "timeframe", "")), fallback)
        return max(1, int(math.ceil(minutes)))

    def _normalize_row_timestamp(self, row: pd.Series, fallback: datetime) -> datetime:
        """教学提示：把 DataFrame 行索引转换成带时区的时间戳，方便跨模块共用。"""
        ts = getattr(row, "name", None)
        if isinstance(ts, pd.Timestamp):
            if ts.tzinfo is None:
                ts = ts.tz_localize(timezone.utc)
            else:
                ts = ts.tz_convert(timezone.utc)
            return ts.to_pydatetime()
        if isinstance(ts, datetime):
            return ts if ts.tzinfo else ts.replace(tzinfo=timezone.utc)
        return fallback

    def _bars_since(self, ref: Optional[datetime], current: datetime) -> int:
        """教学提示：计算从参考时间到当前时间经过了多少根 K 线。"""
        if not isinstance(ref, datetime) or not isinstance(current, datetime):
            return 0
        try:
            ref_aware = ref if ref.tzinfo else ref.replace(tzinfo=timezone.utc)
        except Exception:
            ref_aware = ref
        try:
            cur_aware = current if current.tzinfo else current.replace(tzinfo=timezone.utc)
        except Exception:
            cur_aware = current
        delta = (cur_aware - ref_aware).total_seconds() / 60.0
        if delta <= 0:
            return 0
        tf_minutes = float(getattr(self, "_current_tf_minutes", self._tf_minutes()))
        tf_minutes = max(1.0, tf_minutes)
        return int(delta / tf_minutes)

    def _cluster_window_minutes(self) -> int:
        """教学提示：信号扎堆保护使用的时间窗口（以分钟计）。"""
        lookback = max(1, int(getattr(self, "SIGNAL_CLUSTER_LOOKBACK_BARS", 12)))
        return lookback * self._tf_minutes()

    def _performance_profile(self, pair: str) -> Dict[str, Any]:
        """教学提示：读取最近交易绩效，决定当前处于“热手”还是“回撤刹车”状态。"""
        st = self._pair_state.setdefault(pair, {})
        recent = list(st.get("recent_pnls", []))
        loss_streak = int(st.get("loss_streak", 0) or 0)
        win_streak = int(st.get("win_streak", 0) or 0)
        drawdown_acc = float(st.get("drawdown_acc", 0.0) or 0.0)
        avg_pnl = float(np.mean(recent)) if recent else 0.0

        guard = False
        guard_reasons: List[str] = []
        if bool(getattr(self, "PERFORMANCE_GUARD", True)):
            max_streak = max(0, int(getattr(self, "PERF_MAX_LOSS_STREAK", 0)))
            dd_limit = max(0.0, float(getattr(self, "PERF_DRAWDOWN_LIMIT", 0.0)))
            if max_streak and loss_streak >= max_streak:
                guard = True
                guard_reasons.append("loss_streak")
            if dd_limit > 0 and drawdown_acc <= -dd_limit:
                guard = True
                guard_reasons.append("drawdown")

        hot = False
        if not guard and bool(getattr(self, "PERFORMANCE_GUARD", True)):
            hot_streak = max(0, int(getattr(self, "PERF_HOT_WIN_STREAK", 0)))
            hot_avg = float(getattr(self, "PERF_HOT_AVG_MIN", 0.0))
            if hot_streak and win_streak >= hot_streak and avg_pnl >= hot_avg:
                hot = True

        mode = "drawdown" if guard else ("hot" if hot else "neutral")
        return {
            "mode": mode,
            "drawdown_guard": guard,
            "guard_reasons": guard_reasons,
            "loss_streak": loss_streak,
            "win_streak": win_streak,
            "drawdown": drawdown_acc,
            "recent_avg": avg_pnl,
            "recent_pnls": recent,
        }

    def _register_portfolio_trade(self, trade: Optional[Trade], pair: str, is_short: bool,
                                  current_profit: float, current_rate: float,
                                  current_time: Optional[datetime]) -> None:
        """教学提示：把当前持仓的浮盈、名义敞口登记到组合快照，方便跨单评估。"""
        if trade is None:
            return
        try:
            tid = int(getattr(trade, "id", 0) or 0)
        except (TypeError, ValueError):
            return
        if tid <= 0:
            return
        now = current_time if isinstance(current_time, datetime) else datetime.now(timezone.utc)
        if now.tzinfo is None:
            now = now.replace(tzinfo=timezone.utc)
        stake = float(getattr(trade, "stake_amount", 0.0) or 0.0)
        amount = abs(float(getattr(trade, "amount", 0.0)) or 0.0)
        open_rate = float(getattr(trade, "open_rate", 0.0) or 0.0)
        if not np.isfinite(open_rate) or open_rate <= 0:
            alt_rate = float(getattr(trade, "open_order_price", 0.0) or 0.0)
            if np.isfinite(alt_rate) and alt_rate > 0:
                open_rate = alt_rate
        if (not np.isfinite(open_rate) or open_rate <= 0) and np.isfinite(current_rate) and current_rate > 0:
            open_rate = float(current_rate)
        notional = 0.0
        if np.isfinite(amount) and amount > 0 and np.isfinite(open_rate) and open_rate > 0:
            notional = amount * open_rate
        leverage = float(getattr(trade, "leverage", 0.0) or 0.0)
        if notional <= 0 and stake > 0:
            if np.isfinite(leverage) and leverage > 0:
                notional = stake * leverage
            else:
                notional = stake
        profit_pct = float(current_profit) if np.isfinite(current_profit) else 0.0
        profit_value = notional * profit_pct
        self._portfolio_traces[tid] = {
            "pair": pair,
            "is_short": bool(is_short),
            "profit_pct": profit_pct,
            "notional": max(0.0, float(notional)),
            "stake": max(0.0, stake),
            "leverage": leverage if np.isfinite(leverage) and leverage > 0 else None,
            "profit_value": profit_value,
            "last_update": now,
        }

    def _portfolio_snapshot(self, focus: Optional[int] = None,
                            exclude: Optional[int] = None) -> Dict[str, Any]:
        """教学提示：汇总所有登记持仓，返回组合层面的盈亏与敞口数据。"""
        stats: Dict[str, Any] = {
            "open_count": 0,
            "winner_count": 0,
            "loser_count": 0,
            "total_notional": 0.0,
            "positive_value": 0.0,
            "negative_value": 0.0,
            "positive_weight": 0.0,
            "negative_weight": 0.0,
            "net_profit_value": 0.0,
            "net_profit_pct": 0.0,
            "loss_pressure_pct": 0.0,
            "best_profit_pct": None,
            "worst_loss_pct": None,
            "focus_profit_pct": 0.0,
            "focus_profit_value": 0.0,
            "focus_notional": 0.0,
            "focus_weight_share": 0.0,
            "focus_positive_share": 0.0,
        }
        for tid, info in list(self._portfolio_traces.items()):
            if exclude is not None and tid == exclude:
                continue
            notional = float(info.get("notional", 0.0) or 0.0)
            if notional <= 0:
                continue
            profit_pct = float(info.get("profit_pct", 0.0) or 0.0)
            profit_value = float(info.get("profit_value", profit_pct * notional) or 0.0)
            stats["open_count"] += 1
            stats["total_notional"] += notional
            stats["net_profit_value"] += profit_value
            if profit_pct >= 0:
                stats["winner_count"] += 1
                stats["positive_value"] += profit_value
                stats["positive_weight"] += notional
                best = stats.get("best_profit_pct")
                stats["best_profit_pct"] = profit_pct if best is None else max(best, profit_pct)
            else:
                stats["loser_count"] += 1
                stats["negative_value"] += profit_value
                stats["negative_weight"] += notional
                worst = stats.get("worst_loss_pct")
                stats["worst_loss_pct"] = profit_pct if worst is None else min(worst, profit_pct)
            if focus is not None and tid == focus:
                stats["focus_profit_pct"] = profit_pct
                stats["focus_profit_value"] = profit_value
                stats["focus_notional"] = notional
        total_notional = float(stats.get("total_notional", 0.0) or 0.0)
        if total_notional > 0:
            stats["net_profit_pct"] = float(stats.get("net_profit_value", 0.0)) / total_notional
            stats["loss_pressure_pct"] = float(stats.get("negative_value", 0.0)) / total_notional
            stats["focus_weight_share"] = float(stats.get("focus_notional", 0.0)) / total_notional
        positive_value = float(stats.get("positive_value", 0.0) or 0.0)
        if positive_value > 0 and float(stats.get("focus_profit_value", 0.0) or 0.0) > 0:
            stats["focus_positive_share"] = float(stats.get("focus_profit_value", 0.0)) / positive_value
        else:
            stats["focus_positive_share"] = 0.0
        stats["timestamp"] = datetime.now(timezone.utc)
        self._portfolio_snapshot_cache = stats
        return stats

    def _style_profile(self, mode: str) -> Dict[str, float]:
        """教学提示：根据模式（保守/中性/激进）取出一组门槛乘子。"""
        profiles = dict(getattr(self, "STYLE_PRESET_PROFILES", {}) or {})
        if not profiles:
            return {
                "dist_mult": 1.0,
                "tri_mult": 1.0,
                "quality_add": 0.0,
                "frontload_mult": 1.0,
                "cooldown_mult": 1.0,
            }
        mode_key = str(mode or "").lower()
        if mode_key in profiles:
            base = dict(profiles[mode_key])
        else:
            base = dict(profiles.get("neutral", {}))
        for key in ("dist_mult", "tri_mult", "quality_add", "frontload_mult", "cooldown_mult"):
            base.setdefault(key, 1.0 if key.endswith("mult") else 0.0)
        return base

    def _resolve_style_mode(
        self,
        *,
        side: str,
        session_ctx: Dict[str, Any],
        fast_lane: bool,
        slow_lane: bool,
        channel_narrow: bool,
        channel_wide: bool,
        channel_decay: bool,
        align_score: float,
        rfs_value: float,
        price_position: float,
        dynamic_penalty: bool,
        portfolio_guard: bool,
        portfolio_fragile: bool,
        port_net: float,
        port_loss_pressure: float,
        perf_guard: bool,
        perf_hot: bool,
        mania_lane_active: bool,
        panic_lane_active: bool,
    ) -> Dict[str, Any]:
        """教学提示：结合行情、组合与绩效判断当前应走保守/激进/中性。"""

        base_mode = str(self.PRESET or "conservative").lower().strip()
        if base_mode not in ("conservative", "neutral", "aggressive"):
            base_mode = "conservative"

        autopilot = bool(getattr(self, "STYLE_AUTOPILOT_ENABLE", False))
        thresholds = dict(getattr(self, "STYLE_AUTOPILOT_THRESHOLDS", {}) or {})
        align_strong = float(thresholds.get("align_strong", 0.55))
        rfs_support = float(thresholds.get("rfs_support", 0.12))
        drawdown_floor = float(thresholds.get("drawdown_conservative", -0.02))
        loss_pressure_need = float(thresholds.get("loss_pressure_conservative", 0.08))
        equity_push_need = float(thresholds.get("equity_push_aggressive", 0.015))
        price_top = float(thresholds.get("price_top", 0.72))
        price_bottom = float(thresholds.get("price_bottom", 0.28))
        price_buffer = float(thresholds.get("price_buffer", 0.07))

        mode = base_mode
        reasons: List[str] = []
        bias = "base"

        if not autopilot:
            return {
                "mode": mode,
                "reason": "manual",
                "bias": bias,
                "profile": self._style_profile(mode),
            }

        caution = False
        if perf_guard:
            caution = True
            reasons.append("performance_guard")
        elif portfolio_guard and port_net <= drawdown_floor:
            caution = True
            reasons.append("portfolio_drawdown")
        elif portfolio_guard and portfolio_fragile and port_loss_pressure >= loss_pressure_need:
            caution = True
            reasons.append("portfolio_fragile")
        elif dynamic_penalty:
            caution = True
            reasons.append("dynamic_penalty")
        elif (side == "long" and mania_lane_active) or (side == "short" and panic_lane_active):
            caution = True
            reasons.append("extreme_guard")
        elif (side == "long" and price_position >= price_top) or (side == "short" and price_position <= price_bottom):
            caution = True
            reasons.append("price_extreme")

        if caution:
            mode = "conservative"
            bias = "defensive"
        else:
            strong_align = (side == "long" and align_score >= align_strong) or (
                side == "short" and align_score <= -align_strong
            )
            rfs_ok = (side == "long" and rfs_value >= rfs_support) or (
                side == "short" and rfs_value <= -rfs_support
            )
            price_mid_ok = (price_bottom + price_buffer) <= price_position <= (price_top - price_buffer)
            trend_bias = fast_lane or (slow_lane and channel_narrow and strong_align)
            mania_conflict = (side == "long" and mania_lane_active) or (side == "short" and panic_lane_active)
            session_bias = str(session_ctx.get("bias", ""))

            if (
                trend_bias
                and strong_align
                and rfs_ok
                and price_mid_ok
                and not mania_conflict
                and not dynamic_penalty
            ):
                if perf_hot or port_net >= equity_push_need:
                    mode = "aggressive"
                    bias = "momentum"
                    reasons.append("fast_trend")
            elif base_mode == "aggressive" and not strong_align:
                mode = "neutral"
                bias = "neutralized"
                reasons.append("insufficient_alignment")
            elif session_bias == "calm" and base_mode == "aggressive" and not strong_align:
                mode = "neutral"
                bias = "session_calm"
                reasons.append("session_bias")
            elif base_mode == "neutral" and not strong_align and not rfs_ok:
                mode = "conservative"
                bias = "default_defensive"
                reasons.append("weak_structure")

        profile = self._style_profile(mode)
        reason_txt = "/".join(reasons) if reasons else "auto"
        return {
            "mode": mode,
            "reason": reason_txt,
            "bias": bias,
            "profile": profile,
        }

    def _fragile_align_need(self, align_base: float, side: str,
                            *, fast_lane: bool = False, slow_lane: bool = False,
                            htf_drive: bool = False, port_net: float = 0.0,
                            loss_pressure: float = 0.0,
                            panic_lane: bool = False, mania_lane: bool = False) -> float:
        """教学提示：根据组合状态与信号强度动态调整脆弱期的多周期对齐阈值。"""
        align_need = float(align_base)
        try:
            align_need -= max(0.0, float(port_net)) * float(getattr(self, "PORTFOLIO_FRAGILE_ALIGN_POS_FACTOR", 2.0))
        except Exception:
            pass
        if fast_lane:
            align_need -= float(getattr(self, "PORTFOLIO_FRAGILE_ALIGN_FAST_RELIEF", 0.10))
        elif slow_lane:
            align_need -= float(getattr(self, "PORTFOLIO_FRAGILE_ALIGN_SLOW_RELIEF", 0.05))
        if htf_drive:
            align_need -= float(getattr(self, "PORTFOLIO_FRAGILE_ALIGN_DRIVE_RELIEF", 0.04))
        try:
            loss_pressure = max(0.0, float(loss_pressure))
        except Exception:
            loss_pressure = 0.0
        loss_grace = float(getattr(self, "PORTFOLIO_FRAGILE_LOSS_GRACE", 0.06))
        if loss_pressure <= loss_grace:
            align_need -= float(getattr(self, "PORTFOLIO_FRAGILE_ALIGN_LOSS_RELIEF", 0.04))
        align_min = float(getattr(self, "PORTFOLIO_FRAGILE_ALIGN_MIN", 0.08))
        extreme_min = float(getattr(self, "PORTFOLIO_FRAGILE_ALIGN_EXTREME_MIN", 0.0))
        extreme_active = ((side == "long") and panic_lane) or ((side == "short") and mania_lane)
        min_floor = extreme_min if (extreme_active and fast_lane) else align_min
        align_need = max(min_floor, align_need)
        return max(0.0, align_need)

    def _portfolio_forget(self, trade: Optional[Trade]) -> None:
        """教学提示：平仓后清理组合登记，避免旧单残留影响统计。"""
        if trade is None:
            return
        try:
            tid = int(getattr(trade, "id", 0) or 0)
        except (TypeError, ValueError):
            return
        if tid <= 0:
            return
        self._portfolio_traces.pop(tid, None)


    # -------------------- 软反身性 / 宏观事件辅助 --------------------
    def _session_slot(self, ts: datetime) -> Dict[str, Any]:
        """教学提示：按本地小时划分亚/欧/美交易时区，支持时区偏移的宵禁/软调节。"""

        cfg_params: Dict[str, Any] = {}
        try:
            cfg_params = ((self.config or {}).get("strategy_parameters")) or {}
        except Exception:
            cfg_params = {}
        strat_params = getattr(self, "_strategy_parameters", None)
        if isinstance(strat_params, dict) and strat_params:
            merged_params = dict(cfg_params)
            merged_params.update(strat_params)
            cfg_params = merged_params

        ctx = {
            "label": "unknown",
            "tri_mult": 1.0,
            "dist_mult": 1.0,
            "add_mult": 1.0,
            "bias": "neutral",
            "block_entry": False,
            "block_entries": False,
            "block_add": False,
            "block_adds": False,
        }
        if not bool(getattr(self, "SESSION_PROFILE_ENABLE", True)):
            return ctx

        # 允许通过 SESSION_TZ_OFFSET_HOURS 或 config.session_timezone_offset_hours 将窗口解释为本地时区。
        offset_hours = 0.0
        try:
            offset_hours = float(getattr(self, "SESSION_TZ_OFFSET_HOURS", 0.0) or 0.0)
        except Exception:
            offset_hours = 0.0
        try:
            cfg_offset = float(((self.config or {}).get("session_timezone_offset_hours", offset_hours)) or 0.0)
            offset_hours = cfg_offset
        except Exception:
            pass
        try:
            cfg_offset = float(cfg_params.get("session_timezone_offset_hours", offset_hours) or offset_hours)
            offset_hours = cfg_offset
        except Exception:
            pass

        try:
            ts_utc = ts.astimezone(timezone.utc) if ts.tzinfo else ts.replace(tzinfo=timezone.utc)
        except Exception:
            ts_utc = datetime.now(timezone.utc)
        try:
            ts_local = ts_utc + timedelta(hours=offset_hours)
        except Exception:
            ts_local = ts_utc

        hour = int(ts_local.hour)
        ctx["offset_hours"] = float(offset_hours)
        ctx["local_hour"] = hour
        try:
            slots = cfg_params.get("session_biases") or getattr(self, "SESSION_BIASES", tuple())
            for slot in slots:
                if not isinstance(slot, dict):
                    continue
                start = int(slot.get("start", 0)) % 24
                end = int(slot.get("end", start)) % 24
                if start <= end:
                    in_window = start <= hour < end
                else:
                    in_window = (hour >= start) or (hour < end)
                if in_window:
                    ctx.update({
                        "label": str(slot.get("label", "session")),
                        "tri_mult": float(slot.get("tri_mult", 1.0)),
                        "dist_mult": float(slot.get("dist_mult", 1.0)),
                        "add_mult": float(slot.get("add_mult", 1.0)),
                        "bias": str(slot.get("bias", "neutral")),
                        "block_entry": bool(slot.get("block_entry", False) or slot.get("block_entries", False)),
                        "block_entries": bool(slot.get("block_entries", False)),
                        "block_add": bool(slot.get("block_add", False) or slot.get("block_adds", False)),
                        "block_adds": bool(slot.get("block_adds", False)),
                        "window_local": f"{start:02d}-{end:02d}",
                    })
                    break
        except Exception:
            pass
        ctx["curfew_active"] = bool(
            ctx.get("block_entry")
            or ctx.get("block_entries")
            or ctx.get("block_add")
            or ctx.get("block_adds")
            or float(ctx.get("add_mult", 1.0) or 1.0) == 0.0
        )
        return ctx

    def _update_session_profit_metrics(
        self,
        ts: datetime,
        label: str,
        *,
        realized_r: Optional[float] = None,
        realized_pct: Optional[float] = None,
        peak_r_candidate: Optional[float] = None,
        floating_profit_pct: Optional[float] = None,
        floating_peak_pct: Optional[float] = None,
    ) -> Dict[str, Any]:
        """教学提示：按时区窗口滚动记录已实现/峰值收益，为期望守卫提供当期天花板。"""

        label_key = str(label or "unknown")
        ts_utc = ts if ts.tzinfo else ts.replace(tzinfo=timezone.utc)
        window_hours = float(getattr(self, "SESSION_PROFIT_WINDOW_HOURS", 12.0) or 12.0)
        window_hours = max(1.0, window_hours)
        window_seconds = int(window_hours * 3600)
        epoch = int(ts_utc.timestamp())
        bucket_start = datetime.fromtimestamp((epoch // window_seconds) * window_seconds, tz=timezone.utc)

        state = getattr(self, "_session_profit_state", None)
        if not isinstance(state, dict):
            state = {}
            self._session_profit_state = state

        label_state = state.setdefault(label_key, {})
        history = label_state.setdefault("history", [])
        current = label_state.get("current")

        prev_ceiling = 0.0
        if not isinstance(current, dict) or current.get("start") != bucket_start:
            if isinstance(current, dict):
                history.append(dict(current))
                limit = max(1, int(getattr(self, "SESSION_PROFIT_HISTORY_LIMIT", 6) or 1))
                if len(history) > limit:
                    del history[: len(history) - limit]
                prev_ceiling = float(current.get("profit_ceiling_r", 0.0) or 0.0)
            decay = float(getattr(self, "SESSION_PROFIT_ROLL_DECAY", 0.55) or 0.0)
            carry = float(label_state.get("rolling_ceiling", 0.0) or 0.0)
            if carry > 0 or prev_ceiling > 0:
                carry = max(carry * decay, prev_ceiling * decay)
            else:
                carry = 0.0
            label_state["rolling_ceiling"] = carry
            current = {
                "start": bucket_start,
                "realized_sum_r": 0.0,
                "realized_sum_pct": 0.0,
                "realized_count": 0,
                "realized_avg_r": 0.0,
                "peak_r": 0.0,
                "floating_net_pct": 0.0,
                "floating_peak_pct": 0.0,
                "profit_ceiling_r": carry,
                "ceiling_reason": "",
                "last_update": ts_utc,
            }
            label_state["current"] = current

        if realized_r is not None and np.isfinite(realized_r):
            current["realized_sum_r"] = float(current.get("realized_sum_r", 0.0)) + float(realized_r)
            current["realized_count"] = int(current.get("realized_count", 0) or 0) + 1
            current["realized_avg_r"] = current["realized_sum_r"] / max(1, current["realized_count"])
        if realized_pct is not None and np.isfinite(realized_pct):
            current["realized_sum_pct"] = float(current.get("realized_sum_pct", 0.0)) + float(realized_pct)

        if peak_r_candidate is not None and np.isfinite(peak_r_candidate):
            current["peak_r"] = max(float(current.get("peak_r", 0.0) or 0.0), float(peak_r_candidate))

        if floating_profit_pct is not None and np.isfinite(floating_profit_pct):
            current["floating_net_pct"] = float(floating_profit_pct)
        if floating_peak_pct is not None and np.isfinite(floating_peak_pct):
            current["floating_peak_pct"] = max(float(current.get("floating_peak_pct", 0.0) or 0.0), float(floating_peak_pct))

        base_ceiling = max(float(current.get("peak_r", 0.0) or 0.0), float(current.get("realized_avg_r", 0.0) or 0.0))
        min_ceiling = float(getattr(self, "SESSION_PROFIT_MIN_CEILING_R", 0.0) or 0.0)
        if base_ceiling <= 0 and min_ceiling > 0:
            base_ceiling = min_ceiling

        roll_alpha = float(getattr(self, "SESSION_PROFIT_ROLL_ALPHA", 0.45) or 0.0)
        roll_alpha = min(max(roll_alpha, 0.0), 1.0)
        rolling = float(label_state.get("rolling_ceiling", 0.0) or 0.0)
        if rolling <= 0:
            new_roll = base_ceiling
        elif base_ceiling <= 0:
            new_roll = rolling
        else:
            new_roll = rolling * roll_alpha + base_ceiling * (1.0 - roll_alpha)
        label_state["rolling_ceiling"] = max(new_roll, base_ceiling)
        final_ceiling = max(base_ceiling, label_state["rolling_ceiling"])
        if final_ceiling <= 0 and min_ceiling > 0:
            final_ceiling = min_ceiling

        reason_parts: List[str] = []
        if float(current.get("peak_r", 0.0) or 0.0) > 0:
            reason_parts.append("peak")
        if int(current.get("realized_count", 0) or 0) > 0 and float(current.get("realized_avg_r", 0.0) or 0.0) > 0:
            reason_parts.append("realized")
        if not reason_parts and final_ceiling > 0 and min_ceiling > 0:
            reason_parts.append("floor")

        current["profit_ceiling_r"] = float(final_ceiling)
        current["ceiling_reason"] = "+".join(reason_parts)
        current["last_update"] = ts_utc

        pad_val = float(getattr(self, "SESSION_PROFIT_CEILING_PAD", 0.0) or 0.0)

        return {
            "profit_ceiling_r": float(final_ceiling),
            "profit_ceiling_pad": pad_val,
            "session_profit_window": float(window_hours),
            "session_realized_r": float(current.get("realized_avg_r", 0.0) or 0.0),
            "session_realized_count": int(current.get("realized_count", 0) or 0),
            "session_peak_r": float(current.get("peak_r", 0.0) or 0.0),
            "session_ceiling_reason": current.get("ceiling_reason", ""),
        }

    def _session_context(self, ts: datetime) -> Dict[str, Any]:
        """教学提示：综合交易时区与当期盈亏天花板，反馈给风控/期望守卫。"""

        ctx = self._session_slot(ts)
        ts_utc = ts if ts.tzinfo else ts.replace(tzinfo=timezone.utc)
        label = str(ctx.get("label", "unknown") or "unknown")

        peak_r_candidate = 0.0
        traces = getattr(self, "_portfolio_traces", None)
        if isinstance(traces, dict) and traces:
            r_values: List[float] = []
            for tid, trace in traces.items():
                try:
                    profit_pct = float(trace.get("profit_pct", 0.0) or 0.0)
                except (TypeError, ValueError):
                    continue
                if profit_pct <= 0:
                    continue
                profile = self._lookup_trade_profile(int(tid))
                basis_pct = self._profile_risk_basis_pct(profile)
                if basis_pct > 0:
                    r_val = profit_pct / basis_pct
                    if np.isfinite(r_val) and r_val > 0:
                        r_values.append(r_val)
            if r_values:
                peak_r_candidate = max(r_values)

        floating_net_pct: Optional[float] = None
        floating_peak_pct: Optional[float] = None
        snapshot = getattr(self, "_portfolio_snapshot_cache", None)
        if isinstance(snapshot, dict):
            try:
                floating_net_pct = float(snapshot.get("net_profit_pct", 0.0) or 0.0)
            except (TypeError, ValueError):
                floating_net_pct = None
            best_raw = snapshot.get("best_profit_pct")
            if best_raw is not None:
                try:
                    floating_peak_pct = float(best_raw)
                except (TypeError, ValueError):
                    floating_peak_pct = None

        metrics = self._update_session_profit_metrics(
            ts_utc,
            label,
            peak_r_candidate=peak_r_candidate if peak_r_candidate > 0 else None,
            floating_profit_pct=floating_net_pct,
            floating_peak_pct=floating_peak_pct,
        )
        if metrics:
            ctx.update(metrics)
        return ctx

    def _macro_event_schedule(self) -> List[Dict[str, Any]]:
        """教学提示：读取并复制宏观事件列表，支持在 config 里以函数/列表覆写。"""
        raw = getattr(self, "MACRO_EVENT_WINDOWS", tuple())
        try:
            if callable(raw):
                raw = raw()
        except Exception:
            raw = tuple()
        schedule: List[Dict[str, Any]] = []
        if raw is None:
            return schedule
        for item in (raw if isinstance(raw, (list, tuple)) else [raw]):
            if isinstance(item, dict):
                schedule.append(dict(item))
        return schedule

    @staticmethod
    def _parse_event_time(val: Any) -> Optional[datetime]:
        """教学提示：兼容 ISO 字符串/时间戳/datetime，统一转换为带时区的 UTC 时间。"""
        if isinstance(val, datetime):
            return val if val.tzinfo else val.replace(tzinfo=timezone.utc)
        if isinstance(val, (int, float)):
            try:
                return datetime.fromtimestamp(float(val), tz=timezone.utc)
            except Exception:
                return None
        if isinstance(val, str):
            text = val.strip()
            if not text:
                return None
            if text.endswith("Z"):
                text = text[:-1] + "+00:00"
            try:
                dt = datetime.fromisoformat(text)
            except ValueError:
                return None
            return dt if dt.tzinfo else dt.replace(tzinfo=timezone.utc)
        return None

    def _macro_event_guard(self, now: datetime, pair: str, side: str,
                            purpose: str = "entry") -> Dict[str, Any]:
        """教学提示：根据宏观事件阶段调整闸门或直接暂停，purpose=entry/add/exit。"""
        guard = {
            "active": False,
            "phase": "none",
            "label": "",
            "bias": "",
            "tri_mult": 1.0,
            "dist_mult": 1.0,
            "add_mult": 1.0,
            "block_entry": False,
            "block_add": False,
        }
        if not bool(getattr(self, "REFLEXIVE_EVENT_ENABLE", True)):
            return guard
        schedule = self._macro_event_schedule()
        if not schedule:
            return guard
        defaults = dict(getattr(self, "EVENT_PHASE_DEFAULTS", {}))
        pre_buffer = int(getattr(self, "EVENT_PRE_COOLDOWN_MINUTES", 0))
        post_buffer = int(getattr(self, "EVENT_POST_COOLDOWN_MINUTES", 0))
        now_utc = now if now.tzinfo else now.replace(tzinfo=timezone.utc)

        chosen: Optional[Dict[str, Any]] = None
        chosen_phase = "none"
        for event in schedule:
            start = self._parse_event_time(event.get("start"))
            end = self._parse_event_time(event.get("end"))
            if start is None:
                continue
            duration = int(event.get("duration", event.get("duration_minutes", 0)) or 0)
            if end is None and duration > 0:
                end = start + timedelta(minutes=duration)
            if end is None:
                end = start + timedelta(minutes=60)
            pre = int(event.get("pre_minutes", pre_buffer))
            post = int(event.get("post_minutes", post_buffer))
            pre_start = start - timedelta(minutes=max(0, pre))
            post_end = end + timedelta(minutes=max(0, post))

            phase = None
            if pre_start <= now_utc < start:
                phase = "pre"
            elif start <= now_utc <= end:
                phase = "live"
            elif end < now_utc <= post_end:
                phase = "post"

            if phase:
                chosen = {"start": start, "end": end, **event}
                chosen_phase = phase
                break

        if not chosen or chosen_phase == "none":
            return guard

        rule = {"tri_mult": 1.0, "dist_mult": 1.0, "add_mult": 1.0, "block_entry": False, "block_add": False}
        if chosen_phase in defaults and isinstance(defaults[chosen_phase], dict):
            rule.update(defaults[chosen_phase])
        rule.update({
            "tri_mult": float(chosen.get("tri_mult", rule.get("tri_mult", 1.0))),
            "dist_mult": float(chosen.get("dist_mult", rule.get("dist_mult", 1.0))),
            "add_mult": float(chosen.get("add_mult", rule.get("add_mult", 1.0))),
            "block_entry": bool(chosen.get("block_entry", rule.get("block_entry", False))),
            "block_add": bool(chosen.get("block_add", rule.get("block_add", False))),
        })

        # purpose 细化（entry 默认使用 block_entry；加仓/减仓可用 block_add）
        block_entry = bool(rule.get("block_entry", False))
        block_add = bool(rule.get("block_add", False))
        if purpose == "add" and not block_add and block_entry:
            # 允许设置“仅禁止开新仓但可以加仓”
            block_entry = bool(chosen.get("block_entry", rule.get("block_entry", False)))
        elif purpose == "entry":
            block_add = block_add or block_entry

        guard.update({
            "active": True,
            "phase": chosen_phase,
            "label": str(chosen.get("label", "event")),
            "bias": str(chosen.get("bias", "")),
            "tri_mult": float(rule.get("tri_mult", 1.0)),
            "dist_mult": float(rule.get("dist_mult", 1.0)),
            "add_mult": float(rule.get("add_mult", 1.0)),
            "block_entry": block_entry,
            "block_add": block_add,
            "start": chosen.get("start"),
            "end": chosen.get("end"),
        })
        return guard

    def _side_priority_bias(self, pair: str, row: pd.Series,
                             session_ctx: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """教学提示：综合多周期偏置、护栏状态与反身性标签，动态评估多空优先级，避免止盈被对向信号“卡住”。"""
        result = {
            "long_score": 0.0,
            "short_score": 0.0,
            "prefer": None,
            "confidence": 0.0,
            "details": {"long": [], "short": [], "diff": 0.0},
        }
        if not bool(getattr(self, "SIDE_PRIORITY_ENABLE", True)):
            return result

        session_ctx = session_ctx or {}
        long_reasons: List[str] = []
        short_reasons: List[str] = []

        def add(side: str, value: float, reason: str) -> None:
            if not np.isfinite(value) or value == 0.0:
                return
            if side == "long":
                result["long_score"] += float(value)
                long_reasons.append(f"{reason}:{value:.2f}")
            else:
                result["short_score"] += float(value)
                short_reasons.append(f"{reason}:{value:.2f}")

        try:
            align = float(row.get("htf_alignment", 0.0) or 0.0)
            if np.isfinite(align) and align != 0.0:
                score = min(abs(align), 0.8)
                add("long" if align > 0 else "short", score, "htf_align")
        except Exception:
            pass

        tri_long = float(row.get("tri_bias_long", 0.0) or 0.0)
        tri_short = float(row.get("tri_bias_short", 0.0) or 0.0)
        if np.isfinite(tri_long) and np.isfinite(tri_short):
            tri_diff = tri_long - tri_short
            if tri_diff > 0:
                add("long", tri_diff * 0.6, "tri_bias")
            elif tri_diff < 0:
                add("short", abs(tri_diff) * 0.6, "tri_bias")

        if int(row.get("fast_lane_long", 0) or 0) == 1:
            add("long", 0.18, "fast_lane")
        if int(row.get("fast_lane_short", 0) or 0) == 1:
            add("short", 0.18, "fast_lane")
        if int(row.get("slow_lane_long", 0) or 0) == 1:
            add("long", 0.12, "slow_lane")
        if int(row.get("slow_lane_short", 0) or 0) == 1:
            add("short", 0.12, "slow_lane")

        if int(row.get("channel_mode_htf_drive", 0) or 0) == 1:
            align = float(row.get("htf_alignment", 0.0) or 0.0)
            if align > 0:
                add("long", 0.16, "htf_drive")
            elif align < 0:
                add("short", 0.16, "htf_drive")

        if int(row.get("channel_mode_narrow_trend", 0) or 0) == 1:
            align = float(row.get("htf_alignment", 0.0) or 0.0)
            if align > 0:
                add("long", 0.14, "narrow_trend")
            elif align < 0:
                add("short", 0.14, "narrow_trend")

        if int(row.get("channel_mode_wide_decay", 0) or 0) == 1:
            add("long", 0.08, "wide_decay")
            add("short", 0.08, "wide_decay")

        if int(row.get("panic_tail_short_block", 0) or 0) >= 1:
            add("long", 0.65, "panic_tail")
        if int(row.get("panic_tail_guard", 0) or 0) >= 1:
            add("long", 0.35, "panic_guard")
        if int(row.get("panic_slope_guard", 0) or 0) >= 1:
            add("long", 0.28, "panic_slope")

        if int(row.get("blowoff_tail_long_block", 0) or 0) >= 1:
            add("short", 0.60, "blowoff_tail")
        if int(row.get("blowoff_tail_guard", 0) or 0) >= 1:
            add("short", 0.32, "blowoff_guard")

        if int(row.get("reflex_stop_long", 0) or 0) >= 1:
            add("short", 0.42, "reflex_mania")
        if int(row.get("reflex_stop_short", 0) or 0) >= 1:
            add("long", 0.42, "reflex_panic")

        vol_any = int(row.get("vol_surge_any", 0) or 0)
        if vol_any == 1 and int(row.get("fast_lane_long", 0) or 0) == 1:
            add("long", 0.10, "vol_fast")
        if vol_any == 1 and int(row.get("fast_lane_short", 0) or 0) == 1:
            add("short", 0.10, "vol_fast")

        sess_bias = str(session_ctx.get("bias", "")).lower()
        if sess_bias == "bull":
            add("long", 0.06, "session")
        elif sess_bias == "bear":
            add("short", 0.06, "session")
        elif sess_bias == "calm":
            add("long", 0.03, "session")

        diff = result["long_score"] - result["short_score"]
        tol = float(self._profile_val("priority_balance_tol", getattr(self, "SIDE_PRIORITY_BALANCE_TOL", 0.08)))
        if not np.isfinite(tol):
            tol = float(getattr(self, "SIDE_PRIORITY_BALANCE_TOL", 0.08))
        if abs(diff) > tol:
            result["prefer"] = "long" if diff > 0 else "short"
            result["confidence"] = abs(diff)
        else:
            result["prefer"] = None
            result["confidence"] = abs(diff)

        result["details"] = {"long": long_reasons, "short": short_reasons, "diff": diff}
        return result

    def _position_signal_review(self, pair: str, trade: Trade, row: pd.Series,
                                 current_profit: float,
                                 session_ctx: Optional[Dict[str, Any]] = None,
                                 priority: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """教学提示：持仓后续信号复核，将强势同向/反向信号转为加仓或离场提示。"""
        review: Dict[str, Any] = {
            "action": "hold",
            "tag": "",
            "reason": "",
            "same_signal": False,
            "opp_signal": False,
            "extra": {},
        }
        if not bool(getattr(self, "POSITION_SIGNAL_REVIEW_ENABLE", True)):
            return review

        session_ctx = session_ctx or {}
        is_short = bool(getattr(trade, "is_short", False))
        same_key = "enter_short" if is_short else "enter_long"
        opp_key = "enter_long" if is_short else "enter_short"
        same_signal = int(row.get(same_key, 0) or 0) == 1
        opp_signal = int(row.get(opp_key, 0) or 0) == 1
        fast_lane = int(row.get("fast_lane_short" if is_short else "fast_lane_long", 0) or 0) == 1
        slow_lane = int(row.get("slow_lane_short" if is_short else "slow_lane_long", 0) or 0) == 1
        align = float(row.get("htf_alignment", 0.0) or 0.0)
        align = align if np.isfinite(align) else 0.0
        mania_guard = int(row.get("blowoff_tail_guard", 0) or 0) >= 1
        panic_guard = int(row.get("panic_tail_guard", 0) or 0) >= 1
        reflex_stop = int(row.get("reflex_stop_short" if is_short else "reflex_stop_long", 0) or 0) >= 1
        trade_id = int(getattr(trade, "id", 0) or 0)

        if priority is None:
            priority = self._side_priority_bias(pair, row, session_ctx=session_ctx)
        prefer = priority.get("prefer")
        confidence = float(priority.get("confidence", 0.0) or 0.0)
        opp_side = "long" if is_short else "short"
        same_side = "short" if is_short else "long"

        conf_need = float(getattr(self, "POSITION_SIGNAL_REVIEW_OPP_CONF", 0.26) or 0.0)
        same_conf_need = float(getattr(self, "POSITION_SIGNAL_REVIEW_SAME_CONF", 0.18) or 0.0)
        min_profit = float(getattr(self, "POSITION_SIGNAL_REVIEW_MIN_PROFIT", 0.0) or 0.0)
        trim_min_profit = float(getattr(self, "POSITION_SIGNAL_TRIM_MIN_PROFIT", 0.0) or 0.0)
        align_need = float(getattr(self, "POSITION_SIGNAL_REVIEW_ALIGN_NEED", 0.0) or 0.0)

        align_break = (align <= -align_need) if not is_short else (align >= align_need)
        guard_flip = (panic_guard if is_short else mania_guard) or reflex_stop

        timestamp = None
        try:
            timestamp = self._to_utc_datetime(getattr(row, "name", None))
        except Exception:
            timestamp = None

        extra = {
            "trade_id": trade_id,
            "same_signal": int(same_signal),
            "opp_signal": int(opp_signal),
            "fast_lane": int(fast_lane),
            "slow_lane": int(slow_lane),
            "align": round(align, 4),
            "prefer": prefer,
            "confidence": round(confidence, 4),
            "profit": round(float(current_profit), 6),
            "guard_flip": int(guard_flip),
            "timestamp": timestamp.isoformat() if isinstance(timestamp, datetime) else None,
        }

        action = "hold"
        tag = ""
        reason = ""

        if opp_signal:
            if guard_flip:
                action = "exit"
                tag = "tp_signal_guard"
                reason = "guard_flip"
            elif prefer == opp_side and confidence >= conf_need:
                priority_exit = (current_profit >= min_profit or align_break or current_profit <= 0)
                trim_allowed = (current_profit >= trim_min_profit)
                if priority_exit:
                    action = "exit"
                    tag = "tp_signal_priority"
                    reason = "priority_flip"
                elif trim_allowed:
                    action = "trim"
                    tag = "trim_signal_priority"
                    reason = "priority_trim"
            elif align_break and current_profit <= 0:
                action = "exit"
                tag = "tp_signal_align"
                reason = "align_break"

        if action == "hold" and same_signal:
            if prefer == same_side and confidence >= same_conf_need:
                action = "add"
                tag = "add_signal_follow"
                reason = "priority_follow"
            elif fast_lane and not guard_flip and confidence >= same_conf_need * 0.75:
                action = "add"
                tag = "add_signal_lane"
                reason = "lane_follow"

        review.update({
            "action": action,
            "tag": tag,
            "reason": reason,
            "same_signal": same_signal,
            "opp_signal": opp_signal,
            "extra": extra,
        })
        return review

    def _lock_sensitivity_value(self) -> float:
        """统一读取锁盈敏感度系数，异常输入时自动回落到 1.0。"""
        try:
            raw = float(getattr(self, "LOCK_SENSITIVITY", 1.0))
        except (TypeError, ValueError):
            raw = 1.0
        return float(np.clip(raw, 0.5, 1.5))

    def _lock_buffer_threshold(
        self,
        current_profit: float,
        risk_basis_pct: Optional[float] = None,
        last_floor_source: Optional[str] = None,
        *,
        pair: Optional[str] = None,
    ) -> float:
        """根据敏感度收紧/放宽锁盈缓冲，并允许按风险基准拉开安全距离。"""
        sens = self._lock_sensitivity_value()
        base_min = max(0.0, float(getattr(self, "LOCK_BUFFER_MIN", 0.001)))
        base_frac = max(0.0, float(getattr(self, "LOCK_BUFFER_FRAC", 0.10)))
        buffer_min = base_min * sens
        buffer_frac = base_frac * sens
        if current_profit <= 0:
            return buffer_min

        base_buffer = max(buffer_min, current_profit * buffer_frac)
        risk_buffer = 0.0
        try:
            risk_basis_val = float(risk_basis_pct) if risk_basis_pct is not None else 0.0
        except (TypeError, ValueError):
            risk_basis_val = 0.0
        if risk_basis_val > 0:
            share_override = None
            if pair:
                pair_map = getattr(self, "_exit_tuning_pair_settings", None)
                if isinstance(pair_map, dict):
                    pair_settings = pair_map.get(pair)
                    if isinstance(pair_settings, dict):
                        candidate = pair_settings.get("lock_buffer_r_share")
                        try:
                            share_val = float(candidate)
                        except (TypeError, ValueError):
                            share_val = None
                        else:
                            if np.isfinite(share_val) and share_val >= 0.0:
                                share_override = share_val
            if share_override is None:
                share_override = float(getattr(self, "LOCK_BUFFER_R_SHARE", 0.18))
            r_share = float(np.clip(share_override, 0.0, 1.0))
            if r_share > 0:
                risk_buffer = max(0.0, risk_basis_val * r_share)
        return max(base_buffer, risk_buffer)

    def _clamp_lock(
        self,
        current_profit: float,
        lock: float,
        *,
        risk_basis_pct: Optional[float] = None,
        last_floor_source: Optional[str] = None,
        pair: Optional[str] = None,
    ) -> float:
        """根据当前利润给锁盈地板留出缓冲，避免设置得过近被瞬间扫出。"""
        if current_profit <= 0 or not np.isfinite(lock):
            return 0.0 if not np.isfinite(lock) else max(0.0, lock)
        buffer = self._lock_buffer_threshold(
            current_profit,
            risk_basis_pct=risk_basis_pct,
            last_floor_source=last_floor_source,
            pair=pair,
        )
        max_lock = max(0.0, current_profit - buffer)
        return max(0.0, min(max_lock, lock))

    def _keltner_buffer_floor(self, trade: Trade, row: pd.Series, floor_pct: float,
                               is_short: bool) -> Tuple[float, Dict[str, Any]]:
        """若启用隐藏止损，则把亏损地板抬到 Keltner 边界之外，并返回调整信息。"""
        info: Dict[str, Any] = {}
        try:
            floor_val = float(floor_pct)
        except (TypeError, ValueError):
            floor_val = 0.0
        if floor_val <= 0:
            return floor_val, info
        if not bool(getattr(self, "STOPLOSS_KEL_BUFFER_ENABLE", True)):
            return floor_val, info
        buffer_share = float(getattr(self, "STOPLOSS_KEL_BUFFER_SHARE", 0.0))
        if buffer_share <= 0:
            return floor_val, info
        kel_up = row.get("kel_up")
        kel_dn = row.get("kel_dn")
        try:
            kel_up_val = float(kel_up)
            kel_dn_val = float(kel_dn)
        except (TypeError, ValueError):
            return floor_val, info
        if not (np.isfinite(kel_up_val) and np.isfinite(kel_dn_val)):
            return floor_val, info
        width = kel_up_val - kel_dn_val
        min_width = float(getattr(self, "STOPLOSS_KEL_BUFFER_MIN_WIDTH", 0.0) or 0.0)
        if not np.isfinite(width) or width <= 0 or width < min_width:
            return floor_val, info
        open_rate = getattr(trade, "open_rate", None)
        try:
            open_rate_val = float(open_rate)
        except (TypeError, ValueError):
            open_rate_val = 0.0
        if open_rate_val <= 0:
            return floor_val, info
        buffer_share = max(0.0, buffer_share)
        if not is_short:
            target_price = kel_dn_val - width * buffer_share
            target_price = max(0.0, target_price)
            needed = 1.0 - (target_price / open_rate_val)
        else:
            target_price = kel_up_val + width * buffer_share
            needed = (target_price / open_rate_val) - 1.0
        if not np.isfinite(needed):
            return floor_val, info
        needed = max(0.0, needed)
        cap_val = float(getattr(self, "STOPLOSS_KEL_BUFFER_CAP", float(self.STOPLOSS_FALLBACK)))
        if np.isfinite(cap_val) and cap_val > 0:
            needed = min(needed, cap_val)
        if needed > floor_val + 1e-6:
            info = {
                "kel_buffered": 1,
                "kel_buffer_share": round(buffer_share, 4),
                "kel_target": round(target_price, 6),
                "prev_floor": round(floor_val, 6),
                "new_floor": round(needed, 6),
            }
            floor_val = needed
        return floor_val, info

    def _flash_volatility_probe(
        self,
        df: DataFrame,
        is_short: bool,
        *,
        lookback_min: Optional[int] = None,
        lookback_max: Optional[int] = None,
    ) -> Optional[Dict[str, Any]]:
        """识别突发放量 + 极端 wick 的插针情境，返回闪电守卫上下文。"""
        if not bool(getattr(self, "FLASH_VOL_GUARD_ENABLE", True)):
            return None
        if df is None or df.empty or len(df) < 2:
            return None

        lb_min = max(1, int(lookback_min if lookback_min is not None else getattr(self, "FLASH_VOL_GUARD_LOOKBACK_MIN", 2)))
        lb_max = max(lb_min, int(lookback_max if lookback_max is not None else getattr(self, "FLASH_VOL_GUARD_LOOKBACK_MAX", 6)))
        recent = df.iloc[-(lb_max + 1) :]
        if recent.empty or len(recent) < 2:
            return None

        row = recent.iloc[-1]
        prev = recent.iloc[-2]
        try:
            close_now = float(row.get("close", 0.0) or 0.0)
            close_prev = float(prev.get("close", 0.0) or 0.0)
            open_now = float(row.get("open", close_now) or close_now)
            high_now = float(row.get("high", close_now) or close_now)
            low_now = float(row.get("low", close_now) or close_now)
        except (TypeError, ValueError):
            return None
        if close_now <= 0 or close_prev <= 0:
            return None

        wick_against_col = "wick_up_pct" if not is_short else "wick_dn_pct"
        wick_support_col = "wick_dn_pct" if not is_short else "wick_up_pct"
        wick_against = float(row.get(wick_against_col, 0.0) or 0.0)
        wick_support = float(row.get(wick_support_col, 0.0) or 0.0)
        wick_thr = max(0.0, float(getattr(self, "FLASH_VOL_GUARD_WICK_SHARE", 0.48)))
        wick_against_hit = wick_against >= wick_thr
        wick_support_hit = wick_support >= wick_thr

        volume_now = float(row.get("volume", 0.0) or 0.0)
        vol_ma_slow = float(row.get("vol_ma_slow", 0.0) or 0.0)
        if vol_ma_slow <= 0:
            vol_ma_slow = float(recent["volume"].iloc[:-1].mean() or 0.0)
        vol_ratio = 0.0
        if vol_ma_slow > 0:
            vol_ratio = volume_now / max(vol_ma_slow, 1e-12)
        vol_mult = max(0.0, float(getattr(self, "FLASH_VOL_GUARD_VOLUME_MULT", 2.2)))
        vol_hit = vol_ratio >= vol_mult

        move_pct = (close_now / close_prev) - 1.0
        move_thr = max(0.0, float(getattr(self, "FLASH_VOL_GUARD_MOVE_PCT", 0.0)))
        move_hit = abs(move_pct) >= move_thr

        body_against = (close_now < open_now) if not is_short else (close_now > open_now)
        body_support = not body_against
        mania_lane = int(row.get("blowoff_tail_guard", 0) or 0) >= 1
        panic_lane = int(row.get("panic_tail_guard", 0) or 0) >= 1

        exit_bias = vol_hit and move_hit and wick_against_hit and body_against
        defend_bias = vol_hit and wick_support_hit and (
            body_support or ((not is_short and panic_lane) or (is_short and mania_lane))
        )

        if not (exit_bias or defend_bias):
            return None

        bar_range = 0.0
        try:
            bar_range = (high_now - low_now) / max(close_now, 1e-12)
        except Exception:
            bar_range = 0.0

        ctx: Dict[str, Any] = {
            "exit_bias": bool(exit_bias),
            "defend_bias": bool(defend_bias),
            "wick_against": round(wick_against, 4),
            "wick_support": round(wick_support, 4),
            "volume_ratio": round(vol_ratio, 4),
            "move_pct": round(move_pct, 4),
            "bar_range": round(bar_range, 4),
            "mania_lane": int(mania_lane),
            "panic_lane": int(panic_lane),
        }
        ctx["vol_hit"] = int(vol_hit)
        ctx["move_hit"] = int(move_hit)
        return ctx

    def _flash_vol_exit_thresholds(
        self,
        *,
        pair: str,
        pair_cfg: Mapping[str, Any],
        age_minutes: float,
        locked_r: float,
        base_loss: float,
        base_profit_cap: float,
        current_profit: float,
        is_short: bool,
    ) -> Tuple[float, float, Dict[str, Any]]:
        """按持仓龄与锁盈 R 调整闪电守卫的退出阈值。"""

        schedule_src: Any = None
        if isinstance(pair_cfg, Mapping):
            schedule_src = pair_cfg.get("flash_vol_exit_schedule")
        if schedule_src is None:
            schedule_src = getattr(self, "FLASH_VOL_GUARD_EXIT_SCHEDULE", ())

        if isinstance(schedule_src, Mapping):
            schedule_iter: Sequence[Mapping[str, Any]] = (schedule_src,)  # type: ignore[assignment]
        elif isinstance(schedule_src, Sequence):
            schedule_iter = [entry for entry in schedule_src if isinstance(entry, Mapping)]  # type: ignore[list-item]
        else:
            schedule_iter = ()

        best_loss = float(base_loss)
        best_profit = float(base_profit_cap)
        best_meta: Dict[str, Any] = {}
        best_rank: Optional[Tuple[float, float, int]] = None

        def _coerce(val: Any, default: Optional[float] = None) -> Optional[float]:
            if val is None:
                return default
            try:
                parsed = float(val)
            except (TypeError, ValueError):
                return default
            if not np.isfinite(parsed):
                return default
            return float(parsed)

        for idx, entry in enumerate(schedule_iter):
            min_age = _coerce(entry.get("min_age", entry.get("age_min", entry.get("age"))), 0.0)
            max_age = _coerce(entry.get("max_age"))
            min_locked = _coerce(entry.get("min_locked_r", entry.get("locked_r", entry.get("min_locked"))), 0.0)
            max_locked = _coerce(entry.get("max_locked_r"))
            min_profit = _coerce(entry.get("min_profit"))
            max_profit = _coerce(entry.get("max_profit"))

            if min_age is not None and age_minutes + 1e-9 < float(min_age):
                continue
            if max_age is not None and age_minutes > float(max_age) + 1e-9:
                continue
            if min_locked is not None and locked_r + 1e-9 < float(min_locked):
                continue
            if max_locked is not None and locked_r > float(max_locked) + 1e-9:
                continue
            if min_profit is not None and current_profit + 1e-9 < float(min_profit):
                continue
            if max_profit is not None and current_profit > float(max_profit) + 1e-9:
                continue

            loss_override = _coerce(entry.get("loss", entry.get("exit_loss")))
            if loss_override is None:
                loss_mult = _coerce(entry.get("loss_mult"))
                if loss_mult is not None:
                    loss_override = float(base_loss) * float(loss_mult)

            profit_override = _coerce(entry.get("profit_cap", entry.get("profit")))
            if profit_override is None:
                profit_mult = _coerce(entry.get("profit_mult"))
                if profit_mult is not None:
                    profit_override = float(base_profit_cap) * float(profit_mult)

            if loss_override is None and profit_override is None:
                continue

            rank = (
                float(min_age) if min_age is not None else 0.0,
                float(min_locked) if min_locked is not None else 0.0,
                idx,
            )
            if best_rank is None or rank > best_rank:
                best_rank = rank
                best_loss = float(loss_override) if loss_override is not None else float(base_loss)
                best_profit = float(profit_override) if profit_override is not None else float(base_profit_cap)
                label = entry.get("label") or entry.get("name") or entry.get("id") or f"schedule_{idx}"
                best_meta = {
                    "flash_exit_schedule": str(label),
                    "schedule_min_age": float(min_age) if min_age is not None else 0.0,
                    "schedule_min_locked_r": float(min_locked) if min_locked is not None else 0.0,
                }
                if loss_override is not None:
                    best_meta["schedule_exit_loss"] = float(best_loss)
                if profit_override is not None:
                    best_meta["schedule_profit_cap"] = float(best_profit)

        return float(best_loss), float(best_profit), best_meta

    def _queue_flash_reverse(
        self,
        *,
        pair: str,
        pair_cfg: Mapping[str, Any],
        st: Dict[str, Any],
        now: datetime,
        is_short: bool,
        age_minutes: float,
        locked_r: float,
        current_profit: float,
        current_rate: float,
        flash_ctx: Optional[Dict[str, Any]],
        port_net: float,
        port_loss_pressure: float,
    ) -> Optional[Dict[str, Any]]:
        """闪电止损触发后，根据安全阈值排队一次反手机会。"""

        enable_cfg = None
        if isinstance(pair_cfg, Mapping):
            enable_cfg = pair_cfg.get("flash_vol_reverse_enable")
        enable = bool(enable_cfg) if enable_cfg is not None else bool(getattr(self, "FLASH_VOL_REVERSE_ENABLE", False))
        if not enable:
            return None

        def _cfg_float(key: str, default: float) -> float:
            if isinstance(pair_cfg, Mapping) and pair_cfg.get(key) is not None:
                try:
                    return float(pair_cfg.get(key))
                except (TypeError, ValueError):
                    return float(default)
            try:
                return float(getattr(self, key.upper(), default))  # type: ignore[attr-defined]
            except AttributeError:
                return float(default)

        def _cfg_int(key: str, default: int) -> int:
            if isinstance(pair_cfg, Mapping) and pair_cfg.get(key) is not None:
                try:
                    return int(pair_cfg.get(key))
                except (TypeError, ValueError):
                    return int(default)
            try:
                return int(getattr(self, key.upper(), default))  # type: ignore[attr-defined]
            except AttributeError:
                return int(default)

        delay_min = max(0.0, _cfg_float("flash_vol_reverse_delay_min", getattr(self, "FLASH_VOL_REVERSE_DELAY_MIN", 0.0)))
        window_min = _cfg_float("flash_vol_reverse_window_min", getattr(self, "FLASH_VOL_REVERSE_WINDOW_MIN", delay_min))
        window_min = max(delay_min, window_min)
        early_age_max = _cfg_float("flash_vol_reverse_early_age_max", getattr(self, "FLASH_VOL_REVERSE_EARLY_AGE_MAX", 0.0))
        early_profit_ceil = _cfg_float("flash_vol_reverse_early_profit_ceil", getattr(self, "FLASH_VOL_REVERSE_EARLY_PROFIT_CEIL", 0.0))
        early_delay_min = max(0.0, _cfg_float("flash_vol_reverse_early_delay_min", getattr(self, "FLASH_VOL_REVERSE_EARLY_DELAY_MIN", 0.0)))
        early_window_min = _cfg_float(
            "flash_vol_reverse_early_window_min",
            getattr(self, "FLASH_VOL_REVERSE_EARLY_WINDOW_MIN", 0.0),
        )
        if early_age_max > 0 and age_minutes <= early_age_max and current_profit <= early_profit_ceil:
            delay_min = min(delay_min, early_delay_min) if early_delay_min > 0 else delay_min
            window_min = max(window_min, delay_min + 4.0, early_window_min if early_window_min > 0 else window_min)
        max_attempts = _cfg_int("flash_vol_reverse_max_attempts", getattr(self, "FLASH_VOL_REVERSE_MAX_ATTEMPTS", 0))
        min_port_net = _cfg_float("flash_vol_reverse_min_port_net", getattr(self, "FLASH_VOL_REVERSE_MIN_PORT_NET", -0.02))
        max_loss_pressure = _cfg_float(
            "flash_vol_reverse_max_loss_pressure",
            getattr(self, "FLASH_VOL_REVERSE_MAX_LOSS_PRESSURE", 0.0),
        )
        max_signals = _cfg_int("flash_vol_reverse_max_signals", getattr(self, "FLASH_VOL_REVERSE_MAX_SIGNALS", 0))

        if port_net <= min_port_net:
            return None
        if max_loss_pressure > 0 and port_loss_pressure >= max_loss_pressure:
            return None

        reverse_state = st.setdefault("flash_reverse", {})
        attempts = int(reverse_state.get("attempts", 0))
        if max_attempts > 0 and attempts >= max_attempts:
            return None

        direction = "long" if is_short else "short"
        ready_ts = now + timedelta(minutes=delay_min)
        expire_ts = now + timedelta(minutes=window_min)

        pending: Dict[str, Any] = {
            "direction": direction,
            "trigger_ts": now.isoformat(),
            "ready_ts": ready_ts.isoformat(),
            "expire_ts": expire_ts.isoformat(),
            "price": float(current_rate),
            "profit": float(current_profit),
            "age_minutes": float(age_minutes),
            "locked_r": float(locked_r),
            "max_signals": max_signals if max_signals > 0 else None,
        }
        if isinstance(flash_ctx, dict):
            pending["volume_ratio"] = float(flash_ctx.get("volume_ratio", 0.0) or 0.0)
            pending["wick_against"] = float(flash_ctx.get("wick_against", 0.0) or 0.0)
            pending["move_pct"] = float(flash_ctx.get("move_pct", 0.0) or 0.0)

        reverse_state["pending"] = pending
        reverse_state["attempts"] = attempts + 1
        reverse_state["direction"] = direction
        reverse_state.pop("last_signal_ts", None)
        history = reverse_state.setdefault("history", [])
        history.append({**pending, "attempt": attempts + 1})
        if len(history) > 10:
            del history[:-10]

        return pending

    def _calc_dynamic_loss_floor(self, trade: Trade, row: pd.Series, atr_pct: float,
                                  pair: str,
                                  is_short: bool, fast_lane: bool, slow_lane: bool,
                                  channel_narrow: bool, channel_wide: bool, channel_decay: bool,
                                  htf_drive_lane: bool, align_score: float,
                                  panic_guard: int, blowoff_guard: int,
                                  bars_in_trade: int) -> float:
        """教学提示：亏损阶段的“自适应动态止损”，结合通道/快慢车道/时间衰减调节灵敏度。"""
        atr_pct_val = float(atr_pct if np.isfinite(atr_pct) else row.get("atr_pct", np.nan))
        if not np.isfinite(atr_pct_val) or atr_pct_val <= 0:
            return 0.0

        # 1) 基准：ATR 百分比 × 系数，并限制在安全上下限范围
        base = atr_pct_val * float(self.STOPLOSS_ATR_BASE)
        base = max(float(self.STOPLOSS_MIN_PCT), base)

        # 2) 通道宽度：极窄 → 更紧；极宽 → 更松
        width_5m = float(row.get("kel_width_5m", np.nan))
        if np.isfinite(width_5m) and width_5m > 0:
            if width_5m <= float(self.STOPLOSS_WIDTH_TIGHT):
                base *= float(self.STOPLOSS_WIDTH_TIGHTEN)
            elif width_5m >= float(self.STOPLOSS_WIDTH_LOOSE):
                base *= float(self.STOPLOSS_WIDTH_RELAX)

        # 3) 快慢车道 & 通道形态
        if fast_lane:
            base *= float(self.STOPLOSS_FAST_MULT)
        if slow_lane:
            base *= float(self.STOPLOSS_SLOW_MULT)
        if channel_narrow:
            base *= float(self.STOPLOSS_NARROW_MULT)
        if channel_wide:
            base *= float(self.STOPLOSS_WIDE_MULT)
        if channel_wide and channel_decay:
            base *= float(self.STOPLOSS_DECAY_MULT)
        if htf_drive_lane and ((not is_short and align_score >= 0.20) or (is_short and align_score <= -0.20)):
            base *= float(self.STOPLOSS_HTF_DRIVE_MULT)

        # 3.5) 强趋势放宽：多周期高度同向时给止损留出额外空间
        align_val = float(align_score if np.isfinite(align_score) else 0.0)
        align_relax_thr = float(getattr(self, "STOPLOSS_ALIGN_RELAX_THRESHOLD", 0.0) or 0.0)
        align_relax_scale = float(getattr(self, "STOPLOSS_ALIGN_RELAX_SCALE", 0.0) or 0.0)
        align_relax_max = float(getattr(self, "STOPLOSS_ALIGN_RELAX_MAX", 0.0) or 0.0)
        if align_relax_thr > 0 and align_relax_scale > 0 and align_relax_max > 0:
            if (not is_short and align_val >= align_relax_thr) or (is_short and align_val <= -align_relax_thr):
                align_over = abs(align_val) - align_relax_thr
                if align_over > 0:
                    relax_mult = 1.0 + align_over * align_relax_scale
                    base *= min(align_relax_max, max(1.0, relax_mult))

        # 3.6) 车道叠加：快/慢车道或高周期驱动齐备时进一步放宽，让顺势单能承受更深洗盘
        lane_strength = int(bool(fast_lane)) + int(bool(slow_lane)) + int(bool(htf_drive_lane))
        trend_relax_align = float(getattr(self, "STOPLOSS_TREND_RELAX_ALIGN", 0.0) or 0.0)
        trend_relax_step = float(getattr(self, "STOPLOSS_TREND_RELAX_STEP", 0.0) or 0.0)
        trend_relax_cap = float(getattr(self, "STOPLOSS_TREND_RELAX_CAP", 1.0) or 1.0)
        if lane_strength > 0 and trend_relax_step > 0 and trend_relax_align > 0:
            trend_ok = (not is_short and align_val >= trend_relax_align) or (is_short and align_val <= -trend_relax_align)
            if trend_ok:
                relax_mult = 1.0 + lane_strength * trend_relax_step
                base *= min(trend_relax_cap, max(1.0, relax_mult))

        # 4) 极端护栏：底部爆插的多单给空间，顶部诱多的空单收紧
        panic_slope_guard = int(row.get("panic_slope_guard", 0) or 0)

        relax_after = max(0, int(getattr(self, "STOPLOSS_EXTREME_RELAX_AFTER", 0)))
        relax_steps = max(1, int(getattr(self, "STOPLOSS_EXTREME_RELAX_STEPS", 1)))
        relax_target = float(getattr(self, "STOPLOSS_EXTREME_RELAX_TARGET", 1.0) or 1.0)
        relax_strong_target = float(getattr(self, "STOPLOSS_EXTREME_RELAX_STRONG_TARGET", relax_target) or relax_target)
        strong_align_thr = float(getattr(self, "STOPLOSS_EXTREME_STRONG_ALIGN", align_relax_thr if align_relax_thr > 0 else 0.0) or 0.0)

        def adjust_tight_multiplier(mult: float) -> float:
            if mult >= 1.0:
                return mult
            target = relax_target
            strong_trend = (slow_lane or
                            ((not is_short) and align_val >= strong_align_thr) or
                            (is_short and align_val <= -strong_align_thr))
            if strong_trend:
                target = max(target, relax_strong_target)
            target = max(mult, min(1.0, target))
            if bars_in_trade is None or bars_in_trade <= relax_after:
                return mult
            if target <= mult:
                return mult
            progress = min(1.0, (bars_in_trade - relax_after) / float(relax_steps))
            return mult + (target - mult) * progress

        if not is_short and panic_guard >= 1:
            base *= float(self.STOPLOSS_PANIC_RELAX)
        if is_short and panic_guard >= 1:
            base *= adjust_tight_multiplier(float(self.STOPLOSS_PANIC_TIGHT))
        if is_short and panic_slope_guard >= 1:
            base *= adjust_tight_multiplier(float(self.STOPLOSS_PANIC_SLOPE_TIGHT))
        if is_short and blowoff_guard >= 1:
            base *= adjust_tight_multiplier(float(self.STOPLOSS_MANIA_TIGHTEN))
        if not is_short and blowoff_guard >= 1:
            base *= adjust_tight_multiplier(float(self.STOPLOSS_BLOWOFF_TIGHT))

        # 5) 加仓次数：每次加仓都同步收紧止损，确保总体风险受控
        adds = max(0, int(getattr(trade, "nr_of_successful_entries", 0)))
        if adds > 0:
            base *= float(self.STOPLOSS_ADD_DECAY) ** min(adds, 4)

        # 6) 时间衰减：持仓越久越收紧，直至设定的最小乘数
        tighten_after = max(0, int(self.STOPLOSS_TIME_TIGHTEN_AFTER))
        if bars_in_trade is not None and bars_in_trade >= tighten_after > 0:
            steps = bars_in_trade - tighten_after + 1
            decay = float(self.STOPLOSS_TIME_TIGHTEN_EACH) ** max(0, steps)
            base *= max(float(self.STOPLOSS_TIME_TIGHTEN_MAX), decay)

        perf = self._performance_profile(pair) if pair else {"mode": "neutral", "drawdown_guard": False}
        if perf.get("drawdown_guard", False):
            base *= float(self.PERF_DRAW_SL_TIGHTEN)
        elif perf.get("mode") == "hot":
            base *= float(self.PERF_HOT_SL_RELAX)

        return float(np.clip(base, float(self.STOPLOSS_MIN_PCT), float(self.STOPLOSS_MAX_PCT)))

    def _review_stoploss_fallback(self,
                                  pair: str,
                                  trade: Trade,
                                  row: pd.Series,
                                  fallback_open: float,
                                  dynamic_floor: float,
                                  current_profit: float,
                                  current_time: datetime,
                                  is_short: bool,
                                  fast_lane: bool,
                                  slow_lane: bool,
                                  channel_narrow: bool,
                                  channel_wide: bool,
                                  channel_decay: bool,
                                  htf_drive_lane: bool,
                                  align_score: float,
                                  panic_guard: int,
                                  blowoff_guard: int,
                                  risk_emergency: bool) -> Optional[Dict[str, Any]]:
        """教学提示：在兜底止损触发前，再次结合多周期与宏观背景判断“止损/防守/加仓”。"""
        try:
            now = current_time if current_time.tzinfo else current_time.replace(tzinfo=timezone.utc)
        except Exception:
            now = datetime.now(timezone.utc)

        tb1h = float(row.get("trend_bias_1h", 0.0) or 0.0)
        tb4h = float(row.get("trend_bias_4h", 0.0) or 0.0)
        align_val = float(align_score if np.isfinite(align_score) else 0.0)

        align_min = float(getattr(self, "STOPLOSS_REVIEW_ALIGN_MIN", 0.18))
        align_strong = float(getattr(self, "STOPLOSS_REVIEW_ALIGN_STRONG", 0.32))

        htf_support = (not is_short and tb1h >= align_min and tb4h >= align_min * 0.6) or \
                      (is_short and tb1h <= -align_min and tb4h <= -align_min * 0.6)
        htf_pressure = (not is_short and tb1h <= -align_min and tb4h <= -align_min * 0.6) or \
                       (is_short and tb1h >= align_min and tb4h >= align_min * 0.6)

        align_support = (not is_short and align_val >= align_min) or (is_short and align_val <= -align_min)
        align_strong_flag = (not is_short and align_val >= align_strong) or (is_short and align_val <= -align_strong)

        ema_fast = float(row.get("ema_12", 0.0) or 0.0)
        ema_slow = float(row.get("ema_26", 0.0) or 0.0)
        macd_val = float(row.get("macd", 0.0) or 0.0)
        macd_sig = float(row.get("macdsignal", 0.0) or 0.0)
        micro_trend = (ema_fast >= ema_slow) if not is_short else (ema_fast <= ema_slow)
        micro_momo = (macd_val >= macd_sig) if not is_short else (macd_val <= macd_sig)
        micro_support = bool(micro_trend and micro_momo)

        contra_tail = (is_short and panic_guard >= 1) or (not is_short and blowoff_guard >= 1)
        rescue_tail = ((not is_short and panic_guard >= 1) or (is_short and blowoff_guard >= 1))

        macro_guard = self._macro_event_guard(now, pair, ("short" if is_short else "long"), purpose="stoploss")
        macro_active = bool(macro_guard.get("active", False))
        macro_phase = str(macro_guard.get("phase", ""))
        macro_bias = str(macro_guard.get("bias", ""))
        macro_block_add = bool(macro_guard.get("block_add", False))

        perf = self._performance_profile(pair) if pair else {"mode": "neutral", "drawdown_guard": False}
        draw_guard = bool(perf.get("drawdown_guard", False))

        lane_support = bool(fast_lane or slow_lane or htf_drive_lane)
        channel_decay_flag = bool(channel_wide and channel_decay)

        review: Dict[str, Any] = {
            "floor": fallback_open,
            "mode": "observe",
            "log": {
                "pending_floor": float(dynamic_floor if dynamic_floor > 0 else fallback_open),
                "fallback": float(fallback_open),
                "align": align_val,
                "tb1h": tb1h,
                "tb4h": tb4h,
                "fast_lane": int(fast_lane),
                "slow_lane": int(slow_lane),
                "htf_drive": int(htf_drive_lane),
                "panic_guard": int(panic_guard),
                "blowoff_guard": int(blowoff_guard),
                "risk_hits": int(risk_emergency),
                "macro_phase": macro_phase,
                "channel_narrow": int(channel_narrow),
                "channel_wide": int(channel_wide),
                "channel_decay": int(channel_decay),
                "profit": float(current_profit),
            }
        }

        pressure = risk_emergency or contra_tail or channel_decay_flag or (macro_active and macro_phase == "live") or draw_guard or htf_pressure
        support_ready = (htf_support or (align_support and rescue_tail)) and lane_support and not macro_block_add
        support_ready = support_ready and not pressure
        support_ready = support_ready and (micro_support or align_strong_flag)

        defend_floor = float(fallback_open) * float(getattr(self, "STOPLOSS_REVIEW_DEFEND_MULT", 0.92))
        hold_floor = float(fallback_open) * float(getattr(self, "STOPLOSS_REVIEW_HOLD_MULT", 0.96))
        tighten_floor = float(fallback_open) * float(getattr(self, "STOPLOSS_REVIEW_TIGHTEN_MULT", 0.82))

        if pressure:
            review["mode"] = "tighten"
            review["floor"] = max(float(self.STOPLOSS_MIN_PCT), tighten_floor)
            review["log"].update({
                "pressure": True,
                "macro": macro_phase,
                "macro_bias": macro_bias,
            })
            review["pair_state"] = {
                "ts": now.isoformat(),
                "mode": "tighten",
                "side": "short" if is_short else "long",
                "align": align_val,
            }
            return review

        if support_ready:
            candidate = defend_floor
            if dynamic_floor > 0:
                candidate = max(candidate, float(dynamic_floor))
            review["mode"] = "defend"
            review["floor"] = max(float(self.STOPLOSS_MIN_PCT), min(float(fallback_open), candidate))
            review["log"].update({
                "support": True,
                "macro": macro_phase,
                "macro_bias": macro_bias,
            })
            review["pair_state"] = {
                "ts": now.isoformat(),
                "mode": "defend",
                "side": "short" if is_short else "long",
                "align": align_val,
                "fast_lane": int(fast_lane),
                "slow_lane": int(slow_lane),
                "htf_drive": int(htf_drive_lane),
                "rescue_tail": int(rescue_tail),
            }
            return review

        candidate = hold_floor
        if dynamic_floor > 0:
            candidate = max(candidate, float(dynamic_floor))
        review["floor"] = max(float(self.STOPLOSS_MIN_PCT), min(float(fallback_open), candidate))
        review["log"].update({
            "support": False,
            "macro": macro_phase,
            "macro_bias": macro_bias,
        })
        return review

    def _exit_elastic_threshold(self, *, current_profit: float, fast_lane: bool, slow_lane: bool,
                                align_score: float, mania_lane: bool, panic_lane: bool,
                                perf_guard: bool, perf_hot: bool, prefer: Optional[str],
                                priority_conf: float, exit_min: float, is_short: bool,
                                channel_decay: bool, range_lane: bool) -> float:
        """根据车道/多周期/绩效状态计算当前弹性止盈阈值。"""
        base = float(getattr(self, "EXIT_SCORE_THRESHOLD_BASE", 1.05))
        threshold = base
        align_abs = float(align_score if not is_short else -align_score)
        strong_align = float(getattr(self, "EXIT_SCORE_STRONG_ALIGN", 0.26))
        moderate_align = float(getattr(self, "EXIT_SCORE_MODERATE_ALIGN", 0.16))
        profit_gate = float(getattr(self, "EXIT_SCORE_TREND_PROFIT_GATE", 0.022))
        if fast_lane and align_abs >= strong_align and current_profit >= profit_gate:
            threshold = float(getattr(self, "EXIT_SCORE_THRESHOLD_TREND", 1.55))
        elif slow_lane and align_abs >= moderate_align and current_profit >= profit_gate * 0.6:
            threshold = max(threshold, float(getattr(self, "EXIT_SCORE_THRESHOLD_SLOW", 1.24)))
        elif align_abs <= moderate_align * 0.5:
            threshold = min(threshold, float(getattr(self, "EXIT_SCORE_THRESHOLD_WEAK", 0.88)))

        if channel_decay:
            threshold *= float(getattr(self, "EXIT_SCORE_DECAY_RELAX", 0.88))
        if mania_lane or panic_lane:
            threshold *= float(getattr(self, "EXIT_SCORE_EXTREME_RELAX", 0.84))
        if perf_guard:
            threshold *= float(getattr(self, "EXIT_SCORE_PERF_GUARD_RELAX", 0.90))
        elif perf_hot:
            threshold *= float(getattr(self, "EXIT_SCORE_PERF_HOT_TIGHTEN", 1.08))

        if range_lane:
            range_profit_gate = float(getattr(self, "EXIT_RANGE_PROFIT_CEIL", 0.034))
            range_align_cap = float(getattr(self, "EXIT_RANGE_ALIGN_MAX", 0.18))
            if current_profit <= range_profit_gate and align_abs <= range_align_cap:
                threshold *= float(getattr(self, "EXIT_SCORE_RANGE_RELAX", 0.76))

        if prefer:
            prefer_side = str(prefer)
            current_side = "short" if is_short else "long"
            if prefer_side == current_side:
                threshold *= float(getattr(self, "EXIT_SCORE_PRIORITY_RELAX", 1.12))
            elif prefer_side == ("long" if is_short else "short") and priority_conf >= exit_min:
                threshold *= float(getattr(self, "EXIT_SCORE_PRIORITY_TIGHTEN", 0.82))

        if current_profit <= float(getattr(self, "EXIT_SCORE_SMALL_PROFIT_RELAX", 0.012)):
            threshold *= float(getattr(self, "EXIT_SCORE_SMALL_RELAX_MULT", 0.82))

        threshold *= self._lock_sensitivity_value()
        threshold = float(np.clip(
            threshold,
            float(getattr(self, "EXIT_SCORE_MIN", 0.68)),
            float(getattr(self, "EXIT_SCORE_MAX", 2.40)),
        ))
        return threshold

    def _estimate_exit_orderbook(self, pair: str, trade: Trade, is_short: bool,
                                 current_rate: float) -> Tuple[Optional[float], Optional[float]]:
        """估算在订单簿顶端成交时的利润，用于滑点放行判断。"""
        if not bool(getattr(self, "EXIT_BOOK_USE_ORDERBOOK", True)):
            return None, None
        depth = max(1, int(getattr(self, "EXIT_BOOK_DEPTH", 3) or 1))
        orderbook: Optional[Dict[str, Any]] = None
        dp = getattr(self, "dp", None)
        if dp is not None:
            try:
                orderbook = dp.orderbook(pair, depth)
            except Exception:
                orderbook = None
        if not orderbook:
            exchange = getattr(self, "exchange", None)
            if exchange is not None:
                try:
                    orderbook = exchange.fetch_order_book(pair, depth)  # type: ignore[attr-defined]
                except Exception:
                    orderbook = None
        if not isinstance(orderbook, dict):
            return None, None
        price: Optional[float] = None
        try:
            if is_short:
                asks: Sequence[Sequence[float]] = orderbook.get("asks") or []  # type: ignore[assignment]
                if asks:
                    price = float(asks[0][0])
            else:
                bids: Sequence[Sequence[float]] = orderbook.get("bids") or []  # type: ignore[assignment]
                if bids:
                    price = float(bids[0][0])
        except Exception:
            price = None
        if price is None or not np.isfinite(price):
            return None, None
        slip_share = max(0.0, float(getattr(self, "EXIT_BOOK_SLIPPAGE_SHARE", 0.0005) or 0.0))
        if slip_share > 0:
            if is_short:
                price *= (1.0 + slip_share)
            else:
                price *= (1.0 - slip_share)
        open_rate = getattr(trade, "open_rate", None)
        try:
            open_rate_val = float(open_rate)
        except (TypeError, ValueError):
            open_rate_val = 0.0
        if open_rate_val <= 0:
            return None, price
        if is_short:
            profit = (open_rate_val - price) / open_rate_val
        else:
            profit = (price - open_rate_val) / open_rate_val
        return float(profit), float(price)

    def _exit_elastic_context(self, trade: Trade, now: datetime, *, current_profit: float,
                              fast_lane: bool, slow_lane: bool, align_score: float,
                              mania_lane: bool, panic_lane: bool, perf_guard: bool,
                              perf_hot: bool, prefer: Optional[str], priority_conf: float,
                              exit_min: float, channel_decay: bool, range_lane: bool,
                              pair: Optional[str] = None,
                              current_rate: Optional[float] = None) -> Dict[str, Any]:
        threshold = self._exit_elastic_threshold(
            current_profit=current_profit,
            fast_lane=fast_lane,
            slow_lane=slow_lane,
            align_score=align_score,
            mania_lane=mania_lane,
            panic_lane=panic_lane,
            perf_guard=perf_guard,
            perf_hot=perf_hot,
            prefer=prefer,
            priority_conf=priority_conf,
            exit_min=exit_min,
            is_short=bool(trade.is_short),
            channel_decay=channel_decay,
            range_lane=range_lane,
        )
        now_ctx = now if now.tzinfo else now.replace(tzinfo=timezone.utc)
        ctx = {
            "threshold": threshold,
            "now": now_ctx,
            "fast_lane": bool(fast_lane),
            "slow_lane": bool(slow_lane),
            "align": align_score,
            "mania": bool(mania_lane),
            "panic": bool(panic_lane),
            "perf_guard": bool(perf_guard),
            "perf_hot": bool(perf_hot),
            "prefer": prefer,
            "priority_conf": priority_conf,
            "exit_min": exit_min,
            "current_profit": float(current_profit),
            "range_lane": bool(range_lane),
        }
        pair_name = pair or getattr(trade, "pair", None)
        if pair_name:
            book_profit, book_rate = self._estimate_exit_orderbook(
                str(pair_name),
                trade,
                bool(trade.is_short),
                float(current_rate if current_rate is not None else 0.0),
            )
            if book_profit is not None and np.isfinite(book_profit):
                ctx["book_profit"] = float(book_profit)
            if book_rate is not None and np.isfinite(book_rate):
                ctx["book_rate"] = float(book_rate)
        return ctx

    def _exit_profit_guard(self, ctx: Dict[str, Any], tag: str, current_profit: float) -> Tuple[bool, Dict[str, Any]]:
        """盈亏平衡守卫：若浮盈尚未达到最低阈值，则延迟执行弹性止盈。"""
        if not bool(getattr(self, "EXIT_PROFIT_GUARD_ENABLE", True)):
            return False, {}
        if current_profit <= 0:
            return False, {}
        tag_txt = str(tag or "")
        if tag_txt.startswith("sl_") or tag_txt.startswith("loss"):
            return False, {}

        floor_val = 0.0
        lock_sens = self._lock_sensitivity_value()
        try:
            floor_val = float(ctx.get("profit_floor", 0.0) or 0.0)
        except (TypeError, ValueError):
            floor_val = 0.0

        static_floor = float(getattr(self, "EXIT_PROFIT_GUARD_STATIC", 0.0032)) * lock_sens
        if static_floor > 0:
            floor_val = max(floor_val, static_floor)

        peak_val = ctx.get("peak_profit")
        try:
            peak_float = float(peak_val)
        except (TypeError, ValueError):
            peak_float = float("nan")
        drop_share = 0.0
        drop_abs = 0.0
        if np.isfinite(peak_float) and peak_float > 0:
            share = float(getattr(self, "EXIT_PROFIT_GUARD_PEAK_SHARE", 0.28)) * lock_sens
            share = float(np.clip(share, 0.0, 1.0))
            if share > 0:
                floor_val = max(floor_val, peak_float * share)
            drop_abs = peak_float - current_profit
            if peak_float > 0:
                drop_share = max(0.0, drop_abs / peak_float)

        tol_base = float(getattr(self, "EXIT_PROFIT_GUARD_TOLERANCE", 0.0008))
        tolerance = max(0.0, tol_base * max(0.5, lock_sens))

        book_profit_ctx = ctx.get("book_profit")
        book_rate_ctx = ctx.get("book_rate")
        try:
            book_profit_val = float(book_profit_ctx)
        except (TypeError, ValueError):
            book_profit_val = float("nan")
        try:
            book_rate_val = float(book_rate_ctx)
        except (TypeError, ValueError):
            book_rate_val = float("nan")
        book_tolerance = max(tolerance, float(getattr(self, "EXIT_PROFIT_GUARD_BOOK_TOL", tolerance)))

        relaxed = False
        force_unlock = False
        force_info: Dict[str, Any] = {}
        relax_info: Dict[str, Any] = {}
        tag_key = tag_txt.lower()
        relax_tags_cfg = getattr(self, "EXIT_PROFIT_GUARD_RELAX_TAGS", ())
        relax_tags = {str(t).strip().lower() for t in relax_tags_cfg if str(t).strip()}
        blocked = current_profit + tolerance < floor_val
        if blocked and tag_key in relax_tags:
            drop_share_need = max(0.0, float(getattr(self, "EXIT_PROFIT_GUARD_RELAX_DROP_SHARE", 0.52)))
            drop_abs_need = max(0.0, float(getattr(self, "EXIT_PROFIT_GUARD_RELAX_DROP_ABS", 0.008)))
            static_floor = float(getattr(self, "EXIT_PROFIT_GUARD_STATIC", 0.0032)) * lock_sens
            static_trigger = current_profit + tolerance <= static_floor
            relax_floor = floor_val
            clamp_flag = False
            if static_trigger:
                relax_floor = max(0.0, current_profit)
            elif np.isfinite(peak_float) and peak_float > 0:
                relax_share = float(getattr(self, "EXIT_PROFIT_GUARD_RELAX_SHARE", 0.18)) * lock_sens
                relax_share = float(np.clip(relax_share, 0.0, 1.0))
                relax_floor_candidate = peak_float * relax_share
                if bool(getattr(self, "EXIT_PROFIT_GUARD_RELAX_CLAMP_TO_PROFIT", True)):
                    profit_floor_cap = max(0.0, current_profit)
                    if profit_floor_cap < relax_floor_candidate:
                        relax_floor_candidate = profit_floor_cap
                        clamp_flag = True
                relax_floor = max(static_floor, relax_floor_candidate)
            if static_trigger or drop_share >= drop_share_need or drop_abs >= drop_abs_need:
                orig_floor = floor_val
                floor_val = min(floor_val, relax_floor)
                blocked = current_profit + tolerance < floor_val
                relaxed = True
                relax_info = {
                    "guard_relaxed": 1,
                    "relax_floor": round(floor_val, 4),
                    "drop_share": round(drop_share, 4),
                    "drop_abs": round(drop_abs, 4),
                    "orig_floor": round(orig_floor, 4),
                }
                if clamp_flag:
                    relax_info["relax_clamp_profit"] = round(max(0.0, current_profit), 4)

        if blocked and np.isfinite(book_profit_val):
            if book_profit_val + book_tolerance >= floor_val:
                blocked = False
                relaxed = True
                slip_info = {
                    "guard_slippage_relax": 1,
                    "book_profit": round(book_profit_val, 4),
                    "book_tolerance": round(book_tolerance, 4),
                }
                if np.isfinite(book_rate_val):
                    slip_info["book_rate"] = round(book_rate_val, 4)
                if relax_info:
                    relax_info.update(slip_info)
                else:
                    relax_info = dict(slip_info)

        force_floor_pct = 0.0
        force_r = float(getattr(self, "FORCE_EXIT_MIN_R", 0.0) or 0.0)
        if force_r > 0:
            risk_basis_val = ctx.get("risk_basis_pct")
            try:
                risk_basis_val = float(risk_basis_val)
            except (TypeError, ValueError):
                risk_basis_val = float(getattr(self, "STOPLOSS_FALLBACK", 0.0) or 0.0)
            if not np.isfinite(risk_basis_val) or risk_basis_val <= 0:
                risk_basis_val = float(getattr(self, "STOPLOSS_FALLBACK", 0.0) or 0.0)
            force_floor_pct = risk_basis_val * force_r if risk_basis_val > 0 else 0.0
            if force_floor_pct > 0 and current_profit + tolerance >= force_floor_pct:
                blocked = False
                relaxed = True
                force_unlock = True
                force_info = {
                    "force_lock_allow": 1,
                    "force_lock_floor": round(force_floor_pct, 4),
                    "force_lock_r": round(force_r, 3),
                }
                if np.isfinite(risk_basis_val):
                    force_info["force_lock_basis_pct"] = round(risk_basis_val, 4)

        if blocked:
            payload = {
                "profit_floor": round(floor_val, 4),
                "profit_gap": round(floor_val - current_profit, 4),
            }
            if relax_info:
                payload.update(relax_info)
            if np.isfinite(book_profit_val):
                payload.setdefault("book_profit", round(book_profit_val, 4))
                payload["book_gap"] = round(floor_val - book_profit_val, 4)
            return True, payload

        payload: Dict[str, Any] = {}
        if floor_val > 0:
            payload["profit_floor"] = round(floor_val, 4)
        if relaxed and relax_info:
            payload.update(relax_info)
        if force_unlock and force_info:
            payload.update(force_info)
        if drop_share > 0:
            payload.setdefault("drop_share", round(drop_share, 4))
        if drop_abs > 0:
            payload.setdefault("drop_abs", round(drop_abs, 4))
        return False, payload

    def _elastic_exit_score(self, pair: str, trade_id: int, side_txt: str,
                            ctx: Dict[str, Any], level: str, tag: str,
                            info: Optional[Dict[str, Any]] = None,
                            *, force: bool = False) -> Tuple[bool, float, float, Dict[str, Any]]:
        """事件叠加计分，达到阈值才放行止盈，避免单一小事件“乱跳车”。"""
        st = self._pair_state.setdefault(pair, {})
        board = st.setdefault("elastic_exit_score", {})
        threshold = float(ctx.get("threshold", getattr(self, "EXIT_SCORE_THRESHOLD_BASE", 1.05)))
        now = ctx.get("now")
        if not isinstance(now, datetime):
            now = datetime.now(timezone.utc)
        if now.tzinfo is None:
            now = now.replace(tzinfo=timezone.utc)

        if force:
            board.pop(trade_id, None)
            payload = {"threshold": threshold, "level": level}
            if info:
                payload.update(info)
            self._log_decision("弹性止盈评分", pair, side_txt, "强制", tag, payload)
            return True, threshold, threshold, {"events": []}

        cell = board.setdefault(trade_id, {"score": 0.0, "events": [], "ts": now})
        last_ts = cell.get("ts")
        try:
            if isinstance(last_ts, datetime):
                lt = last_ts if last_ts.tzinfo else last_ts.replace(tzinfo=timezone.utc)
                age_minutes = max(0.0, (now - lt).total_seconds() / 60.0)
                decay_bars = float(getattr(self, "EXIT_SCORE_DECAY_BARS", 3.5))
                tf_minutes = max(1.0, float(self._tf_minutes()))
                if decay_bars > 0 and tf_minutes > 0:
                    age_bars = age_minutes / tf_minutes
                    if age_bars > 0:
                        decay = math.exp(-age_bars / decay_bars)
                        cell["score"] *= decay
        except Exception:
            pass

        weights = dict(getattr(self, "EXIT_SCORE_WEIGHTS", {})) or {"major": 1.80, "medium": 0.82, "minor": 0.46}
        weight = float(weights.get(level, weights.get("minor", 0.46)))
        cell["score"] += weight
        entry = {
            "tag": tag,
            "level": level,
            "weight": round(weight, 4),
            "score": round(cell["score"], 4),
            "ts": now.isoformat(),
        }
        if info:
            entry["info"] = info
        events = cell.setdefault("events", [])
        events.append(entry)
        if len(events) > 8:
            cell["events"] = events[-8:]
        cell["ts"] = now

        total = float(cell.get("score", 0.0))
        remain = max(0.0, threshold - total)
        ratio = (total / threshold) if threshold > 0 else float("inf")
        passed = bool(total >= threshold)
        snapshot = {"events": list(cell.get("events", []))}
        payload = {
            "level": level,
            "score": round(total, 4),
            "threshold": round(threshold, 4),
            "remain": round(remain, 4),
        }
        if threshold > 0:
            payload["ratio"] = round(ratio, 4)
        if info:
            payload.update({k: v for k, v in info.items() if k not in payload})

        pos_weights = [float(w) for w in weights.values() if isinstance(w, (int, float)) and float(w) > 0]
        fallback_weight = min(pos_weights) if pos_weights else 1.0

        def _need_count(target_weight: float) -> int:
            if target_weight <= 0:
                target_weight = fallback_weight
            if remain <= 0:
                return 0
            return int(math.ceil(remain / target_weight))

        payload["need_major_events"] = _need_count(float(weights.get("major", fallback_weight)))
        payload["need_medium_events"] = _need_count(float(weights.get("medium", fallback_weight)))
        payload["need_minor_events"] = _need_count(float(weights.get("minor", fallback_weight)))

        fastpath_used = False
        fastpath_ratio_cfg = float(getattr(self, "EXIT_SCORE_FASTPATH_RATIO", 0.0) or 0.0)
        level_key = str(level).strip().lower()
        fastpath_levels_cfg = getattr(self, "EXIT_SCORE_FASTPATH_LEVELS", ("major",))
        if isinstance(fastpath_levels_cfg, str):
            fastpath_levels = [fastpath_levels_cfg]
        else:
            fastpath_levels = list(fastpath_levels_cfg)
        fastpath_levels = [str(item).strip().lower() for item in fastpath_levels if str(item).strip()]
        if (
            not passed
            and threshold > 0
            and fastpath_ratio_cfg > 0
            and level_key in fastpath_levels
            and ratio >= fastpath_ratio_cfg
        ):
            passed = True
            fastpath_used = True
            payload["fastpath_ratio"] = round(ratio, 4)
            payload["fastpath_level"] = level

        guard_blocked = False
        guard_info: Dict[str, Any] = {}
        current_profit = float(ctx.get("current_profit", 0.0) or 0.0)
        if passed:
            blocked, guard_info = self._exit_profit_guard(ctx, tag, current_profit)
            if guard_info:
                for k, v in guard_info.items():
                    if k not in payload:
                        payload[k] = v
            if blocked:
                guard_blocked = True
                passed = False
                if fastpath_used:
                    payload["fastpath_blocked"] = True
        elif bool(getattr(self, "EXIT_PROFIT_GUARD_ENABLE", True)) and current_profit > 0:
            _, guard_info = self._exit_profit_guard(ctx, tag, current_profit)
            if guard_info:
                for k, v in guard_info.items():
                    if k not in payload:
                        payload[k] = v
        if current_profit:
            payload.setdefault("profit", round(current_profit, 4))

        if passed:
            self._log_decision("弹性止盈评分", pair, side_txt, "执行", tag, payload)
            board.pop(trade_id, None)
        else:
            action = "延迟" if guard_blocked else "累积"
            if guard_blocked:
                payload.setdefault("profit_floor", round(float(ctx.get("profit_floor", payload.get("profit_floor", 0.0))), 4))
            self._log_decision("弹性止盈评分", pair, side_txt, action, tag, payload)

        return passed, total, threshold, snapshot

    def _calc_adaptive_lock(
        self,
        trade: Trade,
        row: pd.Series,
        current_profit: float,
        pair: Optional[str] = None,
        risk_basis_pct: Optional[float] = None,
        last_floor_source: Optional[str] = None,
    ) -> float:
        """结合 ATR 与动能信息计算动态锁盈地板。"""
        if current_profit <= 0:
            return 0.0

        lock = 0.0
        atr_pct = float(row.get("atr_pct", np.nan))
        if np.isfinite(atr_pct) and atr_pct > 0:
            # 允许的波动宽度 = ATR 百分比 * 系数（也有下限）
            allowed_pull = max(float(self.ATR_LOCK_MIN), atr_pct * float(self.ATR_LOCK_MULT))
            lock = max(lock, max(0.0, current_profit - allowed_pull))

        if current_profit >= float(self.PROFIT_LOCK_THRESHOLD):
            lock = max(lock, current_profit * float(self.PROFIT_LOCK_SHARE))

        # 动能转弱时更积极锁盈，避免价格回吐触发止损
        if trade.is_short:
            momo_weak = bool(row.get("macd", 0.0) > row.get("macdsignal", 0.0))
        else:
            momo_weak = bool(row.get("macd", 0.0) < row.get("macdsignal", 0.0))
        momo_weak = momo_weak or (int(row.get("macdh_weak_cnt", 0)) >= 2)
        if momo_weak:
            lock = max(lock, current_profit * float(self.MOMO_LOCK_SHARE))

        if pair:
            perf = self._performance_profile(pair)
            if perf.get("drawdown_guard", False):
                lock = max(lock, current_profit * float(self.PERF_DRAW_LOCK_SHARE))
            elif perf.get("mode") == "hot":
                lock *= float(self.PERF_HOT_LOCK_RELAX)

        return self._clamp_lock(
            current_profit,
            lock,
            risk_basis_pct=risk_basis_pct,
            last_floor_source=last_floor_source,
            pair=pair,
        )

    # --- Quiet 指标 ---
    def _chop(self, df: DataFrame, n: int) -> pd.Series:
        """Choppiness Index 简化（归一到 [0,1]）：越高越震荡。"""
        tr = ta.TRANGE(df)
        sum_tr = tr.rolling(n, min_periods=n).sum()
        hi = df["high"].rolling(n, min_periods=n).max()
        lo = df["low"].rolling(n, min_periods=n).min()
        rng = (hi - lo).replace(0, 1e-12)
        chop = np.log10((sum_tr / rng).clip(lower=1e-12)) / np.log10(float(n))
        return chop.clip(0.0, 1.0)

    def _er(self, close: pd.Series, n: int) -> pd.Series:
        """Kaufman Efficiency Ratio：越高越单边。"""
        signal = (close - close.shift(n)).abs()
        noise = close.diff().abs().rolling(n, min_periods=n).sum().replace(0, 1e-12)
        return (signal / noise).clip(0.0, 1.0)

    # -------------------- 启动/预设 --------------------
    def _apply_data_governance_settings(
        self,
        governance_cfg: Optional[Dict[str, Any]],
        review_cfg: Optional[Any] = None,
        freshness_cfg: Optional[Any] = None,
        scope: str = "strategy_parameters",
    ) -> None:
        """按配置调整复盘导出、数据新鲜度等治理开关。"""

        def _parse_bool(value: Any) -> Optional[bool]:
            if isinstance(value, bool):
                return bool(value)
            if isinstance(value, (int, np.integer)):
                return bool(int(value))
            if isinstance(value, str):
                val = value.strip().lower()
                if val in {"true", "1", "yes", "on"}:
                    return True
                if val in {"false", "0", "no", "off"}:
                    return False
            return None

        def _parse_float(value: Any) -> Optional[float]:
            try:
                parsed = float(value)
            except (TypeError, ValueError):
                return None
            if not np.isfinite(parsed):
                return None
            return float(parsed)

        if isinstance(governance_cfg, dict) and governance_cfg:
            review_cfg = governance_cfg.get("review_export") or governance_cfg.get("review") or review_cfg
            freshness_cfg = (
                governance_cfg.get("data_freshness")
                or governance_cfg.get("freshness")
                or freshness_cfg
            )

        changes: List[str] = []
        runtime: Dict[str, Any] = {}

        review_settings: Optional[Dict[str, Any]] = None
        if isinstance(review_cfg, dict):
            review_settings = dict(review_cfg)
        elif review_cfg is not None:
            parsed_bool = _parse_bool(review_cfg)
            if parsed_bool is not None:
                review_settings = {"json": parsed_bool, "csv": parsed_bool}
            else:
                logger.warning(
                    "[数据治理] review_export=%r 无法解析为布尔值（scope=%s），已忽略。",
                    review_cfg,
                    scope,
                )

        if review_settings:
            json_flag = review_settings.get("json")
            if json_flag is not None:
                parsed_json = _parse_bool(json_flag)
                if parsed_json is None:
                    logger.warning(
                        "[数据治理] review_export.json=%r 无法解析（scope=%s），已忽略。",
                        json_flag,
                        scope,
                    )
                else:
                    if bool(getattr(self, "REVIEW_REPORT_EXPORT_JSON", False)) != parsed_json:
                        changes.append(f"review_json={'on' if parsed_json else 'off'}")
                    self.REVIEW_REPORT_EXPORT_JSON = parsed_json
            csv_flag = review_settings.get("csv")
            if csv_flag is not None:
                parsed_csv = _parse_bool(csv_flag)
                if parsed_csv is None:
                    logger.warning(
                        "[数据治理] review_export.csv=%r 无法解析（scope=%s），已忽略。",
                        csv_flag,
                        scope,
                    )
                else:
                    if bool(getattr(self, "REVIEW_REPORT_EXPORT_CSV", False)) != parsed_csv:
                        changes.append(f"review_csv={'on' if parsed_csv else 'off'}")
                    self.REVIEW_REPORT_EXPORT_CSV = parsed_csv
            dir_value = review_settings.get("dir") or review_settings.get("path")
            if dir_value is not None:
                dir_txt = str(dir_value).strip()
                if dir_txt:
                    if str(getattr(self, "REVIEW_REPORT_EXPORT_DIR", "")).strip() != dir_txt:
                        changes.append(f"review_dir={dir_txt}")
                    self.REVIEW_REPORT_EXPORT_DIR = dir_txt
            host_value = (
                review_settings.get("host_dir")
                or review_settings.get("host_root")
                or review_settings.get("host_path")
            )
            if host_value is not None:
                host_txt = str(host_value).strip()
                if host_txt:
                    if str(getattr(self, "REVIEW_REPORT_HOST_ROOT", "") or "").strip() != host_txt:
                        changes.append(f"review_host={host_txt}")
                    self.REVIEW_REPORT_HOST_ROOT = host_txt
            split_flag: Optional[Any] = None
            split_key: Optional[str] = None
            for candidate_key in (
                "split_by_bot",
                "split",
                "markdown_split",
                "markdown_split_by_bot",
            ):
                if candidate_key in review_settings:
                    split_flag = review_settings.get(candidate_key)
                    split_key = candidate_key
                    break
            if split_flag is not None:
                parsed_split = _parse_bool(split_flag)
                if parsed_split is None:
                    logger.warning(
                        "[数据治理] review_export.%s=%r 无法解析（scope=%s），已忽略。",
                        split_key or "split",
                        split_flag,
                        scope,
                    )
                else:
                    if bool(getattr(self, "REVIEW_REPORT_SPLIT_BY_BOT", False)) != parsed_split:
                        changes.append(f"review_split={'on' if parsed_split else 'off'}")
                    self.REVIEW_REPORT_SPLIT_BY_BOT = parsed_split
            export_split_flag: Optional[Any] = None
            export_split_key: Optional[str] = None
            for candidate_key in (
                "export_split_by_bot",
                "export_split",
                "analytics_split_by_bot",
                "analytics_split",
            ):
                if candidate_key in review_settings:
                    export_split_flag = review_settings.get(candidate_key)
                    export_split_key = candidate_key
                    break
            if export_split_flag is not None:
                parsed_export_split = _parse_bool(export_split_flag)
                if parsed_export_split is None:
                    logger.warning(
                        "[数据治理] review_export.%s=%r 无法解析（scope=%s），已忽略。",
                        export_split_key,
                        export_split_flag,
                        scope,
                    )
                else:
                    if bool(getattr(self, "REVIEW_REPORT_EXPORT_SPLIT_BY_BOT", False)) != parsed_export_split:
                        changes.append(
                            f"review_export_split={'on' if parsed_export_split else 'off'}"
                        )
                    self.REVIEW_REPORT_EXPORT_SPLIT_BY_BOT = parsed_export_split
            analytics_cfg = None
            for key in ("analytics", "export", "analytics_dir"):
                val = review_settings.get(key)
                if isinstance(val, dict):
                    analytics_cfg = val
                    break
            if isinstance(analytics_cfg, dict):
                analytics_host = (
                    analytics_cfg.get("host_dir")
                    or analytics_cfg.get("host_root")
                    or analytics_cfg.get("host_path")
                )
                if analytics_host is not None:
                    host_txt = str(analytics_host).strip()
                    if host_txt:
                        if str(getattr(self, "REVIEW_REPORT_EXPORT_HOST_ROOT", "") or "").strip() != host_txt:
                            changes.append(f"analytics_host={host_txt}")
                        self.REVIEW_REPORT_EXPORT_HOST_ROOT = host_txt
                analytics_dir_override = analytics_cfg.get("dir") or analytics_cfg.get("path")
                if analytics_dir_override:
                    dir_txt = str(analytics_dir_override).strip()
                    if dir_txt:
                        if str(getattr(self, "REVIEW_REPORT_EXPORT_DIR", "")).strip() != dir_txt:
                            changes.append(f"analytics_dir={dir_txt}")
                        self.REVIEW_REPORT_EXPORT_DIR = dir_txt
                analytics_split_flag = None
                analytics_key: Optional[str] = None
                for candidate_key in ("split_by_bot", "split"):
                    if candidate_key in analytics_cfg:
                        analytics_split_flag = analytics_cfg.get(candidate_key)
                        analytics_key = f"analytics.{candidate_key}"
                        break
                if analytics_split_flag is not None:
                    parsed_analytics_split = _parse_bool(analytics_split_flag)
                    if parsed_analytics_split is None:
                        logger.warning(
                            "[数据治理] review_export.%s=%r 无法解析（scope=%s），已忽略。",
                            analytics_key or "analytics.split",
                            analytics_split_flag,
                            scope,
                        )
                    else:
                        if bool(
                            getattr(self, "REVIEW_REPORT_EXPORT_SPLIT_BY_BOT", False)
                        ) != parsed_analytics_split:
                            changes.append(
                                f"analytics_split={'on' if parsed_analytics_split else 'off'}"
                            )
                        self.REVIEW_REPORT_EXPORT_SPLIT_BY_BOT = parsed_analytics_split
            review_state_cfg = None
            for key in ("review_state", "state", "reviewstate"):
                val = review_settings.get(key)
                if isinstance(val, dict):
                    review_state_cfg = val
                    break
            if isinstance(review_state_cfg, dict):
                state_host = (
                    review_state_cfg.get("host_dir")
                    or review_state_cfg.get("host_root")
                    or review_state_cfg.get("host_path")
                )
                if state_host is not None:
                    host_txt = str(state_host).strip()
                    if host_txt:
                        if str(getattr(self, "REVIEW_STATE_HOST_ROOT", "") or "").strip() != host_txt:
                            changes.append(f"review_state_host={host_txt}")
                        self.REVIEW_STATE_HOST_ROOT = host_txt
                state_dir_override = review_state_cfg.get("dir") or review_state_cfg.get("path")
                if state_dir_override:
                    dir_txt = str(state_dir_override).strip()
                    if dir_txt:
                        if str(getattr(self, "REVIEW_STATE_EXPORT_DIR", "")).strip() != dir_txt:
                            changes.append(f"review_state_dir={dir_txt}")
                        self.REVIEW_STATE_EXPORT_DIR = dir_txt
                state_split_flag = None
                state_split_key: Optional[str] = None
                for candidate_key in ("split_by_bot", "split"):
                    if candidate_key in review_state_cfg:
                        state_split_flag = review_state_cfg.get(candidate_key)
                        state_split_key = f"review_state.{candidate_key}"
                        break
                if state_split_flag is not None:
                    parsed_state_split = _parse_bool(state_split_flag)
                    if parsed_state_split is None:
                        logger.warning(
                            "[数据治理] review_export.%s=%r 无法解析（scope=%s），已忽略。",
                            state_split_key or "review_state.split",
                            state_split_flag,
                            scope,
                        )
                    else:
                        if bool(getattr(self, "REVIEW_STATE_SPLIT_BY_BOT", False)) != parsed_state_split:
                            changes.append(
                                f"review_state_split={'on' if parsed_state_split else 'off'}"
                            )
                        self.REVIEW_STATE_SPLIT_BY_BOT = parsed_state_split
                standalone_flag = None
                standalone_key: Optional[str] = None
                for candidate_key in (
                    "standalone",
                    "standalone_export",
                    "export_standalone",
                ):
                    if candidate_key in review_state_cfg:
                        standalone_flag = review_state_cfg.get(candidate_key)
                        standalone_key = f"review_state.{candidate_key}"
                        break
                if standalone_flag is not None:
                    parsed_standalone = _parse_bool(standalone_flag)
                    if parsed_standalone is None:
                        logger.warning(
                            "[数据治理] review_export.%s=%r 无法解析（scope=%s），已忽略。",
                            standalone_key or "review_state.standalone",
                            standalone_flag,
                            scope,
                        )
                    else:
                        if bool(getattr(self, "REVIEW_STATE_EXPORT_STANDALONE", True)) != parsed_standalone:
                            changes.append(
                                f"review_state_standalone={'on' if parsed_standalone else 'off'}"
                            )
                        self.REVIEW_STATE_EXPORT_STANDALONE = parsed_standalone

        runtime["review_export_json"] = bool(getattr(self, "REVIEW_REPORT_EXPORT_JSON", False))
        runtime["review_export_csv"] = bool(getattr(self, "REVIEW_REPORT_EXPORT_CSV", False))
        runtime["review_export_dir"] = getattr(self, "REVIEW_REPORT_EXPORT_DIR", "docs/review_reports/analytics")
        runtime["review_export_host_root"] = getattr(self, "REVIEW_REPORT_HOST_ROOT", None)
        runtime["review_export_analytics_host_root"] = getattr(self, "REVIEW_REPORT_EXPORT_HOST_ROOT", None)
        runtime["review_state_host_root"] = getattr(self, "REVIEW_STATE_HOST_ROOT", None)
        runtime["review_split_by_bot"] = bool(getattr(self, "REVIEW_REPORT_SPLIT_BY_BOT", False))
        runtime["review_export_split_by_bot"] = bool(
            getattr(self, "REVIEW_REPORT_EXPORT_SPLIT_BY_BOT", False)
        )
        runtime["review_state_split_by_bot"] = bool(
            getattr(self, "REVIEW_STATE_SPLIT_BY_BOT", False)
        )
        runtime["review_state_standalone"] = bool(
            getattr(self, "REVIEW_STATE_EXPORT_STANDALONE", True)
        )

        freshness_settings: Optional[Dict[str, Any]] = None
        if isinstance(freshness_cfg, dict):
            freshness_settings = dict(freshness_cfg)
        elif freshness_cfg is not None:
            parsed_threshold = _parse_float(freshness_cfg)
            if parsed_threshold is None:
                logger.warning(
                    "[数据治理] data_freshness=%r 无法解析为数值（scope=%s），已忽略。",
                    freshness_cfg,
                    scope,
                )
            else:
                freshness_settings = {"threshold_minutes": parsed_threshold}

        if freshness_settings:
            thresh_raw = freshness_settings.get("threshold_minutes") or freshness_settings.get("threshold")
            if thresh_raw is not None:
                parsed = _parse_float(thresh_raw)
                if parsed is None:
                    logger.warning(
                        "[数据治理] data_freshness.threshold=%r 无法解析（scope=%s），已忽略。",
                        thresh_raw,
                        scope,
                    )
                else:
                    parsed = max(1.0, parsed)
                    if float(getattr(self, "DATA_STALE_THRESHOLD_MINUTES", 20.0)) != parsed:
                        changes.append(f"stale_threshold={parsed:.2f}m")
                    self.DATA_STALE_THRESHOLD_MINUTES = parsed
            recheck_raw = freshness_settings.get("recheck_minutes") or freshness_settings.get("recheck")
            if recheck_raw is not None:
                parsed = _parse_float(recheck_raw)
                if parsed is None:
                    logger.warning(
                        "[数据治理] data_freshness.recheck=%r 无法解析（scope=%s），已忽略。",
                        recheck_raw,
                        scope,
                    )
                else:
                    parsed = max(1.0, parsed)
                    if float(getattr(self, "DATA_STALE_RECHECK_MINUTES", 5.0)) != parsed:
                        changes.append(f"stale_recheck={parsed:.2f}m")
                    self.DATA_STALE_RECHECK_MINUTES = parsed
            log_cd_raw = (
                freshness_settings.get("log_cooldown_minutes")
                or freshness_settings.get("log_cooldown")
                or freshness_settings.get("log_interval")
            )
            if log_cd_raw is not None:
                parsed = _parse_float(log_cd_raw)
                if parsed is None:
                    logger.warning(
                        "[数据治理] data_freshness.log_cooldown=%r 无法解析（scope=%s），已忽略。",
                        log_cd_raw,
                        scope,
                    )
                else:
                    parsed = max(1.0, parsed)
                    if float(getattr(self, "DATA_STALE_LOG_COOLDOWN_MINUTES", 30.0)) != parsed:
                        changes.append(f"stale_log_cd={parsed:.2f}m")
                    self.DATA_STALE_LOG_COOLDOWN_MINUTES = parsed

        runtime["data_freshness_threshold_minutes"] = float(
            getattr(self, "DATA_STALE_THRESHOLD_MINUTES", 20.0)
        )
        runtime["data_freshness_recheck_minutes"] = float(
            getattr(self, "DATA_STALE_RECHECK_MINUTES", 5.0)
        )
        runtime["data_freshness_log_cooldown_minutes"] = float(
            getattr(self, "DATA_STALE_LOG_COOLDOWN_MINUTES", 30.0)
        )

        self._data_governance_runtime = runtime

        if changes:
            logger.info("[数据治理] 已应用覆盖：%s", ", ".join(changes))

        if bool(getattr(self, "REVIEW_REPORT_ENABLE", True)):
            try:
                self._review_dirs_ready = False
                self._review_prepare_directories(force=True)
            except Exception as exc:
                if self.DEBUG_LOG:
                    self._d(f"[review_prepare_failed] err={exc}")

    def bot_start(self, **kwargs) -> None:
        """读取外部 preset / tri 权重 / 软锁严格度；合并 per-pair 覆盖。"""
        try:
            cfg = getattr(self, "config", {}) or {}
            sp = (cfg.get("strategy_parameters") or {}) or {}

            entry_quality_cfg = sp.get("entry_quality")
            if isinstance(entry_quality_cfg, dict) and entry_quality_cfg:
                eq_settings = self._entry_quality_settings(
                    entry_quality_cfg,
                    scope="strategy_parameters.entry_quality",
                    log=True,
                )
                self._apply_entry_quality_settings(eq_settings)

            exit_tuning_cfg = sp.get("exit_tuning")
            if isinstance(exit_tuning_cfg, dict) and exit_tuning_cfg:
                exit_settings = self._exit_tuning_settings(
                    exit_tuning_cfg,
                    scope="strategy_parameters.exit_tuning",
                    log=True,
                )
                self._apply_exit_tuning_settings(exit_settings)

            risk_forecast_cfg = sp.get("risk_forecast")
            if isinstance(risk_forecast_cfg, dict) and risk_forecast_cfg:
                self._risk_forecast_settings_runtime = self._risk_forecast_settings(
                    risk_forecast_cfg,
                    scope="strategy_parameters.risk_forecast",
                    log=True,
                )
            else:
                # 初始化一次默认配置，避免后续每次读取都重复构建
                self._risk_forecast_settings_runtime = self._risk_forecast_settings(
                    None,
                    scope="strategy_parameters.risk_forecast",
                    log=False,
                )

            self._apply_data_governance_settings(
                sp.get("data_governance"),
                review_cfg=sp.get("review_export"),
                freshness_cfg=sp.get("data_freshness"),
                scope="strategy_parameters",
            )

            directional_cfg = sp.get("directional_guard")
            if isinstance(directional_cfg, dict) and directional_cfg:
                for key, attr, cast in (
                    ("enable", "DIRECTIONAL_SHORT_RATIO_ENABLE", bool),
                    ("short_max_ratio", "DIRECTIONAL_SHORT_MAX_RATIO", float),
                    ("short_lookback_minutes", "DIRECTIONAL_SHORT_LOOKBACK_MINUTES", float),
                    ("short_min_long", "DIRECTIONAL_SHORT_MIN_LONG", int),
                    ("short_mania_override", "DIRECTIONAL_SHORT_MANIA_OVERRIDE", bool),
                    (
                        "short_price_override_floor",
                        "DIRECTIONAL_SHORT_PRICE_OVERRIDE_FLOOR",
                        float,
                    ),
                    ("short_open_enable", "DIRECTIONAL_SHORT_OPEN_ENABLE", bool),
                    ("short_max_open", "DIRECTIONAL_SHORT_MAX_OPEN", int),
                ):
                    if key not in directional_cfg:
                        continue
                    value = directional_cfg.get(key)
                    if value is None:
                        continue
                    try:
                        if cast is bool:
                            resolved = bool(value)
                        elif cast is int:
                            resolved = int(value)
                        else:
                            resolved = float(value)
                    except (TypeError, ValueError):
                        continue
                    setattr(self, attr, resolved)

                disable_flag = None
                if directional_cfg.get("disable") is not None:
                    disable_flag = bool(directional_cfg.get("disable"))
                elif directional_cfg.get("force_disable") is not None:
                    disable_flag = bool(directional_cfg.get("force_disable"))
                if disable_flag is not None:
                    self.DIRECTIONAL_SHORT_FORCE_DISABLE = disable_flag
                    if disable_flag:
                        self.DIRECTIONAL_SHORT_RATIO_ENABLE = False
                        self.DIRECTIONAL_SHORT_OPEN_ENABLE = False
                        logger.warning(
                            "空单比例/数量守卫已被临时关闭：strategy_parameters.directional_guard.disable = True"
                        )
                    else:
                        logger.info(
                            "空单比例/数量守卫已恢复运行：strategy_parameters.directional_guard.disable = False"
                        )

            pyramiding_cfg = sp.get("pyramiding")
            if isinstance(pyramiding_cfg, dict) and pyramiding_cfg:
                for key, attr in (
                    ("max_add_amount", "PYRAMID_MAX_ADD_AMOUNT"),
                    ("max_add_pct", "PYRAMID_MAX_ADD_PCT"),
                    ("max_position_pct", "PYRAMID_MAX_POSITION_PCT"),
                ):
                    if key not in pyramiding_cfg:
                        continue
                    try:
                        setattr(self, attr, float(pyramiding_cfg.get(key)))
                    except (TypeError, ValueError):
                        continue

            daily_profit_cap_cfg = sp.get("daily_profit_cap")
            if isinstance(daily_profit_cap_cfg, dict) and daily_profit_cap_cfg:
                for key, attr, cast in (
                    ("enable", "DAILY_PROFIT_CAP_ENABLE", bool),
                    ("target_pct", "DAILY_PROFIT_CAP_PCT", float),
                    ("target_abs", "DAILY_PROFIT_CAP_ABS", float),
                    ("basis", "DAILY_PROFIT_CAP_BASIS", str),
                    ("tz_offset_hours", "DAILY_PROFIT_CAP_TZ_OFFSET", float),
                ):
                    if key not in daily_profit_cap_cfg:
                        continue
                    try:
                        value = daily_profit_cap_cfg.get(key)
                        if cast is bool:
                            setattr(self, attr, bool(value))
                        elif cast is float:
                            setattr(self, attr, float(value))
                        else:
                            setattr(self, attr, str(value))
                    except (TypeError, ValueError):
                        continue

            enable_short_cfg = sp.get("enable_short")
            if enable_short_cfg is None:
                enable_short_cfg = sp.get("can_short")
            if enable_short_cfg is None:
                enable_short_cfg = cfg.get("can_short")
            if enable_short_cfg is not None:
                new_can_short = bool(enable_short_cfg)
                self.can_short = new_can_short
                if new_can_short:
                    logger.info(
                        "策略已启用空单方向：strategy_parameters.enable_short = True"
                    )
                else:
                    logger.warning(
                        "策略已禁用空单方向：仅保留多单测试，需重新启用请将 strategy_parameters.enable_short 设为 true"
                    )

            log_decisions_cfg = sp.get("log_decisions")
            if log_decisions_cfg is not None:
                self.LOG_DECISIONS = bool(log_decisions_cfg)
            log_level_cfg = sp.get("log_decisions_level")
            if log_level_cfg is not None:
                level_txt = str(log_level_cfg).strip().lower()
                if level_txt:
                    self.LOG_DECISIONS_LEVEL = level_txt

            if bool(getattr(self, "LOG_DECISIONS", True)):
                logger.info("决策日志已启用：级别=%s", getattr(self, "LOG_DECISIONS_LEVEL", "info"))
            else:
                logger.warning("决策日志已关闭：如需在 WebUI 查看判定理由，请在 strategy_parameters.log_decisions 中启用")

            if not self._review_bot_label:
                def _clean_label(val: Any) -> Optional[str]:
                    if val is None:
                        return None
                    text = str(val).strip()
                    return text or None

                label = _clean_label(sp.get("review_label") or sp.get("review_name"))
                if label is None:
                    label = _clean_label(cfg.get("bot_name") or cfg.get("botname"))
                if label is None:
                    api_cfg = (cfg.get("api_server") or {}) if isinstance(cfg.get("api_server"), dict) else {}
                    port_val = api_cfg.get("listen_port") or api_cfg.get("listen-port") or api_cfg.get("port")
                    port_txt = _clean_label(port_val)
                    if port_txt:
                        label = f"port{port_txt}" if port_txt.isdigit() else port_txt
                if label is None:
                    user_dir = _clean_label(cfg.get("user_data_dir"))
                    if user_dir:
                        label = os.path.basename(user_dir.rstrip("/")) or user_dir
                if label is None:
                    try:
                        label = os.path.basename(os.getcwd())
                    except Exception:
                        label = "default"
                self._review_bot_label = label or "default"
                try:
                    self._review_dirs_ready = False
                    self._review_prepare_directories(force=True)
                except Exception as exc:
                    if self.DEBUG_LOG:
                        self._d(f"[review_prepare_failed] err={exc}")

            preset = sp.get("preset", None)
            if preset:
                self.PRESET = preset
            gls = sp.get("global_softlock_strictness", None)
            if gls is not None:
                self.GLOBAL_SOFTLOCK_STRICTNESS = float(gls)
            cfg_sl = cfg.get("stoploss", None)
            try:
                cfg_sl_val = float(cfg_sl)
            except (TypeError, ValueError):
                cfg_sl_val = None
            if cfg_sl_val is not None and abs(cfg_sl_val) > float(self.STOPLOSS_FALLBACK) * 1.5:
                log_fn = logger.warning
                if cfg_sl_val < 0.0 and abs(cfg_sl_val) >= float(self.STOPLOSS_FALLBACK):
                    log_fn = logger.info
                log_fn(
                    "检测到 config.stoploss=%.2f%% 与策略兜底 %.2f%% 不符，已强制同步为 %.2f%% 以保持一致。",
                    cfg_sl_val * 100.0,
                    float(self.STOPLOSS_FALLBACK) * 100.0,
                    float(self.STOPLOSS_FALLBACK) * 100.0,
                )
                cfg["stoploss"] = -float(self.STOPLOSS_FALLBACK)
                self.stoploss = -float(self.STOPLOSS_FALLBACK)
        except Exception:
            if not getattr(self, "_review_bot_label", None):
                self._review_bot_label = "default"
            pass

        try:
            fallback_sl = -float(self.STOPLOSS_FALLBACK)
            self.stoploss = fallback_sl
            if isinstance(self.config, dict):
                self.config["stoploss"] = fallback_sl
        except Exception:
            self.stoploss = -0.12

        p = (self.PRESET or "conservative").lower().strip()
        if p == "aggressive":
            self.DIST_EMA_NEED = 0.0012; self.DIST_EMA_NEAR_MIN = 0.0009
            self.ADX_TREND_MIN = 20; self.ADX_TREND_STRONG = 26
            self.GLOBAL_SOFTLOCK_STRICTNESS = min(self.GLOBAL_SOFTLOCK_STRICTNESS, 0.55)
        elif p == "neutral":
            self.DIST_EMA_NEED = 0.0013; self.DIST_EMA_NEAR_MIN = 0.00095
            self.ADX_TREND_MIN = 22; self.ADX_TREND_STRONG = 30
            self.GLOBAL_SOFTLOCK_STRICTNESS = min(self.GLOBAL_SOFTLOCK_STRICTNESS, 0.58)
        else:
            self.DIST_EMA_NEED = 0.0014; self.DIST_EMA_NEAR_MIN = 0.0010
            self.ADX_TREND_MIN = 25; self.ADX_TREND_STRONG = 40
            self.GLOBAL_SOFTLOCK_STRICTNESS = max(self.GLOBAL_SOFTLOCK_STRICTNESS, 0.60)

        try:
            po_cfg = ((self.config or {}).get("pair_overrides")) or {}
            if isinstance(po_cfg, dict) and po_cfg:
                self.pair_overrides = {**self.pair_overrides, **po_cfg}
                # 名义资金与杠杆覆写可能依赖最新 pair_overrides，重新构建配置
                self._notional_profile = self._build_account_notional_profile()
        except Exception:
            pass

        try:
            config_pairs = ((self.config or {}).get("pair_overrides")) or {}
        except Exception:
            config_pairs = {}

        pair_eq_settings: Dict[str, Dict[str, Any]] = {}
        pair_exit_settings: Dict[str, Dict[str, Any]] = {}
        pair_risk_settings: Dict[str, Dict[str, Any]] = {}
        all_pairs: Set[str] = set()
        try:
            for pair_key in (self.pair_overrides or {}).keys():
                if isinstance(pair_key, str):
                    all_pairs.add(pair_key)
        except Exception:
            pass
        if isinstance(config_pairs, dict):
            for pair_key in config_pairs.keys():
                if isinstance(pair_key, str):
                    all_pairs.add(pair_key)

        for pair_key in sorted(all_pairs):
            pair_cfg_entry = self._pair_cfg(pair_key)
            eq_override = pair_cfg_entry.get("entry_quality")
            if isinstance(eq_override, dict) and eq_override:
                pair_eq_settings[pair_key] = self._entry_quality_settings(
                    eq_override,
                    scope=f"pair:{pair_key}",
                    log=True,
                )

            exit_override = pair_cfg_entry.get("exit_tuning")
            if isinstance(exit_override, dict) and exit_override:
                parsed_exit = self._exit_tuning_settings(
                    exit_override,
                    scope=f"pair:{pair_key}",
                    log=True,
                    include_defaults=False,
                )
                if parsed_exit:
                    pair_exit_settings[pair_key] = parsed_exit

            risk_override = pair_cfg_entry.get("risk_forecast")
            if isinstance(risk_override, dict) and risk_override:
                parsed_risk = self._risk_forecast_settings(
                    risk_override,
                    scope=f"pair:{pair_key}",
                    log=True,
                    include_defaults=False,
                )
                if parsed_risk:
                    pair_risk_settings[pair_key] = parsed_risk

        self._entry_quality_pair_settings = pair_eq_settings
        self._exit_tuning_pair_settings = pair_exit_settings
        self._risk_forecast_pair_settings = pair_risk_settings

        self._audit_runtime_safety()

        try:
            snapshot = self._parameter_snapshot()
            self._parameter_baseline_snapshot = snapshot
            out_path = self._write_parameter_baseline_report(snapshot)
            if out_path:
                logger.info(
                    "参数基线已输出：%s （共 %d 项参数）",
                    out_path,
                    len(snapshot),
                )
        except Exception as exc:
            logger.warning("参数基线生成失败：%s", exc)

        try:
            self._final_pretrade_bug_sweep(stage="bot_start")
        except Exception as exc:
            logger.warning("[灾难体检] bot_start 阶段执行失败：%s", exc)

    # -------------------- 三锚权重读取 --------------------
    def _get_anchors(self) -> Tuple[List[str], List[float], Dict[str, float]]:
        """教学提示：读取三锚（方向/广度/冲击）的参考币对与权重，方便自定义市场温度计。"""
        sp = (getattr(self, "config", {}) or {}).get("strategy_parameters", {}) or {}
        anchors = sp.get("anchors", ["BTC/USDT:USDT", "ETH/USDT:USDT"])
        aw = sp.get("anchor_weights", [0.6, 0.4])
        if len(anchors) != len(aw) or len(anchors) == 0:
            anchors, aw = ["BTC/USDT:USDT", "ETH/USDT:USDT"], [0.6, 0.4]
        tw = sp.get("tri_weights", {"dir": 0.45, "breadth": 0.45, "shock": 0.10})
        s = float(tw.get("dir", 0)) + float(tw.get("breadth", 0)) + float(tw.get("shock", 0))
        tw = {"dir": 0.45, "breadth": 0.45, "shock": 0.10} if s <= 0 else {k: float(v) / s for k, v in tw.items()}
        return anchors, [float(x) for x in aw], tw

    # -------------------- 三锚：方向/广度 --------------------
    def _dir_anchor_index(self, df_base: DataFrame, anchors: List[str], aw: List[float]) -> pd.Series:
        """教学提示：方向锚=强势币是否站上均线并动能同向，值越高说明大盘多头控盘。"""
        idx = df_base.index; vals = pd.Series(0.0, index=idx)
        if not self.dp: return vals
        for a, w in zip(anchors, aw):
            try:
                inf = self.dp.get_pair_dataframe(pair=a, timeframe="1h")
                if inf is None or inf.empty: continue
                ema200 = ta.EMA(inf, timeperiod=200).ffill()
                plus_di = ta.PLUS_DI(inf, timeperiod=14).ffill()
                minus_di = ta.MINUS_DI(inf, timeperiod=14).ffill()
                macd = ta.MACD(inf); macd_hist = (macd["macd"] - macd["macdsignal"]).ffill()
                s1 = np.where(inf["close"] >= ema200, 1.0, -1.0)
                s2 = np.where(plus_di >= minus_di, 1.0, -1.0)
                s3 = np.where(macd_hist >= 0, 1.0, -1.0)
                score = 0.40 * s1 + 0.30 * s2 + 0.30 * s3
                tmp = pd.DataFrame({"score": score}, index=inf.index).reindex(idx, method="ffill")
                vals = vals + w * tmp["score"].clip(-1.0, 1.0).fillna(0.0)
            except Exception:
                continue
        return vals.clip(-1.0, 1.0)

    def _breadth_index(self, df_base: DataFrame) -> pd.Series:
        """教学提示：广度锚=白名单有多少币共振，越高代表普涨/普跌，逆势就要更谨慎。"""
        idx = df_base.index
        pairs = self.base_pairs
        if not self.dp or not pairs:
            return pd.Series(0.0, index=idx)
        pos = pd.Series(0.0, index=idx); n = 0
        for p in pairs:
            try:
                inf = self.dp.get_pair_dataframe(pair=p, timeframe="1h")
                if inf is None or inf.empty: continue
                ema200 = ta.EMA(inf, timeperiod=200).ffill()
                plus_di = ta.PLUS_DI(inf, timeperiod=14).ffill()
                minus_di = ta.MINUS_DI(inf, timeperiod=14).ffill()
                s1 = np.where(inf["close"] >= ema200, 1.0, -1.0)
                s2 = np.where(plus_di >= minus_di, 1.0, -1.0)
                sc = 0.6 * s1 + 0.4 * s2
                tmp = pd.DataFrame({"sc": sc}, index=inf.index).reindex(idx, method="ffill")
                pos = pos + tmp["sc"].clip(-1.0, 1.0).fillna(0.0); n += 1
            except Exception:
                continue
        if n <= 0: return pd.Series(0.0, index=idx)
        return (pos / float(n)).clip(-1.0, 1.0)

    def _get_micro_shock(self, pair: str, df_base: DataFrame) -> pd.Series:
        """冲击锚：综合 1m/3m/5m/15m 等微观时间框架的大影线 + 放量扫流信号。"""
        idx = df_base.index
        if not self.dp:
            return pd.Series(0.0, index=idx)

        micro_tfs = list(getattr(self, "_micro_timeframes", []) or [])
        if not micro_tfs:
            micro_tfs = list(getattr(self, "MICRO_TIMEFRAME_DEFAULT", []))

        base_minutes = float(getattr(self, "_current_tf_minutes", self._tf_minutes()))
        shock_frames: List[pd.Series] = []
        for tf in micro_tfs:
            micro_df = self._fetch_informative_df(pair, tf)
            if micro_df is None or micro_df.empty:
                continue
            micro_minutes = self._timeframe_to_minutes(tf, base_minutes)
            if micro_minutes <= 0 or micro_minutes >= base_minutes:
                continue
            ratio = max(1.0, base_minutes / micro_minutes)
            fast_win = max(3, int(round(ratio)))
            slow_win = max(fast_win * 3, int(round(ratio * 4)))
            sweep_win = max(2, int(round(max(1.0, ratio / 2.0))))
            try:
                vol_fast = micro_df["volume"].rolling(fast_win, min_periods=1).mean()
                vol_slow = micro_df["volume"].rolling(slow_win, min_periods=1).mean()
                vol_ratio = vol_fast / (vol_slow + 1e-12)
                vol_acc = vol_ratio >= 1.30
                rng = (micro_df["high"] - micro_df["low"]).replace(0, 1e-9)
                maxoc = micro_df[["open", "close"]].max(axis=1)
                minoc = micro_df[["open", "close"]].min(axis=1)
                wick_up = ((micro_df["high"] - maxoc) / rng).clip(0, 1)
                wick_dn = ((minoc - micro_df["low"]) / rng).clip(0, 1)
                big_wick = (wick_up >= 0.35) | (wick_dn >= 0.35)
                sweep = (vol_acc & big_wick).rolling(sweep_win, min_periods=1).max().astype(float)
                aligned = pd.DataFrame({"shock": sweep}, index=micro_df.index).reindex(idx, method="ffill")
                shock_frames.append(aligned["shock"].clip(0.0, 1.0).fillna(0.0))
            except Exception:
                continue

        if not shock_frames:
            return pd.Series(0.0, index=idx)

        combined = pd.concat(shock_frames, axis=1).fillna(0.0)
        return combined.max(axis=1).clip(0.0, 1.0)

    # -------------------- 指标计算 --------------------
    def informative_pairs(self) -> List[Tuple[str, str]]:
        """教学提示：告诉 freqtrade 还需要哪些时间框架的数据来做多周期判定。"""
        pairs = list(dict.fromkeys(list(self.base_pairs) + list(self.fallback_pairs)))
        return [(p, tf) for p in pairs for tf in self.informative_timeframes]

    def _fetch_informative_df(self, pair: str, timeframe: str) -> Optional[DataFrame]:
        """教学提示：统一处理多周期数据获取，缺失时设置冷却避免日志刷屏。"""
        if not self.dp:
            return None
        retry_minutes = max(1.0, float(getattr(self, "INFORMATIVE_MISSING_RETRY_MINUTES", 10.0)))
        key = (pair, timeframe)
        now_ts = time.time()
        resume_ts = self._informative_missing_until.get(key)
        if resume_ts and now_ts < resume_ts:
            return None
        try:
            inf = self.dp.get_pair_dataframe(pair=pair, timeframe=timeframe)
        except Exception:
            self._informative_missing_until[key] = now_ts + retry_minutes * 60.0
            return None
        if inf is None or inf.empty:
            self._informative_missing_until[key] = now_ts + retry_minutes * 60.0
            return None
        self._informative_missing_until.pop(key, None)
        inf = inf.copy()
        if "date" not in inf.columns:
            inf["date"] = inf.index
        return inf

    def _merge_htf_basic(self, df: DataFrame, metadata: dict) -> DataFrame:
        """教学提示：把 1h/4h 的趋势、波动、通道宽度合并到 5m 表里，供后续闸门使用。"""
        pair = metadata.get("pair", "UNKNOWN")
        for tf in self.informative_timeframes:
            inf = self._fetch_informative_df(pair, tf)
            if inf is None or inf.empty:
                continue
            try:
                inf[f"rsi_{tf}"] = ta.RSI(inf, timeperiod=14)
                inf[f"ema200_{tf}"] = ta.EMA(inf, timeperiod=200)

                ema50_tf = ta.EMA(inf, timeperiod=50)
                slope_pct = ema50_tf.pct_change(periods=3).fillna(0.0)
                slope_score = pd.Series(np.tanh(slope_pct * 12.0), index=inf.index).fillna(0.0)

                atr20_tf = ta.ATR(inf, timeperiod=20)
                kel_width_tf = ((self.KEL_MULT * atr20_tf * 2.0) / (inf["close"].abs() + 1e-12)).replace([np.inf, -np.inf], np.nan)
                kel_width_tf = kel_width_tf.clip(lower=0.0, upper=0.60).ffill().fillna(0.0)
                atr_pct_tf = (atr20_tf / (inf["close"].abs() + 1e-12)).replace([np.inf, -np.inf], np.nan)
                atr_pct_tf = atr_pct_tf.clip(lower=0.0, upper=0.60).ffill().fillna(0.0)

                macd_tf = ta.MACD(inf)
                macd_hist_tf = (macd_tf["macd"] - macd_tf["macdsignal"]).fillna(0.0)
                macd_norm = macd_hist_tf / (inf["close"].abs() + 1e-12)
                macd_score = pd.Series(np.tanh(macd_norm * 25.0), index=inf.index).fillna(0.0)

                pos_score = pd.Series(np.where(inf["close"] >= inf[f"ema200_{tf}"], 1.0, -1.0), index=inf.index)
                rsi_bias = ((inf[f"rsi_{tf}"] - 50.0) / 15.0).fillna(0.0)
                rsi_score = pd.Series(np.tanh(rsi_bias), index=inf.index).fillna(0.0)
                trend_bias = (0.40 * pos_score + 0.25 * slope_score + 0.20 * macd_score + 0.15 * rsi_score).clip(-1.0, 1.0)
                inf[f"trend_bias_{tf}"] = trend_bias
                inf[f"kel_width_{tf}"] = kel_width_tf
                inf[f"atr_pct_{tf}"] = atr_pct_tf

                merge_cols = [
                    "date",
                    f"rsi_{tf}",
                    f"ema200_{tf}",
                    f"trend_bias_{tf}",
                    f"kel_width_{tf}",
                    f"atr_pct_{tf}",
                ]
                df = merge_informative_pair(
                    df,
                    inf[merge_cols],
                    self.timeframe,
                    tf,
                    ffill=True,
                )
            except Exception as e:
                logger.warning(f"[WARN] merge {tf} fail: {e}")
        if "ema200_1h" not in df.columns:
            df["ema200_1h"] = ta.EMA(df, timeperiod=200)
        df["ema200_1h"] = df["ema200_1h"].ffill()
        df["ema200_1h"] = df["ema200_1h"].fillna(df["close"])
        if "rsi_1h" not in df.columns:
            df["rsi_1h"] = ta.RSI(df, timeperiod=14)
        if "trend_bias_1h" in df.columns:
            df["trend_bias_1h"] = df["trend_bias_1h"].ffill().fillna(0.0)
        else:
            df["trend_bias_1h"] = 0.0
        if "trend_bias_4h" in df.columns:
            df["trend_bias_4h"] = df["trend_bias_4h"].ffill().fillna(df["trend_bias_1h"])
        else:
            df["trend_bias_4h"] = df["trend_bias_1h"].copy()

        if "kel_width_1h" in df.columns:
            df["kel_width_1h"] = df["kel_width_1h"].ffill().fillna(0.0)
        else:
            df["kel_width_1h"] = ta.ATR(df, timeperiod=20)
            df["kel_width_1h"] = ((self.KEL_MULT * df["kel_width_1h"] * 2.0) / (df["close"].abs() + 1e-12)).fillna(0.0)

        if "kel_width_4h" in df.columns:
            df["kel_width_4h"] = df["kel_width_4h"].ffill().fillna(df["kel_width_1h"])
        else:
            df["kel_width_4h"] = df["kel_width_1h"].copy()

        if "atr_pct_1h" in df.columns:
            df["atr_pct_1h"] = df["atr_pct_1h"].ffill().fillna(0.0)
        else:
            df["atr_pct_1h"] = (ta.ATR(df, timeperiod=20) / (df["close"].abs() + 1e-12)).fillna(0.0)

        if "atr_pct_4h" in df.columns:
            df["atr_pct_4h"] = df["atr_pct_4h"].ffill().fillna(df["atr_pct_1h"])
        else:
            df["atr_pct_4h"] = df["atr_pct_1h"].copy()
        return df

    def populate_indicators(self, df: DataFrame, metadata: dict) -> DataFrame:
        """教学提示：核心指标计算中心，逐步构建 5m 主指标 + 多周期偏置 + 护栏标记。"""
        # 5m 基础
        df["sma_20"] = ta.SMA(df, timeperiod=20)
        df["sma_50"] = ta.SMA(df, timeperiod=50)
        df["ema_12"] = ta.EMA(df, timeperiod=12)
        df["ema_26"] = ta.EMA(df, timeperiod=26)
        df["rsi"] = ta.RSI(df, timeperiod=14)
        macd = ta.MACD(df)
        df["macd"], df["macdsignal"] = macd["macd"], macd["macdsignal"]
        df["macdhist"] = df["macd"] - df["macdsignal"]

        high_20 = df["high"].rolling(20).max(); low_20 = df["low"].rolling(20).min()
        df["price_position"] = (df["close"] - low_20) / (high_20 - low_20 + 1e-8)
        high_60 = df["high"].rolling(60).max(); low_60 = df["low"].rolling(60).min()
        df["price_pos_60"] = (df["close"] - low_60) / (high_60 - low_60 + 1e-8)
        high_240 = df["high"].rolling(240).max(); low_240 = df["low"].rolling(240).min()
        df["price_pos_240"] = (df["close"] - low_240) / (high_240 - low_240 + 1e-8)
        vwap_window = max(1, int(getattr(self, "ENTRY_PRICE_VWAP_WINDOW_BARS", self.ENTRY_PRICE_VWAP_WINDOW_BARS)))
        typical_price = (df["high"] + df["low"] + df["close"]) / 3.0
        vol = df["volume"].replace(0, np.nan)
        vwap_num = (typical_price * df["volume"]).rolling(vwap_window, min_periods=max(5, vwap_window // 3)).sum()
        vwap_den = vol.rolling(vwap_window, min_periods=max(5, vwap_window // 3)).sum()
        session_vwap = vwap_num / (vwap_den + 1e-12)
        df["session_vwap_premium"] = ((df["close"] - session_vwap) / session_vwap).replace([np.inf, -np.inf], np.nan)

        df["atr14"] = ta.ATR(df, timeperiod=14)
        df["atr_pct"] = (df["atr14"] / df["close"]).replace([np.inf, -np.inf], np.nan)
        df["adx"] = ta.ADX(df, timeperiod=14)
        df["plus_di"] = ta.PLUS_DI(df, timeperiod=14)
        df["minus_di"] = ta.MINUS_DI(df, timeperiod=14)
        df["adx_flat"] = (df["adx"] >= df["adx"].shift(1) * 0.985).astype(int)

        df = self._merge_htf_basic(df, metadata)
        df = self._apply_risk_forecast_features(df, metadata)

        tb1h = df["trend_bias_1h"] if "trend_bias_1h" in df.columns else pd.Series(0.0, index=df.index)
        tb4h = df["trend_bias_4h"] if "trend_bias_4h" in df.columns else pd.Series(0.0, index=df.index)
        df["htf_alignment"] = ((tb1h + tb4h) / 2.0).clip(-1.0, 1.0)

        strong = df["adx"] > self.ADX_TREND_MIN
        df["bias_long"]  = (strong & (df["plus_di"] > df["minus_di"]) & (df["close"] > df["ema200_1h"]) & (df["adx_flat"] == 1))
        df["bias_short"] = (strong & (df["minus_di"] > df["plus_di"]) & (df["close"] < df["ema200_1h"]) & (df["adx_flat"] == 1))

        ema200_1h = df["ema200_1h"].copy().ffill()
        close = df["close"].replace(0, np.nan)
        df["dist_ema200_1h"] = ((close - ema200_1h).abs() / close).replace([np.inf, -np.inf], np.nan).ffill().fillna(0.0)

        if self.ADAPT_DIST:
            win = 30
            dist_series = df["dist_ema200_1h"].copy()
            q60 = dist_series.rolling(win, min_periods=10).quantile(0.60)
            q40 = dist_series.rolling(win, min_periods=10).quantile(0.40)
            boost = (df["atr_pct"] / (df["atr_pct"].rolling(win).median() + 1e-12)).clip(0.7, 1.3)
            df["dist_need_adapt"] = (q60 * boost).fillna(self.DIST_EMA_NEED).clip(lower=self.DIST_EMA_NEAR_MIN*1.05, upper=self.DIST_EMA_NEED*2.0)
            df["dist_near_min_adapt"] = (q40 * (boost * 0.9)).fillna(self.DIST_EMA_NEAR_MIN).clip(lower=self.DIST_EMA_NEAR_MIN*0.5, upper=self.DIST_EMA_NEED*0.95)
        else:
            df["dist_need_adapt"] = self.DIST_EMA_NEED
            df["dist_near_min_adapt"] = self.DIST_EMA_NEAR_MIN
        df["dist_need_used"] = df["dist_need_adapt"]; df["dist_near_min_used"] = df["dist_near_min_adapt"]

        # EMA 交叉
        bull_now = (df["ema_12"] > df["ema_26"]) & (df["ema_12"].shift(1) <= df["ema_26"].shift(1))
        bear_now = (df["ema_12"] < df["ema_26"]) & (df["ema_12"].shift(1) >= df["ema_26"].shift(1))
        df["bull_cross_now"] = bull_now.astype(int); df["bear_cross_now"] = bear_now.astype(int)
        look = int(self.REENTRY_LOOKBACK)
        df["bull_cross_recent"] = df["bull_cross_now"].rolling(look, min_periods=1).max().astype(int)
        df["bear_cross_recent"] = df["bear_cross_now"].rolling(look, min_periods=1).max().astype(int)

        # 趋势补票
        df["trend_reentry_long_now"]  = (df["bias_long"]  & (df["adx"] >= self.ADX_TREND_STRONG) & (df["macd"] > df["macdsignal"]) & (df["macdhist"] > 0) & (df["bull_cross_now"] == 1)).astype(int)
        df["trend_reentry_short_now"] = (df["bias_short"] & (df["adx"] >= self.ADX_TREND_STRONG) & (df["macd"] < df["macdsignal"]) & (df["macdhist"] < 0) & (df["bear_cross_now"] == 1)).astype(int)
        df["trend_reentry_long_recent"]  = (df["bias_long"]  & (df["adx"] >= self.ADX_TREND_STRONG) & (df["macd"] > df["macdsignal"]) & (df["macdhist"] > 0) & (df["bull_cross_recent"] == 1)).astype(int)
        df["trend_reentry_short_recent"] = (df["bias_short"] & (df["adx"] >= self.ADX_TREND_STRONG) & (df["macd"] < df["macdsignal"]) & (df["macdhist"] < 0) & (df["bear_cross_recent"] == 1)).astype(int)

        # Keltner
        ema_mid = ta.EMA(df, timeperiod=20); atr20 = ta.ATR(df, timeperiod=20)
        df["kel_mid"] = ema_mid; df["kel_up"] = ema_mid + self.KEL_MULT * atr20; df["kel_dn"] = ema_mid - self.KEL_MULT * atr20
        df["kel_outside_up"] = (df["close"] >= df["kel_up"]).astype(int)
        df["kel_outside_dn"] = (df["close"] <= df["kel_dn"]).astype(int)
        df["kel_break_up_now"] = ((df["close"] >= df["kel_up"]) & (df["close"].shift(1) < df["kel_up"].shift(1))).astype(int)
        df["kel_break_dn_now"] = ((df["close"] <= df["kel_dn"]) & (df["close"].shift(1) > df["kel_dn"].shift(1))).astype(int)

        # MACD 动能走弱计数
        macdh_dec = (df["macdhist"] < df["macdhist"].shift(1)).astype(int)
        df["macdh_weak_cnt"] = macdh_dec.rolling(5, min_periods=1).sum()

        # RFS（Rally Fitness Score）
        adx_norm = (df["adx"].clip(10, 45) - 10) / (45 - 10)
        same_side = (((df["close"] > df["ema200_1h"]) & (df["plus_di"] > df["minus_di"])) |
                     ((df["close"] < df["ema200_1h"]) & (df["minus_di"] > df["plus_di"]))).astype(int)
        mom_agree = (((df["macd"] - df["macdsignal"]) * df["macdhist"]) > 0).astype(int)
        adx_up = (df["adx"] >= df["adx"].shift(1)).astype(int)
        df["RFS"] = (0.40 * adx_norm.fillna(0) + 0.25 * same_side.fillna(0) + 0.20 * mom_agree.fillna(0) + 0.15 * adx_up.fillna(0)).clip(0, 1)

        df["slow_lane_long"] = ((tb1h > 0.25) & (tb4h > 0.05)).astype(int)
        df["slow_lane_short"] = ((tb1h < -0.25) & (tb4h < -0.05)).astype(int)
        rfs_gate = max(0.5, float(getattr(self, "RFS_HOLD_THR", 0.30)) * 0.9)
        df["fast_lane_long"] = ((df["RFS"] >= rfs_gate) & (df["macdhist"] > 0) & (tb1h > -0.30)).astype(int)
        df["fast_lane_short"] = ((df["RFS"] >= rfs_gate) & (df["macdhist"] < 0) & (tb1h < 0.30)).astype(int)

        # 影线/实体占比
        rng = (df["high"] - df["low"]).replace(0, 1e-9)
        maxoc = df[["open", "close"]].max(axis=1); minoc = df[["open", "close"]].min(axis=1)
        df["wick_up_pct"] = ((df["high"] - maxoc) / rng).clip(0, 1)
        df["wick_dn_pct"] = ((minoc - df["low"]) / rng).clip(0, 1)
        df["body_pct"]    = ((df["close"] - df["open"]).abs() / rng).clip(0, 1)
        df["pullback_ready_long"] = (
            (df["macdh_weak_cnt"] >= 2)
            | (df["wick_dn_pct"] >= 0.25)
        ).astype(int)
        df["pullback_ready_short"] = (
            (df["macdh_weak_cnt"] >= 2)
            | (df["wick_up_pct"] >= 0.25)
        ).astype(int)

        # 爆插后反抽：检测大幅下插伴随强力回拉（易诱发反手误空）
        # 教学提示：pierce_atr 衡量影线插入深度，rebound_atr 衡量拉回力度，
        #           同时满足时判定为“恐慌针”，之后的数根 K 线会禁止做空。
        prev_close = df["close"].shift(1)
        atr_prev = df["atr14"].shift(1)
        pierce_atr = ((prev_close - df["low"]) / (atr_prev + 1e-12)).clip(lower=0)
        rebound_atr = ((df["close"] - df["low"]) / (df["atr14"] + 1e-12)).clip(lower=0)
        panic_tail = (
            (pierce_atr >= float(self.PANIC_PIERCE_ATR)) &
            (df["wick_dn_pct"] >= float(self.PANIC_WICK_SHARE)) &
            (rebound_atr >= float(self.PANIC_REBOUND_ATR)) &
            (df["close"] >= df["open"])
        )
        df["panic_tail_short_block"] = panic_tail.astype(int)
        guard_bars = max(1, int(self.PANIC_GUARD_BARS))

        # 连续瀑布保护：即使没有长影线，只要持续暴跌后出现明显反弹，也视作恐慌尾声
        slope_lb = max(1, int(self.PANIC_SLOPE_LOOKBACK))
        prev_close_lb = df["close"].shift(slope_lb)
        atr_curr = (df["atr14"] + 1e-12)
        slope_drop = ((prev_close_lb - df["close"]) / atr_curr).replace([np.inf, -np.inf], 0).fillna(0)
        recent_low = df["low"].rolling(slope_lb, min_periods=1).min()
        slope_rebound = ((df["close"] - recent_low) / atr_curr).clip(lower=0).fillna(0)
        df["panic_slope_drop_atr"] = slope_drop
        df["panic_slope_rebound_atr"] = slope_rebound
        panic_slope = (
            (slope_drop >= float(self.PANIC_SLOPE_DROP_ATR)) &
            (slope_rebound >= float(self.PANIC_SLOPE_REBOUND_ATR)) &
            (df["close"] >= df["open"])
        )
        df["panic_slope_short_block"] = panic_slope.astype(int)
        guard_slope = max(guard_bars, int(self.PANIC_SLOPE_GUARD_BARS))
        df["panic_slope_guard"] = df["panic_slope_short_block"].rolling(guard_slope, min_periods=1).max().astype(int)

        combined_block = np.maximum(df["panic_tail_short_block"], df["panic_slope_short_block"])
        df["panic_tail_guard"] = combined_block.rolling(max(guard_bars, guard_slope), min_periods=1).max().astype(int)

        # 瀑布前夕：检测上影线冲高回落（诱多），保护开空节奏
        # 教学提示：pierce_up_atr 是冲高程度，fade_atr 是回落幅度，确认“拉高出货”后暂停追多。
        pierce_up_atr = ((df["high"] - prev_close) / (atr_prev + 1e-12)).clip(lower=0)
        fade_atr = ((df["high"] - df["close"]) / (df["atr14"] + 1e-12)).clip(lower=0)
        blowoff_tail = (
            (pierce_up_atr >= float(self.BLOWOFF_PIERCE_ATR)) &
            (df["wick_up_pct"] >= float(self.BLOWOFF_WICK_SHARE)) &
            (fade_atr >= float(self.BLOWOFF_FADE_ATR)) &
            (df["close"] <= df["open"]) &
            (df["close"] <= prev_close)
        )
        df["blowoff_tail_long_block"] = blowoff_tail.astype(int)
        guard_bars_top = max(1, int(self.BLOWOFF_GUARD_BARS))
        df["blowoff_tail_guard"] = df["blowoff_tail_long_block"].rolling(guard_bars_top, min_periods=1).max().astype(int)

        # 结构台阶/假破
        plp = 5; php = 5; K = 3
        piv_lo = (df["low"] == df["low"].rolling(plp, min_periods=plp).min())
        piv_hi = (df["high"] == df["high"].rolling(php, min_periods=php).max())
        df["pivot_low"]  = (piv_lo & piv_lo.shift(1)).astype(int)
        df["pivot_high"] = (piv_hi & piv_hi.shift(1)).astype(int)
        atr = df["atr14"].fillna(0)
        last_ph = df["high"].where(df["pivot_high"] == 1).ffill()
        last_pl = df["low"].where(df["pivot_low"] == 1).ffill()
        df["new_HH"] = ((df["pivot_high"] == 1) & (df["high"] >= (last_ph.shift(1) + atr * self.STRUCT_STEP_ATR))).astype(int)
        df["new_LL"] = ((df["pivot_low"]  == 1) & (df["low"]  <= (last_pl.shift(1)  - atr * self.STRUCT_STEP_ATR))).astype(int)

        # 结构破位（确认）
        df["struct_trail_long"]  = df["low"].where(df["pivot_low"]  == 1).ffill(limit=500).rolling(K, min_periods=1).min()
        df["struct_trail_short"] = df["high"].where(df["pivot_high"] == 1).ffill(limit=500).rolling(K, min_periods=1).max()
        df["break_below_struct"] = (df["close"] < (df["struct_trail_long"]  - atr * self.EXIT_ATR_PAD))
        df["break_above_struct"] = (df["close"] > (df["struct_trail_short"] + atr * self.EXIT_ATR_PAD))
        df["breakL_conf"] = (df["break_below_struct"].rolling(self.EXIT_CONFIRM_BARS, min_periods=self.EXIT_CONFIRM_BARS).sum() >= self.EXIT_CONFIRM_BARS).astype(int)
        df["breakS_conf"] = (df["break_above_struct"].rolling(self.EXIT_CONFIRM_BARS, min_periods=self.EXIT_CONFIRM_BARS).sum() >= self.EXIT_CONFIRM_BARS).astype(int)
        df["stoprun_long"]  = (df["break_below_struct"] & (df["wick_dn_pct"] >= self.WICK_FILTER)).astype(int)
        df["stoprun_short"] = (df["break_above_struct"] & (df["wick_up_pct"] >= self.WICK_FILTER)).astype(int)

        # 成交量
        vol_accel_mult = float(self._profile_val("vol_accel_mult", 1.0) or 1.0)
        vol_surge_mult = float(self._profile_val("vol_surge_mult", 1.0) or 1.0)
        if "volume" in df.columns:
            df["vol_ma_fast"] = df["volume"].rolling(int(self.VOL_MA_FAST), min_periods=1).mean()
            df["vol_ma_slow"] = df["volume"].rolling(int(self.VOL_MA_SLOW), min_periods=1).mean()
            vratio = (df["vol_ma_fast"] / (df["vol_ma_slow"] + 1e-12))
            df["vol_accel"] = (vratio >= float(self.VOL_ACCEL_RATIO) * vol_accel_mult).astype(int)
            df["vol_surge"] = (df["volume"] >= df["vol_ma_slow"] * float(self.VOL_SURGE_MULT) * vol_surge_mult).astype(int)
            df["vol_surge_any"] = ((df["vol_accel"] == 1) | (df["vol_surge"] == 1)).astype(int)
        else:
            df["vol_accel"] = 0; df["vol_surge"] = 0; df["vol_surge_any"] = 0

        # 软反身性：结合价格偏离与量能/波动反馈，识别趋势末端能量崩塌
        reflex_win = max(2, int(self.REFLEXIVE_WINDOW))
        ema_ref = df.get("ema200_1h", df["close"].rolling(48, min_periods=1).mean())
        perception = ((df["close"] - ema_ref) / (ema_ref.abs() + 1e-12)).fillna(0.0)
        vol_ref = df.get("vol_ma_slow") if "vol_ma_slow" in df else None
        if vol_ref is not None:
            vol_ratio = (df["volume"] / (vol_ref.replace(0, np.nan) + 1e-12)) - 1.0
        else:
            vol_ratio = pd.Series(0.0, index=df.index)
        atr_mean = df["atr14"].rolling(reflex_win, min_periods=1).mean()
        atr_ratio = (df["atr14"] / (atr_mean + 1e-12)) - 1.0
        reality = (0.55 * vol_ratio.fillna(0.0)) + (0.45 * atr_ratio.fillna(0.0))
        feedback = perception * reality
        feedback_ma = feedback.rolling(reflex_win, min_periods=1).mean()
        feedback_std = feedback.rolling(reflex_win, min_periods=2).std().replace(0.0, np.nan)
        feedback_z = (feedback - feedback_ma) / (feedback_std + 1e-9)
        feedback_peak = feedback_ma.rolling(reflex_win, min_periods=1).max().shift(1)
        feedback_trough = feedback_ma.rolling(reflex_win, min_periods=1).min().shift(1)
        drop_ratio = feedback_ma / (feedback_peak.replace(0.0, np.nan) + 1e-12)
        rebound_ratio = feedback_ma / (feedback_trough.replace(0.0, np.nan) + 1e-12)
        perception_prev = perception.shift(1)
        mania_flip = (
            (perception_prev.abs() >= float(self.REFLEXIVE_PERCEPTION_MIN))
            & (perception_prev > 0)
            & (feedback_peak >= float(self.REFLEXIVE_PEAK_THR))
            & (
                (drop_ratio <= (1.0 - float(self.REFLEXIVE_DROP_RATIO)))
                | (feedback_z <= -float(self.REFLEXIVE_Z_THR))
            )
        )
        panic_flip = (
            (perception_prev.abs() >= float(self.REFLEXIVE_PERCEPTION_MIN))
            & (perception_prev < 0)
            & (feedback_trough <= -float(self.REFLEXIVE_PEAK_THR))
            & (
                (rebound_ratio >= (1.0 + float(self.REFLEXIVE_REBOUND_RATIO)))
                | (feedback_z >= float(self.REFLEXIVE_Z_THR))
            )
        )
        guard_len = max(1, int(self.REFLEXIVE_GUARD_BARS))
        df["reflex_stop_long_raw"] = mania_flip.astype(int)
        df["reflex_stop_short_raw"] = panic_flip.astype(int)
        df["reflex_stop_long"] = df["reflex_stop_long_raw"].rolling(guard_len, min_periods=1).max().astype(int)
        df["reflex_stop_short"] = df["reflex_stop_short_raw"].rolling(guard_len, min_periods=1).max().astype(int)
        df["reflex_feedback"] = feedback
        df["reflex_feedback_ma"] = feedback_ma
        df["reflex_feedback_z"] = feedback_z.fillna(0.0)

        # 三锚
        anchors, aw, tw = self._get_anchors()
        dir_idx = self._dir_anchor_index(df, anchors, aw)
        breadth_idx = self._breadth_index(df)
        shock_idx = self._get_micro_shock(metadata.get("pair", ""), df)
        df["tri_dir"] = dir_idx; df["tri_breadth"] = breadth_idx; df["tri_shock"] = shock_idx
        df["tri_bias_long"]  = ((dir_idx+1)/2 * tw["dir"] + (breadth_idx+1)/2 * tw["breadth"] + (1.0 - shock_idx) * tw["shock"])
        df["tri_bias_short"] = ((1-(dir_idx+1)/2) * tw["dir"] + (1-(breadth_idx+1)/2) * tw["breadth"] + (1.0 - shock_idx) * tw["shock"])

        # Quiet：Choppiness & ER
        df["chop"] = self._chop(df, int(self.CHOP_N))
        df["er"]   = self._er(df["close"], int(self.ER_N))

        df["kel_width_5m"] = ((df["kel_up"] - df["kel_dn"]) / (df["close"].abs() + 1e-12)).replace([np.inf, -np.inf], np.nan)
        df["kel_width_5m"] = df["kel_width_5m"].clip(lower=0.0, upper=0.60).ffill().fillna(0.0)
        width_5m_smooth = df["kel_width_5m"].rolling(3, min_periods=1).mean()
        width_1h = df["kel_width_1h"].replace([np.inf, -np.inf, 0], np.nan).fillna(df["kel_width_5m"].rolling(12, min_periods=1).mean())
        width_4h = df["kel_width_4h"].replace([np.inf, -np.inf, 0], np.nan).fillna(width_1h)
        # 教学提示：ratio < 1 表示短周期变窄（趋势积蓄动能），ratio > 1 表示短周期比大周期更散（结构松动）。
        df["kel_width_ratio_1h"] = (width_5m_smooth / (width_1h + 1e-12)).clip(lower=0.0, upper=4.0)
        df["kel_width_ratio_4h"] = (width_5m_smooth / (width_4h + 1e-12)).clip(lower=0.0, upper=4.0)

        chop_smooth = df["chop"].rolling(3, min_periods=1).mean()
        er_smooth = df["er"].rolling(3, min_periods=1).mean()
        align_abs = df["htf_alignment"].abs() if "htf_alignment" in df else pd.Series(0.0, index=df.index)

        narrow_gate = (width_5m_smooth <= float(self.CHANNEL_NARROW_MAX)) & (df["kel_width_ratio_1h"] <= float(self.CHANNEL_RATIO_NARROW))
        narrow_gate = narrow_gate & (er_smooth >= float(self.CHANNEL_NARROW_ER_MIN)) & (chop_smooth <= float(self.CHANNEL_NARROW_CHOP_MAX)) & (align_abs >= float(self.CHANNEL_ALIGN_MIN))
        wide_gate = (width_5m_smooth >= float(self.CHANNEL_WIDE_MIN)) & (df["kel_width_ratio_1h"] >= float(self.CHANNEL_RATIO_WIDE))
        wide_gate = wide_gate & (chop_smooth >= float(self.CHANNEL_WIDE_CHOP_MIN))

        width_decay = width_5m_smooth < (width_5m_smooth.shift(3).fillna(width_5m_smooth) * float(self.CHANNEL_DECAY_RATIO))
        wide_decay = wide_gate & width_decay

        htf_drive = (
            (align_abs >= float(self.CHANNEL_HTF_ALIGN_MIN))
            & (df["kel_width_ratio_4h"] <= float(self.CHANNEL_HTF_RATIO_MAX))
            & (width_4h >= float(self.CHANNEL_WIDE_MIN) * float(self.CHANNEL_HTF_WIDTH_FRAC))
        )

        df["channel_mode_narrow_trend"] = narrow_gate.astype(int)
        df["channel_mode_wide_range"] = wide_gate.astype(int)
        df["channel_mode_wide_decay"] = wide_decay.astype(int)
        df["channel_mode_htf_drive"] = htf_drive.astype(int)

        # GATES 可视化
        if self.DEBUG_GATES_TO_UI:
            atr_ok = ((df["atr_pct"] >= max(self.ATR_WIN_MIN * 0.6, 0.0006)) & (df["atr_pct"] <= self.ATR_WIN_MAX * 1.22)).astype(int)
            df["gate_atr_ok"] = atr_ok
            tri_need = self._tri_need_threshold()
            df["gate_dist_ok_long"]  = ((df["dist_ema200_1h"] >= df["dist_near_min_used"]) & (df["macd"] >= df["macdsignal"])).astype(int)
            df["gate_dist_ok_short"] = ((df["dist_ema200_1h"] >= df["dist_near_min_used"] * self.DIST_EMA_NEAR_MIN_SHORT_BONUS) & (df["macd"] <= df["macdsignal"])).astype(int)
            df["entry_ok_long_shadow"]  = (atr_ok & (df["tri_bias_long"]  >= tri_need)).astype(int)
            df["entry_ok_short_shadow"] = (atr_ok & (df["tri_bias_short"] >= tri_need)).astype(int)
            df["gate_chop_trend"] = (df["chop"] <= float(self.CHOP_TREND_MAX)).astype(int)
            df["gate_chop_range"] = (df["chop"] >= float(self.CHOP_RANGE_MIN)).astype(int)

        overlay_pct_cols = [
            "stop_floor_expect_pct",
            "stop_floor_strict_pct",
            "stop_floor_adaptive_pct",
            "stop_floor_dynamic_pct",
            "stop_floor_final_pct",
            "stop_floor_fallback_pct",
        ]
        overlay_r_cols = [
            "stop_r_current",
            "stop_r_release",
            "stop_r_final",
            "stop_r_expect",
            "stop_r_strict",
        ]
        for col in overlay_pct_cols + overlay_r_cols:
            df[col] = np.nan

        pair = metadata.get("pair") if isinstance(metadata, dict) else None
        if pair and not df.empty:
            st = self._pair_state.setdefault(pair, {})
            history = st.get("stoploss_ui_history")
            applied_overlay = False
            fallback_overlay_used = False
            idx = df.index
            idx_tz = getattr(idx, "tz", None)
            tf_label = str(getattr(self, "timeframe", ""))
            idx_min = idx.min() if len(idx) > 0 else None
            cutoff = None
            if isinstance(history, list) and history:
                if isinstance(idx_min, pd.Timestamp):
                    tf_minutes = max(1, int(getattr(self, "_current_tf_minutes", self._tf_minutes())))
                    cutoff = idx_min - pd.Timedelta(minutes=tf_minutes * 3)
                new_history: List[Dict[str, Any]] = []
                tf_minutes = max(1, int(getattr(self, "_current_tf_minutes", self._tf_minutes())))
                tol = pd.Timedelta(minutes=tf_minutes)
                for entry in history:
                    if not isinstance(entry, dict):
                        continue
                    timeframe_entry = str(entry.get("timeframe") or tf_label)
                    ts_key = entry.get("ts_key")
                    idx_label: Optional[pd.Timestamp] = None
                    if isinstance(ts_key, pd.Timestamp):
                        idx_label = ts_key
                    elif ts_key is not None:
                        try:
                            idx_label = pd.Timestamp(ts_key)
                        except Exception:
                            idx_label = None
                    ts_entry = entry.get("ts")
                    if idx_label is None and ts_entry is not None:
                        if isinstance(ts_entry, pd.Timestamp):
                            idx_label = ts_entry
                        else:
                            try:
                                idx_label = pd.Timestamp(ts_entry)
                            except Exception:
                                idx_label = None
                    if idx_label is not None:
                        if idx_tz is None and idx_label.tzinfo is not None:
                            idx_label = idx_label.tz_convert(None)
                        elif idx_tz is not None:
                            if idx_label.tzinfo is None:
                                idx_label = idx_label.tz_localize(idx_tz)
                            else:
                                idx_label = idx_label.tz_convert(idx_tz)
                    if timeframe_entry != tf_label:
                        new_history.append(entry)
                        continue
                    plot_idx = idx_label
                    if plot_idx is not None and plot_idx not in idx:
                        plot_idx = None
                        try:
                            pos = idx.get_indexer([idx_label], method="nearest")[0]
                        except Exception:
                            pos = -1
                        if pos >= 0 and pos < len(idx):
                            try:
                                candidate = idx[pos]
                            except Exception:
                                candidate = None
                            if isinstance(candidate, pd.Timestamp):
                                delta = abs(candidate - idx_label)
                                if not isinstance(delta, pd.Timedelta):
                                    try:
                                        delta = pd.Timedelta(delta)
                                    except Exception:
                                        delta = None
                                if delta is None or delta <= tol:
                                    plot_idx = candidate
                    if plot_idx is None:
                        new_history.append(entry)
                        continue
                    if cutoff is not None and plot_idx < cutoff:
                        continue
                    for col in overlay_pct_cols:
                        val = entry.get(col)
                        if val is None:
                            continue
                        try:
                            num = float(val)
                        except (TypeError, ValueError):
                            continue
                        if not np.isfinite(num):
                            continue
                        df.at[plot_idx, col] = num
                        applied_overlay = True
                    for col in overlay_r_cols:
                        val = entry.get(col)
                        if val is None:
                            continue
                        try:
                            num = float(val)
                        except (TypeError, ValueError):
                            continue
                        if not np.isfinite(num):
                            continue
                        df.at[plot_idx, col] = num
                        applied_overlay = True
                    new_history.append(entry)
                st["stoploss_ui_history"] = new_history
            if not applied_overlay:
                fallback_snap = self._latest_stoploss_snapshot(pair, tf_label)
                if fallback_snap:
                    try:
                        target_idx = idx[-1]
                    except Exception:
                        target_idx = None
                    fallback_overlay_used = self._apply_stoploss_overlay_snapshot(
                        df,
                        target_idx,
                        fallback_snap,
                        overlay_pct_cols,
                        overlay_r_cols,
                    )
                    if fallback_overlay_used:
                        span_limit = int(getattr(self, "WEBUI_STOP_FALLBACK_BACKFILL_BARS", 0) or 0)
                        if span_limit > 1 and len(idx) > 1:
                            span = min(span_limit, len(idx))
                            span_positions = range(len(idx) - span, len(idx))
                            span_idx: List[Any] = []
                            try:
                                if hasattr(idx, "take"):
                                    span_idx = list(idx.take(list(span_positions)))
                                else:
                                    span_idx = [idx[pos] for pos in span_positions]
                            except Exception:
                                span_idx = []
                            if len(span_idx) > 1:
                                for col in overlay_pct_cols + overlay_r_cols:
                                    val = fallback_snap.get(col)
                                    if val is None:
                                        continue
                                    try:
                                        num = float(val)
                                    except (TypeError, ValueError):
                                        continue
                                    if not np.isfinite(num):
                                        continue
                                    try:
                                        df.loc[span_idx, col] = num
                                        applied_overlay = True
                                    except Exception:
                                        continue
                        applied_overlay = applied_overlay or fallback_overlay_used
            if applied_overlay or fallback_overlay_used:
                df[overlay_pct_cols] = df[overlay_pct_cols].astype(float).ffill()
                df[overlay_r_cols] = df[overlay_r_cols].astype(float).ffill()
                for col in (
                    "stop_floor_expect_pct",
                    "stop_floor_strict_pct",
                    "stop_floor_adaptive_pct",
                    "stop_floor_dynamic_pct",
                    "stop_floor_final_pct",
                ):
                    df[col] = df[col].where(~np.isclose(df[col], 0.0), np.nan)
                for col in ("stop_r_release", "stop_r_final", "stop_r_expect", "stop_r_strict"):
                    df[col] = df[col].where(~np.isclose(df[col], 0.0), np.nan)

        self._audit_dataframe_integrity(df, stage="indicators")
        return df

    # -------------------- 入场影子（Quiet 稀疏化） --------------------
    def populate_entry_trend(self, df: DataFrame, metadata: dict) -> DataFrame:
        """教学提示：生成“候选信号”影子列，供 WebUI/回测观察，不直接下单。"""
        df = df.assign(
            enter_long=0,
            enter_short=0,
            enter_tag="",
            entry_marker_long=0,
            entry_marker_short=0,
            entry_block_long=0,
            entry_block_short=0,
            pullback_gate_long=0,
            pullback_gate_short=0,
        )

        self._record_shadow_init(
            stage="entry_shadow",
            df=df,
            expected=(
                "enter_long",
                "enter_short",
                "enter_tag",
                "entry_marker_long",
                "entry_marker_short",
                "entry_block_long",
                "entry_block_short",
                "pullback_gate_long",
                "pullback_gate_short",
            ),
        )

        pair = metadata.get("pair") if isinstance(metadata, dict) else None
        if pair:
            self._sweep_pending_entry_signals(pair)
            st = self._pair_state.setdefault(pair, {})
            markers_raw = st.get("entry_markers")
            if isinstance(markers_raw, list) and not df.empty:
                idx = df.index
                idx_min = idx.min()
                idx_tz = getattr(idx, "tz", None)
                try:
                    idx_min_utc = pd.Timestamp(idx_min)
                except Exception:
                    idx_min_utc = None
                if isinstance(idx_min_utc, pd.Timestamp):
                    if idx_min_utc.tzinfo is None:
                        idx_min_utc = idx_min_utc.tz_localize(timezone.utc)
                    else:
                        idx_min_utc = idx_min_utc.tz_convert(timezone.utc)
                window_pad = pd.Timedelta(minutes=max(1, int(getattr(self, "_current_tf_minutes", self._tf_minutes()))))
                keep_markers: List[Dict[str, Any]] = []
                for marker in markers_raw:
                    if not isinstance(marker, dict):
                        continue
                    ts_raw = marker.get("ts")
                    side_raw = marker.get("side")
                    if side_raw not in ("long", "short"):
                        continue
                    try:
                        ts_marker = pd.Timestamp(ts_raw)
                    except Exception:
                        continue
                    if ts_marker.tzinfo is None:
                        ts_marker = ts_marker.tz_localize(timezone.utc)
                    else:
                        ts_marker = ts_marker.tz_convert(timezone.utc)
                    if isinstance(idx_min_utc, pd.Timestamp) and ts_marker < (idx_min_utc - window_pad):
                        continue
                    keep_markers.append({"ts": ts_marker, "side": side_raw})
                    if idx_tz is None:
                        plot_ts = ts_marker.tz_localize(None)
                    else:
                        plot_ts = ts_marker.tz_convert(idx_tz)
                    if plot_ts in idx:
                        if side_raw == "long":
                            df.loc[plot_ts, "entry_marker_long"] = 1
                        else:
                            df.loc[plot_ts, "entry_marker_short"] = 1
                st["entry_markers"] = keep_markers

            reverse_state = st.get("flash_reverse")
            if isinstance(reverse_state, dict) and not df.empty:
                pending = reverse_state.get("pending")
                if isinstance(pending, dict):
                    try:
                        now_idx = df.index[-1]
                    except IndexError:
                        now_idx = None
                    now_ts = pd.Timestamp(now_idx) if now_idx is not None else None
                    if now_ts is not None:
                        if now_ts.tzinfo is None:
                            now_utc = now_ts.tz_localize(timezone.utc)
                        else:
                            now_utc = now_ts.tz_convert(timezone.utc)
                        try:
                            ready_ts = pd.Timestamp(pending.get("ready_ts"))
                            expire_ts = pd.Timestamp(pending.get("expire_ts"))
                        except Exception:
                            ready_ts = expire_ts = None
                        if ready_ts is not None:
                            if ready_ts.tzinfo is None:
                                ready_ts = ready_ts.tz_localize(timezone.utc)
                            else:
                                ready_ts = ready_ts.tz_convert(timezone.utc)
                        if expire_ts is not None:
                            if expire_ts.tzinfo is None:
                                expire_ts = expire_ts.tz_localize(timezone.utc)
                            else:
                                expire_ts = expire_ts.tz_convert(timezone.utc)
                        direction = str(pending.get("direction", "") or "").lower()
                        max_signals = pending.get("max_signals")
                        signals_count = int(pending.get("signals", 0) or 0)
                        exhausted = bool(reverse_state.get("exhausted"))
                        if expire_ts is not None and now_utc > expire_ts + pd.Timedelta(minutes=1):
                            reverse_state.pop("pending", None)
                            reverse_state.pop("exhausted", None)
                        elif (
                            ready_ts is not None
                            and expire_ts is not None
                            and ready_ts <= now_utc <= expire_ts
                            and not exhausted
                        ):
                            allow_signal = True
                            if isinstance(max_signals, (int, float)) and max_signals > 0:
                                allow_signal = signals_count < int(max_signals)
                            if allow_signal and direction in {"long", "short"}:
                                if direction == "long":
                                    df.loc[now_ts, "enter_long"] = 1
                                    tag_prev = str(df.loc[now_ts, "enter_tag"] or "")
                                    if "flash_reverse" not in tag_prev.split("+"):
                                        df.loc[now_ts, "enter_tag"] = "+".join(
                                            [t for t in (tag_prev, "flash_reverse") if t]
                                        )
                                else:
                                    df.loc[now_ts, "enter_short"] = 1
                                    tag_prev = str(df.loc[now_ts, "enter_tag"] or "")
                                    if "flash_reverse" not in tag_prev.split("+"):
                                        df.loc[now_ts, "enter_tag"] = "+".join(
                                            [t for t in (tag_prev, "flash_reverse") if t]
                                        )
                                pending["signals"] = signals_count + 1
                                pending["last_signal_ts"] = now_utc.isoformat()
                                reverse_state["last_signal_ts"] = now_utc.isoformat()
                                if isinstance(max_signals, (int, float)) and max_signals > 0 and pending["signals"] >= int(max_signals):
                                    reverse_state["exhausted"] = True
                        elif expire_ts is not None and now_utc > expire_ts:
                            reverse_state.pop("pending", None)
                            reverse_state.pop("exhausted", None)

        is_range = (df["adx"] <= 35)

        # 反转基元
        top = (df["price_position"] >= self.REV_TOP_POS); rsi_high = (df["rsi"] >= self.REV_RSI_HIGH)
        macd_bear = (df["macd"] < df["macdsignal"]) & (df["macdhist"] < 0)
        loc_high = (df["high"] == df["high"].rolling(7, min_periods=7).max()) | (df["high"].shift(1) < df["high"])
        short_base = top.astype(int) + rsi_high.astype(int) + macd_bear.astype(int) + loc_high.astype(int)
        short_sig = pd.Series(np.where(df["bias_short"], short_base >= 2, short_base >= 3).astype(bool), index=df.index)

        bot = (df["price_position"] <= self.REV_BOT_POS); rsi_low = (df["rsi"] <= self.REV_RSI_LOW)
        macd_bull = (df["macd"] > df["macdsignal"]) & (df["macdhist"] > 0)
        loc_low = (df["low"] == df["low"].rolling(7, min_periods=7).min()) | (df["low"].shift(1) > df["low"])
        long_base = bot.astype(int) + rsi_low.astype(int) + macd_bull.astype(int) + loc_low.astype(int)
        long_sig = pd.Series(np.where(df["bias_long"], long_base >= 2, long_base >= 3).astype(bool), index=df.index)

        # 趋势补票
        long_now  = (df["trend_reentry_long_now"]  == 1) & df["price_position"].between(*self.REENTRY_LONG_POS_RANGE)
        short_now = (df["trend_reentry_short_now"] == 1) & df["price_position"].between(*self.REENTRY_SHORT_POS_RANGE)
        long_recent  = ((df["trend_reentry_long_recent"]  == 1) & (df["trend_reentry_long_now"]  == 0) & df["price_position"].between(*self.REENTRY_LONG_POS_RANGE))
        short_recent = ((df["trend_reentry_short_recent"] == 1) & (df["trend_reentry_short_now"] == 0) & df["price_position"].between(*self.REENTRY_SHORT_POS_RANGE))

        # Quiet 稀疏闸门
        if bool(getattr(self, "QUIET_MODE", True)):
            tri_need = self._tri_need_threshold()
            atr_ok = (df["gate_atr_ok"] == 1) if "gate_atr_ok" in df else df["atr_pct"].between(max(self.ATR_WIN_MIN * 0.6, 0.0006), self.ATR_WIN_MAX * 1.22)
            dist_ok_L = (df["gate_dist_ok_long"] == 1) if "gate_dist_ok_long" in df else (df["dist_ema200_1h"] >= df["dist_near_min_used"])
            dist_ok_S = (df["gate_dist_ok_short"] == 1) if "gate_dist_ok_short" in df else (df["dist_ema200_1h"] >= df["dist_near_min_used"] * self.DIST_EMA_NEAR_MIN_SHORT_BONUS)

            slow_lane_long = (df["slow_lane_long"] == 1) if "slow_lane_long" in df else pd.Series(False, index=df.index)
            slow_lane_short = (df["slow_lane_short"] == 1) if "slow_lane_short" in df else pd.Series(False, index=df.index)
            fast_lane_long = (df["fast_lane_long"] == 1) if "fast_lane_long" in df else pd.Series(False, index=df.index)
            fast_lane_short = (df["fast_lane_short"] == 1) if "fast_lane_short" in df else pd.Series(False, index=df.index)
            htf_align = df["htf_alignment"] if "htf_alignment" in df else pd.Series(0.0, index=df.index)
            vol_any = df["vol_surge_any"] if "vol_surge_any" in df else pd.Series(0, index=df.index)
            dist_relax_mult = float(self._profile_val("dist_relax_mult", 1.0) or 1.0)
            extreme_dist_relief = float(self._profile_val("extreme_dist_relief", 1.0) or 1.0)
            extreme_tri_relief = float(self._profile_val("extreme_tri_relief", 1.0) or 1.0)
            require_extreme_vol = bool(self._profile_val("require_vol_on_extreme", False))
            panic_align_need = float(self._profile_val("panic_align_need", 0.0) or 0.0)
            mania_align_need = float(self._profile_val("mania_align_need", 0.0) or 0.0)
            align_floor_short = max(0.0, float(self._profile_val("align_floor_short", self.ENTRY_ALIGN_FLOOR_SHORT)))
            mania_align_floor = max(mania_align_need, align_floor_short * 0.75)  # 教学：顶部诱空若仍是宽通道推进，需要 ≥75% 的空头对齐度才放行。
            # 教学提示：mania_lane 表示“顶部诱多警戒区”，panic_lane 表示“底部恐慌警戒区”，
            #           两者分别禁止盲多/盲空，同时允许顺势快单在确认后接力。
            mania_lane = (df["blowoff_tail_guard"] >= 1) if "blowoff_tail_guard" in df else pd.Series(False, index=df.index)
            panic_lane = (df["panic_tail_guard"] >= 1) if "panic_tail_guard" in df else pd.Series(False, index=df.index)
            narrow_lane = (df["channel_mode_narrow_trend"] == 1) if "channel_mode_narrow_trend" in df else pd.Series(False, index=df.index)
            wide_lane = (df["channel_mode_wide_range"] == 1) if "channel_mode_wide_range" in df else pd.Series(False, index=df.index)
            wide_decay = (df["channel_mode_wide_decay"] == 1) if "channel_mode_wide_decay" in df else pd.Series(False, index=df.index)
            wide_lane_active = wide_lane & (~wide_decay)
            htf_drive_lane = (df["channel_mode_htf_drive"] == 1) if "channel_mode_htf_drive" in df else pd.Series(False, index=df.index)

            dist_relax_L = df["dist_ema200_1h"] >= (df["dist_near_min_used"] * 0.82 * dist_relax_mult)
            dist_relax_S = df["dist_ema200_1h"] >= (
                df["dist_near_min_used"] * self.DIST_EMA_NEAR_MIN_SHORT_BONUS * 0.82 * dist_relax_mult
            )
            if extreme_dist_relief > 0 and extreme_dist_relief != 1.0:
                dist_relax_extreme_L = df["dist_ema200_1h"] >= (
                    df["dist_near_min_used"] * 0.82 * dist_relax_mult * extreme_dist_relief
                )
                dist_relax_extreme_S = df["dist_ema200_1h"] >= (
                    df["dist_near_min_used"] * self.DIST_EMA_NEAR_MIN_SHORT_BONUS * 0.82 * dist_relax_mult * extreme_dist_relief
                )
            else:
                dist_relax_extreme_L = dist_relax_L
                dist_relax_extreme_S = dist_relax_S
            dist_ok_L = dist_ok_L | (slow_lane_long & dist_relax_L) | (narrow_lane & (htf_align >= 0.10)) | (panic_lane & (df["dist_ema200_1h"] >= df["dist_near_min_used"] * 0.75))
            dist_ok_S = dist_ok_S | (slow_lane_short & dist_relax_S) | (narrow_lane & (htf_align <= -0.10)) | (mania_lane & (df["dist_ema200_1h"] >= df["dist_near_min_used"] * self.DIST_EMA_NEAR_MIN_SHORT_BONUS * 0.75))
            if extreme_dist_relief > 0 and extreme_dist_relief != 1.0:
                dist_ok_L = dist_ok_L | (panic_lane & dist_relax_extreme_L)
                dist_ok_S = dist_ok_S | (mania_lane & dist_relax_extreme_S)

            tri_ok_L = (df["tri_bias_long"] >= tri_need) | (narrow_lane & (df["tri_bias_long"] >= tri_need * 0.96))
            tri_ok_S = (df["tri_bias_short"] >= tri_need) | (narrow_lane & (df["tri_bias_short"] >= tri_need * 0.96))
            tri_ok_L = tri_ok_L & (~wide_decay | (htf_align >= 0))
            tri_ok_S = tri_ok_S & (~wide_decay | (htf_align <= 0))
            if extreme_tri_relief > 0 and extreme_tri_relief != 1.0:
                tri_need_extreme = tri_need * extreme_tri_relief
                tri_extreme_L = (df["tri_bias_long"] >= tri_need_extreme) & (~wide_decay | (htf_align >= 0))
                tri_extreme_S = (df["tri_bias_short"] >= tri_need_extreme) & (~wide_decay | (htf_align <= 0))
                tri_ok_L = tri_ok_L | (panic_lane & tri_extreme_L)
                tri_ok_S = tri_ok_S | (mania_lane & tri_extreme_S)

            trend_gate = (df["chop"] <= float(self.CHOP_TREND_MAX)) & (df["er"] >= float(self.ER_TREND_MIN))
            range_gate = (df["chop"] >= float(self.CHOP_RANGE_MIN)) & (df["er"] <= float(self.ER_RANGE_MAX))
            # 快/慢车道补充：快车道允许稍放松的趋势指标，慢车道依赖高周期同向，窄通道则偏向抢先布局。
            trend_gate_L = trend_gate | (
                (fast_lane_long & (df["chop"] <= float(self.CHOP_TREND_MAX) * 1.10) & (df["er"] >= float(self.ER_TREND_MIN) * 0.85)) |
                (slow_lane_long & (htf_align > 0.28) & (df["er"] >= float(self.ER_TREND_MIN) * 0.80)) |
                (narrow_lane & (htf_align > 0.18) & (df["er"] >= float(self.ER_TREND_MIN) * 0.78))
            )
            trend_gate_S = trend_gate | (
                (fast_lane_short & (df["chop"] <= float(self.CHOP_TREND_MAX) * 1.10) & (df["er"] >= float(self.ER_TREND_MIN) * 0.85)) |
                (slow_lane_short & (htf_align < -0.28) & (df["er"] >= float(self.ER_TREND_MIN) * 0.80)) |
                (narrow_lane & (htf_align < -0.18) & (df["er"] >= float(self.ER_TREND_MIN) * 0.78))
            )
            range_gate_L = range_gate | (
                slow_lane_long & (htf_align > 0.20) & (df["chop"] >= float(self.CHOP_RANGE_MIN) * 0.90) & (df["er"] <= float(self.ER_RANGE_MAX) * 1.10)
            )
            range_gate_S = range_gate | (
                slow_lane_short & (htf_align < -0.20) & (df["chop"] >= float(self.CHOP_RANGE_MIN) * 0.90) & (df["er"] <= float(self.ER_RANGE_MAX) * 1.10)
            )
            range_gate_L = range_gate_L | (wide_lane_active & (df["chop"] >= float(self.CHOP_RANGE_MIN) * 0.96))
            range_gate_S = range_gate_S | (wide_lane_active & (df["chop"] >= float(self.CHOP_RANGE_MIN) * 0.96))
            range_gate_L = range_gate_L & (~wide_decay | (htf_align >= 0))
            range_gate_S = range_gate_S & (~wide_decay | (htf_align <= 0))

            trend_L = ((long_now) | (long_recent))
            trend_S = ((short_now) | (short_recent))
            rev_L = long_sig
            rev_S = short_sig
            momentum_lane_long = (fast_lane_long & (vol_any == 1) & (df["macdhist"] > 0))
            momentum_lane_short = (fast_lane_short & (vol_any == 1) & (df["macdhist"] < 0))

            blowoff_ok = (df["blowoff_tail_guard"] == 0) if "blowoff_tail_guard" in df else pd.Series(True, index=df.index)
            panic_clear = (df["panic_tail_guard"] == 0)
            # 教学提示：cand_long/cand_short 组合了“趋势单 + 反转单 + 动能快单”，
            #           并叠加 panic/mania 保护，确保质量不牺牲数量。
            cand_long = (
                ((trend_L & trend_gate_L) | (rev_L & range_gate_L) | (momentum_lane_long & (trend_L | rev_L)))
                & atr_ok & dist_ok_L & tri_ok_L & blowoff_ok
            )
            panic_price_ceiling = float(getattr(self, "PANIC_LONG_PRICE_CEIL", 0.22))
            mania_price_floor = float(getattr(self, "MANIA_SHORT_PRICE_FLOOR", 0.78))

            panic_extra = panic_lane & atr_ok & dist_ok_L & tri_ok_L & (trend_gate_L | range_gate_L | momentum_lane_long)
            if require_extreme_vol:
                panic_extra = panic_extra & (vol_any == 1)
            if panic_align_need > 0:
                panic_extra = panic_extra & (htf_align >= panic_align_need)
            panic_extra = panic_extra & (df["price_position"] <= panic_price_ceiling)
            cand_long = cand_long | panic_extra
            cand_short = (
                ((trend_S & trend_gate_S) | (rev_S & range_gate_S) | (momentum_lane_short & (trend_S | rev_S)))
                & atr_ok & dist_ok_S & tri_ok_S & panic_clear
            )
            mania_extra = mania_lane & atr_ok & dist_ok_S & tri_ok_S & (trend_gate_S | range_gate_S | momentum_lane_short)
            if require_extreme_vol:
                mania_extra = mania_extra & (vol_any == 1)
            if mania_align_need > 0:
                mania_extra = mania_extra & (htf_align <= -mania_align_need)
            mania_extra = mania_extra & (
                ~wide_lane_active | wide_decay | (htf_align <= -mania_align_floor)
            )  # 教学：宽通道仍在扩张时，只有高周期显著转空才允许 mania 诱空接力，避免“窄转宽”处误判。
            mania_extra = mania_extra & (df["price_position"] >= mania_price_floor)
            cand_short = cand_short | mania_extra
            cand_long = cand_long & (~wide_decay | (htf_align >= 0))
            cand_short = cand_short & (~wide_decay | (htf_align <= 0))
            reflex_ok_L = (df["reflex_stop_long"] == 0) if "reflex_stop_long" in df else pd.Series(True, index=df.index)
            reflex_ok_S = (df["reflex_stop_short"] == 0) if "reflex_stop_short" in df else pd.Series(True, index=df.index)
            cand_long = cand_long & reflex_ok_L
            cand_short = cand_short & reflex_ok_S
            mania_drive = htf_drive_lane & mania_lane & atr_ok & dist_ok_S & tri_ok_S
            panic_drive = htf_drive_lane & panic_lane & atr_ok & dist_ok_L & tri_ok_L
            if require_extreme_vol:
                mania_drive = mania_drive & (vol_any == 1)
                panic_drive = panic_drive & (vol_any == 1)
            if mania_align_need > 0:
                mania_drive = mania_drive & (htf_align <= -mania_align_need)
            if panic_align_need > 0:
                panic_drive = panic_drive & (htf_align >= panic_align_need)
            mania_drive = mania_drive & (
                ~wide_lane_active | wide_decay | (htf_align <= -mania_align_floor)
            )
            mania_drive = mania_drive & reflex_ok_S & (df["price_position"] >= mania_price_floor)
            panic_drive = panic_drive & reflex_ok_L & (df["price_position"] <= panic_price_ceiling)
            cand_short = cand_short | mania_drive
            cand_long = cand_long | panic_drive

            pullback_ready_long = (df["pullback_ready_long"] == 1) if "pullback_ready_long" in df else pd.Series(False, index=df.index)
            pullback_ready_short = (df["pullback_ready_short"] == 1) if "pullback_ready_short" in df else pd.Series(False, index=df.index)
            pullback_window = max(1, int(getattr(self, "ENTRY_PULLBACK_RECENT_WINDOW", self.ENTRY_PULLBACK_RECENT_WINDOW)))
            recent_long = (
                cand_long.astype(int)
                .rolling(pullback_window, min_periods=1)
                .max()
                .shift(1)
                .fillna(0)
                .astype(bool)
            )
            recent_short = (
                cand_short.astype(int)
                .rolling(pullback_window, min_periods=1)
                .max()
                .shift(1)
                .fillna(0)
                .astype(bool)
            )
            pullback_need_long = (df["price_position"] <= panic_price_ceiling) | recent_long
            pullback_need_short = (df["price_position"] >= mania_price_floor) | recent_short
            if "pullback_gate_long" in df:
                df.loc[:, "pullback_gate_long"] = pullback_need_long.astype(int)
            if "pullback_gate_short" in df:
                df.loc[:, "pullback_gate_short"] = pullback_need_short.astype(int)
            cand_long = cand_long & (~pullback_need_long | pullback_ready_long)
            cand_short = cand_short & (~pullback_need_short | pullback_ready_short)

            if bool(getattr(self, "SIGNAL_CLUSTER_PLOT_ENABLE", True)):
                cool_base = max(0, int(getattr(self, "SIGNAL_CLUSTER_PLOT_COOLDOWN_BARS", 0)))
                cool_fast = max(0, int(getattr(self, "SIGNAL_CLUSTER_PLOT_COOLDOWN_FAST", cool_base)))
                window_bars = max(1, int(getattr(self, "SIGNAL_CLUSTER_PLOT_WINDOW_BARS", self.SIGNAL_CLUSTER_LOOKBACK_BARS)))
                max_per_window = max(1, int(getattr(self, "SIGNAL_CLUSTER_PLOT_MAX_PER_WINDOW", 1)))
                fast_align_need = float(getattr(self, "SIGNAL_CLUSTER_PLOT_FAST_ALIGN", 0.42))

                def _sparsify(arr: np.ndarray, fast_arr: np.ndarray, align_arr: np.ndarray, positive: bool) -> np.ndarray:
                    if arr.size == 0:
                        return arr
                    cooldown = 0
                    recent: deque[int] = deque()
                    for idx in range(arr.size):
                        if cooldown > 0:
                            cooldown -= 1
                        while recent and idx - recent[0] >= window_bars:
                            recent.popleft()
                        if not arr[idx]:
                            continue
                        fast = bool(fast_arr[idx])
                        align_val = float(align_arr[idx])
                        bypass = fast and ((align_val >= fast_align_need) if positive else (align_val <= -fast_align_need))
                        need = cool_fast if fast else cool_base
                        if not bypass and need > 0 and cooldown > 0:
                            arr[idx] = False
                            continue
                        if not bypass and need > 0:
                            cooldown = need
                        if not bypass and max_per_window > 0 and len(recent) >= max_per_window:
                            arr[idx] = False
                            continue
                        recent.append(idx)
                    return arr

                long_mask = cand_long.to_numpy(dtype=bool, copy=True)
                short_mask = cand_short.to_numpy(dtype=bool, copy=True)
                fast_long = fast_lane_long.to_numpy(dtype=bool, copy=True)
                fast_short = fast_lane_short.to_numpy(dtype=bool, copy=True)
                align_values = htf_align.to_numpy(dtype=float, copy=True)

                long_mask = _sparsify(long_mask, fast_long, align_values, True)
                short_mask = _sparsify(short_mask, fast_short, align_values, False)

                cand_long = pd.Series(long_mask, index=df.index)
                cand_short = pd.Series(short_mask, index=df.index)

            df.loc[cand_long, "enter_long"] = 1
            df.loc[cand_short, "enter_short"] = 1
            df.loc[cand_long, "enter_tag"] = "quiet_long"
            df.loc[cand_short, "enter_tag"] = "quiet_short"
        else:
            # 不稀疏时，回退为“较活跃”逻辑（略）
            blowoff_ok = (df["blowoff_tail_guard"] == 0) if "blowoff_tail_guard" in df else pd.Series(True, index=df.index)
            reflex_ok_L = (df["reflex_stop_long"] == 0) if "reflex_stop_long" in df else pd.Series(True, index=df.index)
            reflex_ok_S = (df["reflex_stop_short"] == 0) if "reflex_stop_short" in df else pd.Series(True, index=df.index)
            cand_long  = (long_sig | long_now | long_recent) & blowoff_ok & reflex_ok_L
            cand_short = ((short_sig | short_now | short_recent) & (df["panic_tail_guard"] == 0) & reflex_ok_S)
            df.loc[cand_long,  "enter_long"]  = 1
            df.loc[cand_short, "enter_short"] = 1
            df.loc[cand_long,  "enter_tag"]   = "active_long"
            df.loc[cand_short, "enter_tag"]   = "active_short"

        # 双向同亮 → 以 1h EMA200 方向偏置择一
        both = (df["enter_long"] == 1) & (df["enter_short"] == 1)
        if both.any():
            pref_long = df["close"] >= df["ema200_1h"]
            df.loc[both & pref_long,  "enter_short"] = 0
            df.loc[both & (~pref_long), "enter_long"] = 0

        if pair:
            self._apply_entry_block_overlay(df, pair)

        # 可视化
        df = df.assign(
            sig_long_cand=(df["enter_long"] == 1).astype(int),
            sig_short_cand=(df["enter_short"] == 1).astype(int),
        )
        df = df.assign(
            sig_take_long=df["sig_long_cand"],
            sig_take_short=df["sig_short_cand"],
        )
        if pair:
            self._entry_signal_history_replay(df, pair)
        if pair and not df.empty:
            last_idx = df.index[-1]
            last_row = df.iloc[-1]
            runtime_now = self._utc_now()
            last_ts = self._normalize_row_timestamp(last_row, runtime_now)
            if int(last_row.get("enter_long", 0) or 0) == 1:
                self._entry_signal_track(
                    pair,
                    "long",
                    last_idx,
                    last_row.get("enter_tag"),
                    last_row.get("close"),
                    fallback_ts=last_ts,
                )
            if int(last_row.get("enter_short", 0) or 0) == 1:
                self._entry_signal_track(
                    pair,
                    "short",
                    last_idx,
                    last_row.get("enter_tag"),
                    last_row.get("close"),
                    fallback_ts=last_ts,
                )
        if pair:
            self._entry_signal_history_capture(df, pair)
        return df

    # -------------------- 退出影子（展示；实盘走 custom_exit） --------------------
    def populate_exit_trend(self, df: DataFrame, metadata: dict) -> DataFrame:
        """教学提示：仅用于图表展示的离场影子，实盘离场走 custom_exit。"""
        df = df.assign(exit_long=0, exit_short=0, exit_tag="")

        self._record_shadow_init(
            stage="exit_shadow",
            df=df,
            expected=("exit_long", "exit_short", "exit_tag"),
        )
        di_flip_long  = ((df["minus_di"] > df["plus_di"]) & (df["minus_di"].rolling(self.DIR_GUARD_BARS).mean() > df["plus_di"].rolling(self.DIR_GUARD_BARS).mean()))
        di_flip_short = ((df["plus_di"]  > df["minus_di"]) & (df["plus_di"].rolling(self.DIR_GUARD_BARS).mean()  > df["minus_di"].rolling(self.DIR_GUARD_BARS).mean()))
        exitL_conf = (df["breakL_conf"] == 1) & (df["stoprun_long"] == 0) & di_flip_long
        exitS_conf = (df["breakS_conf"] == 1) & (df["stoprun_short"] == 0) & di_flip_short

        both = exitL_conf & exitS_conf
        exitL_conf = exitL_conf & (~both | (df["close"] >= df["ema200_1h"]))
        exitS_conf = exitS_conf & (~both | (df["close"] <  df["ema200_1h"]))
        df.loc[exitL_conf, "exit_long"]  = 1; df.loc[exitL_conf, "exit_tag"]  = "tp_struct_guard_conf"
        df.loc[exitS_conf, "exit_short"] = 1; df.loc[exitS_conf, "exit_tag"]   = "tp_struct_guard_conf"
        return df

    # -------------------- 入场终审（硬闸 + 冷静期/限次） --------------------
    def confirm_trade_entry(self, pair: str, order_type: str, amount: float, rate: float,
                            time_in_force: str, current_time: Optional[datetime] = None,
                            entry_tag: Optional[str] = None, side: str = "long",
                            **kwargs) -> bool:
        """教学提示：实盘终审闸门，逐一检查 ATR/距离/三锚/护栏/冷静期 等硬条件。"""
        df, _ = self.dp.get_analyzed_dataframe(pair, self.timeframe)
        if df is None or df.empty:
            self._log_decision("入场终审", pair, side, "拦截", "数据帧为空，暂缓下单")
            return False
        row = df.iloc[-1]
        st = self._pair_state.setdefault(pair, {})
        runtime_now = self._utc_now()
        candle_time = self._to_utc_datetime(current_time) if isinstance(current_time, datetime) else None
        row_ts = self._normalize_row_timestamp(row, runtime_now)
        now = candle_time or row_ts
        session_clock = now or runtime_now
        self._entry_signal_consume(pair, side, row_ts, session_clock)
        vol_any = int(row.get("vol_surge_any", 0) or 0)
        stage = "入场终审"

        darkside_ctx: Dict[str, Any] = {}
        darkside_ok = False
        darkside_align_relief = 0.0
        darkside_quality_bonus = 0.0
        darkside_quality_relief = 0.0

        snapshot_base: Dict[str, Any] = {}
        session_ctx = self._session_context(session_clock)
        session_realized_r = 0.0
        session_peak_r = 0.0
        session_realized_count = 0
        session_bias_label = str(session_ctx.get("bias", "") or "").lower()
        session_bias_side = ""
        if session_bias_label in ("bull", "long"):
            session_bias_side = "long"
        elif session_bias_label in ("bear", "short"):
            session_bias_side = "short"
        try:
            session_realized_r = float(session_ctx.get("session_realized_r", 0.0) or 0.0)
        except (TypeError, ValueError):
            session_realized_r = 0.0
        try:
            session_peak_r = float(session_ctx.get("session_peak_r", 0.0) or 0.0)
        except (TypeError, ValueError):
            session_peak_r = 0.0
        try:
            session_realized_count = int(session_ctx.get("session_realized_count", 0) or 0)
        except (TypeError, ValueError):
            session_realized_count = 0
        snapshot_base.update({
            "session": session_ctx.get("label", "unknown"),
            "session_bias": session_ctx.get("bias", "neutral"),
            "session_realized_r": round(session_realized_r, 4),
            "session_peak_r": round(session_peak_r, 4),
            "session_realized_count": session_realized_count,
        })
        snapshot_base["entry_tag"] = (entry_tag or "")
        snapshot_base["candle_time"] = row_ts.isoformat()

        pair_cfg_entry = self._pair_cfg(pair)
        directional_guard_cfg = None
        if isinstance(pair_cfg_entry, dict):
            directional_guard_cfg = pair_cfg_entry.get("directional_guard")
        expectation_enabled = bool(pair_cfg_entry.get("expectation_guard_enable", getattr(self, "EXPECTATION_GUARD_ENABLE", False)))
        if expectation_enabled:
            target_r_cfg = float(pair_cfg_entry.get("expectation_target_r", getattr(self, "EXPECTATION_TARGET_R", 0.0)) or 0.0)
            if target_r_cfg > 0:
                snapshot_base["expectation_target_r"] = round(target_r_cfg, 3)
            release_r_cfg = float(pair_cfg_entry.get("expectation_release_r", getattr(self, "EXPECTATION_RELEASE_R", 0.0)) or 0.0)
            if release_r_cfg > 0:
                snapshot_base["expectation_release_r"] = round(release_r_cfg, 3)
            floor_r_cfg = float(
                pair_cfg_entry.get("expectation_release_floor_r", getattr(self, "EXPECTATION_RELEASE_FLOOR_R", 0.0)) or 0.0
            )
            if floor_r_cfg > 0:
                snapshot_base["expectation_release_floor_r"] = round(floor_r_cfg, 3)
            floor_max_cfg = float(
                pair_cfg_entry.get("expectation_floor_max_r", getattr(self, "EXPECTATION_FLOOR_MAX_R", 0.0)) or 0.0
            )
            if floor_max_cfg > 0:
                snapshot_base["expectation_floor_max_r"] = round(floor_max_cfg, 3)
            floor_escalate_cfg = float(
                pair_cfg_entry.get("expectation_floor_escalate_at_r", getattr(self, "EXPECTATION_FLOOR_ESCALATE_AT_R", 0.0))
                or 0.0
            )
            if floor_escalate_cfg > 0:
                snapshot_base["expectation_floor_escalate_at_r"] = round(floor_escalate_cfg, 3)
            floor_pad_cfg = float(
                pair_cfg_entry.get("expectation_floor_escalate_pad_r", getattr(self, "EXPECTATION_FLOOR_ESCALATE_PAD_R", 0.0))
                or 0.0
            )
            if floor_pad_cfg > 0:
                snapshot_base["expectation_floor_escalate_pad_r"] = round(floor_pad_cfg, 3)
            time_minutes_cfg = float(
                pair_cfg_entry.get(
                    "expectation_time_escalate_minutes",
                    getattr(self, "EXPECTATION_TIME_ESCALATE_MINUTES", 0.0),
                )
                or 0.0
            )
            if time_minutes_cfg > 0:
                snapshot_base["expectation_time_escalate_minutes"] = round(time_minutes_cfg, 2)
            time_target_cfg = float(
                pair_cfg_entry.get(
                    "expectation_time_escalate_target_r",
                    getattr(self, "EXPECTATION_TIME_ESCALATE_TARGET_R", 0.0),
                )
                or 0.0
            )
            if time_target_cfg > 0:
                snapshot_base["expectation_time_escalate_target_r"] = round(time_target_cfg, 3)
            time_min_r_cfg = float(
                pair_cfg_entry.get(
                    "expectation_time_escalate_min_r",
                    getattr(self, "EXPECTATION_TIME_ESCALATE_MIN_R", 0.0),
                )
                or 0.0
            )
            if time_min_r_cfg > 0:
                snapshot_base["expectation_time_escalate_min_r"] = round(time_min_r_cfg, 3)
            time_pad_cfg = float(
                pair_cfg_entry.get(
                    "expectation_time_escalate_pad_r",
                    getattr(self, "EXPECTATION_TIME_ESCALATE_PAD_R", 0.0),
                )
                or 0.0
            )
            if time_pad_cfg > 0:
                snapshot_base["expectation_time_escalate_pad_r"] = round(time_pad_cfg, 3)
            relax_minutes_cfg = float(pair_cfg_entry.get("expectation_relax_minutes", getattr(self, "EXPECTATION_RELAX_MINUTES", 0.0)) or 0.0)
            if relax_minutes_cfg > 0:
                snapshot_base["expectation_relax_minutes"] = round(relax_minutes_cfg, 2)

        eq_settings = None
        pair_eq_map = getattr(self, "_entry_quality_pair_settings", None)
        if isinstance(pair_eq_map, dict):
            eq_settings = pair_eq_map.get(pair)
        if eq_settings is None:
            eq_override_cfg = pair_cfg_entry.get("entry_quality") if isinstance(pair_cfg_entry, dict) else None
            eq_settings = self._entry_quality_settings(
                eq_override_cfg if isinstance(eq_override_cfg, dict) else None,
                scope=f"runtime:{pair}",
                log=False,
            )
        if isinstance(eq_settings, dict):
            eq_settings = dict(eq_settings)
            per_side_cfg = eq_settings.pop("_per_side", None)
            if isinstance(per_side_cfg, dict):
                side_cfg = per_side_cfg.get(side)
                if isinstance(side_cfg, dict):
                    for key, value in side_cfg.items():
                        if key == "_per_side":
                            continue
                        eq_settings[key] = value

        price_pos_raw = row.get("price_position", np.nan)
        price_position = float(price_pos_raw) if pd.notna(price_pos_raw) else float("nan")
        if not np.isfinite(price_position):
            price_position = 0.5
        snapshot_base["price_position"] = round(float(price_position), 4)
        price_pos_60_raw = row.get("price_pos_60", np.nan)
        price_pos_60 = float(price_pos_60_raw) if pd.notna(price_pos_60_raw) else float("nan")
        if np.isfinite(price_pos_60):
            snapshot_base["price_pos_60"] = round(float(price_pos_60), 4)
        price_pos_240_raw = row.get("price_pos_240", np.nan)
        price_pos_240 = float(price_pos_240_raw) if pd.notna(price_pos_240_raw) else float("nan")
        if np.isfinite(price_pos_240):
            snapshot_base["price_pos_240"] = round(float(price_pos_240), 4)
        vwap_premium_raw = row.get("session_vwap_premium", np.nan)
        session_vwap_premium = float(vwap_premium_raw) if pd.notna(vwap_premium_raw) else float("nan")
        if np.isfinite(session_vwap_premium):
            snapshot_base["session_vwap_premium"] = round(float(session_vwap_premium), 6)

        risk_cfg = self._risk_forecast_cfg(pair)
        if isinstance(risk_cfg, dict):
            snapshot_base["risk_forecast_mode"] = risk_cfg.get("mode", "atr")

        atr_pct_raw = row.get("atr_pct", np.nan)
        atr_pct_val = float(atr_pct_raw) if pd.notna(atr_pct_raw) else float("nan")
        stoploss_min_pct = max(0.0, float(getattr(self, "STOPLOSS_MIN_PCT", 0.0)))
        fallback_floor = max(0.0, float(getattr(self, "STOPLOSS_FALLBACK", 0.20)))
        stoploss_max_pct = float(getattr(self, "STOPLOSS_MAX_PCT", fallback_floor))
        stoploss_atr_base = float(getattr(self, "STOPLOSS_ATR_BASE", 0.0))
        atr_risk_candidate = float("nan")
        if np.isfinite(atr_pct_val) and atr_pct_val > 0 and stoploss_atr_base > 0:
            snapshot_base["entry_atr_pct"] = round(float(atr_pct_val), 6)
            atr_risk_candidate = atr_pct_val * stoploss_atr_base
        risk_cap = max(stoploss_min_pct, max(stoploss_max_pct, fallback_floor))
        if not np.isfinite(atr_risk_candidate) or atr_risk_candidate <= 0:
            atr_risk_candidate = fallback_floor if fallback_floor > 0 else stoploss_min_pct

        forecast_value, forecast_info = self._risk_forecast_resolve_pct(
            row,
            risk_cfg,
            atr_risk_pct=atr_risk_candidate,
            fallback_floor=fallback_floor,
            stoploss_min_pct=stoploss_min_pct,
            risk_cap=risk_cap,
        ) if isinstance(risk_cfg, dict) else (atr_risk_candidate, {"mode": "atr", "source": "atr"})

        initial_risk = max(forecast_value, stoploss_min_pct)
        if risk_cap > 0:
            initial_risk = min(initial_risk, risk_cap)
        snapshot_base["initial_risk_pct"] = round(float(initial_risk), 6)
        snapshot_base["risk_forecast_pct"] = round(float(initial_risk), 6)
        if isinstance(forecast_info, dict):
            for key in ("source", "mode", "atr", "ewma", "har", "scale"):
                if key in forecast_info and forecast_info[key] is not None:
                    snapshot_base[f"risk_forecast_{key}"] = forecast_info[key]

        rfs_val_raw = row.get("RFS", np.nan)
        rfs_value = float(rfs_val_raw) if pd.notna(rfs_val_raw) else 0.0
        if not np.isfinite(rfs_value):
            rfs_value = 0.0
        snapshot_base["rfs"] = round(float(rfs_value), 4)

        def _apply_balance_snapshot(info: Optional[Dict[str, Any]]) -> None:
            if not isinstance(info, dict):
                return

            def _assign_numeric(key: str, value: Any, digits: int = 6) -> None:
                try:
                    if value is None:
                        return
                    num = float(value)
                except (TypeError, ValueError):
                    return
                if not np.isfinite(num):
                    return
                snapshot_base[key] = round(num, digits)

            def _assign_raw(key: str, value: Any) -> None:
                if value is None:
                    return
                snapshot_base[key] = value

            _assign_numeric("balance_available", info.get("available"))
            _assign_numeric("balance_usable", info.get("usable_after_reserve"))
            _assign_numeric("balance_min_required", info.get("min_required"))
            _assign_numeric("balance_need_margin", info.get("need_margin"))
            _assign_numeric("balance_need_notional", info.get("need_notional"))
            _assign_numeric("balance_reserve_gap", info.get("reserve_gap"))
            _assign_numeric("balance_reserve_buffer", info.get("reserve_buffer"))
            _assign_numeric("balance_reserve_tap_frac", info.get("reserve_tap_frac"), digits=4)

            reserve_mode = info.get("reserve_mode")
            if reserve_mode is not None:
                snapshot_base["balance_reserve_mode"] = reserve_mode
                if str(reserve_mode) in {"buffer", "full"}:
                    snapshot_base["balance_reserve_tap"] = 1
                else:
                    snapshot_base["balance_reserve_tap"] = 0
            elif "balance_reserve_tap" not in snapshot_base:
                snapshot_base["balance_reserve_tap"] = 0

            meta = info.get("min_requirement")
            if isinstance(meta, dict):
                _assign_numeric("balance_requirement_leverage", meta.get("leverage"), digits=4)
                _assign_numeric("balance_requirement_override", meta.get("override_margin"))
                _assign_numeric("balance_requirement_baseline", meta.get("baseline_margin"))
                source = meta.get("source") or meta.get("override_source")
                if source:
                    _assign_raw("balance_requirement_source", source)
                reqs = meta.get("requirements")
                if isinstance(reqs, list) and reqs:
                    detail_parts: List[str] = []
                    for req in reqs:
                        if not isinstance(req, dict):
                            continue
                        req_type = req.get("type")
                        margin_val = req.get("margin")
                        notional_val = req.get("notional")
                        try:
                            margin_str = f"{float(margin_val):.6f}" if margin_val is not None else ""
                        except (TypeError, ValueError):
                            margin_str = ""
                        try:
                            notional_str = f"{float(notional_val):.6f}" if notional_val is not None else ""
                        except (TypeError, ValueError):
                            notional_str = ""
                        label = str(req_type or "req")
                        detail = label
                        if margin_str:
                            detail += f":margin={margin_str}"
                        if notional_str:
                            detail += f"/notional={notional_str}"
                        detail_parts.append(detail)
                    if detail_parts:
                        snapshot_base["balance_requirement_details"] = ";".join(detail_parts)

        iceberg_cfg = self._iceberg_config(pair)
        tier_label = iceberg_cfg.get("tier_label")
        if tier_label:
            snapshot_base["position_tier"] = str(tier_label)
        balance_est = iceberg_cfg.get("balance_total")
        if balance_est is not None:
            try:
                balance_float = float(balance_est)
            except (TypeError, ValueError):
                balance_float = None
            else:
                if np.isfinite(balance_float):
                    snapshot_base["position_balance_est"] = round(balance_float, 4)
        legs_cfg = tuple(iceberg_cfg.get("legs", ()))
        if legs_cfg:
            snapshot_base["position_legs"] = ",".join(f"{val:.2f}" for val in legs_cfg)
            leg_shape = self._classify_iceberg_leg_structure(legs_cfg)
            if leg_shape:
                snapshot_base["position_leg_structure"] = leg_shape.get("structure", "")
                snapshot_base["position_leg_descending"] = int(bool(leg_shape.get("descending", False)))
                ratio12 = leg_shape.get("ratio_12")
                if ratio12 is not None and np.isfinite(float(ratio12)):
                    snapshot_base["position_leg_ratio12"] = round(float(ratio12), 3)
                snapshot_base["position_leg_frontload"] = round(float(leg_shape.get("frontload", 0.0) or 0.0), 4)
                snapshot_base["position_leg_second"] = round(float(leg_shape.get("second", 0.0) or 0.0), 4)
                snapshot_base["position_leg_tail"] = round(float(leg_shape.get("tail", 0.0) or 0.0), 4)
                snapshot_base["position_leg_n_candidate"] = int(bool(leg_shape.get("n_candidate", False)))
        max_adds_cfg = int(iceberg_cfg.get("max_adds", int(getattr(self, "max_entry_position_adjustment", 0) or 0)))
        snapshot_base["position_max_adds"] = max_adds_cfg
        pullback_cfg = float(iceberg_cfg.get("min_pullback_atr", getattr(self, "ICEBERG_MIN_PULLBACK_ATR", 0.0)) or 0.0)
        if pullback_cfg > 0:
            snapshot_base["position_pullback_atr"] = round(pullback_cfg, 4)

        pivot_snapshot = self._update_channel_pivot_state(st, row, now, row_ts)
        if pivot_snapshot:
            snapshot_base.update(pivot_snapshot)

        daily_limit = self._daily_entry_limit()

        def block(reason: str, extra: Optional[Dict[str, Any]] = None) -> bool:
            info = dict(extra or {})
            highlights = self._entry_log_highlights(snapshot_base)
            for key, value in highlights.items():
                info.setdefault(key, value)
            if darkside_ctx:
                info.setdefault("darkside", int(bool(darkside_ctx.get("ok"))))
                info.setdefault("darkside_score", round(float(darkside_ctx.get("score", 0.0) or 0.0), 4))
                info.setdefault("darkside_need", round(float(darkside_ctx.get("need", 0.0) or 0.0), 4))
                info.setdefault("darkside_mode", darkside_ctx.get("mode"))
            self._log_decision(stage, pair, side, "拦截", reason, info)
            try:
                st["last_entry_block"] = {
                    "reason": reason,
                    "time": row_ts,
                    "stage": stage,
                    "extra": dict(extra or {}),
                    "side": side,
                    "row_index": getattr(row, "name", None),
                }
            except Exception:
                pass
            return False

        daily_profit_ctx = self._daily_profit_cap_state(now, pair)
        if daily_profit_ctx.get("active") and daily_profit_ctx.get("hit"):
            return block(
                "当日盈利达标，休息模式暂停新仓",
                {
                    "daily_profit_cap": round(float(daily_profit_ctx.get("cap_abs", 0.0) or 0.0), 6),
                    "daily_profit_progress": round(float(daily_profit_ctx.get("progress_abs", 0.0) or 0.0), 6),
                    "daily_profit_basis": daily_profit_ctx.get("basis", "available"),
                    "daily_profit_sources": daily_profit_ctx.get("sources", ""),
                },
            )

        def _parse_handoff_ts(raw_val: Any) -> Optional[datetime]:
            if isinstance(raw_val, datetime):
                return raw_val if raw_val.tzinfo else raw_val.replace(tzinfo=timezone.utc)
            if raw_val is None:
                return None
            try:
                ts_val = pd.to_datetime(raw_val)
            except Exception:
                return None
            if ts_val is None or (isinstance(ts_val, float) and np.isnan(ts_val)):
                return None
            if isinstance(ts_val, pd.Timestamp):
                ts_dt = ts_val.to_pydatetime()
            else:
                ts_dt = ts_val if isinstance(ts_val, datetime) else None
            if ts_dt is None:
                return None
            return ts_dt if ts_dt.tzinfo else ts_dt.replace(tzinfo=timezone.utc)

        handoff_relax_mult = 1.0
        handoff_align_bonus = 0.0
        handoff_active = False
        relax_side = str(st.get("opp_handoff_relax_side", "") or "").lower()
        relax_until = _parse_handoff_ts(st.get("opp_handoff_relax_until"))
        relax_mult = float(getattr(self, "OPP_SIGNAL_HANDOFF_TRI_RELAX", 0.96))
        relax_align_cfg = float(getattr(self, "OPP_SIGNAL_HANDOFF_ALIGN_BONUS", 0.02))
        if relax_until is not None and now is not None:
            relax_until = relax_until.astimezone(timezone.utc)
            if now > relax_until:
                st.pop("opp_handoff_relax_until", None)
                st.pop("opp_handoff_relax_side", None)
                st.pop("opp_handoff_relax_mult", None)
                st.pop("opp_handoff_align_bonus", None)
            elif relax_side in {"long", "short"} and relax_side == side:
                handoff_active = True
                handoff_relax_mult = float(st.get("opp_handoff_relax_mult", relax_mult) or relax_mult)
                handoff_align_bonus = float(st.get("opp_handoff_align_bonus", relax_align_cfg) or relax_align_cfg)

        directional_guard_snapshot: Optional[Dict[str, Any]] = None

        session_block_entry = bool(session_ctx.get("block_entry") or session_ctx.get("block_entries"))
        session_block_add = bool(session_ctx.get("block_add") or session_ctx.get("block_adds"))
        session_add_mult = float(session_ctx.get("add_mult", 1.0))
        if session_block_entry or session_add_mult == 0.0:
            return block("交易时段宵禁暂停新仓", {
                "session": session_ctx.get("label", "session"),
                "session_bias": session_ctx.get("bias", "neutral"),
                "block_add": int(session_block_add),
                "curfew_reason": "session_curfew",
                "local_hour": session_ctx.get("local_hour"),
                "tz_offset_hours": session_ctx.get("offset_hours"),
                "window_local": session_ctx.get("window_local"),
            })

        def allow(reason: str,
                  extra: Optional[Dict[str, Any]] = None,
                  snapshot: Optional[Dict[str, Any]] = None) -> bool:
            snap = dict(snapshot_base)
            if snapshot:
                snap.update(snapshot)
            snap.setdefault("time", row_ts)
            snap.setdefault("entry_signal_dt", row_ts)
            price_snapshot = self._safe_float(row.get("close"))
            if price_snapshot is not None and price_snapshot > 0:
                snap.setdefault("entry_signal_price", price_snapshot)
            snap.setdefault("side", side)
            entries_used = int(st.get("entries_today", 0))
            snap.setdefault("entries_today", entries_used)
            limit_log_value = daily_limit if daily_limit is not None else 0
            snap.setdefault("daily_limit", limit_log_value)
            entries_left = None
            if daily_limit is not None:
                entries_left = max(0, daily_limit - entries_used - 1)
            snap.setdefault("entries_left", entries_left)
            st["pending_entry_snapshot"] = snap
            st.pop("last_entry_block", None)
            info = dict(extra or {})
            info.setdefault("entries_today", entries_used)
            info.setdefault("daily_limit", limit_log_value)
            if daily_limit is not None:
                info.setdefault("entries_left", max(0, daily_limit - entries_used - 1))
            if handoff_active:
                info.setdefault("handoff_relax", 1)
                info.setdefault("handoff_until", relax_until.isoformat() if relax_until else None)
                st.pop("opp_handoff_relax_until", None)
                st.pop("opp_handoff_relax_side", None)
                st.pop("opp_handoff_relax_mult", None)
                st.pop("opp_handoff_align_bonus", None)
            highlights = self._entry_log_highlights(snap)
            for key, value in highlights.items():
                info.setdefault(key, value)
            pivot_state = st.get("channel_pivot")
            if isinstance(pivot_state, dict):
                pivot_state["pending_side"] = side
                pivot_state["pending_time"] = now
            if darkside_ctx:
                info.setdefault("darkside", int(bool(darkside_ctx.get("ok"))))
                info.setdefault("darkside_score", round(float(darkside_ctx.get("score", 0.0) or 0.0), 4))
                info.setdefault("darkside_need", round(float(darkside_ctx.get("need", 0.0) or 0.0), 4))
                info.setdefault("darkside_mode", darkside_ctx.get("mode"))
                if darkside_ctx.get("ok") and not reason.startswith("[暗面]"):
                    reason = "[暗面]" + reason
            self._log_decision(stage, pair, side, "放行", reason, info)
            self._directional_register_entry(side, now, directional_guard_cfg if side == "short" else None)
            if side == "short":
                self._review_track_directional_guard(
                    directional_guard_snapshot,
                    pair=pair,
                    side=side,
                    verdict="allow",
                    reason=None,
                    timestamp=now,
                )
            return True

        fresh_ok, fresh_reason, fresh_extra = self._ensure_data_fresh(
            pair,
            runtime_now,
            df=df,
            current_time=now,
            row_ts=row_ts,
        )
        if not fresh_ok:
            reason_txt = fresh_reason or "数据刷新冷却中"
            return block(reason_txt, fresh_extra)

        price_val = self._safe_float(row.get("close"))
        if (price_val is None or price_val <= 0) and rate and rate > 0:
            price_val = self._safe_float(rate)
        balance_ok, balance_reason, balance_extra = self._ensure_min_stake_balance(pair, now, price_val)
        if balance_reason == "reserve_tap" and isinstance(balance_extra, dict):
            tap_info = dict(balance_extra)
            st["last_balance_reserve_tap"] = {"ts": now, **tap_info}
            if "reserve_ratio_used" in tap_info:
                snapshot_base["balance_reserve_ratio_used"] = tap_info.get("reserve_ratio_used")
            if "reserve_static_used" in tap_info:
                snapshot_base["balance_reserve_static_used"] = tap_info.get("reserve_static_used")
            _apply_balance_snapshot(tap_info)
            self._log_decision(
                stage,
                pair,
                side,
                "放行",
                "保证金缓冲动用预留资金",
                tap_info,
            )
            balance_reason = None
            balance_extra = None
        elif balance_ok and isinstance(balance_extra, dict):
            _apply_balance_snapshot(balance_extra)
            balance_extra = None

        if not balance_ok:
            reason_txt = balance_reason or "保证金冷静期"
            return block(reason_txt, balance_extra)

        event_guard = self._macro_event_guard(now, pair, side, purpose="entry")
        if event_guard.get("active"):
            snapshot_base.update({
                "event_label": event_guard.get("label", ""),
                "event_phase": event_guard.get("phase", ""),
            })
            if event_guard.get("block_entry", False):
                return block("宏观事件保护窗口暂停新仓", {
                    "event": event_guard.get("label", "event"),
                    "phase": event_guard.get("phase", "live"),
                })

        dynamic_penalty = False
        dyn_extra_info: Dict[str, Any] = {}
        dyn_ok, dyn_extra = self._dynamic_pair_guard(pair, now, session_ctx=session_ctx)
        if isinstance(dyn_extra, dict):
            dyn_extra_info = dict(dyn_extra)
            st["dynamic_profile"] = {**dyn_extra_info, "ts": now}
            snapshot_base.update({
                "dynamic_mode": dyn_extra_info.get("dynamic_mode"),
                "dynamic_source": dyn_extra_info.get("dynamic_source"),
                "dynamic_reason": dyn_extra_info.get("dynamic_reason"),
            })
            metrics = dyn_extra_info.get("dynamic_metric")
            if isinstance(metrics, dict):
                snapshot_base["dynamic_change"] = metrics.get("change")
                snapshot_base["dynamic_quote_volume"] = metrics.get("quote_volume")
            hotlist = dyn_extra_info.get("dynamic_pairs")
            if isinstance(hotlist, list) and hotlist:
                snapshot_base["dynamic_pairs"] = ",".join(list(map(str, hotlist[:5])))
        if not dyn_ok:
            return block("动态热榜未包含该币", dyn_extra_info or dyn_extra)
        dynamic_penalty = bool(dyn_extra_info.get("dynamic_penalty"))
        snapshot_base["dynamic_penalty"] = int(dynamic_penalty)

        slow_lane_col = "slow_lane_short" if side == "short" else "slow_lane_long"
        fast_lane_col = "fast_lane_short" if side == "short" else "fast_lane_long"
        slow_lane_val = row.get(slow_lane_col, 0)
        fast_lane_val = row.get(fast_lane_col, 0)
        slow_lane = bool(int(slow_lane_val)) if pd.notna(slow_lane_val) and np.isfinite(slow_lane_val) else False
        fast_lane = bool(int(fast_lane_val)) if pd.notna(fast_lane_val) and np.isfinite(fast_lane_val) else False
        align_score = float(row.get("htf_alignment", 0.0) or 0.0)
        if not np.isfinite(align_score):
            align_score = 0.0

        if dynamic_penalty and not (fast_lane or slow_lane):
            return block("动态热榜优先：等待快/慢车道确认", {
                "dynamic_mode": dyn_extra_info.get("dynamic_mode"),
                "dynamic_reason": dyn_extra_info.get("dynamic_reason"),
            })

        channel_narrow = bool(int(row.get("channel_mode_narrow_trend", 0) or 0))
        channel_wide = bool(int(row.get("channel_mode_wide_range", 0) or 0))
        channel_decay = bool(int(row.get("channel_mode_wide_decay", 0) or 0))
        htf_drive_lane = bool(int(row.get("channel_mode_htf_drive", 0) or 0))

        pivot_ok, pivot_reason, pivot_extra, pivot_snap = self._channel_pivot_guard(
            pair=pair,
            side=side,
            row=row,
            st=st,
            align_score=align_score,
            now=now,
            row_ts=row_ts,
            pair_cfg=pair_cfg_entry if isinstance(pair_cfg_entry, dict) else None,
        )
        if pivot_snap:
            snapshot_base.update(pivot_snap)
        if not pivot_ok:
            return block(pivot_reason or "Keltner 突破节奏拦截", pivot_extra)

        def _profile_float(key: str, fallback: float) -> float:
            try:
                raw_val = self._profile_val(key, fallback)
            except Exception:
                raw_val = fallback
            try:
                resolved = float(raw_val)
            except (TypeError, ValueError):
                resolved = float(fallback)
            if not np.isfinite(resolved):
                resolved = float(fallback)
            return resolved

        profile_align_long = _profile_float("align_floor_long", getattr(self, "ENTRY_ALIGN_FLOOR_LONG", 0.0))
        profile_align_short = _profile_float("align_floor_short", getattr(self, "ENTRY_ALIGN_FLOOR_SHORT", 0.0))
        profile_mania_need = max(0.0, _profile_float("mania_align_need", 0.0))
        profile_panic_need = max(0.0, _profile_float("panic_align_need", 0.0))
        profile_tri_mult = max(0.0, _profile_float("tri_need_mult", 1.0))
        profile_dist_mult = max(0.0, _profile_float("dist_relax_mult", 1.0))
        profile_extreme_tri_relief = max(0.0, _profile_float("extreme_tri_relief", 1.0))
        profile_extreme_dist_relief = max(0.0, _profile_float("extreme_dist_relief", 1.0))
        profile_cooldown_mult = max(0.0, _profile_float("entry_cooldown_mult", 1.0))
        profile_mania_floor = max(profile_mania_need, profile_align_short * 0.75)
        panic_val = row.get("panic_tail_guard", 0)
        blowoff_val = row.get("blowoff_tail_guard", 0)
        panic_guard = int(panic_val) if pd.notna(panic_val) and np.isfinite(panic_val) else 0
        panic_slope_val = row.get("panic_slope_guard", 0)
        panic_slope_guard = int(panic_slope_val) if pd.notna(panic_slope_val) and np.isfinite(panic_slope_val) else 0
        panic_tail_block = int(row.get("panic_tail_short_block", 0) or 0)
        panic_slope_block = int(row.get("panic_slope_short_block", 0) or 0)
        blowoff_guard = int(blowoff_val) if pd.notna(blowoff_val) and np.isfinite(blowoff_val) else 0
        reflex_col = "reflex_stop_short" if side == "short" else "reflex_stop_long"
        reflex_val = row.get(reflex_col, 0)
        reflex_guard = int(reflex_val) if pd.notna(reflex_val) and np.isfinite(reflex_val) else 0
        reflex_feedback = float(row.get("reflex_feedback", 0.0) or 0.0)
        reflex_feedback_ma = float(row.get("reflex_feedback_ma", 0.0) or 0.0)
        reflex_feedback_z = float(row.get("reflex_feedback_z", 0.0) or 0.0)

        priority = self._side_priority_bias(pair, row, session_ctx=session_ctx)
        priority_prefer = str(priority.get("prefer") or "")
        try:
            priority_conf_val = float(priority.get("confidence", 0.0) or 0.0)
        except (TypeError, ValueError):
            priority_conf_val = 0.0
        entry_min = float(self._profile_val("priority_entry_min", getattr(self, "SIDE_PRIORITY_ENTRY_BASE", 0.18)))
        fast_override = False
        if bool(getattr(self, "SIDE_PRIORITY_FASTLANE_OVERRIDE", True)):
            fast_override = fast_lane and (vol_any == 1)

        portfolio_guard = bool(getattr(self, "PORTFOLIO_CONTEXT_ENABLE", True))
        portfolio_fragile = False
        port_net = 0.0
        port_losers = 0
        port_loss_pressure = 0.0
        if portfolio_guard:
            portfolio = self._portfolio_snapshot()
            port_net = float(portfolio.get("net_profit_pct", 0.0) or 0.0)
            port_losers = int(portfolio.get("loser_count", 0) or 0)
            port_loss_pressure = float(portfolio.get("loss_pressure_pct", 0.0) or 0.0)
            snapshot_base["portfolio_net"] = round(port_net, 4)
            snapshot_base["portfolio_losers"] = port_losers
            snapshot_base["portfolio_loss_pressure"] = round(port_loss_pressure, 4)
            drain_limit = float(getattr(self, "PORTFOLIO_NET_DRAIN_LIMIT", -0.012))
            fragile_floor = float(getattr(self, "PORTFOLIO_FRAGILE_FLOOR", 0.022))
            loss_need = float(getattr(self, "PORTFOLIO_FRAGILE_LOSS_PRESSURE", 0.10))
            snapshot_base["portfolio_loss_need"] = loss_need
            if port_net <= drain_limit and not fast_override:
                return block("组合净值回撤暂停新仓", {
                    "portfolio_net": port_net,
                    "losers": port_losers,
                })
            if port_net <= fragile_floor and port_losers > 0 and port_loss_pressure >= loss_need:
                portfolio_fragile = True

        mania_lane_active = bool(blowoff_guard >= 1)
        panic_lane_active = bool((panic_guard >= 1) or (panic_slope_guard >= 1))
        pullback_ready_flag = False
        pullback_need_flag = False
        pullback_ready_key = "pullback_ready_long" if side == "long" else "pullback_ready_short"
        pullback_need_key = "pullback_gate_long" if side == "long" else "pullback_gate_short"
        pr_val = row.get(pullback_ready_key, 0)
        pn_val = row.get(pullback_need_key, 0)
        try:
            pullback_ready_flag = bool(int(pr_val))
        except (TypeError, ValueError):
            pullback_ready_flag = False
        try:
            pullback_need_flag = bool(int(pn_val))
        except (TypeError, ValueError):
            pullback_need_flag = False
        snapshot_base["pullback_ready"] = int(pullback_ready_flag)
        snapshot_base["pullback_need"] = int(pullback_need_flag)

        price_guard_ok, price_guard_reason, price_guard_extra = self._entry_price_band_guard(
            side=side,
            price_position=float(price_position),
            price_pos_60=float(price_pos_60),
            price_pos_240=float(price_pos_240),
            session_vwap_premium=float(session_vwap_premium),
            fast_lane=fast_lane,
            slow_lane=slow_lane,
            panic_lane_active=panic_lane_active,
            mania_lane_active=mania_lane_active,
            darkside_ok=darkside_ok,
            vol_confirm=bool(vol_any),
        )
        if not price_guard_ok:
            return block(price_guard_reason or "价格位置不符", price_guard_extra)

        if side == "short":
            ratio_ok, ratio_reason, ratio_info = self._directional_short_guard(
                now=now,
                settings=directional_guard_cfg if isinstance(directional_guard_cfg, dict) else None,
                mania_override=mania_lane_active,
                price_position=price_position,
            )
            if isinstance(ratio_info, dict):
                for key, value in ratio_info.items():
                    if isinstance(value, datetime):
                        snapshot_base[key] = value.isoformat()
                    else:
                        snapshot_base[key] = value
                directional_guard_snapshot = dict(ratio_info)
            if not ratio_ok:
                self._review_track_directional_guard(
                    directional_guard_snapshot,
                    pair=pair,
                    side=side,
                    verdict="block",
                    reason=ratio_reason or "空单比例守卫",
                    timestamp=now,
                )
                return block(ratio_reason or "空单比例守卫", ratio_info)

        snapshot_base.update({
            "fast_lane": int(fast_lane),
            "slow_lane": int(slow_lane),
            "align": align_score,
            "channel_narrow": int(channel_narrow),
            "channel_wide": int(channel_wide),
            "channel_decay": int(channel_decay),
            "htf_drive": int(htf_drive_lane),
            "panic_guard": int(panic_guard),
            "panic_slope_guard": int(panic_slope_guard),
            "panic_tail_block": int(panic_tail_block),
            "panic_slope_block": int(panic_slope_block),
            "panic_slope_drop": float(row.get("panic_slope_drop_atr", 0.0) or 0.0),
            "panic_slope_rebound": float(row.get("panic_slope_rebound_atr", 0.0) or 0.0),
            "blowoff_guard": int(blowoff_guard),
            "reflex_guard": int(reflex_guard),
            "reflex_feedback": reflex_feedback,
            "reflex_feedback_ma": reflex_feedback_ma,
            "reflex_feedback_z": reflex_feedback_z,
            "enter_tag": str(row.get("enter_tag", "") or ""),
            "vol_any": vol_any,
            "priority_long": round(float(priority.get("long_score", 0.0) or 0.0), 3),
            "priority_short": round(float(priority.get("short_score", 0.0) or 0.0), 3),
            "priority_prefer": priority_prefer,
            "priority_conf": round(priority_conf_val, 3),
            "portfolio_fragile": int(portfolio_fragile),
            "profile_align_long": round(profile_align_long, 4),
            "profile_align_short": round(profile_align_short, 4),
            "profile_mania_align_need": round(profile_mania_need, 4),
            "profile_mania_align_floor": round(profile_mania_floor, 4),
            "profile_panic_align_need": round(profile_panic_need, 4),
            "profile_tri_need_mult": round(profile_tri_mult, 4),
            "profile_dist_relax_mult": round(profile_dist_mult, 4),
            "profile_extreme_tri_relief": round(profile_extreme_tri_relief, 4),
            "profile_extreme_dist_relief": round(profile_extreme_dist_relief, 4),
            "profile_entry_cooldown_mult": round(profile_cooldown_mult, 4),
            "mania_lane_active": int(mania_lane_active),
            "panic_lane_active": int(panic_lane_active),
        })

        style_ctx = self._resolve_style_mode(
            side=side,
            session_ctx=session_ctx,
            fast_lane=fast_lane,
            slow_lane=slow_lane,
            channel_narrow=channel_narrow,
            channel_wide=channel_wide,
            channel_decay=channel_decay,
            align_score=float(align_score),
            rfs_value=float(rfs_value),
            price_position=float(price_position),
            dynamic_penalty=dynamic_penalty,
            portfolio_guard=portfolio_guard,
            portfolio_fragile=portfolio_fragile,
            port_net=float(port_net),
            port_loss_pressure=float(port_loss_pressure),
            perf_guard=perf_guard,
            perf_hot=perf_hot,
            mania_lane_active=mania_lane_active,
            panic_lane_active=panic_lane_active,
        )
        style_profile = dict(style_ctx.get("profile") or {})
        style_mode = style_ctx.get("mode", str(self.PRESET or "conservative").lower())
        style_dist_mult = float(style_profile.get("dist_mult", 1.0) or 1.0)
        style_tri_mult = float(style_profile.get("tri_mult", 1.0) or 1.0)
        style_quality_add = float(style_profile.get("quality_add", 0.0) or 0.0)
        style_frontload_mult = float(style_profile.get("frontload_mult", 1.0) or 1.0)
        style_cooldown_mult = float(style_profile.get("cooldown_mult", 1.0) or 1.0)
        snapshot_base.update({
            "style_mode": style_mode,
            "style_reason": style_ctx.get("reason"),
            "style_bias": style_ctx.get("bias"),
            "style_dist_mult": style_dist_mult,
            "style_tri_mult": style_tri_mult,
            "style_quality_add": style_quality_add,
            "style_frontload_mult": style_frontload_mult,
            "style_cooldown_mult": style_cooldown_mult,
        })

        if mania_lane_active:
            mania_need_pass = align_score <= (-profile_mania_need if profile_mania_need > 0 else 0.0)
            mania_floor_pass = align_score <= -profile_mania_floor
            snapshot_base["profile_mania_need_pass"] = int(mania_need_pass)
            snapshot_base["profile_mania_floor_pass"] = int(mania_floor_pass)
        if panic_lane_active and profile_panic_need > 0:
            snapshot_base["profile_panic_need_pass"] = int(align_score >= profile_panic_need)

        if portfolio_fragile and not fast_override:
            align_need_base = float(getattr(self, "PORTFOLIO_FRAGILE_ALIGN", 0.28))
            align_need = self._fragile_align_need(
                align_need_base,
                side,
                fast_lane=fast_lane,
                slow_lane=slow_lane,
                htf_drive=htf_drive_lane,
                port_net=port_net,
                loss_pressure=port_loss_pressure,
                panic_lane=((panic_guard >= 1) or (panic_slope_guard >= 1)),
                mania_lane=(blowoff_guard >= 1),
            )
            if (side == "long" and align_score < align_need) or (side == "short" and align_score > -align_need):
                return block("组合脆弱期需更强多周期对齐", {
                    "align": align_score,
                    "align_need": align_need,
                    "align_need_base": align_need_base,
                    "portfolio_net": port_net,
                    "losers": port_losers,
                    "loss_pressure": port_loss_pressure,
                    "loss_need": loss_need,
                })

        perf = self._performance_profile(pair)
        perf_guard = bool(perf.get("drawdown_guard", False))
        perf_hot = (perf.get("mode") == "hot")

        if perf_guard:
            strong_trend = fast_lane and ((side == "long" and align_score >= 0.55) or (side == "short" and align_score <= -0.55))
            structured = channel_narrow and ((side == "long" and align_score >= 0.45) or (side == "short" and align_score <= -0.45))
            if not (strong_trend or structured):
                return block("绩效刹车：等待高胜率形态", {
                    "loss_streak": int(perf.get("loss_streak", 0)),
                    "drawdown": float(perf.get("drawdown", 0.0)),
                    "reasons": "/".join(perf.get("guard_reasons", [])) or "drawdown",
                })

        # ATR 窗
        atr_pct = float(row.get("atr_pct", np.nan))
        if not np.isfinite(atr_pct):
            return block("ATR 指标缺失", {"atr_pct": atr_pct})
        atr_min = max(self.ATR_WIN_MIN * 0.6, 0.0006); atr_max = self.ATR_WIN_MAX * 1.22
        if not (atr_min <= atr_pct <= atr_max):
            return block("ATR 超出允许窗口", {"atr_pct": atr_pct, "atr_min": atr_min, "atr_max": atr_max})

        if reflex_guard >= 1:
            reason = "顶部能量塌陷" if side == "long" else "底部恐慌缓解"
            return block("反身性护栏：" + reason, {
                "feedback": reflex_feedback,
                "feedback_ma": reflex_feedback_ma,
                "feedback_z": reflex_feedback_z,
                "guard": reflex_guard,
            })

        prefer = priority.get("prefer")
        confidence = float(priority.get("confidence", 0.0) or 0.0)
        if prefer and prefer != side and confidence >= entry_min and not fast_override:
            return block("方向优先级倾向" + ("多头" if prefer == "long" else "空头"), {
                "prefer": prefer,
                "confidence": confidence,
                "fast_override": int(fast_override),
                "details": priority.get("details"),
            })

        if dynamic_penalty:
            penalty_need = max(0.0, float(getattr(self, "POSITION_SIGNAL_REVIEW_ALIGN_NEED", 0.0) or 0.0))
            if (side == "long" and align_score < penalty_need) or (side == "short" and align_score > -penalty_need):
                return block("动态热榜优先：等待多周期对齐", {
                    "align": align_score,
                    "align_need": penalty_need,
                    "dynamic_mode": dyn_extra_info.get("dynamic_mode"),
                })

        # 与 1h EMA200 距离
        dist_ema = float(row.get("dist_ema200_1h", np.nan))
        if not np.isfinite(dist_ema):
            ema200 = float(row.get("ema200_1h", np.nan))
            ref = float(rate) if rate and rate > 0 else float(row.get("close", np.nan))
            if np.isfinite(ema200) and np.isfinite(ref) and ref > 0:
                dist_ema = abs(ref - ema200) / ref
            else:
                return block("EMA200 距离无法计算", {"ema200": ema200, "ref": ref})
        dist_need = float(row.get("dist_need_adapt", self.DIST_EMA_NEED))
        dist_near = float(row.get("dist_near_min_adapt", self.DIST_EMA_NEAR_MIN))
        if portfolio_fragile and not fast_override:
            mult = float(getattr(self, "PORTFOLIO_FRAGILE_DIST_MULT", 1.04))
            dist_need *= mult
            dist_near *= mult
        if slow_lane:
            dist_need *= 0.90
            dist_near *= 0.85
        elif fast_lane:
            dist_need *= 0.95
            dist_near *= 0.92
        if channel_narrow:
            if side == "long" and align_score >= 0.10:
                dist_need *= 0.92
                dist_near *= 0.88
            if side == "short" and align_score <= -0.10:
                dist_need *= 0.93
                dist_near *= 0.90
        if channel_wide and not channel_decay:
            dist_need *= 0.97
        if channel_wide and channel_decay:
            dist_need *= 1.04
            dist_near *= 1.02
        if perf_guard:
            dist_need *= 1.02
            dist_near *= 1.01
        if perf_hot:
            relax = float(self.PERF_HOT_DIST_RELAX)
            dist_need *= relax
            dist_near *= relax
        dist_mult = float(session_ctx.get("dist_mult", 1.0))
        if event_guard.get("active"):
            dist_mult *= float(event_guard.get("dist_mult", 1.0))
        dist_need *= dist_mult
        dist_near *= dist_mult
        dist_relax_mult = float(self._profile_val("dist_relax_mult", 1.0) or 1.0)
        dist_need *= dist_relax_mult
        dist_near *= dist_relax_mult
        if style_dist_mult != 1.0:
            dist_need *= style_dist_mult
            dist_near *= style_dist_mult
        base_near_floor = self.DIST_EMA_NEAR_MIN * 0.75
        dist_near = max(dist_near, base_near_floor)
        if side == "short":
            dist_need *= self.DIST_EMA_NEED_SHORT_BONUS
            dist_near *= self.DIST_EMA_NEAR_MIN_SHORT_BONUS
        if side == "long" and panic_guard >= 1:
            dist_need *= 0.94
            dist_near *= 0.90
        if side == "short" and blowoff_guard >= 1:
            dist_need *= 0.94
            dist_near *= 0.92
        extreme_dist_relief = profile_extreme_dist_relief if profile_extreme_dist_relief > 0 else 1.0
        if extreme_dist_relief != 1.0:
            if side == "long" and panic_guard >= 1:
                dist_need *= extreme_dist_relief
                dist_near *= extreme_dist_relief
            if side == "short" and blowoff_guard >= 1:
                dist_need *= extreme_dist_relief
                dist_near *= extreme_dist_relief
        dist_near = max(dist_near, self.DIST_EMA_NEAR_MIN * (self.DIST_EMA_NEAR_MIN_SHORT_BONUS if side == "short" else 1.0) * 0.75)
        dist_need = max(dist_need, dist_near)

        snapshot_base.update({
            "dist_need": float(dist_need),
            "dist_near": float(dist_near),
            "dist_ema": float(dist_ema),
        })

        # 三锚软锁
        tri_need = self._tri_need_threshold()
        if slow_lane and align_score > 0.25:
            tri_need *= 0.92
        elif fast_lane:
            tri_need *= 0.97
        if channel_narrow and ((side == "long" and align_score >= 0.15) or (side == "short" and align_score <= -0.15)):
            tri_need *= 0.95
        if channel_wide and channel_decay:
            tri_need *= 1.03
        if side == "long" and panic_guard >= 1:
            tri_need *= 0.95
        if side == "short" and blowoff_guard >= 1:
            tri_need *= 0.95
        extreme_tri_relief = profile_extreme_tri_relief if profile_extreme_tri_relief > 0 else 1.0
        if extreme_tri_relief != 1.0:
            if side == "long" and panic_guard >= 1:
                tri_need *= extreme_tri_relief
            if side == "short" and blowoff_guard >= 1:
                tri_need *= extreme_tri_relief
        if perf_guard:
            tri_need *= 1.03
        if perf_hot:
            tri_need *= float(self.PERF_HOT_DIST_RELAX)
        tri_need *= float(session_ctx.get("tri_mult", 1.0))
        if event_guard.get("active"):
            tri_need *= float(event_guard.get("tri_mult", 1.0))
        if portfolio_fragile and not fast_override:
            tri_need *= float(getattr(self, "PORTFOLIO_FRAGILE_TRI_MULT", 1.05))
        if style_tri_mult != 1.0:
            tri_need *= style_tri_mult
        if handoff_active:
            tri_need *= handoff_relax_mult
            align_score += handoff_align_bonus
        tri_need = float(np.clip(tri_need, 0.0, 1.0))
        tri_bias_val = float(row.get("tri_bias_long", 0.0) if side == "long" else row.get("tri_bias_short", 0.0))

        tri_need_base = float(tri_need)
        snapshot_base.update({
            "tri_need_base": tri_need_base,
            "tri_bias": tri_bias_val,
        })

        try:
            ctx = self._darkside_entry_context(
                side=side,
                tri_need=tri_need_base,
                tri_bias=float(tri_bias_val),
                align_score=float(align_score),
                rfs_value=float(rfs_value),
                price_position=float(price_position),
                panic_guard=int(panic_guard),
                panic_slope_guard=int(panic_slope_guard),
                blowoff_guard=int(blowoff_guard),
                reflex_z=float(reflex_feedback_z),
                fast_lane=fast_lane,
                slow_lane=slow_lane,
                channel_narrow=channel_narrow,
                channel_wide=channel_wide,
                channel_decay=channel_decay,
                vol_any=int(vol_any),
            )
            if isinstance(ctx, dict) and ctx:
                darkside_ctx = ctx
        except Exception:
            ctx = {}

        if isinstance(darkside_ctx, dict) and darkside_ctx:
            snap_extra = darkside_ctx.get("snapshot", {})
            if isinstance(snap_extra, dict):
                for key, value in snap_extra.items():
                    if value is not None:
                        snapshot_base[key] = value
            snapshot_base.setdefault("darkside_penalty_pass", float(getattr(self, "ENTRY_FRONTLOAD_DARKSIDE_PASS_PENALTY", 1.0)))
            snapshot_base.setdefault("darkside_penalty_active", float(getattr(self, "ENTRY_FRONTLOAD_DARKSIDE_ACTIVE_PENALTY", 1.0)))
            darkside_ok = bool(darkside_ctx.get("ok", False))
            if darkside_ok:
                tri_relief = float(darkside_ctx.get("tri_relief", 0.0) or 0.0)
                tri_need = max(0.0, tri_need_base - tri_relief)
                darkside_align_relief = float(darkside_ctx.get("align_relief", 0.0) or 0.0)
                darkside_quality_bonus = float(darkside_ctx.get("quality_bonus", 0.0) or 0.0)
                darkside_quality_relief = float(darkside_ctx.get("quality_relief", 0.0) or 0.0)
        else:
            snapshot_base.setdefault("darkside_active", 0)
            snapshot_base.setdefault("darkside_pass", 0)

        snapshot_base["tri_need"] = round(float(tri_need), 4)

        if tri_bias_val < tri_need:
            return block("三锚偏置不足", {"tri_need": tri_need, "tri_bias": tri_bias_val})

        align_floor_long = max(0.0, float(self._profile_val("align_floor_long", self.ENTRY_ALIGN_FLOOR_LONG)))
        align_floor_short = max(0.0, float(self._profile_val("align_floor_short", self.ENTRY_ALIGN_FLOOR_SHORT)))

        if darkside_ok:
            if side == "long":
                align_floor_long = max(0.0, align_floor_long - darkside_align_relief)
            else:
                align_floor_short = max(0.0, align_floor_short - darkside_align_relief)

        guard_override = (side == "long" and panic_guard >= 1) or (side == "short" and blowoff_guard >= 1)

        long_override = fast_lane or (htf_drive_lane and align_score >= (align_floor_long * 0.8)) or (channel_narrow and slow_lane)
        if (
            side == "long"
            and align_score < align_floor_long
            and not guard_override
            and not long_override
        ):
            return block("多周期仍偏空，暂缓抄底", {
                "align": align_score,
                "align_floor": align_floor_long,
                "fast_lane": int(fast_lane),
                "slow_lane": int(slow_lane),
                "htf_drive": int(htf_drive_lane),
            })

        short_override = fast_lane or (htf_drive_lane and align_score <= -(align_floor_short * 0.8)) or (channel_wide and channel_decay)
        if (
            side == "short"
            and align_score > -align_floor_short
            and not guard_override
            and not short_override
        ):
            return block("多周期仍偏多，暂缓追空", {
                "align": align_score,
                "align_floor": -align_floor_short,
                "fast_lane": int(fast_lane),
                "slow_lane": int(slow_lane),
                "htf_drive": int(htf_drive_lane),
                "channel_wide": int(channel_wide),
                "channel_decay": int(channel_decay),
            })

        quality_score = 0.0
        quality_need = 0.0
        quality_need_raw = 0.0
        quality_buffer = 0.0
        quality_details: Dict[str, float] = {}
        extreme_lane = False
        quality_enabled = bool(eq_settings.get("enable", getattr(self, "ENTRY_QUALITY_ENABLE", self.ENTRY_QUALITY_ENABLE)))
        if quality_enabled:
            priority_conf = float(priority.get("confidence", 0.0) or 0.0)
            quality_score, quality_details = self._entry_quality_score(
                side=side,
                align_score=float(align_score),
                tri_bias=float(tri_bias_val),
                rfs_value=float(rfs_value),
                priority_conf=priority_conf,
                price_position=float(price_position),
                price_pos_60=float(price_pos_60),
                price_pos_240=float(price_pos_240),
                session_vwap_premium=float(session_vwap_premium),
                pullback_ready=pullback_ready_flag,
                pullback_needed=pullback_need_flag,
                fast_lane=fast_lane,
                slow_lane=slow_lane,
                htf_drive=htf_drive_lane,
                channel_narrow=channel_narrow,
                channel_wide=channel_wide,
                channel_decay=channel_decay,
                vol_surge=int(vol_any == 1),
                settings=eq_settings,
            )
            if darkside_ok and darkside_quality_bonus > 0:
                quality_score = float(np.clip(quality_score + darkside_quality_bonus, 0.0, 1.0))
                quality_details["darkside_bonus"] = darkside_quality_bonus
            base_need = float(eq_settings.get("base_need", getattr(self, "ENTRY_QUALITY_BASE_NEED", self.ENTRY_QUALITY_BASE_NEED)))
            fast_need_default = max(base_need, getattr(self, "ENTRY_QUALITY_FAST_NEED", self.ENTRY_QUALITY_FAST_NEED))
            fast_need = float(eq_settings.get("fast_need", fast_need_default))
            slow_need_default = max(base_need, getattr(self, "ENTRY_QUALITY_SLOW_NEED", self.ENTRY_QUALITY_SLOW_NEED))
            slow_need = float(eq_settings.get("slow_need", slow_need_default))
            if style_quality_add != 0.0:
                base_need = max(0.0, base_need + style_quality_add)
                fast_need = max(0.0, fast_need + style_quality_add)
                slow_need = max(0.0, slow_need + style_quality_add)
            if fast_lane:
                quality_need = fast_need
            elif slow_lane:
                quality_need = slow_need
            else:
                quality_need = base_need
            if dynamic_penalty:
                quality_need += float(eq_settings.get("dynamic_add", getattr(self, "ENTRY_QUALITY_DYNAMIC_ADD", self.ENTRY_QUALITY_DYNAMIC_ADD)))
            if portfolio_fragile and not fast_override:
                quality_need += float(eq_settings.get("fragile_add", getattr(self, "ENTRY_QUALITY_FRAGILE_ADD", self.ENTRY_QUALITY_FRAGILE_ADD)))
            if channel_wide and channel_decay:
                quality_need += float(eq_settings.get("decay_add", getattr(self, "ENTRY_QUALITY_DECAY_ADD", self.ENTRY_QUALITY_DECAY_ADD)))
            extreme_lane = (side == "long" and panic_guard >= 1) or (side == "short" and blowoff_guard >= 1)
            if extreme_lane:
                quality_need += float(eq_settings.get("extreme_add", getattr(self, "ENTRY_QUALITY_EXTREME_ADD", self.ENTRY_QUALITY_EXTREME_ADD)))
            prefer_dir = priority.get("prefer")
            if isinstance(prefer_dir, str) and prefer_dir == side:
                quality_need -= float(eq_settings.get("prefer_relief", getattr(self, "ENTRY_QUALITY_PREFER_RELIEF", self.ENTRY_QUALITY_PREFER_RELIEF)))
            if darkside_ok and darkside_quality_relief > 0:
                quality_need -= darkside_quality_relief
            quality_need_raw = float(np.clip(quality_need, 0.0, 0.95))
            buffer_base = float(eq_settings.get("need_buffer", getattr(self, "ENTRY_QUALITY_NEED_BUFFER", self.ENTRY_QUALITY_NEED_BUFFER)))
            if buffer_base > 0:
                buffer_mult = 1.0
                if fast_lane:
                    buffer_mult *= float(eq_settings.get(
                        "need_buffer_fast_mult",
                        getattr(self, "ENTRY_QUALITY_NEED_BUFFER_FAST_MULT", self.ENTRY_QUALITY_NEED_BUFFER_FAST_MULT),
                    ))
                elif slow_lane:
                    buffer_mult *= float(eq_settings.get(
                        "need_buffer_slow_mult",
                        getattr(self, "ENTRY_QUALITY_NEED_BUFFER_SLOW_MULT", self.ENTRY_QUALITY_NEED_BUFFER_SLOW_MULT),
                    ))
                if extreme_lane:
                    buffer_mult *= float(eq_settings.get(
                        "need_buffer_extreme_mult",
                        getattr(self, "ENTRY_QUALITY_NEED_BUFFER_EXTREME_MULT", self.ENTRY_QUALITY_NEED_BUFFER_EXTREME_MULT),
                    ))
                if buffer_mult > 0:
                    quality_buffer = buffer_base * buffer_mult
            if quality_buffer > 0:
                quality_need = float(np.clip(quality_need_raw + quality_buffer, 0.0, 0.98))
            else:
                quality_need = quality_need_raw
            snapshot_base["entry_quality"] = round(float(quality_score), 4)
            snapshot_base["entry_quality_need"] = round(float(quality_need), 4)
            if quality_need != quality_need_raw:
                snapshot_base["entry_quality_need_raw"] = round(float(quality_need_raw), 4)
                snapshot_base["entry_quality_buffer"] = round(float(quality_buffer), 4)
            comp_map = {
                "align_component": "quality_align",
                "tri_component": "quality_tri",
                "rfs_component": "quality_rfs",
                "priority_component": "quality_priority",
            }
            for src, dest in comp_map.items():
                val = quality_details.get(src)
                if val is not None and np.isfinite(val):
                    snapshot_base[dest] = round(float(val), 4)
            base_component = quality_details.get("base_score")
            if base_component is not None and np.isfinite(base_component):
                snapshot_base["quality_base"] = round(float(base_component), 4)
            lane_component = quality_details.get("lane_bonus")
            if lane_component is not None and np.isfinite(lane_component):
                snapshot_base["quality_lane_bonus"] = round(float(lane_component), 4)
            price_component = quality_details.get("price_penalty")
            if price_component is not None and np.isfinite(price_component):
                snapshot_base["quality_price_penalty"] = round(float(price_component), 4)
            anchor_component = quality_details.get("price_anchor_penalty")
            if anchor_component is not None and np.isfinite(anchor_component):
                snapshot_base["quality_price_anchor"] = round(float(anchor_component), 4)
            pullback_component = quality_details.get("pullback_component")
            if pullback_component is not None and np.isfinite(pullback_component):
                snapshot_base["quality_pullback_component"] = round(float(pullback_component), 4)
            if darkside_ok:
                if "darkside_bonus" in quality_details:
                    snapshot_base["quality_darkside_bonus"] = round(float(quality_details["darkside_bonus"]), 4)
                if darkside_quality_relief > 0:
                    snapshot_base["quality_need_relaxed"] = round(float(quality_need), 4)

            quality_ctx = st.setdefault("quality_context", {})
            exit_cluster_score = float(quality_ctx.get("exit_cluster_score", float("nan")))
            exit_cluster_count = int(quality_ctx.get("exit_cluster_count", 0) or 0)
            exit_cluster_window = int(quality_ctx.get("exit_cluster_window", 0) or 0)
            signal_filter_cfg = self._signal_filter_settings(pair_cfg_entry if isinstance(pair_cfg_entry, dict) else None)
            ob_imbalance_val = row.get("orderbook_imbalance", row.get("ob_imbalance", np.nan))
            flow_rate_val = row.get("orderflow_rate", row.get("net_flow_rate", np.nan))
            volume_val = row.get("quote_volume", row.get("volume", 0.0))
            volume_ma_val = row.get("quote_volume_mean", row.get("volume_mean", 0.0))
            gate_ok, gate_reason, gate_meta = self._signal_quality_gate(
                side=side,
                quality_score=float(quality_score),
                quality_need=float(quality_need if quality_need else quality_need_raw),
                align_score=float(align_score),
                tri_bias=float(tri_bias_val),
                rfs_value=float(rfs_value),
                volume=float(volume_val or 0.0),
                volume_ma=float(volume_ma_val or 0.0),
                orderbook_imbalance=float(ob_imbalance_val) if pd.notna(ob_imbalance_val) else float("nan"),
                flow_rate=float(flow_rate_val) if pd.notna(flow_rate_val) else float("nan"),
                exit_cluster_score=exit_cluster_score,
                settings=signal_filter_cfg,
            )
            if gate_meta:
                try:
                    if "signal_tags" in gate_meta:
                        snapshot_base["signal_quality_tags"] = list(gate_meta.get("signal_tags", []))
                    snapshot_base["signal_quality_final"] = gate_meta.get("signal_quality_final")
                    snapshot_base["signal_quality_need"] = gate_meta.get("signal_quality_need")
                    if "signal_volume_ratio" in gate_meta:
                        snapshot_base["signal_volume_ratio"] = gate_meta.get("signal_volume_ratio")
                    if "orderbook_imbalance" in gate_meta:
                        snapshot_base["orderbook_imbalance"] = gate_meta.get("orderbook_imbalance")
                    if "orderflow_rate" in gate_meta:
                        snapshot_base["orderflow_rate"] = gate_meta.get("orderflow_rate")
                    if "exit_cluster_score" in gate_meta:
                        snapshot_base["exit_cluster_score"] = gate_meta.get("exit_cluster_score")
                        snapshot_base["exit_cluster_need"] = gate_meta.get("exit_cluster_need")
                        snapshot_base["exit_cluster_count"] = exit_cluster_count
                        snapshot_base["exit_cluster_window"] = exit_cluster_window
                except Exception:
                    pass
            if not gate_ok:
                return block(gate_reason or "信号质量过滤未通过", gate_meta)
            quality_ratio = quality_score / max(quality_need, 1e-9)
            snapshot_base["entry_quality_ratio"] = round(float(quality_ratio), 4)
            ratio_need = float(eq_settings.get("pass_ratio_min", getattr(self, "ENTRY_QUALITY_PASS_RATIO_MIN", self.ENTRY_QUALITY_PASS_RATIO_MIN)))
            if fast_lane:
                ratio_need = float(eq_settings.get(
                    "pass_ratio_fast_min",
                    getattr(self, "ENTRY_QUALITY_PASS_RATIO_FAST_MIN", ratio_need),
                ))
            elif slow_lane:
                ratio_need = float(eq_settings.get(
                    "pass_ratio_slow_min",
                    getattr(self, "ENTRY_QUALITY_PASS_RATIO_SLOW_MIN", ratio_need),
                ))
            if extreme_lane:
                ratio_need = float(eq_settings.get(
                    "pass_ratio_extreme_min",
                    getattr(self, "ENTRY_QUALITY_PASS_RATIO_EXTREME_MIN", ratio_need),
                ))
            if ratio_need > 1.0 and quality_ratio + 1e-9 < ratio_need:
                return block("综合信号质量略低，等待更强确认", {
                    "quality_score": round(float(quality_score), 4),
                    "quality_need": round(float(quality_need), 4),
                    "quality_ratio": round(float(quality_ratio), 4),
                    "ratio_need": round(float(ratio_need), 4),
                    "fast_lane": int(fast_lane),
                    "slow_lane": int(slow_lane),
                    "extreme_lane": int(extreme_lane),
                })
        decay_component = quality_details.get("decay_penalty")
        if decay_component is not None and np.isfinite(decay_component):
            snapshot_base["quality_decay_penalty"] = round(float(decay_component), 4)
        if quality_score < quality_need:
            extra: Dict[str, Any] = {
                k: round(float(v), 4)
                for k, v in quality_details.items()
                if isinstance(v, (int, float))
            }
            extra.update({
                "quality_score": round(float(quality_score), 4),
                "quality_need": round(float(quality_need), 4),
            })
            if quality_need_raw and quality_need != quality_need_raw:
                extra.setdefault("quality_need_raw", round(float(quality_need_raw), 4))
            if quality_buffer > 0:
                extra.setdefault("quality_buffer", round(float(quality_buffer), 4))
            if dynamic_penalty:
                extra.setdefault("dynamic_penalty", 1)
            if portfolio_fragile:
                extra.setdefault("portfolio_fragile", 1)
            if extreme_lane:
                extra.setdefault("extreme_guard", 1)
            if darkside_ok:
                extra.setdefault("darkside", 1)
                extra.setdefault("darkside_score", round(float(darkside_ctx.get("score", 0.0) or 0.0), 4))
            return block("综合信号质量不足", extra)

        require_extreme_vol = bool(self._profile_val("require_vol_on_extreme", False))
        panic_align_need = float(self._profile_val("panic_align_need", 0.0) or 0.0)
        mania_align_need = float(self._profile_val("mania_align_need", 0.0) or 0.0)

        if side == "short":
            if panic_guard >= 1:
                wick_dn = float(row.get("wick_dn_pct", 0.0) or 0.0)
                close_val = float(row.get("close", 0.0) or 0.0)
                open_val = float(row.get("open", 0.0) or 0.0)
                fast_override = fast_lane and (align_score <= -0.45) and (wick_dn <= 0.35) and (close_val < open_val)
                if channel_wide and not channel_decay and align_score <= -0.25:
                    fast_override = True
                if htf_drive_lane and align_score <= -0.30:
                    fast_override = True
                if panic_align_need > 0 and align_score > -panic_align_need:
                    fast_override = False
                if require_extreme_vol and vol_any == 0:
                    fast_override = False
                if not fast_override:
                    reason_txt = "连续瀑布保护窗口内禁止追空" if panic_slope_guard >= 1 else "恐慌针保护窗口内禁止追空"
                    return block(reason_txt, {
                        "panic_guard": panic_guard,
                        "panic_slope_guard": panic_slope_guard,
                        "panic_tail_block": panic_tail_block,
                        "panic_slope_block": panic_slope_block,
                        "panic_slope_drop": float(row.get("panic_slope_drop_atr", 0.0) or 0.0),
                        "panic_slope_rebound": float(row.get("panic_slope_rebound_atr", 0.0) or 0.0),
                        "wick_dn_pct": wick_dn,
                        "fast_lane": int(fast_lane),
                        "align": align_score,
                    })
        if side == "long" and blowoff_guard >= 1:
            mania_override = channel_wide and not channel_decay and align_score >= 0.45 and htf_drive_lane
            if mania_align_need > 0 and align_score < mania_align_need:
                mania_override = False
            if require_extreme_vol and vol_any == 0:
                mania_override = False
            if not mania_override:
                return block("顶部诱多保护窗口内禁止盲多", {
                    "blowoff_guard": blowoff_guard,
                    "channel_wide": int(channel_wide),
                    "align": align_score,
                    "vol_any": vol_any,
                })

        pos_high = float(getattr(self, "ENTRY_POS_EXTREME_HIGH", 0.82))
        pos_low = float(getattr(self, "ENTRY_POS_EXTREME_LOW", 0.18))
        align_extreme = float(getattr(self, "ENTRY_POS_ALIGN_NEED", 0.42))
        align_relax = float(getattr(self, "ENTRY_POS_ALIGN_EASE", 0.06))
        tri_delta = float(getattr(self, "ENTRY_POS_TRI_DELTA", 0.06))
        rfs_need_ext = float(getattr(self, "ENTRY_POS_RFS_NEED", 0.58))

        if side == "long" and price_position >= pos_high and panic_guard == 0:
            align_need_ext = align_extreme
            if fast_lane:
                align_need_ext -= align_relax * 0.6
            if slow_lane and channel_narrow:
                align_need_ext -= align_relax * 0.4
            if htf_drive_lane:
                align_need_ext -= align_relax * 0.5
            if channel_wide and not channel_decay:
                align_need_ext += align_relax * 0.8
            if perf_guard:
                align_need_ext += align_relax * 0.3
            if perf_hot:
                align_need_ext -= align_relax * 0.25
            align_need_ext = max(align_floor_long, align_need_ext)

            tri_need_ext = min(1.0, tri_need + tri_delta + (tri_delta * 0.5 if (channel_wide and not channel_decay) else 0.0))
            rfs_gate = rfs_need_ext
            if fast_lane or htf_drive_lane:
                rfs_gate -= align_relax * 0.35
            if perf_guard:
                rfs_gate += align_relax * 0.3
            if perf_hot:
                rfs_gate -= align_relax * 0.25
            rfs_gate = float(np.clip(rfs_gate, 0.0, 1.0))

            extreme_ok = (
                align_score >= align_need_ext
                and tri_bias_val >= tri_need_ext
                and rfs_value >= rfs_gate
            )

            if not extreme_ok:
                return block("价格位于区间上沿，等待回踩或更强驱动", {
                    "price_pos": round(price_position, 4),
                    "align": round(align_score, 4),
                    "align_need": round(align_need_ext, 4),
                    "tri_bias": round(tri_bias_val, 4),
                    "tri_need_ext": round(tri_need_ext, 4),
                    "rfs": round(rfs_value, 4),
                    "rfs_need": round(rfs_gate, 4),
                    "fast_lane": int(fast_lane),
                    "slow_lane": int(slow_lane),
                    "htf_drive": int(htf_drive_lane),
                    "channel_narrow": int(channel_narrow),
                    "channel_wide": int(channel_wide),
                })

        if side == "short" and price_position <= pos_low and panic_guard == 0 and panic_slope_guard == 0:
            align_need_ext = align_extreme
            if fast_lane:
                align_need_ext -= align_relax * 0.6
            if slow_lane and channel_wide and not channel_decay:
                align_need_ext -= align_relax * 0.3
            if htf_drive_lane:
                align_need_ext -= align_relax * 0.5
            if channel_narrow:
                align_need_ext += align_relax * 0.8
            if perf_guard:
                align_need_ext += align_relax * 0.3
            if perf_hot:
                align_need_ext -= align_relax * 0.2
            align_need_ext = max(align_floor_short, align_need_ext)

            tri_need_ext = min(1.0, tri_need + tri_delta + (tri_delta * 0.6 if channel_narrow else 0.0))
            rfs_gate = rfs_need_ext
            if fast_lane or htf_drive_lane:
                rfs_gate -= align_relax * 0.35
            if channel_decay or (channel_wide and not channel_decay):
                rfs_gate -= align_relax * 0.2
            if perf_guard:
                rfs_gate += align_relax * 0.3
            rfs_gate = float(np.clip(rfs_gate, 0.0, 1.0))

            extreme_ok = (
                align_score <= -align_need_ext
                and tri_bias_val >= tri_need_ext
                and rfs_value >= rfs_gate
            )

            if not extreme_ok:
                return block("价格位于区间下沿，等待反弹或更强驱动", {
                    "price_pos": round(price_position, 4),
                    "align": round(align_score, 4),
                    "align_need": round(-align_need_ext, 4),
                    "tri_bias": round(tri_bias_val, 4),
                    "tri_need_ext": round(tri_need_ext, 4),
                    "rfs": round(rfs_value, 4),
                    "rfs_need": round(rfs_gate, 4),
                    "fast_lane": int(fast_lane),
                    "slow_lane": int(slow_lane),
                    "htf_drive": int(htf_drive_lane),
                    "channel_narrow": int(channel_narrow),
                    "channel_wide": int(channel_wide),
                })

        # 信号扎堆 / 反向假信号保护
        cluster_hist = list(st.get("entry_cluster", []))
        window_minutes = self._cluster_window_minutes()
        window_delta = timedelta(minutes=window_minutes)
        pruned_hist = []
        for rec in cluster_hist:
            when = rec.get("time")
            if isinstance(when, str):
                try:
                    when = datetime.fromisoformat(when)
                except ValueError:
                    continue
            if not isinstance(when, datetime):
                continue
            if when.tzinfo is None:
                when = when.replace(tzinfo=timezone.utc)
            if now - when <= window_delta:
                pruned_hist.append({**rec, "time": when})
        pruned_hist.sort(key=lambda x: x.get("time", now))
        st["entry_cluster"] = pruned_hist

        bias_align_w = float(getattr(self, "SIGNAL_CLUSTER_BIAS_WEIGHT_ALIGN", 0.52))
        bias_tri_w = float(getattr(self, "SIGNAL_CLUSTER_BIAS_WEIGHT_TRI", 0.34))
        bias_priority_w = float(getattr(self, "SIGNAL_CLUSTER_BIAS_WEIGHT_PRIORITY", 0.28))
        bias_fastlane_w = float(getattr(self, "SIGNAL_CLUSTER_BIAS_WEIGHT_FASTLANE", 0.14))
        bias_slowlane_w = float(getattr(self, "SIGNAL_CLUSTER_BIAS_WEIGHT_SLOWLANE", 0.09))
        bias_decay = max(0.0, float(getattr(self, "SIGNAL_CLUSTER_BIAS_DECAY", 0.92)))
        tf_minutes = max(1, self._tf_minutes())
        bias_score = 0.0
        for rec in pruned_hist:
            rec_side = rec.get("side")
            if rec_side not in ("long", "short"):
                continue
            when = rec.get("time")
            if not isinstance(when, datetime):
                continue
            age_minutes = max(0.0, (now - when).total_seconds() / 60.0)
            age_bars = age_minutes / float(tf_minutes)
            decay_mult = 1.0
            if 0.0 < bias_decay < 1.0:
                decay_mult = bias_decay ** age_bars
            align_comp = abs(float(rec.get("align", 0.0) or 0.0)) * bias_align_w
            tri_comp = abs(float(rec.get("tri_bias", 0.0) or 0.0)) * bias_tri_w
            priority_comp = abs(float(rec.get("priority_conf", 0.0) or 0.0)) * bias_priority_w
            lane_bonus = 0.0
            if int(rec.get("fast_lane", 0) or 0):
                lane_bonus += bias_fastlane_w
            if int(rec.get("slow_lane", 0) or 0):
                lane_bonus += bias_slowlane_w
            weight = (align_comp + tri_comp + priority_comp + lane_bonus)
            if weight <= 0:
                continue
            weight *= decay_mult
            direction = 1.0 if rec_side == "long" else -1.0
            bias_score += direction * weight

        same_recent = sum(1 for rec in pruned_hist if rec.get("side") == side)
        opp_recent = sum(1 for rec in pruned_hist if rec.get("side") not in (None, side))
        last_entry = pruned_hist[-1] if pruned_hist else None
        last_side = last_entry.get("side") if isinstance(last_entry, dict) else None
        bias_side = ""
        if abs(bias_score) >= 1e-6:
            bias_side = "long" if bias_score > 0 else "short"
        snapshot_base.update({
            "cluster_same": same_recent,
            "cluster_opp": opp_recent,
            "cluster_window_m": window_minutes,
            "cluster_last_side": str(last_side or ""),
            "cluster_bias": round(bias_score, 4),
            "cluster_bias_side": bias_side,
        })

        same_soft = max(0, int(getattr(self, "SIGNAL_CLUSTER_SAME_SOFT", 2)))
        same_hard = max(same_soft, int(getattr(self, "SIGNAL_CLUSTER_SAME_HARD", same_soft + 1)))
        align_strict = float(getattr(self, "SIGNAL_CLUSTER_ALIGN_STRICT", 0.42))
        align_fast = float(getattr(self, "SIGNAL_CLUSTER_ALIGN_FAST", 0.60))
        opp_cool = max(1, int(getattr(self, "SIGNAL_CLUSTER_OPP_COOLDOWN", 6)))
        tri_bonus = float(getattr(self, "SIGNAL_CLUSTER_TRI_BONUS", 0.08))
        align_abs = abs(align_score)
        # fast_push：快车道 + 足够对齐的强趋势；新增支持「宽通道但未衰减」继续视作推进，以免强趋势被扎堆护栏挡下
        fast_push = fast_lane and align_abs >= align_fast and (
            htf_drive_lane
            or channel_narrow
            or not channel_wide
            or (channel_wide and not channel_decay)
        )
        structured_push = slow_lane and channel_narrow and align_abs >= align_strict
        bias_warn = max(0.0, float(getattr(self, "SIGNAL_CLUSTER_BIAS_WARN", 1.15)))
        bias_block = max(bias_warn, float(getattr(self, "SIGNAL_CLUSTER_BIAS_BLOCK", 1.85)))
        bias_abs = abs(bias_score)

        if bias_side and bias_side != side and bias_abs >= bias_warn:
            if bias_abs >= bias_block:
                return block("信号扎堆保护：历史偏向仍指向对侧，等待偏向翻转", {
                    "cluster_bias": round(bias_score, 4),
                    "cluster_bias_side": bias_side,
                    "bias_block": bias_block,
                })
            align_bias_need = align_strict + 0.05 + min(0.35, 0.08 * max(0.0, bias_abs - bias_warn))
            align_bias_need = float(np.clip(align_bias_need, 0.0, 0.92))
            tri_bias_need = tri_need + tri_bonus + max(0.0, 0.05 * (bias_abs - bias_warn))
            tri_bias_need = float(np.clip(tri_bias_need, 0.0, 1.0))
            align_pass_bias = (align_score >= align_bias_need) if side == "long" else (align_score <= -align_bias_need)
            tri_pass_bias = (tri_bias_val >= tri_bias_need)
            if not (align_pass_bias and (tri_pass_bias or guard_override or fast_push or structured_push)):
                return block("信号扎堆保护：偏向未逆转，需更强对齐/三锚确认", {
                    "cluster_bias": round(bias_score, 4),
                    "cluster_bias_side": bias_side,
                    "align": align_score,
                    "align_need": align_bias_need,
                    "tri_bias": tri_bias_val,
                    "tri_need": tri_bias_need,
                })

        if same_recent >= same_hard:
            if not (fast_push or (htf_drive_lane and align_abs >= align_fast) or guard_override):
                return block("信号扎堆保护：同向连击已触发硬限制", {
                    "cluster_same": same_recent,
                    "need_fast": align_fast,
                    "align": align_score,
                })
        elif same_recent >= same_soft:
            # 宽通道但已衰减时继续视为震荡网格，强制冷却；若宽通道仍在推进，上方 fast_push 会放宽闸门
            if channel_wide and channel_decay:
                return block("信号扎堆保护：宽通道衰减暂停网格", {
                    "cluster_same": same_recent,
                    "channel_decay": int(channel_decay),
                })
            if not (fast_push or structured_push or (htf_drive_lane and align_abs >= align_strict) or guard_override):
                return block("信号扎堆保护：等待更强驱动后再追单", {
                    "cluster_same": same_recent,
                    "align": align_score,
                    "align_need": align_strict,
                })

        if last_entry and last_side and last_side != side:
            last_time = last_entry.get("time")
            if isinstance(last_time, datetime):
                delta = now - (last_time if last_time.tzinfo else last_time.replace(tzinfo=timezone.utc))
                bars_since_last = int(max(0.0, delta.total_seconds() // 60) // self._tf_minutes())
            else:
                bars_since_last = opp_cool
            prev_same = sum(1 for rec in pruned_hist if rec.get("side") == last_side)
            align_req = min(0.85, align_strict + 0.05 * max(0, prev_same - same_soft + 1))
            align_pass = (align_score >= align_req) if side == "long" else (align_score <= -align_req)
            tri_extra_need = min(1.0, tri_need + tri_bonus)
            decay_support = channel_decay or (channel_wide and align_abs <= 0.35)
            if bars_since_last < opp_cool and prev_same >= same_soft:
                if not align_pass:
                    return block("信号扎堆保护：反向对冲缺少趋势反转", {
                        "align": align_score,
                        "align_need": align_req,
                        "bars_since": bars_since_last,
                    })
                if tri_bias_val < tri_extra_need and not (guard_override or fast_push):
                    return block("信号扎堆保护：反向对冲缺少三锚确认", {
                        "tri_bias": tri_bias_val,
                        "tri_need": tri_extra_need,
                        "prev_same": prev_same,
                    })
                if not (decay_support or guard_override or fast_push or structured_push):
                    return block("信号扎堆保护：结构尚未衰减，暂缓反向试单", {
                        "decay": int(channel_decay),
                        "channel_wide": int(channel_wide),
                        "bars_since": bars_since_last,
                    })

        session_bias_pressure = 0.0
        prefer_alignment = 0.0
        same_factor = 0.0
        session_bias_realized_need = float(
            getattr(self, "SESSION_BIAS_COOLDOWN_REALIZED_NEED_R", 1.0) or 0.0
        )
        session_bias_peak_need = float(
            getattr(self, "SESSION_BIAS_COOLDOWN_PEAK_NEED_R", 1.5) or 0.0
        )
        session_bias_min_count = int(getattr(self, "SESSION_BIAS_COOLDOWN_MIN_COUNT", 2) or 0)
        if (
            session_bias_realized_need > 0
            and session_realized_count >= max(1, session_bias_min_count)
            and session_realized_r >= session_bias_realized_need
        ):
            session_bias_pressure = max(
                session_bias_pressure,
                min(
                    1.0,
                    (session_realized_r - session_bias_realized_need)
                    / max(session_bias_realized_need, 1e-6),
                ),
            )
        if session_bias_peak_need > 0 and session_peak_r >= session_bias_peak_need:
            session_bias_pressure = max(
                session_bias_pressure,
                min(
                    1.0,
                    (session_peak_r - session_bias_peak_need)
                    / max(session_bias_peak_need, 1e-6),
                ),
            )
        if priority_prefer == side and priority_conf_val > 0:
            prefer_alignment = max(prefer_alignment, min(1.0, priority_conf_val))
        if session_bias_side == side and session_bias_side:
            prefer_alignment = max(prefer_alignment, 0.6)
        if bias_side == side and bias_abs >= bias_warn:
            denom = (bias_block - bias_warn) if bias_block > bias_warn else 1.0
            prefer_alignment = max(
                prefer_alignment,
                min(1.0, (bias_abs - bias_warn) / max(denom, 1e-6)),
            )
        if same_recent >= same_soft and same_soft > 0:
            same_factor = min(
                1.0,
                (same_recent - same_soft + 1) / max(1, same_hard - same_soft + 1),
            )
            prefer_alignment = max(prefer_alignment, same_factor)

        session_bias_base_bars = int(getattr(self, "SESSION_BIAS_COOLDOWN_BASE_BARS", 2) or 0)
        session_bias_same_bonus = max(
            0.0, float(getattr(self, "SESSION_BIAS_COOLDOWN_SAME_BONUS", 0.35) or 0.0)
        )
        session_bias_priority_bonus = max(
            0.0, float(getattr(self, "SESSION_BIAS_COOLDOWN_PRIORITY_BONUS", 0.35) or 0.0)
        )
        if (
            session_bias_base_bars > 0
            and session_bias_pressure > 0
            and prefer_alignment > 0
            and not fast_override
        ):
            pressure = session_bias_pressure * (
                1.0
                + session_bias_same_bonus * same_factor
                + session_bias_priority_bonus * prefer_alignment
            )
            pressure = float(np.clip(pressure, 0.0, 1.0))
            extra_bias_bars = max(1, int(math.ceil(session_bias_base_bars * pressure)))
            snapshot_base["session_bias_cooldown"] = {
                "side": side,
                "bias_pressure": round(session_bias_pressure, 4),
                "alignment": round(prefer_alignment, 4),
                "same_factor": round(same_factor, 4),
                "extra_bars": extra_bias_bars,
                "base_bars": session_bias_base_bars,
                "realized_r": round(session_realized_r, 4),
                "peak_r": round(session_peak_r, 4),
                "realized_count": session_realized_count,
            }
        else:
            snapshot_base.pop("session_bias_cooldown", None)

        # Quiet：冷静期 + 日内限次
        if bool(getattr(self, "QUIET_MODE", True)):
            last_time = st.get("last_entry_time", None)
            required_cooldown = int(self.ENTRY_COOLDOWN_BARS)
            cooldown_mult = float(self._profile_val("entry_cooldown_mult", 1.0) or 1.0)
            if cooldown_mult != 1.0:
                required_cooldown = max(1, int(math.ceil(required_cooldown * cooldown_mult)))
            if style_cooldown_mult != 1.0:
                required_cooldown = max(1, int(math.ceil(required_cooldown * style_cooldown_mult)))
            if perf_guard:
                required_cooldown += 1
            if perf_hot and required_cooldown > 1:
                required_cooldown = max(1, required_cooldown - 1)
            if fast_lane:
                required_cooldown = max(1, required_cooldown - 1)
            if slow_lane and align_score > 0.35:
                required_cooldown = max(1, required_cooldown - 1)
            if channel_narrow and align_score > 0.12:
                required_cooldown = max(1, required_cooldown - 1)
            if channel_wide and channel_decay:
                required_cooldown += 1
            if "session_bias_cooldown" in snapshot_base:
                required_cooldown += snapshot_base["session_bias_cooldown"].get("extra_bars", 0)
            min_minutes = max(0.0, float(getattr(self, "ENTRY_COOLDOWN_MIN_MINUTES", 0.0) or 0.0))
            if min_minutes > 0:
                tf_minutes = max(1.0, float(getattr(self, "_current_tf_minutes", self._tf_minutes())))
                min_bars = max(1, int(math.ceil(min_minutes / tf_minutes)))
                if required_cooldown < min_bars:
                    required_cooldown = min_bars
            if last_time:
                bars = int(((now - last_time).total_seconds() // 60) // self._tf_minutes())
                if bars < required_cooldown:
                    return block("冷静期尚未结束", {"cooldown_need": required_cooldown, "cooldown_done": bars})
            day_key = f"entries_{_date.fromtimestamp(now.timestamp()).isoformat()}"
            if st.get("day_key") != day_key:
                st["day_key"] = day_key; st["entries_today"] = 0
            limit_base = daily_limit
            max_entries_today = limit_base
            if perf_guard and max_entries_today is not None:
                max_entries_today = max(1, max_entries_today - 1)
            entries_used = int(st.get("entries_today", 0))
            if max_entries_today is not None and entries_used >= max_entries_today:
                return block("已达当日入场上限", {
                    "entries": entries_used,
                    "max_entries": max_entries_today,
                    "entries_left": 0,
                })

            # Quiet：震荡过滤（趋势单：CI 低/ER 高；逆转单：CI 高/ER 低）
            chop = float(row.get("chop", 0.5)); er = float(row.get("er", 0.5))
            ema12 = float(row.get("ema_12", 0)); ema26 = float(row.get("ema_26", 0))
            is_trend_side = (ema12 >= ema26) if side == "long" else (ema12 <= ema26)
            chop_trend_max = float(self.CHOP_TREND_MAX)
            er_trend_min = float(self.ER_TREND_MIN)
            chop_range_min = float(self.CHOP_RANGE_MIN)
            er_range_max = float(self.ER_RANGE_MAX)
            if perf_guard:
                chop_trend_max *= 0.96
                er_trend_min *= 1.05
                chop_range_min *= 1.04
                er_range_max *= 0.95
            elif perf_hot:
                chop_trend_max *= 1.05
                er_trend_min *= 0.95
                chop_range_min *= 0.96
                er_range_max *= 1.04
            if fast_lane:
                chop_trend_max *= 1.10
                er_trend_min *= 0.90
            if slow_lane:
                chop_trend_max *= 1.05
                er_trend_min *= 0.88
                chop_range_min *= 0.95
                er_range_max *= 1.05
                if align_score > 0.35:
                    er_trend_min *= 0.95
                if align_score < -0.35:
                    er_range_max *= 1.08
            if channel_narrow:
                chop_trend_max *= 1.05
                er_trend_min *= 0.90
            if channel_wide and not channel_decay:
                chop_range_min *= 0.96
                er_range_max *= 1.04
            if channel_wide and channel_decay:
                chop_range_min *= 1.02
                er_range_max *= 0.97
            if side == "long" and panic_guard >= 1:
                chop_trend_max *= 1.04
                er_trend_min *= 0.90
            if side == "short" and blowoff_guard >= 1:
                chop_range_min *= 0.97
                er_range_max *= 1.06
            if is_trend_side:
                if not (chop <= chop_trend_max and er >= er_trend_min):
                    return block("趋势闸门未通过", {"chop": chop, "chop_max": chop_trend_max, "er": er, "er_min": er_trend_min})
            else:
                if not (chop >= chop_range_min and er <= er_range_max):
                    return block("震荡闸门未通过", {"chop": chop, "chop_min": chop_range_min, "er": er, "er_max": er_range_max})

        # 距离硬闸：到“需要值”直接放行；到“接近值”需动能同向
        macd, macds, macdh = float(row.get("macd", 0)), float(row.get("macdsignal", 0)), float(row.get("macdhist", 0))
        if dist_ema >= dist_need:
            return allow("距离达到硬闸", {"dist": dist_ema, "dist_need": dist_need})
        if dist_near <= dist_ema < dist_need:
            if (side == "long" and macd >= macds and macdh >= -1e-9) or (side == "short" and macd <= macds and macdh <= 1e-9):
                return allow("距离接近值 + 动能同向", {
                    "dist": dist_ema,
                    "dist_need": dist_need,
                    "dist_near": dist_near,
                    "macd": macd,
                    "macds": macds,
                    "macdh": macdh,
                })
            return block("接近值缺少动能确认", {
                "dist": dist_ema,
                "dist_need": dist_need,
                "dist_near": dist_near,
                "macd": macd,
                "macds": macds,
                "macdh": macdh,
            })
        return block("距离/动能均未满足硬闸", {"dist": dist_ema, "dist_need": dist_need, "dist_near": dist_near})

    # -------------------- 反马丁冷静窗（亏损/翻向窗口） --------------------
    def _anti_martin_block(self, pair: str, side: str, rate: float, atr: float) -> Optional[str]:
        """教学提示：记录最近亏损/翻向时间，防止短时间内连环加码（反马丁防御）。"""
        st = self._pair_state.setdefault(pair, {})
        last_loss_time = st.get("last_loss_time", None); last_loss_side = st.get("last_loss_side", None)
        last_loss_entry = float(st.get("last_loss_entry", 0.0) or 0.0)
        if last_loss_time is not None:
            bars_since = max(0, (datetime.now(timezone.utc) - last_loss_time).total_seconds() // 60 // self._tf_minutes())
            if bars_since < 6 and last_loss_side == side:
                return "AM same-side cooldown"
            if np.isfinite(atr) and atr > 0 and last_loss_entry > 0:
                if abs(rate - last_loss_entry) < (atr * 0.8):
                    return "AM too close to last loss"
        last_dir = st.get("last_dir", None); last_dir_time = st.get("last_dir_time", None)
        if last_dir is not None and last_dir_time is not None:
            bars_since_dir = max(0, (datetime.now(timezone.utc) - last_dir_time).total_seconds() // 60 // self._tf_minutes())
            if bars_since_dir < 3 and last_dir != side:
                return "AM flip-flop window"
        return None

    def _fill_slippage_adjustment(
        self, pair: str, trade_profile: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        if not isinstance(trade_profile, dict):
            return {"active": False}
        fill_ratio = self._safe_float(trade_profile.get("fill_slippage_ratio")) or 0.0
        if fill_ratio <= 0:
            return {"active": False}
        dev = abs(fill_ratio - 1.0)
        cfg = self._pair_cfg(pair)
        adjust_cfg = cfg.get("fill_slippage_adjust", {}) if isinstance(cfg, dict) else {}
        threshold = float(adjust_cfg.get("threshold", getattr(self, "FILL_SLIPPAGE_THRESHOLD", 0.06)) or getattr(self, "FILL_SLIPPAGE_THRESHOLD", 0.06))
        if dev < max(0.0, threshold):
            return {"active": False, "ratio": fill_ratio, "deviation": dev}

        lock_scale = 1.0
        target_scale = 1.0
        leg_scale = 1.0
        lock_boost = float(adjust_cfg.get("lock_boost", getattr(self, "FILL_SLIPPAGE_LOCK_BOOST", 0.55)) or getattr(self, "FILL_SLIPPAGE_LOCK_BOOST", 0.55))
        lock_boost_max = float(adjust_cfg.get("lock_boost_max", getattr(self, "FILL_SLIPPAGE_LOCK_BOOST_MAX", 1.42)) or getattr(self, "FILL_SLIPPAGE_LOCK_BOOST_MAX", 1.42))
        target_penalty = float(adjust_cfg.get("target_penalty", getattr(self, "FILL_SLIPPAGE_TARGET_PENALTY", 0.42)) or getattr(self, "FILL_SLIPPAGE_TARGET_PENALTY", 0.42))
        leg_penalty = float(adjust_cfg.get("leg_penalty", getattr(self, "FILL_SLIPPAGE_LEG_PENALTY", 0.60)) or getattr(self, "FILL_SLIPPAGE_LEG_PENALTY", 0.60))
        leg_floor = float(adjust_cfg.get("leg_floor", getattr(self, "FILL_SLIPPAGE_LEG_FLOOR", 0.58)) or getattr(self, "FILL_SLIPPAGE_LEG_FLOOR", 0.58))

        lock_scale = min(lock_boost_max, 1.0 + dev * lock_boost) if fill_ratio > 1.0 else 1.0
        target_scale = max(0.5, 1.0 - dev * target_penalty) if fill_ratio > 1.0 else 1.0
        leg_scale = max(leg_floor, 1.0 - dev * leg_penalty) if fill_ratio > 1.0 else 1.0

        guard = {
            "active": fill_ratio > 1.0,
            "ratio": fill_ratio,
            "deviation": dev,
            "lock_scale": lock_scale,
            "target_scale": target_scale,
            "leg_scale": leg_scale,
        }
        return guard

    # -------------------- 自定义止损（台阶锁盈 + 恢复） --------------------
    def custom_stoploss(self, pair: str, trade: Trade, current_time: datetime,
                        current_rate: float, current_profit: float, **kwargs) -> float:
        """教学提示：统一计算台阶锁盈 + 自适应锁盈 + 恢复止损三层地板。"""
        stage = "止损终审"
        st = self._pair_state.setdefault(pair, {})
        trade_id = int(getattr(trade, "id", 0) or 0)
        floor_state = st.setdefault("stoploss_floor", {})
        is_short = bool(getattr(trade, "is_short", False))
        side_txt = "short" if is_short else "long"
        po = self._pair_cfg(pair)
        trade_profiles_obj = st.setdefault("trade_profiles", {})
        if not isinstance(trade_profiles_obj, dict):
            trade_profiles_obj = {}
            st["trade_profiles"] = trade_profiles_obj
        trade_profile = trade_profiles_obj.get(trade_id)
        if trade_id > 0 and not isinstance(trade_profile, dict):
            trade_profile = {}
            trade_profiles_obj[trade_id] = trade_profile

        if isinstance(trade_profile, dict):
            events_obj = trade_profile.get("stoploss_events")
            if isinstance(events_obj, list):
                stoploss_events = events_obj
            else:
                stoploss_events = []
                trade_profile["stoploss_events"] = stoploss_events
        else:
            stoploss_events = []

        fill_adjust = self._fill_slippage_adjustment(pair, trade_profile)

        def _normalize_stoploss_label(value: Any) -> str:
            label = str(value or "").strip().lower()
            if not label:
                return "unknown"
            mapping = {
                "adaptive": "adaptive_lock",
                "adaptive_lock": "adaptive_lock",
                "dynamic": "dynamic_loss",
                "dynamic_loss": "dynamic_loss",
                "fallback": "fallback_default",
                "fallback_default": "fallback_default",
                "fallback_open": "fallback_default",
                "fallback_base": "fallback_default",
                "expectation_release_stop": "expectation_release",
                "expectation_release": "expectation_release",
                "breakeven": "breakeven_step",
                "breakeven_step": "breakeven_step",
                "portfolio_lock": "portfolio_lock",
                "strict_giveback": "strict_giveback",
                "emergency": "emergency_review",
                "emergency_review": "emergency_review",
                "clear": "clear",
            }
            if label in mapping:
                return mapping[label]
            for prefix, canonical in (
                ("fallback_review", "fallback_review"),
                ("fallback_", "fallback_default"),
                ("adaptive_", "adaptive_lock"),
                ("dynamic_", "dynamic_loss"),
                ("emergency_", "emergency_review"),
                ("strict_", "strict_giveback"),
            ):
                if label.startswith(prefix):
                    return canonical
            return label

        def _stoploss_timestamp(dt: datetime) -> str:
            try:
                ts = dt if dt.tzinfo else dt.replace(tzinfo=timezone.utc)
            except Exception:
                ts = datetime.now(timezone.utc)
            return ts.astimezone(timezone.utc).isoformat()

        def _clean_stoploss_payload(payload: Optional[Dict[str, Any]]) -> Dict[str, Any]:
            if not isinstance(payload, dict):
                return {}
            cleaned: Dict[str, Any] = {}
            for key, raw_val in payload.items():
                if isinstance(raw_val, datetime):
                    ts_val = raw_val if raw_val.tzinfo else raw_val.replace(tzinfo=timezone.utc)
                    cleaned[key] = ts_val.astimezone(timezone.utc).isoformat()
                elif isinstance(raw_val, (bool, str)):
                    cleaned[key] = raw_val
                elif isinstance(raw_val, (int, np.integer)):
                    cleaned[key] = int(raw_val)
                elif isinstance(raw_val, (float, np.floating)):
                    val = float(raw_val)
                    cleaned[key] = round(val, 6) if np.isfinite(val) else "nan"
                elif isinstance(raw_val, Decimal):
                    try:
                        val = float(raw_val)
                    except (InvalidOperation, ValueError):
                        cleaned[key] = str(raw_val)
                    else:
                        cleaned[key] = round(val, 6) if np.isfinite(val) else "nan"
                else:
                    try:
                        val = float(raw_val)
                    except (TypeError, ValueError):
                        cleaned[key] = str(raw_val)
                    else:
                        cleaned[key] = round(val, 6) if np.isfinite(val) else "nan"
            return cleaned

        def _append_stoploss_event(kind: str, source: str, floor_value: Optional[float],
                                   payload: Optional[Dict[str, Any]] = None) -> None:
            if trade_id <= 0 or not isinstance(trade_profile, dict):
                return
            label = _normalize_stoploss_label(source)
            events_list = trade_profile.get("stoploss_events")
            if not isinstance(events_list, list):
                events_list = []
                trade_profile["stoploss_events"] = events_list
            entry: Dict[str, Any] = {
                "ts": _stoploss_timestamp(current_time),
                "kind": kind,
                "label": label,
            }
            if source and label != str(source).strip().lower():
                entry["raw_label"] = str(source)
            floor_num: Optional[float] = None
            if floor_value is not None:
                try:
                    floor_num = float(floor_value)
                except (TypeError, ValueError):
                    floor_num = None
                if floor_num is not None and np.isfinite(floor_num):
                    entry["floor"] = round(floor_num, 6)
            payload_clean = _clean_stoploss_payload(payload)
            if payload_clean:
                entry["context"] = payload_clean
            last_event = events_list[-1] if events_list else None
            if isinstance(last_event, dict) and last_event.get("kind") == kind and last_event.get("label") == label:
                try:
                    if "floor" in entry and "floor" in last_event:
                        if np.isclose(float(last_event.get("floor", 0.0)), float(entry.get("floor", 0.0)), atol=1e-6):
                            last_event.update(entry)
                            return
                    if "floor" not in entry and "floor" not in last_event:
                        last_event.update(entry)
                        return
                except (TypeError, ValueError):
                    pass
            events_list.append(entry)

        def remember_floor(value: float, source: str = "adaptive", context: Optional[Dict[str, Any]] = None) -> None:
            """记录锁盈地板，便于 custom_exit 主动离场而非落入 trailing_stop."""
            if trade_id <= 0:
                return
            try:
                value = float(value)
            except (TypeError, ValueError):
                value = 0.0
            context = dict(context or {})
            source_norm = _normalize_stoploss_label(source)
            if value > 0:
                prev = floor_state.get(trade_id) or {}
                prev_floor = float(prev.get("floor", 0.0) or 0.0)
                prev_source = str(prev.get("source", "") or "")
                changed = not np.isclose(prev_floor, value, atol=1e-6) or prev_source != source_norm
                floor_state[trade_id] = {
                    "floor": value,
                    "source": source_norm,
                    "ts": current_time,
                    "context": context,
                }
                if changed:
                    extra = {"floor": value, "source": source_norm}
                    extra.update(context)
                    self._log_decision(stage, pair, side_txt, "调整", f"{source_norm}止损地板", extra)
                    basis_pct_guard = 0.0
                    release_stop_r_val = 0.0
                    if isinstance(trade_profile, dict):
                        guard_snapshot = trade_profile.get("expectation_guard")
                        if isinstance(guard_snapshot, dict):
                            try:
                                basis_pct_guard = float(guard_snapshot.get("risk_basis_pct", 0.0) or 0.0)
                            except (TypeError, ValueError):
                                basis_pct_guard = 0.0
                            try:
                                release_stop_r_val = float(guard_snapshot.get("release_stop_r", 0.0) or 0.0)
                            except (TypeError, ValueError):
                                release_stop_r_val = 0.0
                            if release_stop_r_val <= 0 and basis_pct_guard > 0:
                                release_stop_r_val = value / basis_pct_guard
                    side_cn = "空" if is_short else "多"
                    logger.info(
                        "[止损地板] %s %s 锁盈 %.4f%% (≈%.3fR)，当前浮盈 %.4f%%，风险基准 %.4f%%，来源=%s",
                        pair,
                        side_cn,
                        value * 100.0,
                        release_stop_r_val,
                        current_profit * 100.0,
                        basis_pct_guard * 100.0,
                        source_norm,
                    )
                    _append_stoploss_event("floor", source_norm, value, context)
            else:
                prev = floor_state.pop(trade_id, None)
                if prev and float(prev.get("floor", 0.0) or 0.0) > 0:
                    extra = {"previous_floor": float(prev.get("floor", 0.0) or 0.0), "source": prev.get("source", source_norm)}
                    extra.update(context)
                    self._log_decision(stage, pair, side_txt, "重置", "止损地板释放", extra)
                    _append_stoploss_event("clear", source_norm, 0.0, context)

        fallback_open_base = float(getattr(self, "STOPLOSS_FALLBACK", 0.20))
        fallback_open = float(fallback_open_base)
        default_sl = stoploss_from_open(fallback_open, current_profit, is_short=is_short)
        stoploss_min_pct = max(0.0, float(getattr(self, "STOPLOSS_MIN_PCT", 0.0)))
        stoploss_max_pct = float(getattr(self, "STOPLOSS_MAX_PCT", fallback_open_base))

        def record_risk(value: float, mode: str, context: Optional[Dict[str, Any]] = None) -> None:
            label = _normalize_stoploss_label(mode)
            cap_val = max(stoploss_min_pct, max(stoploss_max_pct, float(fallback_open)))
            self._update_trade_risk_profile(
                pair,
                trade_id,
                risk_pct=value,
                mode=label,
                current_time=current_time,
                context=context,
                cap=cap_val,
            )
            _append_stoploss_event("risk", label, value, context)

        df, _ = self.dp.get_analyzed_dataframe(pair, self.timeframe)
        if df is None or df.empty:
            remember_floor(0.0, "clear", {"reason": "数据为空"})
            record_risk(fallback_open, "fallback_default", {"reason": "data_unavailable"})
            return default_sl
        row = df.iloc[-1]
        row_index_key = getattr(row, "name", None)
        row_ts_utc = self._to_utc_datetime(row_index_key) or self._utc_now(current_time)
        is_short = bool(trade.is_short)
        session_ctx = self._session_context(current_time)
        flash_ctx = self._flash_volatility_probe(df, is_short)
        flash_state = st.setdefault("flash_guard", {})
        if isinstance(flash_state, dict):
            if flash_ctx:
                try:
                    ts_now = current_time if current_time.tzinfo else current_time.replace(tzinfo=timezone.utc)
                except Exception:
                    ts_now = current_time
                flash_state["last_seen"] = ts_now.isoformat()
                flash_state["exit_bias"] = int(bool(flash_ctx.get("exit_bias")))
                flash_state["defend_bias"] = int(bool(flash_ctx.get("defend_bias")))
                flash_state["volume_ratio"] = float(flash_ctx.get("volume_ratio", 0.0) or 0.0)
                flash_state["wick_against"] = float(flash_ctx.get("wick_against", 0.0) or 0.0)
                flash_state["wick_support"] = float(flash_ctx.get("wick_support", 0.0) or 0.0)
            else:
                flash_state["exit_bias"] = 0
                flash_state["defend_bias"] = 0
        kel_fallback_info: Dict[str, Any] = {}
        flash_relaxed = False
        flash_relax_info: Dict[str, Any] = {}
        fallback_state = st.setdefault("stoploss_fallback_state", {})
        if bool(getattr(self, "STOPLOSS_KEL_BUFFER_EXPAND_FALLBACK", True)):
            raw_cap = float(getattr(self, "STOPLOSS_FALLBACK_EXPAND_CAP", float(getattr(self, "STOPLOSS_KEL_BUFFER_CAP", fallback_open_base))))
            if not np.isfinite(raw_cap) or raw_cap <= 0:
                raw_cap = float(fallback_open_base)
            fallback_cap = max(float(raw_cap), float(fallback_open_base))
            expanded_floor, kel_info = self._keltner_buffer_floor(trade, row, fallback_open_base, is_short)
            if expanded_floor > fallback_open_base + 1e-6:
                expanded_floor = min(expanded_floor, fallback_cap)
                if expanded_floor > fallback_open + 1e-6:
                    fallback_open = float(expanded_floor)
                    default_sl = stoploss_from_open(fallback_open, current_profit, is_short=is_short)
                    kel_fallback_info = dict(kel_info or {})
                    kel_fallback_info.update({
                        "fallback_prev": round(float(fallback_open_base), 6),
                        "fallback_new": round(float(fallback_open), 6),
                        "fallback_cap": round(float(fallback_cap), 6),
                    })
        fallback_cap_flash = float(getattr(self, "STOPLOSS_FALLBACK_EXPAND_CAP", float(getattr(self, "STOPLOSS_KEL_BUFFER_CAP", fallback_open_base))))
        if not np.isfinite(fallback_cap_flash) or fallback_cap_flash <= 0:
            fallback_cap_flash = float(fallback_open_base)
        fallback_cap_flash = max(float(fallback_cap_flash), float(fallback_open_base))
        flash_cap_override = float(getattr(self, "FLASH_VOL_GUARD_RELAX_CAP", 0.0) or 0.0)
        if flash_cap_override > 0:
            fallback_cap_flash = min(fallback_cap_flash, max(float(flash_cap_override), float(fallback_open_base)))
        if flash_ctx and flash_ctx.get("defend_bias") and bool(getattr(self, "FLASH_VOL_GUARD_RELAX_ENABLE", True)):
            relax_mult = float(getattr(self, "FLASH_VOL_GUARD_RELAX_MULT", 1.0) or 1.0)
            relax_mult = max(1.0, relax_mult)
            prev_floor = float(fallback_open)
            relaxed_floor = min(prev_floor * relax_mult, float(fallback_cap_flash))
            if relaxed_floor > prev_floor + 1e-6:
                flash_relaxed = True
                flash_relax_info = {
                    "fallback_prev": round(prev_floor, 6),
                    "fallback_new": round(relaxed_floor, 6),
                    "flash_volume": round(float(flash_ctx.get("volume_ratio", 0.0) or 0.0), 4),
                    "flash_wick": round(float(flash_ctx.get("wick_support", 0.0) or 0.0), 4),
                    "panic_lane": int(flash_ctx.get("panic_lane", 0)),
                    "mania_lane": int(flash_ctx.get("mania_lane", 0)),
                }
                fallback_open = float(relaxed_floor)
                default_sl = stoploss_from_open(fallback_open, current_profit, is_short=is_short)
        last_mode = str(fallback_state.get("mode", "base") or "base")
        try:
            last_floor = float(fallback_state.get("floor", float(fallback_open_base)) or float(fallback_open_base))
        except (TypeError, ValueError):
            last_floor = float(fallback_open_base)
        if fallback_open > fallback_open_base + 1e-6:
            mode_label = "flash_relax" if flash_relaxed else "kel_expand"
            fallback_state["mode"] = mode_label
            fallback_state["floor"] = float(fallback_open)
            if fallback_open > last_floor + 1e-6 or last_mode != mode_label:
                if flash_relaxed:
                    info = dict(flash_relax_info or {})
                    if not info:
                        info = {
                            "fallback_prev": round(float(last_floor), 6),
                            "fallback_new": round(float(fallback_open), 6),
                        }
                    info.setdefault("flash_guard", 1)
                    self._log_decision(stage, pair, side_txt, "放宽", "flash_guard_relax", info)
                else:
                    info = dict(kel_fallback_info or {})
                    if not info:
                        info = {
                            "fallback_prev": round(float(fallback_open_base), 6),
                            "fallback_new": round(float(fallback_open), 6),
                        }
                    self._log_decision(stage, pair, side_txt, "放宽", "Keltner兜底抬升", info)
        else:
            if last_mode in ("kel_expand", "flash_relax") and last_floor > fallback_open_base + 1e-6:
                self._log_decision(stage, pair, side_txt, "恢复", "Keltner兜底归位", {
                    "fallback_prev": round(float(last_floor), 6),
                    "fallback_new": round(float(fallback_open_base), 6),
                })
            fallback_state["mode"] = "base"
            fallback_state["floor"] = float(fallback_open_base)
            fallback_open = float(fallback_open_base)
            default_sl = stoploss_from_open(fallback_open, current_profit, is_short=is_short)

        self._register_portfolio_trade(trade, pair, is_short, float(current_profit), float(current_rate), current_time)
        portfolio = self._portfolio_snapshot(focus=int(getattr(trade, "id", 0) or 0))
        portfolio_guard = bool(getattr(self, "PORTFOLIO_CONTEXT_ENABLE", True))
        port_net = float(portfolio.get("net_profit_pct", 0.0) if portfolio_guard else 0.0)
        port_focus_share = float(portfolio.get("focus_positive_share", 0.0) if portfolio_guard else 0.0)
        port_focus_weight = float(portfolio.get("focus_weight_share", 0.0) if portfolio_guard else 0.0)
        port_neg_value = float(portfolio.get("negative_value", 0.0) if portfolio_guard else 0.0)
        port_loss_pressure = float(portfolio.get("loss_pressure_pct", 0.0) if portfolio_guard else 0.0)
        port_losers = int(portfolio.get("loser_count", 0) if portfolio_guard else 0)
        portfolio_lock_floor = 0.0
        drain_limit = float(getattr(self, "PORTFOLIO_NET_DRAIN_LIMIT", -0.012))
        loss_need = float(getattr(self, "PORTFOLIO_FRAGILE_LOSS_PRESSURE", 0.10))

        fast_lane_col = "fast_lane_short" if is_short else "fast_lane_long"
        slow_lane_col = "slow_lane_short" if is_short else "slow_lane_long"
        fast_val = row.get(fast_lane_col, 0)
        slow_val = row.get(slow_lane_col, 0)
        fast_lane = bool(int(fast_val)) if pd.notna(fast_val) and np.isfinite(fast_val) else False
        slow_lane = bool(int(slow_val)) if pd.notna(slow_val) and np.isfinite(slow_val) else False
        narrow_val = row.get("channel_mode_narrow_trend", 0)
        wide_val = row.get("channel_mode_wide_range", 0)
        decay_val = row.get("channel_mode_wide_decay", 0)
        drive_val = row.get("channel_mode_htf_drive", 0)
        channel_narrow = bool(int(narrow_val)) if pd.notna(narrow_val) and np.isfinite(narrow_val) else False
        channel_wide = bool(int(wide_val)) if pd.notna(wide_val) and np.isfinite(wide_val) else False
        channel_decay = bool(int(decay_val)) if pd.notna(decay_val) and np.isfinite(decay_val) else False
        htf_drive_lane = bool(int(drive_val)) if pd.notna(drive_val) and np.isfinite(drive_val) else False
        align_score = float(row.get("htf_alignment", 0.0) or 0.0)
        if not np.isfinite(align_score):
            align_score = 0.0
        panic_val = row.get("panic_tail_guard", 0)
        blowoff_val = row.get("blowoff_tail_guard", 0)
        panic_guard = int(panic_val) if pd.notna(panic_val) and np.isfinite(panic_val) else 0
        blowoff_guard = int(blowoff_val) if pd.notna(blowoff_val) and np.isfinite(blowoff_val) else 0
        panic_lane = bool(panic_guard >= 1)
        mania_lane = bool(blowoff_guard >= 1)
        mm_context: Optional[Dict[str, Any]] = None
        context_info: Optional[Dict[str, Any]] = None
        fallback_mode_before_context = str(fallback_state.get("mode", "base") or "base")
        context_enable = bool(po.get("stoploss_context_enable", getattr(self, "STOPLOSS_CONTEXT_ENABLE", False)))
        if context_enable:
            mm_context = self._measured_move_context_target(
                pair=pair,
                trade=trade,
                fast_lane=fast_lane,
                slow_lane=slow_lane,
                channel_narrow=channel_narrow,
                channel_wide=channel_wide,
                channel_decay=channel_decay,
                htf_drive_lane=htf_drive_lane,
                align_score=align_score,
                is_short=is_short,
                panic_lane=panic_lane,
                mania_lane=mania_lane,
                trade_profile=trade_profile,
                session_ctx=session_ctx,
            )
            context_floor, context_info = self._contextual_stoploss_tighten(
                fallback_open=fallback_open,
                mm_context=mm_context,
                pair_cfg=po,
                trade_profile=trade_profile,
                align_score=align_score,
                fast_lane=fast_lane,
                slow_lane=slow_lane,
                htf_drive_lane=htf_drive_lane,
                channel_narrow=channel_narrow,
                channel_wide=channel_wide,
                channel_decay=channel_decay,
            )
            if context_floor < fallback_open - 1e-6:
                fallback_open = float(context_floor)
                default_sl = stoploss_from_open(fallback_open, current_profit, is_short=is_short)
                fallback_state["mode"] = "context_tighten"
                fallback_state["floor"] = float(fallback_open)
            else:
                fallback_state.setdefault("mode", fallback_mode_before_context)
                fallback_state["floor"] = float(fallback_open)
        else:
            if isinstance(trade_profile, dict):
                trade_profile.pop("stoploss_context", None)
        final_mode = str(fallback_state.get("mode", fallback_mode_before_context) or fallback_mode_before_context)
        final_floor = float(fallback_state.get("floor", fallback_open))
        if final_mode == "context_tighten":
            if last_mode != "context_tighten" or not np.isclose(last_floor, final_floor, atol=1e-6):
                info = dict(context_info or {})
                info.setdefault("fallback_prev", round(float(last_floor), 6))
                info.setdefault("fallback_new", round(float(final_floor), 6))
                if isinstance(mm_context, dict):
                    info.setdefault("context", mm_context.get("context"))
                    try:
                        info.setdefault("target_r", float(mm_context.get("target_r", 0.0) or 0.0))
                    except (TypeError, ValueError):
                        pass
                self._log_decision(stage, pair, side_txt, "收紧", "context_stoploss", info)
        elif last_mode == "context_tighten":
            info = {
                "fallback_prev": round(float(last_floor), 6),
                "fallback_new": round(float(final_floor), 6),
            }
            if isinstance(mm_context, dict):
                info["context"] = mm_context.get("context")
                try:
                    info["target_r"] = float(mm_context.get("target_r", 0.0) or 0.0)
                except (TypeError, ValueError):
                    pass
            self._log_decision(stage, pair, side_txt, "恢复", "context_stoploss_release", info)
        if isinstance(trade_profile, dict):
            ctx_store = trade_profile.setdefault("stoploss_context", {}) if context_enable else None
            if ctx_store is not None:
                ctx_store["active"] = bool(final_mode == "context_tighten")
                ctx_store["mode"] = final_mode
                ctx_store["floor"] = float(round(fallback_open, 6))
                if isinstance(mm_context, dict):
                    ctx_store.setdefault("context", mm_context.get("context"))
                    try:
                        ctx_store["target_r"] = float(mm_context.get("target_r", 0.0) or 0.0)
                    except (TypeError, ValueError):
                        pass
        try:
            prev_effective = float(getattr(self, "_effective_stoploss_fallback", fallback_open_base))
        except (TypeError, ValueError):
            prev_effective = float(fallback_open_base)
        if abs(fallback_open - prev_effective) > 1e-6:
            try:
                self.stoploss = -float(fallback_open)
                self._effective_stoploss_fallback = float(fallback_open)
                if isinstance(getattr(self, "config", None), dict):
                    self.config["stoploss"] = -float(fallback_open)
            except Exception:
                pass

        risk_info_payload, risk_info_error = self._stoploss_risk_snapshot(
            pair=pair,
            trade_profile=trade_profile,
            pair_cfg=po,
            trade=trade,
            current_rate=current_rate,
        )
        strict_guard_floor = 0.0
        strict_guard_info: Optional[Dict[str, Any]] = None
        if current_profit > 0:
            strict_guard_floor, strict_guard_info = self._strict_giveback_guard(
                pair=pair,
                trade=trade,
                current_profit=float(current_profit),
                trade_profile=trade_profile,
                risk_info=risk_info_payload,
                mm_context=mm_context,
                current_rate=current_rate,
            )
            if strict_guard_info is not None and risk_info_error:
                if isinstance(strict_guard_info, dict):
                    strict_guard_info.setdefault("risk_resolve_error", risk_info_error)

        if risk_info_payload is None:
            retry_payload, retry_error = self._stoploss_risk_snapshot(
                pair=pair,
                trade_profile=trade_profile,
                pair_cfg=po,
                trade=trade,
                current_rate=current_rate,
            )
            if retry_payload is not None:
                risk_info_payload = retry_payload
            if risk_info_error is None and retry_error:
                risk_info_error = retry_error

        risk_basis_pct = 0.0
        if isinstance(trade_profile, dict):
            try:
                profile_basis = float(trade_profile.get("risk_basis_pct", 0.0) or 0.0)
            except (TypeError, ValueError):
                profile_basis = 0.0
            else:
                if profile_basis > 0:
                    risk_basis_pct = profile_basis
        if risk_basis_pct <= 0 and isinstance(risk_info_payload, dict):
            try:
                basis_candidate = float(risk_info_payload.get("risk_basis_pct", 0.0) or 0.0)
            except (TypeError, ValueError):
                basis_candidate = 0.0
            else:
                if basis_candidate > 0:
                    risk_basis_pct = basis_candidate

        # 预先计算一次锁盈地板，供风险判断与主动离场使用
        adaptive_lock = (
            self._calc_adaptive_lock(
                trade,
                row,
                float(current_profit),
                pair=pair,
                risk_basis_pct=risk_basis_pct if risk_basis_pct > 0 else None,
            )
            if current_profit > 0
            else 0.0
        )

        atr = float(row.get("atr14", np.nan)); ref = float(current_rate or row.get("close", np.nan))
        if not (np.isfinite(atr) and np.isfinite(ref) and ref > 0):
            remember_floor(0.0, "clear", {"reason": "ATR 缺失"})
            return default_sl

        atr_pct = float(row.get("atr_pct", np.nan))
        if not np.isfinite(atr_pct) and np.isfinite(atr) and ref > 0:
            atr_pct = atr / ref

        now_ts = current_time if current_time.tzinfo else current_time.replace(tzinfo=timezone.utc)
        try:
            opened = trade.open_date_utc
            opened = opened if opened.tzinfo else opened.replace(tzinfo=timezone.utc)
            now_ts = now_ts if now_ts.tzinfo else now_ts.replace(tzinfo=timezone.utc)
            minutes = max(0.0, (now_ts - opened).total_seconds() / 60.0)
            bars_in_trade = int(minutes // max(1, self._tf_minutes()))
        except Exception:
            bars_in_trade = None

        dynamic_loss_floor = 0.0
        kel_dynamic_info: Dict[str, Any] = {}
        flash_stop_applied = False
        flash_lock_val: Optional[float] = None
        if current_profit <= 0:
            dynamic_loss_floor = self._calc_dynamic_loss_floor(
                trade=trade,
                row=row,
                atr_pct=atr_pct,
                pair=pair,
                is_short=is_short,
                fast_lane=fast_lane,
                slow_lane=slow_lane,
                channel_narrow=channel_narrow,
                channel_wide=channel_wide,
                channel_decay=channel_decay,
                htf_drive_lane=htf_drive_lane,
                align_score=align_score,
                panic_guard=panic_guard,
                blowoff_guard=blowoff_guard,
                bars_in_trade=bars_in_trade,
            )
            if dynamic_loss_floor <= 0:
                dynamic_loss_floor = float(getattr(self, "STOPLOSS_MIN_PCT", 0.0065))
            if flash_ctx and flash_ctx.get("exit_bias"):
                raw_lock = float(getattr(self, "FLASH_VOL_GUARD_STOP_LOCK", 0.0) or 0.0)
                if raw_lock > 0:
                    flash_lock_val = max(stoploss_min_pct, raw_lock)
                    if dynamic_loss_floor <= 0 or dynamic_loss_floor > flash_lock_val:
                        dynamic_loss_floor = flash_lock_val
                        flash_stop_applied = True
            dynamic_loss_floor, kel_dynamic_info = self._keltner_buffer_floor(
                trade,
                row,
                dynamic_loss_floor,
                is_short,
            )
            if flash_lock_val is not None and flash_lock_val > 0:
                if dynamic_loss_floor <= 0 or dynamic_loss_floor > flash_lock_val:
                    dynamic_loss_floor = flash_lock_val
                    flash_stop_applied = True
                if flash_stop_applied:
                    kel_dynamic_info.setdefault("flash_guard_exit", 1)

        opp_side = "long" if is_short else "short"
        opp_raw = int(row.get("sig_long_cand", 0) if is_short else row.get("sig_short_cand", 0))
        di_flip_against = int(((row.get("minus_di", 0) > row.get("plus_di", 0)) if not is_short else (row.get("plus_di", 0) > row.get("minus_di", 0))))
        struct_break_against = int(row.get("breakL_conf", 0) if not is_short else row.get("breakS_conf", 0))
        stoprun_against = int(row.get("stoprun_long", 0) if not is_short else row.get("stoprun_short", 0))
        momo_against = int((row.get("macd", 0.0) < row.get("macdsignal", 0.0)) if not is_short else (row.get("macd", 0.0) > row.get("macdsignal", 0.0)))
        rfs_low = float(row.get("RFS", 0.5)) <= float(getattr(self, "EMERGENCY_RFS_THR", 0.20))
        ema_against = (row.get("close", 0.0) < row.get("ema200_1h", 0.0)) if not is_short else (row.get("close", 0.0) > row.get("ema200_1h", 0.0))
        risk_hits = int(opp_raw == 1) + int(di_flip_against == 1) + int(struct_break_against == 1) + int(momo_against == 1) + int(rfs_low or ema_against)
        risk_emergency = (risk_hits >= 3)

        struct_guard_cfg = po.get("struct_guard_stoploss") if isinstance(po, dict) else None
        struct_guard_enable = bool(getattr(self, "STRUCT_GUARD_STOPLOSS_ENABLE", True))
        try:
            if isinstance(struct_guard_cfg, dict) and "enable" in struct_guard_cfg:
                struct_guard_enable = bool(struct_guard_cfg.get("enable"))
        except Exception:
            struct_guard_enable = struct_guard_enable
        require_di_flip = bool(getattr(self, "STRUCT_GUARD_REQUIRE_DI_FLIP", True))
        block_stoprun = bool(getattr(self, "STRUCT_GUARD_BLOCK_STOPRUN", True))
        align_cap = float(getattr(self, "STRUCT_GUARD_ALIGN_CAP", 0.28))
        min_profit_gate = float(getattr(self, "STRUCT_GUARD_MIN_PROFIT", -0.004))
        if isinstance(struct_guard_cfg, dict):
            require_di_flip = bool(struct_guard_cfg.get("require_di_flip", require_di_flip))
            block_stoprun = bool(struct_guard_cfg.get("block_stoprun", block_stoprun))
            try:
                align_cap = float(struct_guard_cfg.get("align_cap", align_cap) or align_cap)
            except (TypeError, ValueError):
                pass
            try:
                min_profit_gate = float(struct_guard_cfg.get("min_profit_pct", min_profit_gate) or min_profit_gate)
            except (TypeError, ValueError):
                pass
        align_signed = float(align_score if not is_short else -align_score)
        align_abs = abs(align_signed) if np.isfinite(align_signed) else 0.0
        struct_guard_hit = (struct_break_against == 1) and (di_flip_against == 1 or not require_di_flip)
        if block_stoprun:
            struct_guard_hit = struct_guard_hit and (stoprun_against == 0)
        align_gate_ok = (align_cap >= 1.0) or (align_abs <= align_cap)
        if struct_guard_enable and struct_guard_hit and align_gate_ok and current_profit >= min_profit_gate:
            info = {
                "struct_break": struct_break_against,
                "di_flip": di_flip_against,
                "stoprun": stoprun_against,
                "align_abs": round(align_abs, 4),
                "profit_pct": round(current_profit * 100.0, 3),
                "min_profit_pct": round(min_profit_gate * 100.0, 3),
                "align_cap": round(align_cap, 4),
                "basis": "struct_guard_stoploss",
            }
            tag = "tp_struct_guard_stop" if current_profit >= 0 else "sl_struct_guard_stop"
            return trigger(tag, info)

        opp_signal_active = bool(opp_raw == 1 and risk_hits >= max(1, int(getattr(self, "OPP_SIGNAL_FORCE_EXIT_RISK_NEED", 2))))
        opp_stage_cfg = po.get("opp_stage_exit") if isinstance(po, dict) else None

        def _stage_cfg(key: str, attr: str) -> float:
            try:
                if isinstance(opp_stage_cfg, dict) and key in opp_stage_cfg:
                    return float(opp_stage_cfg.get(key))
            except (TypeError, ValueError):
                pass
            try:
                return float(getattr(self, attr))
            except (TypeError, ValueError):
                return 0.0

        # stoploss 层负责三段反向落袋（避免与 exit 层弹性止盈/ROI 冲突），默认 pullback_pct=0 直接按 R/超时触发。
        stage1_r = _stage_cfg("opp_stage1_r", "OPP_STAGE1_R")
        stage2_r = _stage_cfg("opp_stage2_r", "OPP_STAGE2_R")
        stage3_r = _stage_cfg("opp_stage3_r", "OPP_STAGE3_R")
        stage1_reduce = float(np.clip(_stage_cfg("opp_stage1_reduce", "OPP_STAGE1_REDUCE"), 0.0, 1.0))
        stage2_reduce = float(np.clip(_stage_cfg("opp_stage2_reduce", "OPP_STAGE2_REDUCE"), 0.0, 1.0))
        stage3_reduce = float(np.clip(_stage_cfg("opp_stage3_reduce", "OPP_STAGE3_REDUCE"), 0.0, 1.0))
        stage1_pullback = max(0.0, _stage_cfg("opp_stage1_pullback_pct", "OPP_STAGE1_PULLBACK"))
        stage2_pullback = max(0.0, _stage_cfg("opp_stage2_pullback_pct", "OPP_STAGE2_PULLBACK"))
        stage3_pullback = max(0.0, _stage_cfg("opp_stage3_pullback_pct", "OPP_STAGE3_PULLBACK"))
        stage_timeout_minutes = _stage_cfg("opp_stage_timeout_minutes", "OPP_STAGE_TIMEOUT_MINUTES")
        stage_pullbacks = {1: stage1_pullback, 2: stage2_pullback, 3: stage3_pullback}

        opp_stage_state: Dict[str, Any] = {}
        if isinstance(trade_profile, dict):
            opp_stage_state = trade_profile.setdefault("opp_stage_state", {})
            if isinstance(opp_stage_state, dict) and "entry_amount" not in opp_stage_state:
                try:
                    opp_stage_state["entry_amount"] = abs(float(getattr(trade, "amount", 0.0)) or 0.0)
                except Exception:
                    opp_stage_state["entry_amount"] = 0.0
        pos_amount = abs(float(getattr(trade, "amount", 0.0)) or 0.0)
        current_r: Optional[float] = None
        if risk_basis_pct and risk_basis_pct > 0:
            try:
                current_r = float(current_profit) / float(risk_basis_pct)
            except Exception:
                current_r = None

        peak_profit_state = 0.0
        if isinstance(opp_stage_state, dict):
            try:
                peak_profit_state = max(0.0, float(opp_stage_state.get("peak_profit", 0.0) or 0.0))
            except (TypeError, ValueError):
                peak_profit_state = 0.0
            if current_profit > 0:
                peak_profit_state = max(peak_profit_state, float(current_profit))
                opp_stage_state["peak_profit"] = peak_profit_state
        elif current_profit > 0:
            peak_profit_state = float(current_profit)

        def _opp_stage_exit(stage_idx: int, thr_r: float, reduce_to: float, tag_label: str) -> Optional[str]:
            if not opp_signal_active or current_r is None or current_r < thr_r - 1e-12:
                return None
            if not isinstance(opp_stage_state, dict):
                return None
            drawdown = 0.0
            pullback_need = float(stage_pullbacks.get(stage_idx, 0.0) or 0.0)
            if pullback_need > 0 and tag_label != "opp_stage_timeout":
                if peak_profit_state <= 0:
                    return None
                drawdown = max(0.0, peak_profit_state - current_profit)
                if drawdown < pullback_need - 1e-12:
                    return None
            max_stage_done = int(opp_stage_state.get("max_stage", 0) or 0)
            if max_stage_done >= stage_idx:
                return None
            entry_amt = float(opp_stage_state.get("entry_amount", pos_amount) or pos_amount)
            entry_amt = entry_amt if entry_amt > 0 else pos_amount
            target_ratio = float(np.clip(reduce_to, 0.0, 1.0))
            current_ratio = (pos_amount / entry_amt) if entry_amt > 0 else 1.0
            target_amt = entry_amt * target_ratio if entry_amt > 0 else pos_amount * target_ratio
            trim_amt = max(0.0, pos_amount - target_amt)
            opp_stage_state["max_stage"] = stage_idx
            opp_stage_state["last_tag"] = tag_label
            opp_stage_state["last_ts"] = now_ts.isoformat() if isinstance(now_ts, datetime) else str(now_ts)
            info = {
                "stage": stage_idx,
                "current_r": round(float(current_r), 6),
                "threshold_r": round(float(thr_r), 6),
                "reduce_to": round(target_ratio, 4),
                "current_ratio": round(current_ratio, 4),
                "pos_amount": round(pos_amount, 6),
                "entry_amount": round(entry_amt, 6),
                "target_amount": round(target_amt, 6),
                "trim_amount": round(trim_amt, 6),
                "stage_timeout_min": round(stage_timeout_minutes, 2),
                "pullback_need": round(pullback_need, 6),
                "drawdown": round(drawdown, 6),
                "peak_profit": round(peak_profit_state, 6),
            }
            if trim_amt <= 0:
                return trigger(f"{tag_label}_skip", info)
            return trigger(tag_label, info)

        if opp_signal_active and current_r is not None and current_profit >= 0:
            stage_result = _opp_stage_exit(1, stage1_r, stage1_reduce, "opp_stage1_trim")
            if stage_result:
                return stage_result
            stage_result = _opp_stage_exit(2, stage2_r, stage2_reduce, "opp_stage2_trim")
            if stage_result:
                return stage_result
            timeout_hit = bool(stage_timeout_minutes and minutes >= stage_timeout_minutes)
            stage3_ready = (current_r is not None and current_r >= stage3_r - 1e-12)
            if stage3_ready or timeout_hit:
                tag_lbl = "opp_stage_timeout" if timeout_hit and not stage3_ready else "opp_stage3_exit"
                stage_result = _opp_stage_exit(3, stage3_r if not timeout_hit else -float("inf"), stage3_reduce, tag_lbl)
                if stage_result:
                    return stage_result

        opp_force_exit = False
        opp_force_reason: Optional[str] = None
        opp_profit_cap = float(getattr(self, "OPP_SIGNAL_FORCE_EXIT_PROFIT_MAX", 0.02))
        opp_loss_cap = float(getattr(self, "OPP_SIGNAL_FORCE_EXIT_LOSS_MAX", 0.05))
        opp_need_hits = max(1, int(getattr(self, "OPP_SIGNAL_FORCE_EXIT_RISK_NEED", 2)))
        if opp_raw == 1 and risk_hits >= opp_need_hits:
            bad_loc = bool(ema_against or struct_break_against or momo_against or rfs_low)
            if bad_loc and (-opp_loss_cap <= current_profit <= opp_profit_cap):
                opp_force_exit = True
                opp_force_reason = "opp_signal_force_exit"

        if portfolio_guard:
            fragile_floor = float(getattr(self, "PORTFOLIO_FRAGILE_FLOOR", 0.022))
            lock_share_min = float(getattr(self, "PORTFOLIO_LOCK_SHARE_MIN", 0.55))
            lock_min_profit = float(getattr(self, "PORTFOLIO_LOCK_MIN_PROFIT", 0.018))
            lock_ratio = float(np.clip(float(getattr(self, "PORTFOLIO_LOCK_RATIO", 0.60)), 0.0, 1.0))
            lock_ratio_max = float(np.clip(float(getattr(self, "PORTFOLIO_LOCK_RATIO_MAX", 0.85)), 0.0, 1.0))
            allow_fast = bool(getattr(self, "PORTFOLIO_ALLOW_FASTLANE_OVERRIDE", True))
            strong_trend = bool(fast_lane and ((not is_short and align_score >= 0.45) or (is_short and align_score <= -0.45)))
            if port_net <= drain_limit and current_profit >= 0:
                risk_emergency = True
            fragile = (port_net <= fragile_floor and port_neg_value < 0 and port_losers > 0 and port_loss_pressure >= loss_need)
            if fragile and current_profit > 0 and port_focus_share >= lock_share_min:
                base_lock = current_profit * lock_ratio
                if lock_ratio_max > 0:
                    base_lock = min(base_lock, current_profit * lock_ratio_max)
                base_lock = max(lock_min_profit, base_lock)
                base_lock = min(base_lock, max(current_profit - 1e-4, current_profit))
                portfolio_lock_floor = max(portfolio_lock_floor, base_lock)
                if not (allow_fast and strong_trend):
                    risk_emergency = True
        if portfolio_guard and portfolio:
            st.setdefault("portfolio_context", {
                "net": port_net,
                "focus_share": port_focus_share,
                "focus_weight": port_focus_weight,
                "losers": port_losers,
                "loss_pressure": port_loss_pressure,
            })

        if portfolio_lock_floor > 0 and current_profit > 0:
            adaptive_lock = max(adaptive_lock, portfolio_lock_floor)

        review_result: Optional[Dict[str, Any]] = None
        review_sl: Optional[float] = None
        review_floor: Optional[float] = None
        review_mode: Optional[str] = None

        trigger_mult = float(getattr(self, "STOPLOSS_REVIEW_TRIGGER", 0.0) or 0.0)
        pending_floor = float(dynamic_loss_floor if dynamic_loss_floor > 0 else fallback_open)
        contra_tail = (is_short and panic_guard >= 1) or (not is_short and blowoff_guard >= 1)
        emergency_clamp: Optional[float] = None
        emergency_reasons: List[str] = []
        emergency_trigger = float(getattr(self, "STOPLOSS_EMERGENCY_TRIGGER", 0.0) or 0.0)
        emergency_cap = float(getattr(self, "STOPLOSS_EMERGENCY_CAP", fallback_open))
        emergency_cap = max(float(self.STOPLOSS_MIN_PCT), min(emergency_cap, float(fallback_open)))
        if emergency_trigger > 0 and current_profit <= -emergency_trigger:
            if risk_emergency:
                emergency_reasons.append("risk_stack")
            if contra_tail:
                emergency_reasons.append("contra_tail_guard")
            if channel_decay:
                emergency_reasons.append("channel_decay")
            if portfolio_guard and port_net <= drain_limit:
                emergency_reasons.append("portfolio_drawdown")
            if portfolio_guard and port_loss_pressure >= loss_need and port_neg_value < 0:
                emergency_reasons.append("loss_pressure")
            if panic_guard >= 1 and is_short:
                emergency_reasons.append("panic_tail_short")
            if blowoff_guard >= 1 and not is_short:
                emergency_reasons.append("blowoff_tail_long")
        if emergency_reasons:
            if dynamic_loss_floor <= 0 or dynamic_loss_floor > emergency_cap:
                dynamic_loss_floor = emergency_cap
            dynamic_loss_floor, kel_emergency_info = self._keltner_buffer_floor(
                trade,
                row,
                dynamic_loss_floor,
                is_short,
            )
            if kel_emergency_info:
                kel_dynamic_info.update(kel_emergency_info)
            emergency_clamp = float(min(dynamic_loss_floor, emergency_cap))
            try:
                ts_now = current_time if current_time.tzinfo else current_time.replace(tzinfo=timezone.utc)
                ts_val = ts_now.isoformat()
            except Exception:
                ts_val = str(current_time)
            st["stoploss_emergency_hint"] = {
                "ts": ts_val,
                "reasons": list(emergency_reasons),
                "floor": float(emergency_clamp),
            }
            self._log_decision(
                stage,
                pair,
                ("short" if is_short else "long"),
                "紧急兜底收紧",
                {
                    "reasons": ",".join(emergency_reasons),
                    "floor": float(emergency_clamp),
                    "profit": float(current_profit),
                },
            )
        should_review = False
        if trigger_mult > 0:
            should_review = bool(pending_floor >= float(fallback_open) * trigger_mult)
        if risk_emergency or contra_tail:
            should_review = True
        if should_review:
            review_result = self._review_stoploss_fallback(
                pair=pair,
                trade=trade,
                row=row,
                fallback_open=fallback_open,
                dynamic_floor=float(dynamic_loss_floor),
                current_profit=float(current_profit),
                current_time=current_time,
                is_short=is_short,
                fast_lane=fast_lane,
                slow_lane=slow_lane,
                channel_narrow=channel_narrow,
                channel_wide=channel_wide,
                channel_decay=channel_decay,
                htf_drive_lane=htf_drive_lane,
                align_score=align_score,
                panic_guard=panic_guard,
                blowoff_guard=blowoff_guard,
                risk_emergency=risk_emergency,
            )
            if review_result:
                review_mode = str(review_result.get("mode", "observe"))
                review_floor = float(review_result.get("floor", fallback_open))
                if emergency_clamp is not None and review_floor > emergency_clamp:
                    review_floor = emergency_clamp
                review_floor = float(np.clip(review_floor, float(self.STOPLOSS_MIN_PCT), float(fallback_open)))
                review_sl = stoploss_from_open(review_floor, current_profit, is_short=is_short)
                last_mode = st.get("fallback_review_last_mode")
                last_floor = st.get("fallback_review_last_floor")
                floor_changed = True
                if last_floor is not None and np.isfinite(last_floor):
                    floor_changed = not np.isclose(float(last_floor), review_floor, atol=1e-6)
                if last_mode != review_mode or floor_changed:
                    self._log_decision(stage, pair, ("short" if is_short else "long"), "复核",
                                       f"fallback_review_{review_mode}", review_result.get("log", {}))
                st["fallback_review_last_mode"] = review_mode
                st["fallback_review_last_floor"] = review_floor
                hint_state = review_result.get("pair_state")
                if hint_state:
                    st["fallback_review_hint"] = dict(hint_state)

        # 利润地板
        floor_open = 0.0
        floor_source: Optional[str] = None
        floor_context_info: Dict[str, Any] = {}
        expectation_floor = 0.0
        expectation_context: Dict[str, Any] = {}
        if isinstance(trade_profile, dict):
            exp_guard = trade_profile.get("expectation_guard")
            if isinstance(exp_guard, dict):
                try:
                    expectation_floor = float(exp_guard.get("release_stop_profit", 0.0) or 0.0)
                except (TypeError, ValueError):
                    expectation_floor = 0.0
                if expectation_floor > 0 and current_profit > 0:
                    try:
                        stop_r_val = float(exp_guard.get("release_stop_r", 0.0) or 0.0)
                    except (TypeError, ValueError):
                        stop_r_val = 0.0
                    if stop_r_val > 0:
                        expectation_context["release_stop_r"] = round(stop_r_val, 6)
                    try:
                        peak_profit_raw = float(exp_guard.get("release_peak_profit", 0.0) or 0.0)
                    except (TypeError, ValueError):
                        peak_profit_raw = 0.0
                    try:
                        basis_pct_guard = float(exp_guard.get("risk_basis_pct", 0.0) or 0.0)
                    except (TypeError, ValueError):
                        basis_pct_guard = 0.0
                    else:
                        if basis_pct_guard > 0:
                            risk_basis_pct = max(risk_basis_pct, basis_pct_guard)
                    if basis_pct_guard > 0 and peak_profit_raw > 0:
                        expectation_context["release_peak_r"] = round(peak_profit_raw / basis_pct_guard, 6)
                    try:
                        release_r_val = float(exp_guard.get("release_r", 0.0) or 0.0)
                    except (TypeError, ValueError):
                        release_r_val = 0.0
                    if release_r_val > 0:
                        expectation_context["release_r"] = round(release_r_val, 6)

        if risk_basis_pct <= 0 and isinstance(trade_profile, dict):
            try:
                profile_basis = float(trade_profile.get("risk_basis_pct", 0.0) or 0.0)
            except (TypeError, ValueError):
                profile_basis = 0.0
            else:
                if profile_basis > 0:
                    risk_basis_pct = profile_basis
        if risk_basis_pct <= 0 and isinstance(risk_info_payload, dict):
            try:
                basis_candidate = float(risk_info_payload.get("risk_basis_pct", 0.0) or 0.0)
            except (TypeError, ValueError):
                basis_candidate = 0.0
            else:
                if basis_candidate > 0:
                    risk_basis_pct = basis_candidate

        be_trigger = float(getattr(self, "BE_TRIGGER", 0.0))
        if current_profit >= be_trigger:
            for step in self._breakeven_floor_steps(risk_basis_pct):
                try:
                    thr_val = float(step.get("threshold_pct", 0.0) or 0.0)
                except (TypeError, ValueError):
                    thr_val = 0.0
                try:
                    lock_val = float(step.get("lock_pct", 0.0) or 0.0)
                except (TypeError, ValueError):
                    lock_val = 0.0
                if current_profit >= thr_val and lock_val > floor_open:
                    floor_open = lock_val
                    floor_source = "breakeven_step"
                    context: Dict[str, Any] = {"step": thr_val}
                    thr_r = step.get("threshold_r")
                    lock_r = step.get("lock_r")
                    if thr_r is not None:
                        try:
                            context["step_r"] = float(thr_r)
                        except (TypeError, ValueError):
                            pass
                    if lock_r is not None:
                        try:
                            context["lock_r"] = float(lock_r)
                        except (TypeError, ValueError):
                            pass
                    floor_context_info = context
        if expectation_floor > 0 and current_profit > 0 and expectation_floor > floor_open:
            floor_open = expectation_floor
            floor_source = "expectation_release_stop"
            floor_context_info = dict(expectation_context)
        if portfolio_lock_floor > 0 and current_profit > 0 and portfolio_lock_floor > floor_open:
            floor_open = float(portfolio_lock_floor)
            floor_source = "portfolio_lock"
            floor_context_info = {"portfolio": True}
        if strict_guard_floor > 0 and current_profit > 0 and strict_guard_floor > floor_open:
            floor_open = float(strict_guard_floor)
            floor_source = "strict_giveback"
            floor_context_info = dict(strict_guard_info or {})
        if adaptive_lock > floor_open:
            floor_open = float(adaptive_lock)
            floor_source = "adaptive_lock"
            floor_context_info = {}

        try:
            release_stop_r_val = float(expectation_context.get("release_stop_r", 0.0) or 0.0)
        except (TypeError, ValueError):
            release_stop_r_val = 0.0

        expectation_floor_val = float(expectation_floor) if expectation_floor > 0 else 0.0
        strict_guard_floor_val = float(strict_guard_floor) if strict_guard_floor > 0 else 0.0
        adaptive_lock_val = float(adaptive_lock) if adaptive_lock > 0 else 0.0
        dynamic_loss_floor_val = float(dynamic_loss_floor) if dynamic_loss_floor > 0 else 0.0
        portfolio_lock_floor_val = float(portfolio_lock_floor) if portfolio_lock_floor > 0 else 0.0
        fallback_open_val = float(fallback_open) if fallback_open > 0 else 0.0
        review_floor_val = float(review_floor) if review_floor is not None and review_floor > 0 else 0.0
        basis_val = float(risk_basis_pct) if risk_basis_pct and risk_basis_pct > 0 else 0.0

        def push_ui_snapshot(final_floor_pct: float, final_source_label: str,
                              *, final_context: Optional[Dict[str, Any]] = None) -> None:
            snapshot: Dict[str, Any] = {
                "ts": pd.Timestamp(row_ts_utc),
                "ts_key": row_index_key,
                "timeframe": getattr(self, "timeframe", ""),
                "trade_id": trade_id,
                "side": side_txt,
                "risk_basis_pct": basis_val,
                "current_profit_pct": float(current_profit),
                "expectation_floor_pct": expectation_floor_val,
                "strict_floor_pct": strict_guard_floor_val,
                "adaptive_floor_pct": adaptive_lock_val,
                "dynamic_floor_pct": dynamic_loss_floor_val,
                "portfolio_floor_pct": portfolio_lock_floor_val,
                "fallback_floor_pct": fallback_open_val,
                "review_floor_pct": review_floor_val,
                "release_stop_r": release_stop_r_val if release_stop_r_val > 0 else 0.0,
                "stop_floor_expect_pct": expectation_floor_val,
                "stop_floor_strict_pct": strict_guard_floor_val,
                "stop_floor_adaptive_pct": adaptive_lock_val,
                "stop_floor_dynamic_pct": dynamic_loss_floor_val,
                "stop_floor_fallback_pct": fallback_open_val,
                "stop_floor_final_pct": max(0.0, float(final_floor_pct)),
                "final_floor_pct": max(0.0, float(final_floor_pct)),
                "final_source": str(final_source_label or ""),
            }
            if final_context:
                try:
                    snapshot["final_context"] = dict(final_context)
                except Exception:
                    snapshot["final_context"] = {"context": str(final_context)}
            if floor_source:
                snapshot.setdefault("primary_floor_source", str(floor_source))
            if strict_guard_info:
                try:
                    snapshot.setdefault("strict_guard", dict(strict_guard_info))
                except Exception:
                    snapshot.setdefault("strict_guard", {"info": str(strict_guard_info)})

            snapshot["stop_r_release"] = release_stop_r_val if release_stop_r_val > 0 else 0.0

            if basis_val > 0:
                current_r = float(current_profit) / basis_val
                snapshot["current_r"] = current_r
                snapshot["stop_r_current"] = current_r
                final_floor_r = snapshot["final_floor_pct"] / basis_val if snapshot["final_floor_pct"] > 0 else 0.0
                snapshot["final_floor_r"] = final_floor_r
                snapshot["stop_r_final"] = final_floor_r
                expect_r = expectation_floor_val / basis_val if expectation_floor_val > 0 else 0.0
                snapshot["expectation_floor_r"] = expect_r
                snapshot["stop_r_expect"] = expect_r
                strict_r = strict_guard_floor_val / basis_val if strict_guard_floor_val > 0 else 0.0
                snapshot["strict_floor_r"] = strict_r
                snapshot["stop_r_strict"] = strict_r
            else:
                snapshot["stop_r_current"] = float("nan")
                snapshot["stop_r_final"] = float("nan")
                snapshot["stop_r_expect"] = float("nan")
                snapshot["stop_r_strict"] = float("nan")

            self._record_stoploss_ui_snapshot(pair, snapshot)

        # 恢复止损
        use_recover = False
        if bool(getattr(self, "STOPLOSS_RECOVER_MODE", True)):
            if bool(getattr(self, "RECOVER_ONLY_ON_RISK", False)):
                use_recover = bool(risk_emergency)
            else:
                adds_done = int(getattr(trade, "nr_of_successful_entries", 0))
                use_recover = bool(risk_emergency or (adds_done >= int(self.STOPLOSS_RECOVER_ADD_THRESHOLD)))

        if use_recover:
            k = float(self.STOPLOSS_RECOVER_ATR_K)
            emergency_sl_open = min(float(self.STOPLOSS_RECOVER_MAX),
                                    max(self.VSL_MIN_FLOOR, (k * atr) / max(float(trade.open_rate or ref), 1e-8)))
            use_open = max(floor_open, emergency_sl_open, adaptive_lock, dynamic_loss_floor)
            if review_floor is not None:
                use_open = max(use_open, review_floor)
            use_open, kel_recover_info = self._keltner_buffer_floor(trade, row, use_open, is_short)
            use_open = min(use_open, float(fallback_open))
            context = {"profit": float(current_profit)}
            if kel_recover_info:
                context.update(kel_recover_info)
            remember_floor(use_open, "emergency_review", context)
            record_risk(use_open, "emergency_review", context)
            push_ui_snapshot(use_open, "emergency_review", final_context=context)
            return stoploss_from_open(use_open, current_profit, is_short=is_short)

        if floor_open > 0:
            floor_use = max(floor_open, review_floor or 0.0)
            floor_use, kel_floor_info = self._keltner_buffer_floor(trade, row, floor_use, is_short)
            floor_use = min(floor_use, float(fallback_open))
            source_label = floor_source or "adaptive_lock"
            if review_floor is not None and floor_use > floor_open + 1e-6:
                source_label = "fallback_review"
            context: Dict[str, Any] = {"profit": float(current_profit)}
            if floor_source == "breakeven_step":
                step_val = floor_context_info.get("step")
                if step_val is not None:
                    context["breakeven_step"] = float(step_val)
            if floor_source == "portfolio_lock":
                context["portfolio_lock"] = 1
            if floor_source == "strict_giveback":
                if strict_guard_info:
                    for key, val in strict_guard_info.items():
                        if key not in ("basis_pct",):
                            context.setdefault(key, val)
                context["strict_guard"] = 1
            if kel_floor_info:
                context.update(kel_floor_info)
            remember_floor(floor_use, source_label, context)
            record_risk(floor_use, source_label, context)
            push_ui_snapshot(floor_use, source_label, final_context=context)
            if isinstance(trade_profile, dict):
                sg_state = trade_profile.get("strict_giveback")
                if isinstance(sg_state, dict):
                    if strict_guard_floor > 0:
                        sg_state["floor_applied"] = float(min(floor_use, strict_guard_floor, fallback_open))
                        try:
                            ts_now = current_time if current_time.tzinfo else current_time.replace(tzinfo=timezone.utc)
                        except Exception:
                            ts_now = current_time
                        sg_state["applied_ts"] = ts_now
                    else:
                        sg_state.pop("floor_applied", None)
                        sg_state.pop("applied_ts", None)
            return stoploss_from_open(floor_use, current_profit, is_short=is_short)
        if dynamic_loss_floor > 0:
            context = {
                "profit": float(current_profit),
                "align": float(align_score),
                "fast_lane": int(fast_lane),
                "slow_lane": int(slow_lane),
            }
            if kel_dynamic_info:
                context.update(kel_dynamic_info)
            if flash_ctx and flash_ctx.get("exit_bias"):
                context.setdefault("flash_guard_exit", 1)
                context.setdefault("flash_wick", round(float(flash_ctx.get("wick_against", 0.0) or 0.0), 4))
                context.setdefault("flash_volume", round(float(flash_ctx.get("volume_ratio", 0.0) or 0.0), 4))
                if flash_lock_val is not None and flash_lock_val > 0:
                    context.setdefault("flash_stop_lock", round(float(flash_lock_val), 6))
            risk_use = float(dynamic_loss_floor)
            if review_floor is not None:
                risk_use = min(risk_use, float(review_floor))
                context.setdefault("review_floor", round(float(review_floor), 6))
            risk_use = min(risk_use, float(fallback_open))
            risk_use = max(risk_use, stoploss_min_pct)
            remember_floor(risk_use, "dynamic_loss", context)
            record_risk(risk_use, "dynamic_loss", context)
            push_ui_snapshot(risk_use, "dynamic_loss", final_context=context)
            dyn_sl = stoploss_from_open(risk_use, current_profit, is_short=is_short)
            if review_sl is not None:
                dyn_sl = max(dyn_sl, review_sl)
            return max(dyn_sl, default_sl)
        if review_sl is not None:
            remember_floor(0.0, "clear", {"reason": "review_floor"})
            if review_floor is not None:
                record_risk(review_floor, "fallback_review", {"mode": review_mode or "observe"})
            else:
                record_risk(fallback_open, "fallback_review", {"mode": review_mode or "observe"})
            push_ui_snapshot(review_floor if review_floor is not None else fallback_open,
                             "fallback_review",
                             final_context={"mode": review_mode or "observe"})
            return max(review_sl, default_sl)
        remember_floor(0.0, "clear", {"reason": "default"})
        record_risk(fallback_open, "fallback_default", {"reason": "default"})
        push_ui_snapshot(fallback_open, "fallback_default")
        return default_sl

    # -------------------- 自定义离场（优先级见文件头说明） --------------------
    def custom_exit(self, pair: str, trade: Trade, current_time: datetime, current_rate: float,
                    current_profit: float, **kwargs) -> Optional[str]:
        """教学提示：根据风险项/动能/小回调等条件决定主动离场或观察。"""
        df, _ = self.dp.get_analyzed_dataframe(pair, self.timeframe)
        if df is None or df.empty: return None
        row = df.iloc[-1]; is_short = bool(trade.is_short)
        st = self._pair_state.setdefault(pair, {})
        trade_id = int(getattr(trade, "id", 0) or 0)
        trade_profiles_obj = st.get("trade_profiles")
        trade_profiles = trade_profiles_obj if isinstance(trade_profiles_obj, dict) else {}
        trade_profile = trade_profiles.get(trade_id)
        iceberg_cfg = self._iceberg_config(pair)
        legs = tuple(iceberg_cfg.get("legs", ()))
        tier_label = iceberg_cfg.get("tier_label")
        if tier_label is not None:
            st.setdefault("position_tier_label", tier_label)
        if isinstance(trade_profile, dict):
            if tier_label is not None and not trade_profile.get("position_tier"):
                trade_profile.setdefault("position_tier", str(tier_label))
            if iceberg_cfg.get("balance_total") is not None and not trade_profile.get("position_tier_balance"):
                trade_profile.setdefault("position_tier_balance", float(iceberg_cfg.get("balance_total")))
            if legs and not trade_profile.get("iceberg_legs"):
                trade_profile.setdefault("iceberg_legs", [round(float(x), 6) for x in legs])
            if legs:
                leg_shape = self._classify_iceberg_leg_structure(legs)
                if leg_shape:
                    trade_profile.setdefault("leg_structure", leg_shape.get("structure", ""))
                    trade_profile.setdefault("leg_descending", int(bool(leg_shape.get("descending", False))))
                    if leg_shape.get("ratio_12") is not None:
                        try:
                            trade_profile.setdefault("leg_ratio_12", round(float(leg_shape.get("ratio_12")), 3))
                        except (TypeError, ValueError):
                            pass
                    trade_profile.setdefault("leg_frontload", round(float(leg_shape.get("frontload", 0.0) or 0.0), 4))
                    trade_profile.setdefault("leg_second", round(float(leg_shape.get("second", 0.0) or 0.0), 4))
                    trade_profile.setdefault("leg_tail", round(float(leg_shape.get("tail", 0.0) or 0.0), 4))
                    trade_profile.setdefault("leg_n_candidate", int(bool(leg_shape.get("n_candidate", False))))
            events_obj = trade_profile.get("stoploss_events")
            if not isinstance(events_obj, list):
                trade_profile["stoploss_events"] = []
        quality_tier = str((trade_profile or {}).get("tier", "base") or "base").lower()

        def _stoploss_exit_timestamp(dt: datetime) -> str:
            try:
                ts = dt if dt.tzinfo else dt.replace(tzinfo=timezone.utc)
            except Exception:
                ts = datetime.now(timezone.utc)
            return ts.astimezone(timezone.utc).isoformat()

        def _clean_stoploss_exit_payload(payload: Optional[Dict[str, Any]]) -> Dict[str, Any]:
            if not isinstance(payload, dict):
                return {}
            cleaned: Dict[str, Any] = {}
            for key, raw_val in payload.items():
                if isinstance(raw_val, datetime):
                    ts_val = raw_val if raw_val.tzinfo else raw_val.replace(tzinfo=timezone.utc)
                    cleaned[key] = ts_val.astimezone(timezone.utc).isoformat()
                elif isinstance(raw_val, (bool, str)):
                    cleaned[key] = raw_val
                elif isinstance(raw_val, (int, np.integer)):
                    cleaned[key] = int(raw_val)
                elif isinstance(raw_val, (float, np.floating)):
                    val = float(raw_val)
                    cleaned[key] = round(val, 6) if np.isfinite(val) else "nan"
                elif isinstance(raw_val, Decimal):
                    try:
                        val = float(raw_val)
                    except (InvalidOperation, ValueError):
                        cleaned[key] = str(raw_val)
                    else:
                        cleaned[key] = round(val, 6) if np.isfinite(val) else "nan"
                else:
                    try:
                        val = float(raw_val)
                    except (TypeError, ValueError):
                        cleaned[key] = str(raw_val)
                    else:
                        cleaned[key] = round(val, 6) if np.isfinite(val) else "nan"
            return cleaned

        def _normalize_stoploss_exit_tag(tag: str) -> str:
            text = str(tag or "").strip().lower()
            if not text:
                return "unknown"
            if text.startswith("sl_"):
                return text
            if text.startswith("tp_trailing_floor"):
                return "tp_trailing_floor_release"
            if text.startswith("tp_adaptive_lock"):
                return "tp_adaptive_lock_release"
            if text.startswith("tp_micro_target_floor"):
                return "tp_micro_target_floor"
            if text.startswith("tp_micro_target_release"):
                return "tp_micro_target_release"
            if text.startswith("tp_high_target_floor"):
                return "tp_high_target_floor"
            if text.startswith("tp_high_target_release"):
                return "tp_high_target_release"
            if text.startswith("tp_small_target_floor"):
                return "tp_small_target_floor"
            if text.startswith("tp_small_target_breakeven"):
                return "tp_small_target_breakeven"
            if text.startswith("tp_small_target_forced"):
                return "tp_small_target_forced"
            return text

        def _should_mark_stoploss_exit(tag: str) -> bool:
            label = str(tag or "").strip().lower()
            if not label:
                return False
            if label.startswith("sl_"):
                return True
            if label.startswith("tp_") and ("floor" in label or "lock" in label):
                return True
            if label in {
                "tp_trailing_floor_release",
                "tp_adaptive_lock_release",
                "tp_micro_target_release",
            }:
                return True
            return False

        def _update_exit_cluster() -> None:
            try:
                cfg = self._signal_filter_settings(po if isinstance(po, dict) else None)
            except Exception:
                cfg = {}
            window_bars = int(cfg.get("exit_cluster_window", 0) or 0)
            if window_bars <= 0:
                return
            tf_minutes = max(1, int(getattr(self, "_current_tf_minutes", self._tf_minutes())))
            cutoff = current_time.astimezone(timezone.utc) - pd.Timedelta(minutes=window_bars * tf_minutes)
            events_list = trade_profile.get("stoploss_events") if isinstance(trade_profile, dict) else None
            if not isinstance(events_list, list) or not events_list:
                return
            count = 0
            for ev in events_list:
                if not isinstance(ev, dict):
                    continue
                if str(ev.get("kind", "") or "").lower() != "close":
                    continue
                ts_raw = ev.get("ts")
                try:
                    ts_val = pd.Timestamp(ts_raw)
                    if ts_val.tzinfo is None:
                        ts_val = ts_val.tz_localize(timezone.utc)
                    else:
                        ts_val = ts_val.tz_convert(timezone.utc)
                except Exception:
                    continue
                if ts_val >= cutoff:
                    count += 1
            if count <= 0:
                quality_ctx = st.setdefault("quality_context", {})
                quality_ctx["exit_cluster_score"] = 0.0
                quality_ctx["exit_cluster_count"] = 0
                quality_ctx["exit_cluster_window"] = window_bars
                return
            score = min(1.0, float(count) / float(window_bars))
            quality_ctx = st.setdefault("quality_context", {})
            quality_ctx.update(
                {
                    "exit_cluster_score": round(score, 4),
                    "exit_cluster_count": int(count),
                    "exit_cluster_window": int(window_bars),
                }
            )

        def _append_stoploss_closure(tag: str, payload: Optional[Dict[str, Any]]) -> None:
            if trade_id <= 0 or not isinstance(trade_profile, dict):
                return
            if not _should_mark_stoploss_exit(tag):
                return
            events_list = trade_profile.get("stoploss_events")
            if not isinstance(events_list, list) or not events_list:
                return
            normalized_tag = _normalize_stoploss_exit_tag(tag)
            entry: Dict[str, Any] = {
                "ts": _stoploss_exit_timestamp(current_time),
                "kind": "close",
                "label": normalized_tag,
                "tag": tag,
            }
            prev_label: Optional[str] = None
            prev_floor: Optional[float] = None
            for ev in reversed(events_list):
                if not isinstance(ev, dict):
                    continue
                kind = str(ev.get("kind", "") or "").lower()
                if kind in {"risk", "floor"}:
                    raw_label = ev.get("label") or ev.get("source")
                    if raw_label:
                        prev_label = str(raw_label)
                    floor_raw = ev.get("floor")
                    try:
                        floor_val = float(floor_raw)
                    except (TypeError, ValueError):
                        floor_val = None
                    if floor_val is not None and np.isfinite(floor_val):
                        prev_floor = floor_val
                    break
            if prev_label:
                entry["prev_label"] = prev_label
            if prev_floor is not None:
                entry["prev_floor"] = round(prev_floor, 6)
            payload_clean = _clean_stoploss_exit_payload(payload)
            if payload_clean:
                entry["context"] = payload_clean
                if "realized_r" in payload_clean and payload_clean["realized_r"] is not None:
                    try:
                        entry["realized_r"] = float(payload_clean["realized_r"])
                    except (TypeError, ValueError):
                        pass
            if risk_basis_pct > 0:
                entry["risk_basis_pct"] = round(float(risk_basis_pct), 6)
                try:
                    realized_r_val = float(current_profit) / float(risk_basis_pct)
                except Exception:
                    realized_r_val = None
                else:
                    if np.isfinite(realized_r_val):
                        entry.setdefault("realized_r", round(realized_r_val, 6))
            last_event = events_list[-1] if events_list else None
            if isinstance(last_event, dict) and last_event.get("kind") == "close" and str(last_event.get("tag")) == tag:
                last_event.update(entry)
                trade_profile["stoploss_closure"] = last_event
                _update_exit_cluster()
                return
            events_list.append(entry)
            trade_profile["stoploss_closure"] = entry
            _update_exit_cluster()

        pair_cfg = kwargs.get("pair_cfg")
        base_pair_cfg = pair_cfg if isinstance(pair_cfg, dict) else self._pair_cfg(pair)
        po = self._exit_tuning_merge_cfg(base_pair_cfg, pair)
        try:
            scale_out_near_frac = float(
                po.get("scale_out_near_frac", getattr(self, "SCALE_OUT_NEAR_FRAC", 0.0)) or 0.0
            )
        except (TypeError, ValueError):
            scale_out_near_frac = float(getattr(self, "SCALE_OUT_NEAR_FRAC", 0.0) or 0.0)
        try:
            scale_out_exhaust_frac = float(
                po.get("scale_out_exhaust_frac", getattr(self, "SCALE_OUT_EXHAUST_FRAC", 0.0)) or 0.0
            )
        except (TypeError, ValueError):
            scale_out_exhaust_frac = float(getattr(self, "SCALE_OUT_EXHAUST_FRAC", 0.0) or 0.0)
        add_log_flags = st.setdefault("add_log_flags", {})
        trade_log_flags = add_log_flags.setdefault(trade_id, {}) if trade_id else {}
        cooldown_minutes = float(getattr(self, "ADD_LOG_COOLDOWN_MINUTES", 15.0) or 15.0)
        quality_ratio = float((trade_profile or {}).get("quality_ratio", 1.0) or 1.0)
        measured_map = st.setdefault("measured_move_watch", {})
        mm_state = measured_map.get(trade_id) if trade_id else None
        fast_lane_col = "fast_lane_short" if is_short else "fast_lane_long"
        slow_lane_col = "slow_lane_short" if is_short else "slow_lane_long"
        fast_lane = bool(int(row.get(fast_lane_col, 0) or 0)) if pd.notna(row.get(fast_lane_col, 0)) else False
        slow_lane = bool(int(row.get(slow_lane_col, 0) or 0)) if pd.notna(row.get(slow_lane_col, 0)) else False
        align_score = float(row.get("htf_alignment", 0.0) or 0.0)
        if not np.isfinite(align_score):
            align_score = 0.0
        narrow_val = row.get("channel_mode_narrow_trend", 0)
        wide_val = row.get("channel_mode_wide_range", 0)
        decay_val = row.get("channel_mode_wide_decay", 0)
        drive_val = row.get("channel_mode_htf_drive", 0)
        channel_narrow = bool(int(narrow_val)) if pd.notna(narrow_val) and np.isfinite(narrow_val) else False
        channel_wide = bool(int(wide_val)) if pd.notna(wide_val) and np.isfinite(wide_val) else False
        channel_decay = bool(int(decay_val)) if pd.notna(decay_val) and np.isfinite(decay_val) else False
        htf_drive_lane = bool(int(drive_val)) if pd.notna(drive_val) and np.isfinite(drive_val) else False
        score_board = st.setdefault("elastic_exit_score", {})
        stagnation_map = st.setdefault("stagnation_watch", {})
        range_map = st.setdefault("range_exit_watch", {})
        micro_map = st.setdefault("micro_target_state", {})
        retreat_map = st.setdefault("peak_retreat_watch", {})
        high_map = st.setdefault("high_target_hit", {})
        if current_profit <= 0:
            score_board.pop(trade_id, None)
            if abs(current_profit) > float(getattr(self, "EXIT_STAGNATION_PROFIT_BAND", 0.011)):
                stagnation_map.pop(trade_id, None)
            range_map.pop(trade_id, None)
            retreat_map.pop(trade_id, None)
            high_map.pop(trade_id, None)
            measured_map.pop(trade_id, None)
        self._register_portfolio_trade(trade, pair, is_short, float(current_profit), float(current_rate), current_time)
        portfolio = self._portfolio_snapshot(focus=int(getattr(trade, "id", 0) or 0))
        portfolio_guard = bool(getattr(self, "PORTFOLIO_CONTEXT_ENABLE", True))
        port_net = float(portfolio.get("net_profit_pct", 0.0) if portfolio_guard else 0.0)
        port_neg_value = float(portfolio.get("negative_value", 0.0) if portfolio_guard else 0.0)
        port_focus_share = float(portfolio.get("focus_positive_share", 0.0) if portfolio_guard else 0.0)
        port_focus_weight = float(portfolio.get("focus_weight_share", 0.0) if portfolio_guard else 0.0)
        port_losers = int(portfolio.get("loser_count", 0) if portfolio_guard else 0)
        port_loss_pressure = float(portfolio.get("loss_pressure_pct", 0.0) if portfolio_guard else 0.0)
        portfolio_exit_now = False
        portfolio_lock_floor = 0.0
        risk_basis_pct = 0.0
        if isinstance(trade_profile, dict):
            exp_guard_src = trade_profile.get("expectation_guard")
            if isinstance(exp_guard_src, dict):
                try:
                    guard_basis = float(exp_guard_src.get("risk_basis_pct", 0.0) or 0.0)
                except (TypeError, ValueError):
                    guard_basis = 0.0
                else:
                    if guard_basis > 0:
                        risk_basis_pct = max(risk_basis_pct, guard_basis)
        if risk_basis_pct <= 0 and isinstance(trade_profile, dict):
            try:
                profile_basis = float(trade_profile.get("risk_basis_pct", 0.0) or 0.0)
            except (TypeError, ValueError):
                profile_basis = 0.0
            else:
                if profile_basis > 0:
                    risk_basis_pct = profile_basis
        risk_info_dict_initial: Dict[str, Any] = risk_info_payload or {}
        if not risk_info_dict_initial:
            retry_payload, retry_error = self._stoploss_risk_snapshot(
                pair=pair,
                trade_profile=trade_profile,
                pair_cfg=po,
                trade=trade,
                current_rate=current_rate,
                risk_info=risk_info_payload,
            )
            if retry_payload is not None:
                risk_info_payload = retry_payload
                risk_info_dict_initial = retry_payload
            if risk_info_error is None and retry_error:
                risk_info_error = retry_error
        if isinstance(risk_info_dict_initial, dict):
            try:
                basis_candidate = float(risk_info_dict_initial.get("risk_basis_pct", 0.0) or 0.0)
            except (TypeError, ValueError):
                basis_candidate = 0.0
            else:
                if basis_candidate > 0:
                    risk_basis_pct = max(risk_basis_pct, basis_candidate)

        adaptive_lock = (
            self._calc_adaptive_lock(
                trade,
                row,
                float(current_profit),
                pair=pair,
                risk_basis_pct=risk_basis_pct if risk_basis_pct > 0 else None,
            )
            if current_profit > 0
            else 0.0
        )

        perf = self._performance_profile(pair)
        perf_guard = bool(perf.get("drawdown_guard", False))
        perf_hot = (perf.get("mode") == "hot")

        mania_lane = int(row.get("blowoff_tail_guard", 0) or 0) >= 1
        panic_lane = int(row.get("panic_tail_guard", 0) or 0) >= 1

        add_log_flags = st.setdefault("add_log_flags", {})
        trade_log_flags = add_log_flags.setdefault(trade_id, {}) if trade_id else {}
        cooldown_minutes = float(getattr(self, "ADD_LOG_COOLDOWN_MINUTES", 15.0) or 15.0)
        range_lane = bool(channel_wide)

        stage = "离场决策"
        side_txt = "short" if is_short else "long"

        def trigger(tag: str, extra: Optional[Dict[str, Any]] = None) -> str:
            info = dict(extra or {})
            info.setdefault("profit", current_profit)
            self._log_decision(stage, pair, side_txt, "触发", tag, info)
            score_board.pop(trade_id, None)
            stagnation_map.pop(trade_id, None)
            range_map.pop(trade_id, None)
            micro_map.pop(trade_id, None)
            retreat_map.pop(trade_id, None)
            high_map.pop(trade_id, None)
            measured_map.pop(trade_id, None)
            _append_stoploss_closure(tag, info)
            return tag

        if opp_force_exit:
            relax_minutes = max(1, int(getattr(self, "OPP_SIGNAL_HANDOFF_RELAX_MINUTES", 18)))
            relax_until = now + timedelta(minutes=relax_minutes)
            relax_mult = float(getattr(self, "OPP_SIGNAL_HANDOFF_TRI_RELAX", 0.96))
            relax_align = float(getattr(self, "OPP_SIGNAL_HANDOFF_ALIGN_BONUS", 0.02))
            st["opp_handoff_relax_until"] = relax_until
            st["opp_handoff_relax_side"] = opp_side
            st["opp_handoff_relax_mult"] = relax_mult
            st["opp_handoff_align_bonus"] = relax_align
            return trigger(opp_force_reason or "opp_signal_force_exit", {
                "risk_hits": risk_hits,
                "opp_need": opp_need_hits,
                "profit_cap": opp_profit_cap,
                "loss_cap": opp_loss_cap,
                "relax_until": relax_until.isoformat(),
                "relax_mult": relax_mult,
                "handoff_to": opp_side,
            })

        now_ctx = current_time if current_time.tzinfo else current_time.replace(tzinfo=timezone.utc)
        session_ctx = self._session_context(now_ctx)
        open_dt = self._to_utc_datetime(
            getattr(trade, "open_date_utc", None) or getattr(trade, "open_date", None)
        )
        flash_ctx = self._flash_volatility_probe(df, is_short)
        flash_state = st.setdefault("flash_guard", {})
        if isinstance(flash_state, dict):
            if flash_ctx:
                flash_state["exit_bias"] = int(bool(flash_ctx.get("exit_bias")))
                flash_state["defend_bias"] = int(bool(flash_ctx.get("defend_bias")))
                flash_state["volume_ratio"] = float(flash_ctx.get("volume_ratio", 0.0) or 0.0)
                flash_state["wick_against"] = float(flash_ctx.get("wick_against", 0.0) or 0.0)
                flash_state["wick_support"] = float(flash_ctx.get("wick_support", 0.0) or 0.0)
                flash_state["last_seen"] = now_ctx.isoformat()
            else:
                flash_state.setdefault("defend_bias", 0)
                flash_state["exit_bias"] = 0
        priority = self._side_priority_bias(pair, row, session_ctx=session_ctx)
        exit_min = float(self._profile_val("priority_exit_min", getattr(self, "SIDE_PRIORITY_EXIT_BASE", 0.14)))
        prefer = priority.get("prefer")
        priority_conf = float(priority.get("confidence", 0.0) or 0.0)
        priority_opp = "long" if is_short else "short"

        exit_score_ctx = self._exit_elastic_context(
            trade,
            now_ctx,
            current_profit=float(current_profit),
            fast_lane=fast_lane,
            slow_lane=slow_lane,
            align_score=align_score,
            mania_lane=mania_lane,
            panic_lane=panic_lane,
            perf_guard=perf_guard,
            perf_hot=perf_hot,
            prefer=prefer,
            priority_conf=priority_conf,
            exit_min=exit_min,
            channel_decay=channel_decay,
            range_lane=range_lane,
            pair=pair,
            current_rate=float(current_rate),
        )
        exit_score_ctx["quality_tier"] = quality_tier
        exit_score_ctx["entry_quality_ratio"] = quality_ratio
        if flash_ctx:
            exit_score_ctx["flash_guard"] = {
                "exit_bias": int(bool(flash_ctx.get("exit_bias"))),
                "defend_bias": int(bool(flash_ctx.get("defend_bias"))),
                "wick_against": round(float(flash_ctx.get("wick_against", 0.0) or 0.0), 4),
                "wick_support": round(float(flash_ctx.get("wick_support", 0.0) or 0.0), 4),
                "volume_ratio": round(float(flash_ctx.get("volume_ratio", 0.0) or 0.0), 4),
                "move_pct": round(float(flash_ctx.get("move_pct", 0.0) or 0.0), 4),
            }
        base_profit_floor = 0.0
        if current_profit > 0:
            base_profit_floor = max(base_profit_floor, adaptive_lock)
        exit_score_ctx["profit_floor"] = max(0.0, float(exit_score_ctx.get("profit_floor", 0.0) or 0.0), base_profit_floor)

        trailing_floor = 0.0

        if flash_ctx and flash_ctx.get("exit_bias"):
            age_minutes = 0.0
            if open_dt:
                age_minutes = max(0.0, (now_ctx - open_dt).total_seconds() / 60.0)

            def _safe_float(val: Any, default: float = 0.0) -> float:
                try:
                    parsed = float(val)
                except (TypeError, ValueError):
                    return float(default)
                return float(parsed)

            locked_r = 0.0
            if isinstance(trade_profile, dict):
                strict_snapshot = trade_profile.get("strict_giveback")
                if isinstance(strict_snapshot, dict):
                    floor_r_prev = _safe_float(strict_snapshot.get("floor_r"), 0.0)
                    if floor_r_prev > 0:
                        locked_r = max(locked_r, floor_r_prev)
                    else:
                        floor_val_prev = _safe_float(strict_snapshot.get("floor"), 0.0)
                        basis_val_prev = _safe_float(strict_snapshot.get("risk_basis_pct"), risk_basis_pct)
                        if basis_val_prev > 0 and floor_val_prev > 0:
                            locked_r = max(locked_r, floor_val_prev / basis_val_prev)
                exp_snapshot = trade_profile.get("expectation_guard")
                if isinstance(exp_snapshot, dict):
                    stop_r_prev = _safe_float(exp_snapshot.get("release_stop_r"), 0.0)
                    floor_r_prev = _safe_float(exp_snapshot.get("release_floor_r"), 0.0)
                    floor_profit_prev = _safe_float(exp_snapshot.get("release_stop_profit"), 0.0)
                    basis_prev = _safe_float(exp_snapshot.get("risk_basis_pct"), risk_basis_pct)
                    for candidate in (stop_r_prev, floor_r_prev):
                        if candidate > 0:
                            locked_r = max(locked_r, candidate)
                    if basis_prev > 0 and floor_profit_prev > 0:
                        locked_r = max(locked_r, floor_profit_prev / basis_prev)

            exit_loss_base = float(getattr(self, "FLASH_VOL_GUARD_EXIT_LOSS", -0.012) or -0.012)
            profit_cap_base = float(getattr(self, "FLASH_VOL_GUARD_EXIT_PROFIT_CAP", 0.0) or 0.0)
            exit_loss, profit_cap, schedule_meta = self._flash_vol_exit_thresholds(
                pair=pair,
                pair_cfg=po,
                age_minutes=age_minutes,
                locked_r=locked_r,
                base_loss=exit_loss_base,
                base_profit_cap=profit_cap_base,
                current_profit=float(current_profit),
                is_short=is_short,
            )
            cooldown_min = max(1.0, float(getattr(self, "FLASH_VOL_GUARD_EXIT_COOLDOWN_MIN", 20.0)))
            flash_state = st.setdefault("flash_guard", {})
            last_exit_dt = self._to_utc_datetime(flash_state.get("exit_ts")) if isinstance(flash_state, dict) else None
            cooldown_ok = True
            if last_exit_dt:
                cooldown_ok = ((now_ctx - last_exit_dt).total_seconds() / 60.0) >= cooldown_min
            loss_hit = (exit_loss < 0) and (current_profit <= exit_loss)
            profit_hit = (profit_cap > 0) and (0.0 <= current_profit <= profit_cap)
            if cooldown_ok and (loss_hit or profit_hit):
                info = {
                    "wick_against": round(float(flash_ctx.get("wick_against", 0.0) or 0.0), 4),
                    "volume_ratio": round(float(flash_ctx.get("volume_ratio", 0.0) or 0.0), 4),
                    "move_pct": round(float(flash_ctx.get("move_pct", 0.0) or 0.0), 4),
                    "cooldown_min": round(cooldown_min, 2),
                    "age_minutes": round(age_minutes, 2),
                    "locked_r": round(locked_r, 4),
                    "flash_exit_loss": round(exit_loss, 6),
                    "flash_profit_cap": round(profit_cap, 6),
                    "flash_guard": 1,
                }
                if schedule_meta:
                    info.update(schedule_meta)
                reverse_payload = self._queue_flash_reverse(
                    pair=pair,
                    pair_cfg=po,
                    st=st,
                    now=now_ctx,
                    is_short=is_short,
                    age_minutes=age_minutes,
                    locked_r=locked_r,
                    current_profit=float(current_profit),
                    current_rate=float(current_rate),
                    flash_ctx=flash_ctx,
                    port_net=port_net,
                    port_loss_pressure=port_loss_pressure,
                )
                if reverse_payload:
                    info.setdefault(
                        "flash_reverse",
                        {
                            "direction": reverse_payload.get("direction"),
                            "ready_ts": reverse_payload.get("ready_ts"),
                            "expire_ts": reverse_payload.get("expire_ts"),
                        },
                    )
                if isinstance(flash_state, dict):
                    flash_state["exit_ts"] = now_ctx.isoformat()
                    flash_state["exit_bias"] = 0
                return trigger("sl_flash_volatility_exit", info)

        if risk_info_payload is None:
            retry_payload, retry_error = self._stoploss_risk_snapshot(
                pair=pair,
                trade_profile=trade_profile,
                pair_cfg=po,
                trade=trade,
                current_rate=current_rate,
            )
            if retry_payload is not None:
                risk_info_payload = retry_payload
            if risk_info_error is None and retry_error:
                risk_info_error = retry_error
        risk_info_dict: Dict[str, Any] = risk_info_payload or {}
        mm_context = self._measured_move_context_target(
            pair=pair,
            trade=trade,
            fast_lane=fast_lane,
            slow_lane=slow_lane,
            channel_narrow=channel_narrow,
            channel_wide=channel_wide,
            channel_decay=channel_decay,
            htf_drive_lane=htf_drive_lane,
            align_score=align_score,
            is_short=is_short,
            panic_lane=panic_lane,
            mania_lane=mania_lane,
            risk_info=risk_info_payload,
            trade_profile=trade_profile,
            session_ctx=session_ctx,
            current_profit=current_profit,
        )
        mm_context_r = float(mm_context.get("target_r", 0.0) or 0.0)

        strict_guard_floor = 0.0
        strict_guard_info: Optional[Dict[str, Any]] = None
        if current_profit > 0:
            strict_guard_floor, strict_guard_info = self._strict_giveback_guard(
                pair=pair,
                trade=trade,
                current_profit=float(current_profit),
                trade_profile=trade_profile,
                risk_info=risk_info_payload,
                mm_context=mm_context,
                current_rate=current_rate,
            )
            if strict_guard_floor > 0:
                trailing_floor = max(trailing_floor, strict_guard_floor)
            if strict_guard_info is not None and risk_info_error:
                if isinstance(strict_guard_info, dict):
                    strict_guard_info.setdefault("risk_resolve_error", risk_info_error)
        strict_guard_state: Optional[Dict[str, Any]] = None
        if isinstance(trade_profile, dict):
            sg_candidate = trade_profile.get("strict_giveback")
            if isinstance(sg_candidate, dict):
                strict_guard_state = sg_candidate

        if current_profit > 0:
            strict_exit_tol = max(
                0.0,
                float(po.get("strict_giveback_exit_tolerance", getattr(self, "STRICT_GIVEBACK_EXIT_TOLERANCE", 0.0)) or 0.0),
            )
            guard_exit_ready = bool(strict_guard_state.get("armed") or strict_guard_state.get("active")) if strict_guard_state else False
            guard_exit_done = bool(strict_guard_state.get("exit_triggered")) if strict_guard_state else False
            if strict_guard_floor > 0:
                strict_exit_floor = max(0.0, strict_guard_floor - strict_exit_tol)
                if strict_guard_state is not None:
                    strict_guard_state["exit_floor"] = float(strict_exit_floor)
                    strict_guard_state["exit_tolerance"] = float(strict_exit_tol)
                if guard_exit_ready and not guard_exit_done and current_profit <= strict_exit_floor + 1e-9:
                    extra = {
                        "floor": round(float(strict_guard_floor), 6),
                        "exit_floor": round(float(strict_exit_floor), 6),
                        "tolerance": round(float(strict_exit_tol), 6),
                    }
                    if isinstance(strict_guard_info, dict):
                        for key, val in strict_guard_info.items():
                            if key not in ("basis_pct", "buffer_share", "buffer_abs"):
                                extra.setdefault(key, val)
                    if strict_guard_state is not None:
                        strict_guard_state["exit_triggered"] = True
                        strict_guard_state["exit_ts"] = now_ctx
                    return trigger("tp_strict_giveback_floor", extra)

        guard_state = trade_profile.setdefault("expectation_guard", {}) if isinstance(trade_profile, dict) else None
        if guard_state is not None:
            basis_pct = float(risk_info_dict.get("risk_basis_pct", 0.0) or 0.0)
            target_r_cfg = float(po.get("expectation_target_r", getattr(self, "EXPECTATION_TARGET_R", 0.0)) or 0.0)
            guard_state["risk_basis_pct"] = basis_pct
            guard_state["target_r"] = target_r_cfg
            guard_state["target_profit"] = basis_pct * target_r_cfg if (basis_pct > 0 and target_r_cfg > 0) else 0.0
            if mm_context_r > 0:
                guard_state["context_hint_r"] = mm_context_r
                guard_state["context_hint_label"] = mm_context.get("context")
            else:
                guard_state.pop("context_hint_r", None)
                guard_state.pop("context_hint_label", None)

        def make_exit_ctx(**extra_ctx: Any) -> Dict[str, Any]:
            ctx_local = dict(exit_score_ctx)
            floor_val = 0.0
            try:
                floor_val = float(ctx_local.get("profit_floor", 0.0) or 0.0)
            except (TypeError, ValueError):
                floor_val = 0.0
            if portfolio_lock_floor > 0 and current_profit > 0:
                floor_val = max(floor_val, portfolio_lock_floor)
            if trailing_floor > 0 and current_profit > 0:
                floor_val = max(floor_val, trailing_floor)
            extra_floor = extra_ctx.pop("profit_floor", None)
            if extra_floor is not None:
                try:
                    floor_val = max(floor_val, float(extra_floor))
                except (TypeError, ValueError):
                    pass
            ctx_local["profit_floor"] = max(0.0, floor_val)
            if "peak_profit" in extra_ctx:
                ctx_local["peak_profit"] = extra_ctx["peak_profit"]
            ctx_local.update(extra_ctx)
            return ctx_local

        if bool(getattr(self, "EXIT_GIVEBACK_ENABLE", True)) and np.isfinite(entry_rate):
            peak_effective = peak_profit_live
            if np.isfinite(peak_effective):
                giveback_min = max(0.0, float(getattr(self, "EXIT_GIVEBACK_MIN_PROFIT", 0.032)))
                if peak_effective >= giveback_min:
                    drop_abs = max(0.0, peak_effective - current_profit)
                    drop_share = (drop_abs / peak_effective) if peak_effective > 0 else 0.0
                    lock_sens = self._lock_sensitivity_value()
                    drop_share_need = max(0.0, float(getattr(self, "EXIT_GIVEBACK_DROP_SHARE", 0.36)) * lock_sens)
                    drop_abs_need = max(0.0, float(getattr(self, "EXIT_GIVEBACK_DROP_ABS", 0.009)) * lock_sens)
                    if drop_share >= drop_share_need or drop_abs >= drop_abs_need:
                        info = {
                            "peak_profit": round(peak_effective, 4),
                            "current_profit": round(current_profit, 4),
                            "drop_share": round(drop_share, 4),
                            "drop_abs": round(drop_abs, 4),
                            "min_profit": round(giveback_min, 4),
                        }
                        level_tag = str(getattr(self, "EXIT_GIVEBACK_LEVEL", "major")) or "major"
                        ok, score_total, score_need, snap = self._elastic_exit_score(
                            pair,
                            trade_id,
                            side_txt,
                            make_exit_ctx(
                                profit_floor=max(0.0, current_profit),
                                peak_profit=peak_effective,
                            ),
                            level=level_tag,
                            tag="peak_giveback_release",
                            info=info,
                        )
                        if ok:
                            extra = dict(info)
                            extra.update(
                                {
                                    "elastic_score": round(score_total, 4),
                                    "elastic_need": round(score_need, 4),
                                }
                            )
                            events_log = snap.get("events") if isinstance(snap, dict) else None
                            if isinstance(events_log, list) and events_log:
                                extra["elastic_events"] = events_log[-3:]
                            return trigger("tp_peak_giveback_release", extra)

        if bool(getattr(self, "EXIT_STAGNATION_ENABLE", True)):
            band = max(0.0, float(getattr(self, "EXIT_STAGNATION_PROFIT_BAND", 0.011)))
            align_cap = float(getattr(self, "EXIT_STAGNATION_ALIGN_CAP", 0.18))
            adx_cap = float(getattr(self, "EXIT_STAGNATION_ADX_MAX", 22.0))
            tf_minutes = max(1.0, float(self._tf_minutes()))
            hold_bars = max(0.0, float(getattr(self, "EXIT_STAGNATION_MIN_BARS", 6.0)))
            hold_minutes = max(float(getattr(self, "EXIT_STAGNATION_MIN_DURATION_MIN", 18.0)), hold_bars * tf_minutes)
            repeat_cooldown = max(1.0, float(getattr(self, "EXIT_STAGNATION_REPEAT_COOLDOWN_MIN", 12.0)))
            level = str(getattr(self, "EXIT_STAGNATION_LEVEL", "minor")) or "minor"
            align_signed = float(align_score if not is_short else -align_score)
            align_abs = abs(align_signed)
            adx_val = float(row.get("adx", 0.0) or 0.0)
            age_minutes = 0.0
            if open_dt:
                age_minutes = max(0.0, (now_ctx - open_dt).total_seconds() / 60.0)
            stagnation_cell = stagnation_map.get(trade_id)
            in_band = abs(current_profit) <= band
            mania_active = bool(mania_lane or panic_lane)
            prefer_same = bool(prefer == ("short" if is_short else "long"))
            align_relaxed = align_abs <= align_cap or prefer_same
            if in_band and age_minutes >= hold_minutes and not mania_active and align_relaxed and adx_val <= adx_cap:
                if not isinstance(stagnation_cell, dict):
                    stagnation_cell = {"start": now_ctx}
                    stagnation_map[trade_id] = stagnation_cell
                stagnation_cell.setdefault("start", now_ctx)
                stagnation_cell["last_seen"] = now_ctx
                start_dt = self._to_utc_datetime(stagnation_cell.get("start")) or now_ctx
                stagnation_cell["start"] = start_dt
                duration_minutes = max(0.0, (now_ctx - start_dt).total_seconds() / 60.0)
                if duration_minutes >= hold_minutes:
                    last_fire_dt = self._to_utc_datetime(stagnation_cell.get("last_fire"))
                    gap_minutes = float("inf")
                    if last_fire_dt:
                        gap_minutes = max(0.0, (now_ctx - last_fire_dt).total_seconds() / 60.0)
                    if gap_minutes >= repeat_cooldown:
                        info = {
                            "age_min": round(age_minutes, 2),
                            "duration_min": round(duration_minutes, 2),
                            "band_pct": round(band * 100.0, 2),
                            "align": round(align_signed, 4),
                            "adx": round(adx_val, 2),
                        }
                        ok, score_total, score_need, snap = self._elastic_exit_score(
                            pair,
                            trade_id,
                            side_txt,
                            make_exit_ctx(),
                            level=level,
                            tag="stagnation_band",
                            info=info,
                        )
                        stagnation_cell["last_fire"] = now_ctx
                        if ok:
                            extra = dict(info)
                            extra.update({
                                "elastic_score": round(score_total, 4),
                                "elastic_need": round(score_need, 4),
                            })
                            events_log = snap.get("events") if isinstance(snap, dict) else None
                            if isinstance(events_log, list) and events_log:
                                extra["elastic_events"] = events_log[-3:]
                            return trigger("tp_stagnation_exit", extra)
            elif isinstance(stagnation_cell, dict):
                stagnation_map.pop(trade_id, None)
        else:
            stagnation_map.pop(trade_id, None)

        short_stale_cfg = po.get("short_stale_exit") if isinstance(po, dict) else None
        short_stale_enable = bool(getattr(self, "SHORT_STALE_EXIT_ENABLE", True))
        if isinstance(short_stale_cfg, dict) and "enable" in short_stale_cfg:
            try:
                short_stale_enable = bool(short_stale_cfg.get("enable"))
            except Exception:
                short_stale_enable = short_stale_enable
        if is_short and short_stale_enable:
            age_minutes = 0.0
            if open_dt:
                age_minutes = max(0.0, (now_ctx - open_dt).total_seconds() / 60.0)
            tf_minutes = max(1.0, float(self._tf_minutes()))
            min_age_default = float(getattr(self, "SHORT_STALE_MIN_AGE_MIN", 24.0))
            force_age_default = float(getattr(self, "SHORT_STALE_FORCE_EXIT_MIN", 40.0))
            profit_cap_default = float(getattr(self, "SHORT_STALE_PROFIT_CEIL", 0.004))
            loss_floor_default = float(getattr(self, "SHORT_STALE_LOSS_FLOOR", -0.012))
            align_floor_default = float(getattr(self, "SHORT_STALE_ALIGN_FLOOR", -0.06))
            release_buffer_default = float(getattr(self, "SHORT_STALE_RELEASE_BUFFER", 0.0012))
            skip_extreme_default = bool(getattr(self, "SHORT_STALE_SKIP_EXTREMES", True))
            allow_fastlane_default = bool(getattr(self, "SHORT_STALE_ALLOW_FASTLANE", False))
            slow_bleed_age_default = float(getattr(self, "SHORT_STALE_SLOW_BLEED_MIN_AGE", 26.0))
            slow_bleed_loss_default = float(getattr(self, "SHORT_STALE_SLOW_BLEED_LOSS", -0.026))
            slow_bleed_adx_default = float(getattr(self, "SHORT_STALE_SLOW_BLEED_ADX_CAP", 18.0))
            slow_bleed_align_cap_default = float(getattr(self, "SHORT_STALE_SLOW_BLEED_ALIGN_CAP", 0.22))
            if isinstance(short_stale_cfg, dict):
                min_age_default = float(short_stale_cfg.get("min_age_min", min_age_default) or min_age_default)
                force_age_default = float(short_stale_cfg.get("force_exit_min", force_age_default) or force_age_default)
                profit_cap_default = float(short_stale_cfg.get("profit_ceil", profit_cap_default) or profit_cap_default)
                loss_floor_candidate = short_stale_cfg.get("loss_floor")
                if loss_floor_candidate is not None:
                    try:
                        loss_floor_default = float(loss_floor_candidate)
                    except (TypeError, ValueError):
                        pass
                align_floor_candidate = short_stale_cfg.get("align_floor")
                if align_floor_candidate is not None:
                    try:
                        align_floor_default = float(align_floor_candidate)
                    except (TypeError, ValueError):
                        pass
                release_buffer_candidate = short_stale_cfg.get("release_buffer")
                if release_buffer_candidate is not None:
                    try:
                        release_buffer_default = float(release_buffer_candidate)
                    except (TypeError, ValueError):
                        pass
                skip_candidate = short_stale_cfg.get("skip_extremes")
                if skip_candidate is not None:
                    skip_extreme_default = bool(skip_candidate)
                fastlane_candidate = short_stale_cfg.get("allow_fastlane")
                if fastlane_candidate is not None:
                    allow_fastlane_default = bool(fastlane_candidate)
                slow_bleed_age_candidate = short_stale_cfg.get("slow_bleed_age_min")
                if slow_bleed_age_candidate is not None:
                    try:
                        slow_bleed_age_default = float(slow_bleed_age_candidate)
                    except (TypeError, ValueError):
                        pass
                slow_bleed_loss_candidate = short_stale_cfg.get("slow_bleed_loss_floor")
                if slow_bleed_loss_candidate is not None:
                    try:
                        slow_bleed_loss_default = float(slow_bleed_loss_candidate)
                    except (TypeError, ValueError):
                        pass
                slow_bleed_adx_candidate = short_stale_cfg.get("slow_bleed_adx_cap")
                if slow_bleed_adx_candidate is not None:
                    try:
                        slow_bleed_adx_default = float(slow_bleed_adx_candidate)
                    except (TypeError, ValueError):
                        pass
                slow_bleed_align_candidate = short_stale_cfg.get("slow_bleed_align_cap")
                if slow_bleed_align_candidate is not None:
                    try:
                        slow_bleed_align_cap_default = float(slow_bleed_align_candidate)
                    except (TypeError, ValueError):
                        pass
            min_age = max(min_age_default, tf_minutes * 3.2)
            force_age = max(min_age, force_age_default)
            slow_bleed_age = max(min_age, slow_bleed_age_default)
            profit_cap = profit_cap_default
            loss_floor = loss_floor_default
            slow_bleed_loss = min(loss_floor, slow_bleed_loss_default)
            slow_bleed_adx_cap = slow_bleed_adx_default
            slow_bleed_align_cap = slow_bleed_align_cap_default
            align_floor = align_floor_default
            release_buffer = release_buffer_default
            skip_extreme = skip_extreme_default and bool(mania_lane or panic_lane)
            allow_fastlane = allow_fastlane_default
            align_signed = float(align_score if not is_short else -align_score)
            prefer_same = bool(prefer == "short")
            lane_active = bool(fast_lane or slow_lane)
            lane_block = lane_active and not allow_fastlane
            guard_reason: Optional[str] = None
            if not skip_extreme and not lane_block and open_dt and loss_floor < profit_cap:
                if age_minutes >= min_age and align_signed <= align_floor and not prefer_same:
                    if loss_floor <= current_profit <= profit_cap:
                        guard_reason = "align_stale"
                if guard_reason is None and age_minutes >= force_age:
                    if loss_floor <= current_profit <= profit_cap * 1.25:
                        guard_reason = "time_force"
            if guard_reason is None and age_minutes >= slow_bleed_age:
                adx_val = float(row.get("adx", 0.0) or 0.0)
                align_abs = abs(align_signed)
                if current_profit <= slow_bleed_loss and adx_val <= slow_bleed_adx_cap and align_abs <= slow_bleed_align_cap:
                    guard_reason = "slow_bleed"
            if guard_reason:
                info = {
                    "age_min": round(age_minutes, 2),
                    "profit_pct": round(current_profit * 100.0, 3),
                    "align_signed": round(align_signed, 4),
                    "reason": guard_reason,
                    "loss_floor_pct": round(loss_floor * 100.0, 2),
                    "profit_cap_pct": round(profit_cap * 100.0, 2),
                    "prefer": prefer,
                    "fast_lane": int(bool(fast_lane)),
                    "slow_lane": int(bool(slow_lane)),
                }
                scope_label = str(short_stale_cfg.get("label")) if isinstance(short_stale_cfg, dict) else None
                if not scope_label:
                    scope_label = pair
                info["short_stale_scope"] = scope_label
                info["short_stale_pair"] = pair
                if skip_extreme:
                    info["extreme_lane"] = int(bool(mania_lane or panic_lane))
                if release_buffer > 0:
                    info["release_buffer"] = round(release_buffer, 4)
                if guard_reason == "slow_bleed":
                    info.update(
                        {
                            "slow_bleed_loss_pct": round(slow_bleed_loss * 100.0, 3),
                            "slow_bleed_age_min": round(slow_bleed_age, 2),
                            "slow_bleed_adx_cap": round(slow_bleed_adx_cap, 2),
                            "slow_bleed_align_cap": round(slow_bleed_align_cap, 4),
                        }
                    )
                return trigger("sl_short_stale_release", info)

        if bool(getattr(self, "EXIT_RANGE_ENABLE", True)):
            tf_minutes = max(1.0, float(self._tf_minutes()))
            hold_bars = max(0.0, float(getattr(self, "EXIT_RANGE_HOLD_MIN_BARS", 3.0)))
            hold_minutes = max(float(getattr(self, "EXIT_RANGE_HOLD_MINUTES", 12.0)), hold_bars * tf_minutes)
            repeat_cooldown = max(1.0, float(getattr(self, "EXIT_RANGE_REPEAT_COOLDOWN_MIN", 10.0)))
            level = str(getattr(self, "EXIT_RANGE_LEVEL", "medium")) or "medium"
            range_align_cap = float(getattr(self, "EXIT_RANGE_ALIGN_MAX", 0.18))
            range_adx_cap = float(getattr(self, "EXIT_RANGE_ADX_MAX", 20.0))
            profit_floor = float(getattr(self, "EXIT_RANGE_PROFIT_FLOOR", -0.003))
            profit_ceil = float(getattr(self, "EXIT_RANGE_PROFIT_CEIL", 0.034))
            align_signed = float(align_score if not is_short else -align_score)
            align_abs = abs(align_signed)
            adx_val = float(row.get("adx", 0.0) or 0.0)
            mania_active = bool(mania_lane or panic_lane)
            prefer_same = bool(prefer == ("short" if is_short else "long"))
            range_cell = range_map.get(trade_id)
            if range_lane and profit_floor <= current_profit <= profit_ceil and not mania_active and (
                align_abs <= range_align_cap or prefer_same
            ) and adx_val <= range_adx_cap:
                if not isinstance(range_cell, dict):
                    range_cell = {"start": now_ctx}
                    range_map[trade_id] = range_cell
                range_cell.setdefault("start", now_ctx)
                range_cell["last_seen"] = now_ctx
                start_dt = self._to_utc_datetime(range_cell.get("start")) or now_ctx
                range_cell["start"] = start_dt
                duration_minutes = max(0.0, (now_ctx - start_dt).total_seconds() / 60.0)
                if duration_minutes >= hold_minutes:
                    last_fire_dt = self._to_utc_datetime(range_cell.get("last_fire"))
                    gap_minutes = float("inf")
                    if last_fire_dt:
                        gap_minutes = max(0.0, (now_ctx - last_fire_dt).total_seconds() / 60.0)
                    if gap_minutes >= repeat_cooldown:
                        info = {
                            "duration_min": round(duration_minutes, 2),
                            "profit_pct": round(current_profit * 100.0, 2),
                            "align": round(align_signed, 4),
                            "adx": round(adx_val, 2),
                        }
                        ok, score_total, score_need, snap = self._elastic_exit_score(
                            pair,
                            trade_id,
                            side_txt,
                            make_exit_ctx(),
                            level=level,
                            tag="range_congestion",
                            info=info,
                        )
                        range_cell["last_fire"] = now_ctx
                        if ok:
                            extra = dict(info)
                            extra.update({
                                "elastic_score": round(score_total, 4),
                                "elastic_need": round(score_need, 4),
                            })
                            events_log = snap.get("events") if isinstance(snap, dict) else None
                            if isinstance(events_log, list) and events_log:
                                extra["elastic_events"] = events_log[-3:]
                            return trigger("tp_range_congestion", extra)
            elif isinstance(range_cell, dict):
                range_map.pop(trade_id, None)
        else:
            range_map.pop(trade_id, None)

        signal_map = st.setdefault("position_signal_review", {})
        signal_review = self._position_signal_review(pair, trade, row, float(current_profit), session_ctx=session_ctx, priority=priority)
        action = signal_review.get("action")
        if action == "exit":
            extra = dict(signal_review.get("extra", {}))
            extra["reason"] = signal_review.get("reason")
            extra["signal_action"] = action
            signal_map.pop(trade_id, None)
            tag = signal_review.get("tag") or "tp_signal_flip"
            return trigger(tag, extra)
        elif action in ("trim", "add"):
            hint_payload = {**signal_review, "ts": now_ctx}
            signal_map[trade_id] = hint_payload
            note_extra = dict(signal_review.get("extra", {}))
            note_extra["reason"] = signal_review.get("reason")
            note_extra["signal_action"] = action
            self._log_decision(stage, pair, side_txt, "提示", f"signal_{action}_review", note_extra)
        else:
            signal_map.pop(trade_id, None)

        signal_hint = signal_map.get(trade_id)
        signal_hint_action = None
        signal_hint_valid = False
        signal_hint_extra = {}
        if isinstance(signal_hint, dict):
            signal_hint_action = signal_hint.get("action")
            signal_hint_extra = dict(signal_hint.get("extra", {}))
            ts_hint = self._to_utc_datetime(signal_hint.get("ts"))
            max_age_min = float(getattr(self, "POSITION_SIGNAL_REVIEW_MAX_AGE", 15) or 15)
            if ts_hint:
                age_minutes = max(0.0, (now_ctx - ts_hint).total_seconds() / 60.0)
                if age_minutes <= max_age_min:
                    signal_hint_valid = True
                else:
                    signal_map.pop(trade_id, None)
                    signal_hint_action = None
            else:
                signal_hint_valid = True

        try:
            last_ts = df.index[-1]
            open_ts = pd.Timestamp(trade.open_date_utc, tz=last_ts.tz if last_ts.tz is not None else None)
            since_open_full = df.loc[df.index >= open_ts]
        except Exception:
            since_open_full = df.tail(1)
        if since_open_full is None or since_open_full.empty:
            since_open_full = df.tail(1)

        entry_rate = float(getattr(trade, "open_rate", float("nan")))
        if not np.isfinite(entry_rate):
            entry_rate = float(getattr(trade, "open_order_price", float("nan")))
        if not np.isfinite(entry_rate):
            entry_rate = float(row.get("open", float("nan")))

        peak_profit_live = float("nan")
        peak_rate_live = float("nan")
        trough_rate_live = float("nan")
        if len(since_open_full) > 0 and np.isfinite(entry_rate):
            if not is_short:
                peak_rate_live = float(since_open_full["high"].max())
                if entry_rate > 0:
                    peak_profit_live = (peak_rate_live / entry_rate) - 1.0
            else:
                trough_rate_live = float(since_open_full["low"].min())
                if trough_rate_live > 0:
                    peak_profit_live = (entry_rate / trough_rate_live) - 1.0
        peak_for_guard = peak_profit_live if np.isfinite(peak_profit_live) else current_profit

        if current_profit > 0 and np.isfinite(peak_profit_live):
            latest_floor, _ = self._strict_giveback_guard(
                pair=pair,
                trade=trade,
                current_profit=float(current_profit),
                trade_profile=trade_profile,
                risk_info=risk_info_payload,
                mm_context=mm_context,
                peak_profit=float(peak_profit_live),
                current_rate=current_rate,
            )
            if latest_floor > 0:
                trailing_floor = max(trailing_floor, latest_floor)

        peak_retreat_enabled = bool(getattr(self, "EXIT_PEAK_RETREAT_ENABLE", True))
        if peak_retreat_enabled:
            if current_profit > 0:
                cell = retreat_map.setdefault(trade_id, {})
                stored_peak_raw = cell.get("peak_profit")
                try:
                    stored_peak = float(stored_peak_raw) if stored_peak_raw is not None else float("nan")
                except (TypeError, ValueError):
                    stored_peak = float("nan")
                candidates: List[float] = []
                if np.isfinite(peak_profit_live):
                    candidates.append(float(peak_profit_live))
                if np.isfinite(stored_peak):
                    candidates.append(stored_peak)
                if candidates:
                    peak_effective = max(candidates)
                else:
                    peak_effective = float("nan")
                if np.isfinite(peak_effective):
                    if not np.isfinite(stored_peak) or peak_effective > stored_peak + 1e-9:
                        cell.pop("last_fire", None)
                    cell["peak_profit"] = peak_effective
                    cell["last_seen"] = now_ctx
                    lock_sens = self._lock_sensitivity_value()
                    min_profit = max(0.0, float(getattr(self, "EXIT_PEAK_RETREAT_MIN_PROFIT", 0.028)) * lock_sens)
                    drop_share_need = max(0.0, float(getattr(self, "EXIT_PEAK_RETREAT_DROP_SHARE", 0.45)) * lock_sens)
                    drop_abs_need = max(0.0, float(getattr(self, "EXIT_PEAK_RETREAT_DROP_ABS", 0.012)) * lock_sens)
                    cooldown_need = max(0.0, float(getattr(self, "EXIT_PEAK_RETREAT_COOLDOWN_MIN", 4.0)))
                    if peak_effective >= min_profit:
                        drop_val = peak_effective - current_profit
                        if drop_val >= drop_abs_need:
                            share_val = drop_val / peak_effective if peak_effective > 0 else 0.0
                            if share_val >= drop_share_need:
                                last_fire_dt = self._to_utc_datetime(cell.get("last_fire"))
                                gap_minutes = float("inf")
                                if last_fire_dt is not None:
                                    gap_minutes = max(0.0, (now_ctx - last_fire_dt).total_seconds() / 60.0)
                                if gap_minutes >= cooldown_need:
                                    level = str(getattr(self, "EXIT_PEAK_RETREAT_LEVEL", "major")) or "major"
                                    floor_hint = max(0.0, max(current_profit, peak_effective * max(0.0, 1.0 - drop_share_need)))
                                    info = {
                                        "peak_profit": round(peak_effective, 4),
                                        "current_profit": round(current_profit, 4),
                                        "drop": round(drop_val, 4),
                                        "drop_share": round(share_val, 4),
                                        "cooldown_gap": round(gap_minutes, 2),
                                    }
                                    ok, score_total, score_need, snap = self._elastic_exit_score(
                                        pair,
                                        trade_id,
                                        side_txt,
                                        make_exit_ctx(profit_floor=floor_hint, peak_profit=peak_effective),
                                        level=level,
                                        tag="peak_retreat_guard",
                                        info=info,
                                    )
                                    cell["last_fire"] = now_ctx
                                    if ok:
                                        extra = dict(info)
                                        extra.update({
                                            "elastic_score": round(score_total, 4),
                                            "elastic_need": round(score_need, 4),
                                        })
                                        events_log = snap.get("events") if isinstance(snap, dict) else None
                                        if isinstance(events_log, list) and events_log:
                                            extra["elastic_events"] = events_log[-3:]
                                        return trigger("tp_peak_retreat_guard", extra)
                else:
                    retreat_map.pop(trade_id, None)
            else:
                retreat_map.pop(trade_id, None)

        measured_enable = bool(po.get("measured_move_enable", getattr(self, "MEASURED_MOVE_ENABLE", False)))
        if measured_enable and trade_id:
            mm_state = measured_map.setdefault(trade_id, {})
            entry_risk_pct = float(risk_info_dict.get("entry_risk_pct", 0.0) or 0.0)
            live_src = risk_info_dict.get("live_risk_pct")
            if live_src in (None, 0, 0.0):
                live_src = risk_info_dict.get("actual_risk_pct", 0.0)
            actual_risk_pct = float(live_src or 0.0)
            risk_basis_pct = float(risk_info_dict.get("risk_basis_pct", entry_risk_pct) or entry_risk_pct)
            risk_basis_mode = str(risk_info_dict.get("risk_basis_mode", "initial") or "initial")
            stoploss_min_pct = float(risk_info_dict.get("stoploss_min_pct", max(0.0, float(getattr(self, "STOPLOSS_MIN_PCT", 0.0)))))
            risk_cap = float(risk_info_dict.get("risk_cap_pct", 0.0) or 0.0)

            context_label = mm_context.get("context")
            context_reasons_raw = mm_context.get("reasons")
            context_reasons = context_reasons_raw if isinstance(context_reasons_raw, list) else []
            context_target_r = mm_context_r if mm_context_r > 0 else 0.0

            mm_r_mult = context_target_r if context_target_r > 0 else float(po.get("measured_move_r_mult", getattr(self, "MEASURED_MOVE_R_MULT", 0.0)))
            if mm_r_mult <= 0:
                mm_r_mult = float(getattr(self, "MEASURED_MOVE_R_MULT", 0.0))
            if mm_r_mult <= 0:
                mm_r_mult = float(getattr(self, "MEASURED_MOVE_BALANCE_R", 1.0))
            mm_r_mult = max(0.0, mm_r_mult)
            mm_min_profit = max(0.0, float(po.get("measured_move_min_profit", getattr(self, "MEASURED_MOVE_MIN_PROFIT", 0.0))))
            target_profit = max(mm_min_profit, risk_basis_pct * mm_r_mult)

            prev_target = mm_state.get("target")
            if prev_target is None or not np.isfinite(prev_target) or abs(prev_target - target_profit) > 1e-6:
                mm_state.clear()
                mm_state["target"] = target_profit
                mm_state["entry_risk_pct"] = entry_risk_pct
                mm_state["risk_basis_pct"] = risk_basis_pct
                mm_state["risk_basis_mode"] = risk_basis_mode
                if actual_risk_pct > 0:
                    mm_state["live_risk_pct"] = actual_risk_pct
            else:
                mm_state.setdefault("entry_risk_pct", entry_risk_pct)
                mm_state["risk_basis_pct"] = risk_basis_pct
                mm_state["risk_basis_mode"] = risk_basis_mode
                if actual_risk_pct > 0:
                    mm_state["live_risk_pct"] = actual_risk_pct
                else:
                    mm_state.pop("live_risk_pct", None)

            if context_label:
                mm_state["context"] = str(context_label)
            else:
                mm_state.pop("context", None)
            if context_target_r > 0:
                mm_state["context_r"] = float(context_target_r)
            else:
                mm_state.pop("context_r", None)
            if context_reasons:
                mm_state["context_reasons"] = list(context_reasons)
            else:
                mm_state.pop("context_reasons", None)
            mm_state["base_r"] = float(mm_context.get("base_r", 0.0) or 0.0)
            mm_state["balance_r"] = float(mm_context.get("balance_r", 0.0) or 0.0)
            mm_state["trend_r"] = float(mm_context.get("trend_r", 0.0) or 0.0)
            mm_state["narrow_r"] = float(mm_context.get("narrow_r", 0.0) or 0.0)
            mm_state["decay_r"] = float(mm_context.get("decay_r", 0.0) or 0.0)
            ctx_floor = risk_info_dict.get("context_floor_pct") if isinstance(risk_info_dict, dict) else None
            if ctx_floor:
                try:
                    mm_state["context_floor_pct"] = float(ctx_floor)
                except (TypeError, ValueError):
                    mm_state.pop("context_floor_pct", None)
            else:
                mm_state.pop("context_floor_pct", None)
            ctx_guard = risk_info_dict.get("context_guard_pct") if isinstance(risk_info_dict, dict) else None
            if ctx_guard:
                try:
                    mm_state["context_guard_pct"] = float(ctx_guard)
                except (TypeError, ValueError):
                    mm_state.pop("context_guard_pct", None)
            else:
                mm_state.pop("context_guard_pct", None)

            if guard_state is not None:
                guard_state["measured_target_profit"] = target_profit
                guard_state["measured_r"] = target_profit / risk_basis_pct if risk_basis_pct > 0 else 0.0
                if context_target_r > 0:
                    guard_state["measured_context_r"] = float(context_target_r)
                    if context_label:
                        guard_state["measured_context_label"] = str(context_label)
                else:
                    guard_state.pop("measured_context_r", None)
                    guard_state.pop("measured_context_label", None)

            if target_profit > 0 and current_profit >= target_profit:
                peak_effective = peak_profit_live if np.isfinite(peak_profit_live) else current_profit
                mm_state.setdefault("hit_ts", now_ctx)
                mm_state["last_profit"] = current_profit
                if guard_state is not None:
                    guard_state["satisfied"] = True
                    guard_state["active"] = False
                    guard_state.pop("reason", None)
                    if risk_basis_pct > 0:
                        guard_state["satisfied_r"] = current_profit / risk_basis_pct
                lock_share_cfg = po.get("measured_move_lock_share", getattr(self, "MEASURED_MOVE_LOCK_SHARE", 0.62))
                try:
                    lock_share = float(lock_share_cfg)
                except (TypeError, ValueError):
                    lock_share = float(getattr(self, "MEASURED_MOVE_LOCK_SHARE", 0.62))
                lock_share = float(np.clip(lock_share, 0.0, 1.0))
                lock_min_cfg = po.get("measured_move_lock_min", getattr(self, "MEASURED_MOVE_LOCK_MIN", 0.018))
                try:
                    lock_min = float(lock_min_cfg)
                except (TypeError, ValueError):
                    lock_min = float(getattr(self, "MEASURED_MOVE_LOCK_MIN", 0.018))
                lock_min = max(0.0, lock_min)
                base_for_floor = peak_effective if np.isfinite(peak_effective) and peak_effective > 0 else current_profit
                lock_floor = max(lock_min, base_for_floor * lock_share)
                trailing_floor = max(trailing_floor, lock_floor)
                level = str(po.get("measured_move_level", getattr(self, "MEASURED_MOVE_LEVEL", "major")) or "major")
                retry_cfg = po.get("measured_move_retry_minutes", getattr(self, "MEASURED_MOVE_RETRY_MINUTES", 0.0))
                try:
                    retry_minutes = float(retry_cfg)
                except (TypeError, ValueError):
                    retry_minutes = float(getattr(self, "MEASURED_MOVE_RETRY_MINUTES", 0.0))
                retry_minutes = max(0.0, retry_minutes)
                last_fire_dt = self._to_utc_datetime(mm_state.get("last_fire"))
                gap_minutes = float("inf")
                if last_fire_dt is not None:
                    gap_minutes = max(0.0, (now_ctx - last_fire_dt).total_seconds() / 60.0)
                if not mm_state.get("fired") or gap_minutes >= retry_minutes:
                    info = {
                        "target_profit": round(target_profit, 4),
                        "entry_risk_pct": round(entry_risk_pct, 4),
                        "risk_basis_pct": round(risk_basis_pct, 4),
                        "risk_basis_mode": risk_basis_mode or "initial",
                        "current_profit": round(current_profit, 4),
                        "lock_floor": round(lock_floor, 4),
                        "lock_share": round(lock_share, 4),
                    }
                    if actual_risk_pct > 0:
                        info["actual_risk_pct"] = round(actual_risk_pct, 4)
                    if risk_basis_pct > 0:
                        info["r_multiple_basis"] = round(current_profit / risk_basis_pct, 4)
                        info["target_r_multiple"] = round(target_profit / risk_basis_pct, 4)
                    if entry_risk_pct > 0:
                        info["r_multiple_initial"] = round(current_profit / entry_risk_pct, 4)
                    if actual_risk_pct > 0:
                        info["r_multiple_live"] = round(current_profit / actual_risk_pct, 4)
                    if np.isfinite(peak_effective):
                        info["peak_profit"] = round(peak_effective, 4)
                    if guard_state is not None:
                        target_r_cfg = float(guard_state.get("target_r", 0.0) or 0.0)
                        if target_r_cfg > 0:
                            info["expectation_target_r"] = round(target_r_cfg, 3)
                    if context_target_r > 0:
                        info["context_r_multiple"] = round(context_target_r, 4)
                    if context_label:
                        info["context_label"] = str(context_label)
                    if context_reasons:
                        info["context_reasons"] = context_reasons[-3:]
                    ctx_floor = risk_info_dict.get("context_floor_pct") if isinstance(risk_info_dict, dict) else None
                    if ctx_floor:
                        try:
                            info["context_floor_pct"] = round(float(ctx_floor), 4)
                        except (TypeError, ValueError):
                            pass
                    ctx_guard = risk_info_dict.get("context_guard_pct") if isinstance(risk_info_dict, dict) else None
                    if ctx_guard:
                        try:
                            info["context_guard_pct"] = round(float(ctx_guard), 4)
                        except (TypeError, ValueError):
                            pass
                    ok, score_total, score_need, snap = self._elastic_exit_score(
                        pair,
                        trade_id,
                        side_txt,
                        make_exit_ctx(
                            profit_floor=lock_floor,
                            peak_profit=peak_effective if np.isfinite(peak_effective) else current_profit,
                        ),
                        level=level,
                        tag="measured_move_target",
                        info=info,
                    )
                    if ok:
                        mm_state["fired"] = True
                        mm_state["last_fire"] = now_ctx
                        extra = dict(info)
                        extra.update(
                            {
                                "elastic_score": round(score_total, 4),
                                "elastic_need": round(score_need, 4),
                            }
                        )
                        events_log = snap.get("events") if isinstance(snap, dict) else None
                        if isinstance(events_log, list) and events_log:
                            extra["elastic_events"] = events_log[-3:]
                        return trigger("tp_measured_move", extra)

        po = self._pair_cfg(pair)
        min_profit_exit = float(po.get("min_profit_exit", 0.02))
        near_exit_mult  = float(po.get("near_exit_mult", 0.90))
        near_exit_alt   = float(po.get("near_exit_alt",  0.017))
        pb_min_gate     = float(po.get("pb_min_profit_gate", 0.019))
        hard_tp = float(po.get("hard_tp", 0.0))

        if portfolio_guard:
            st = self._pair_state.setdefault(pair, {})
            st["portfolio_context"] = {
                "net": port_net,
                "focus_share": port_focus_share,
                "focus_weight": port_focus_weight,
                "losers": port_losers,
                "loss_pressure": port_loss_pressure,
            }
            allow_fast = bool(getattr(self, "PORTFOLIO_ALLOW_FASTLANE_OVERRIDE", True))
            strong_trend = bool(fast_lane and ((not is_short and align_score >= 0.45) or (is_short and align_score <= -0.45)))
            drain_limit = float(getattr(self, "PORTFOLIO_NET_DRAIN_LIMIT", -0.012))
            fragile_floor = float(getattr(self, "PORTFOLIO_FRAGILE_FLOOR", 0.022))
            lock_share_min = float(getattr(self, "PORTFOLIO_LOCK_SHARE_MIN", 0.55))
            lock_min_profit = float(getattr(self, "PORTFOLIO_LOCK_MIN_PROFIT", 0.018))
            lock_ratio = float(np.clip(float(getattr(self, "PORTFOLIO_LOCK_RATIO", 0.60)), 0.0, 1.0))
            lock_ratio_max = float(np.clip(float(getattr(self, "PORTFOLIO_LOCK_RATIO_MAX", 0.85)), 0.0, 1.0))
            if port_net <= drain_limit and current_profit > 0 and not (allow_fast and strong_trend):
                portfolio_exit_now = True
            loss_need = float(getattr(self, "PORTFOLIO_FRAGILE_LOSS_PRESSURE", 0.10))
            fragile = (port_net <= fragile_floor and port_neg_value < 0 and port_losers > 0 and port_loss_pressure >= loss_need)
            if fragile and current_profit >= lock_min_profit and port_focus_share >= lock_share_min:
                base_lock = current_profit * lock_ratio
                if lock_ratio_max > 0:
                    base_lock = min(base_lock, current_profit * lock_ratio_max)
                base_lock = max(lock_min_profit, base_lock)
                base_lock = min(base_lock, max(current_profit - 1e-4, current_profit))
                portfolio_lock_floor = max(portfolio_lock_floor, base_lock)
                if not (allow_fast and strong_trend):
                    portfolio_exit_now = True

        if perf_guard:
            min_profit_exit *= 0.90
            near_exit_mult *= 0.95
            near_exit_alt *= 0.85
            pb_min_gate *= 0.90
        elif perf_hot:
            min_profit_exit *= 1.10
            near_exit_mult *= 1.05
            near_exit_alt *= 1.10
            pb_min_gate *= 1.08

        if hard_tp > 0 and current_profit >= hard_tp:
            return trigger("tp_hard_cap", {"hard_tp": hard_tp})

        if portfolio_guard and portfolio_exit_now and current_profit > 0:
            return trigger("tp_portfolio_guard", {
                "portfolio_net": port_net,
                "losers": port_losers,
                "focus_share": port_focus_share,
                "focus_weight": port_focus_weight,
            })
        if portfolio_lock_floor > 0 and current_profit > 0:
            adaptive_lock = max(adaptive_lock, portfolio_lock_floor)

        trailing_floor = 0.0
        floor_source = ""
        floor_state = st.get("stoploss_floor")
        if isinstance(floor_state, dict) and trade_id in floor_state:
            info = floor_state.get(trade_id) or {}
            try:
                trailing_floor = float(info.get("floor", 0.0) or 0.0)
            except (TypeError, ValueError):
                trailing_floor = 0.0
            if isinstance(info, dict):
                src = info.get("source")
                floor_source = str(src) if src is not None else ""

        if current_profit > 0 and trailing_floor > 0:
            buffer = self._lock_buffer_threshold(
                current_profit,
                risk_basis_pct=risk_basis_pct if risk_basis_pct > 0 else None,
                last_floor_source=floor_source or None,
                pair=pair,
            )
            lock_gap = current_profit - trailing_floor
            if lock_gap <= buffer:
                if isinstance(floor_state, dict) and trade_id in floor_state:
                    floor_state.pop(trade_id, None)
                return trigger("tp_trailing_floor_release", {
                    "lock_gap": lock_gap,
                    "buffer": buffer,
                    "floor": trailing_floor,
                    "source": floor_source or "adaptive",
                })

        opp_raw = int(row.get("sig_long_cand", 0) if is_short else row.get("sig_short_cand", 0))
        di_flip_against = int(((row.get("minus_di", 0) > row.get("plus_di", 0)) if not is_short else (row.get("plus_di", 0) > row.get("minus_di", 0))))
        struct_break_against = int(row.get("breakL_conf", 0) if not is_short else row.get("breakS_conf", 0))
        momo_against = int((row.get("macd", 0.0) < row.get("macdsignal", 0.0)) if not is_short else (row.get("macd", 0.0) > row.get("macdsignal", 0.0)))
        rfs_low = float(row.get("RFS", 0.5)) <= float(self.EMERGENCY_RFS_THR)
        ema_against = (row.get("close", 0.0) < row.get("ema200_1h", 0.0)) if not is_short else (row.get("close", 0.0) > row.get("ema200_1h", 0.0))
        risk_hits = int(opp_raw == 1) + int(di_flip_against == 1) + int(struct_break_against == 1) + int(momo_against == 1) + int(rfs_low or ema_against)
        risk_threshold = 3
        if perf_guard:
            risk_threshold = 2
        elif perf_hot:
            risk_threshold = 4
        risk_emergency = (risk_hits >= risk_threshold)

        if prefer == priority_opp and priority_conf >= exit_min:
            tag = "tp_priority_shift" if current_profit >= 0 else "sl_priority_shift"
            return trigger(tag, {
                "priority_prefer": prefer,
                "priority_conf": priority_conf,
                "details": priority.get("details"),
            })

        # 风险项超阈值且已有浮盈 → 直接离场锁定利润，不等待止损触发（回撤期阈值更低，热手期更高）
        if risk_emergency and current_profit > 0:
            tag = "tp_perf_risk_guard" if perf_guard else "tp_risk_guard"
            return trigger(tag, {"risk_hits": risk_hits, "threshold": risk_threshold})

        adds_done = int(getattr(trade, "nr_of_successful_entries", 0))
        recover_on = (adds_done >= int(self.STOPLOSS_RECOVER_ADD_THRESHOLD)) or risk_emergency

        if recover_on and bool(self.EMERGENCY_FLIP_ON_LOSS) and (opp_raw == 1):
            ok_loss = (current_profit < 0) and (current_profit > -float(self.EMERGENCY_FLIP_MAX_LOSS))
            vol_gate = bool(row.get("vol_surge_any", 0) == 1)
            if ok_loss and vol_gate:
                tag = "emergency_flip_to_long" if is_short else "emergency_flip_to_short"
                return trigger(tag, {"vol_gate": vol_gate, "risk_hits": risk_hits})
            else:
                return trigger("emergency_exit_observe", {"vol_gate": vol_gate, "risk_hits": risk_hits})

        # 自适应锁盈地板与当前利润几乎贴合，同时动能/结构转弱 → 主动兑现
        if current_profit > 0 and adaptive_lock > 0:
            lock_gap = current_profit - adaptive_lock
            buffer = self._lock_buffer_threshold(
                current_profit,
                risk_basis_pct=risk_basis_pct if risk_basis_pct > 0 else None,
                last_floor_source="adaptive_lock",
                pair=pair,
            )
            if lock_gap <= buffer and (momo_against or di_flip_against or struct_break_against):
                info = {
                    "lock_gap": lock_gap,
                    "buffer": buffer,
                    "momo": int(momo_against),
                    "di_flip": int(di_flip_against),
                    "struct": int(struct_break_against),
                }
                ok, score_total, score_need, snap = self._elastic_exit_score(
                    pair,
                    trade_id,
                    side_txt,
                    make_exit_ctx(profit_floor=adaptive_lock),
                    level="medium",
                    tag="adaptive_lock_release",
                    info=info,
                )
                if ok:
                    extra = {
                        "lock_gap": lock_gap,
                        "buffer": buffer,
                        "elastic_score": round(score_total, 4),
                        "elastic_need": round(score_need, 4),
                    }
                    events_log = snap.get("events") if isinstance(snap, dict) else None
                    if isinstance(events_log, list) and events_log:
                        extra["elastic_events"] = events_log[-3:]
                    return trigger("tp_adaptive_lock_release", extra)

        prev_micro = micro_map.get(trade_id)
        prev_micro_peak = float("nan")
        if isinstance(prev_micro, dict):
            try:
                prev_micro_peak = float(prev_micro.get("peak_profit", float("nan")))
            except (TypeError, ValueError):
                prev_micro_peak = float("nan")

        micro_peak_effective = peak_profit_live
        if np.isfinite(prev_micro_peak):
            if not np.isfinite(micro_peak_effective):
                micro_peak_effective = prev_micro_peak
            else:
                micro_peak_effective = max(micro_peak_effective, prev_micro_peak)

        small_level_cfg = float(getattr(self, "SMALL_TARGET_LEVEL", 0.06))
        micro_level_cfg = float(getattr(self, "MICRO_TARGET_LEVEL", 0.004))

        if bool(getattr(self, "MICRO_TARGET_ENABLE", True)) and np.isfinite(entry_rate):
            micro_ceil = max(micro_level_cfg, float(getattr(self, "MICRO_TARGET_CEIL", 0.012)))
            lock_ratio = float(getattr(self, "MICRO_TARGET_LOCK_RATIO", 0.38))
            floor_min = max(0.0, float(getattr(self, "MICRO_TARGET_FLOOR_MIN", 0.0)))
            force_minutes = max(0.0, float(getattr(self, "MICRO_TARGET_FORCE_MINUTES", 18.0)))
            relax_weaken = bool(getattr(self, "MICRO_TARGET_RELAX_WEAKEN", True))
            score_level = str(getattr(self, "MICRO_TARGET_SCORE_LEVEL", "minor")) or "minor"
            max_drawdown = max(0.0, float(getattr(self, "MICRO_TARGET_MAX_DRAWDOWN", 0.005)))
            if quality_tier == "high":
                lock_ratio = max(lock_ratio, float(getattr(self, "HIGH_QUALITY_MICRO_LOCK_RATIO", lock_ratio)))
                floor_min = max(floor_min, float(getattr(self, "HIGH_QUALITY_MICRO_FLOOR_MIN", floor_min)))
                force_minutes = min(force_minutes, float(getattr(self, "HIGH_QUALITY_MICRO_FORCE_MINUTES", force_minutes)))
                max_drawdown = min(max_drawdown, float(getattr(self, "HIGH_QUALITY_MICRO_MAX_DRAWDOWN", max_drawdown)))
            elif quality_tier == "low":
                lock_ratio = min(lock_ratio, float(getattr(self, "LOW_QUALITY_MICRO_LOCK_RATIO", lock_ratio)))
                force_minutes = max(force_minutes, float(getattr(self, "LOW_QUALITY_MICRO_FORCE_MINUTES", force_minutes)))
                max_drawdown = max(max_drawdown, float(getattr(self, "LOW_QUALITY_MICRO_MAX_DRAWDOWN", max_drawdown)))
            if micro_level_cfg > 0 and np.isfinite(micro_peak_effective) and micro_peak_effective >= micro_level_cfg and micro_peak_effective < max(micro_ceil, small_level_cfg):
                fav_rate = peak_rate_live if not is_short else trough_rate_live
                micro_cell = micro_map.setdefault(trade_id, {})
                micro_cell["trade_id"] = trade_id
                micro_cell["peak_profit"] = micro_peak_effective
                if np.isfinite(fav_rate):
                    micro_cell["favorable_rate"] = fav_rate
                hit_ts = self._to_utc_datetime(micro_cell.get("hit_ts"))
                if hit_ts is None:
                    hit_ts = now_ctx
                micro_cell["hit_ts"] = hit_ts
                release_gate = min(micro_ceil, max(micro_level_cfg, micro_peak_effective))
                lock_floor = max(floor_min, release_gate * lock_ratio)
                micro_cell["lock_floor"] = lock_floor
                age_minutes = max(0.0, (now_ctx - hit_ts).total_seconds() / 60.0)
                release_ready = current_profit <= release_gate
                priority_flip = (prefer == priority_opp and priority_conf >= exit_min)
                weakness = relax_weaken and (momo_against or di_flip_against or struct_break_against or priority_flip)
                if current_profit <= lock_floor:
                    tag_name = "tp_micro_target_floor" if current_profit >= 0 else "sl_micro_target_floor"
                    return trigger(tag_name, {
                        "peak_profit": micro_peak_effective,
                        "release_gate": release_gate,
                        "lock_floor": lock_floor,
                        "age_min": round(age_minutes, 2),
                        "weakness": int(weakness),
                    })
                if max_drawdown > 0 and current_profit <= -max_drawdown:
                    return trigger("sl_micro_target_drawdown", {
                        "peak_profit": micro_peak_effective,
                        "drawdown": current_profit,
                        "max_drawdown": -max_drawdown,
                        "age_min": round(age_minutes, 2),
                    })
                force_ready = force_minutes > 0 and age_minutes >= force_minutes and current_profit <= max(release_gate, lock_floor + 0.0002)
                if (release_ready and (weakness or priority_flip)) or force_ready:
                    info = {
                        "peak_profit": micro_peak_effective,
                        "release_gate": release_gate,
                        "lock_floor": lock_floor,
                        "age_min": round(age_minutes, 2),
                        "weakness": int(weakness),
                        "priority_flip": int(priority_flip),
                        "force_ready": int(force_ready),
                    }
                    ok, score_total, score_need, snap = self._elastic_exit_score(
                        pair,
                        trade_id,
                        side_txt,
                        make_exit_ctx(profit_floor=lock_floor, peak_profit=micro_peak_effective),
                        level=score_level,
                        tag="micro_target_release",
                        info=info,
                    )
                    if ok:
                        extra = dict(info)
                        extra.update({
                            "elastic_score": round(score_total, 4),
                            "elastic_need": round(score_need, 4),
                        })
                        events_log = snap.get("events") if isinstance(snap, dict) else None
                        if isinstance(events_log, list) and events_log:
                            extra["elastic_events"] = events_log[-3:]
                        return trigger("tp_micro_target_release", extra)
            else:
                micro_map.pop(trade_id, None)

        if bool(getattr(self, "SMALL_TARGET_ENABLE", True)) and np.isfinite(entry_rate):
            pair_cfg = self._pair_cfg(pair)
            level = max(0.0, float(getattr(self, "SMALL_TARGET_LEVEL", 0.06)))
            level_r = float(getattr(self, "SMALL_TARGET_LEVEL_R", 0.0))
            if level_r > 0 and risk_basis_pct > 0:
                target_level = risk_basis_pct * level_r
                if np.isfinite(target_level) and target_level > 0:
                    level = max(level, target_level)
            lock_ratio = float(getattr(self, "SMALL_TARGET_LOCK_RATIO", 0.55))
            floor_min = float(getattr(self, "SMALL_TARGET_FLOOR_MIN", 0.018))
            relax_weaken = bool(getattr(self, "SMALL_TARGET_RELAX_WEAKEN", True))
            use_peak_scale = bool(getattr(self, "SMALL_TARGET_USE_PEAK", True))
            max_hold_override = None
            if isinstance(pair_cfg, dict):
                max_hold_override = pair_cfg.get("small_target_max_hold_minutes")
            if level > 0 and len(since_open_full) > 0:
                if not is_short:
                    peak_price = peak_rate_live if np.isfinite(peak_rate_live) else float(since_open_full["high"].max())
                    peak_profit_live = (peak_price / entry_rate) - 1.0 if entry_rate > 0 else float("nan")
                else:
                    trough_price = trough_rate_live if np.isfinite(trough_rate_live) else float(since_open_full["low"].min())
                    peak_profit_live = (entry_rate / trough_price) - 1.0 if trough_price > 0 else float("nan")

                target_state = st.setdefault("small_target_hit", {})
                trade_id = int(getattr(trade, "id", 0) or 0)
                stored_id = int(target_state.get("trade_id", 0) or 0)
                if stored_id and stored_id != trade_id:
                    target_state.clear()

                stored_peak = target_state.get("peak_profit")
                peak_profit_effective = peak_profit_live
                if stored_peak is not None:
                    try:
                        stored_peak_val = float(stored_peak)
                    except (TypeError, ValueError):
                        stored_peak_val = float("nan")
                    if np.isfinite(stored_peak_val):
                        if not np.isfinite(peak_profit_effective):
                            peak_profit_effective = stored_peak_val
                        else:
                            peak_profit_effective = max(peak_profit_effective, stored_peak_val)

                fill_target_scale = 1.0
                fill_lock_scale = 1.0
                if fill_adjust.get("active"):
                    fill_target_scale = float(fill_adjust.get("target_scale", 1.0) or 1.0)
                    fill_lock_scale = float(fill_adjust.get("lock_scale", 1.0) or 1.0)

                if np.isfinite(peak_profit_effective) and peak_profit_effective >= level:
                    target_state["trade_id"] = trade_id
                    target_state["level"] = level
                    target_state["peak_profit"] = peak_profit_effective
                    if not is_short:
                        target_state["peak_rate"] = peak_price
                    else:
                        target_state["peak_rate"] = trough_price

                    hit_ts_any = target_state.get("hit_ts")
                    if isinstance(hit_ts_any, datetime):
                        hit_dt = hit_ts_any if hit_ts_any.tzinfo else hit_ts_any.replace(tzinfo=timezone.utc)
                        target_state["hit_ts"] = hit_dt
                    else:
                        target_state["hit_ts"] = now_ctx

                    release_gate = peak_profit_effective if use_peak_scale else level
                    release_gate *= fill_target_scale
                    force_gate = None
                    force_r = float(getattr(self, "SMALL_TARGET_FORCE_R", 0.0))
                    if force_r > 0 and risk_basis_pct > 0:
                        candidate_gate = risk_basis_pct * force_r
                        if np.isfinite(candidate_gate) and candidate_gate > 0:
                            force_gate = candidate_gate
                            release_gate = max(release_gate, candidate_gate)
                    if current_profit >= release_gate:
                        ts = target_state.get("ts")
                        if isinstance(ts, datetime):
                            hit_dt = ts if ts.tzinfo else ts.replace(tzinfo=timezone.utc)
                        else:
                            hit_dt = now_ctx
                        target_state["ts"] = hit_dt
                    else:
                        target_state.pop("ts", None)
                        target_state.pop("forced", None)

                    base_for_floor = peak_profit_effective if use_peak_scale else level
                    lock_floor = max(floor_min, base_for_floor * lock_ratio)
                    lock_floor *= fill_lock_scale
                    if force_gate is not None and np.isfinite(force_gate):
                        lock_floor = max(lock_floor, force_gate * lock_ratio)
                    if quality_tier == "high":
                        lock_floor = max(
                            lock_floor,
                            peak_profit_effective * float(getattr(self, "HIGH_QUALITY_SMALL_LOCK_SHARE", lock_ratio)),
                            float(getattr(self, "HIGH_QUALITY_SMALL_LOCK_MIN", lock_floor)),
                        )
                    elif quality_tier == "low":
                        lock_floor = max(
                            lock_floor,
                            peak_profit_effective * float(getattr(self, "LOW_QUALITY_SMALL_LOCK_SHARE", lock_ratio)),
                        )
                    if bool(getattr(self, "SMALL_TARGET_BREAKEVEN_RELEASE", True)):
                        breakeven_floor = float(getattr(self, "SMALL_TARGET_BREAKEVEN_FLOOR", 0.0))
                        tolerance = max(0.0, float(getattr(self, "SMALL_TARGET_BREAKEVEN_TOLERANCE", 0.0008)))
                        floor_cmp = min(lock_floor, breakeven_floor)
                        drop_val = float("nan")
                        if np.isfinite(peak_profit_effective):
                            drop_val = peak_profit_effective - current_profit
                        if current_profit <= floor_cmp + tolerance and not target_state.get("breakeven_exit"):
                            target_state["breakeven_exit"] = True
                            return trigger("tp_small_target_breakeven", {
                                "peak_profit": peak_profit_effective,
                                "peak_profit_live": peak_profit_live,
                                "lock_floor": lock_floor,
                                "breakeven_floor": breakeven_floor,
                                "tolerance": tolerance,
                                "drop": drop_val,
                                "level": level,
                                "use_peak": use_peak_scale,
                            })
                    if current_profit <= lock_floor:
                        return trigger("tp_small_target_floor", {
                            "peak_profit": peak_profit_effective,
                            "peak_profit_live": peak_profit_live,
                            "lock_floor": lock_floor,
                            "level": level,
                            "use_peak": use_peak_scale
                        })

                    bars_need = max(0, int(getattr(self, "SMALL_TARGET_FORCE_BARS", 0)))
                    add_cap = max(0, int(getattr(self, "SMALL_TARGET_FORCE_MAX_ADDS", 0)))
                    if quality_tier == "high":
                        bars_need = min(bars_need, max(0, int(getattr(self, "HIGH_QUALITY_SMALL_FORCE_BARS", bars_need))))
                        add_cap = max(add_cap, int(getattr(self, "HIGH_QUALITY_SMALL_FORCE_MAX_ADDS", add_cap)))
                    elif quality_tier == "low":
                        bars_need = max(bars_need, max(0, int(getattr(self, "LOW_QUALITY_SMALL_FORCE_BARS", bars_need))))
                        if add_cap > 0:
                            add_cap = min(add_cap, max(0, int(getattr(self, "LOW_QUALITY_SMALL_FORCE_MAX_ADDS", add_cap))))
                    hold_base = max_hold_override if max_hold_override is not None else getattr(self, "SMALL_TARGET_MAX_HOLD_MINUTES", 0.0)
                    max_hold_minutes = max(0.0, float(hold_base or 0.0))
                    hold_elapsed = None
                    hold_timeout = False
                    hit_ts_any = target_state.get("hit_ts")
                    if isinstance(hit_ts_any, datetime):
                        hit_dt3 = hit_ts_any if hit_ts_any.tzinfo else hit_ts_any.replace(tzinfo=timezone.utc)
                        hold_elapsed = max(0.0, (now_ctx - hit_dt3).total_seconds() / 60.0)
                        if max_hold_minutes > 0 and hold_elapsed >= max_hold_minutes:
                            hold_timeout = True

                    bars_since_hit = None
                    hold_gate = False
                    force_trigger = False
                    force_ready = False
                    force_tol = max(0.0, float(getattr(self, "SMALL_TARGET_FORCE_TOLERANCE", 0.0)))
                    if force_gate is not None and np.isfinite(force_gate) and np.isfinite(peak_profit_effective):
                        if peak_profit_effective >= force_gate:
                            force_trigger = True
                            target_state["force_gate"] = force_gate
                            bars_need = 0
                        else:
                            target_state.pop("force_gate", None)
                    else:
                        target_state.pop("force_gate", None)
                    if current_profit >= release_gate:
                        ts_now = target_state.get("ts")
                        if isinstance(ts_now, datetime):
                            hit_dt2 = ts_now if ts_now.tzinfo else ts_now.replace(tzinfo=timezone.utc)
                            bars_since_hit = int(max(0.0, (now_ctx - hit_dt2).total_seconds() / 60.0) // max(1, self._tf_minutes()))
                        if bars_need <= 0:
                            hold_gate = True
                        else:
                            hold_gate = bars_since_hit is not None and bars_since_hit >= bars_need
                    if force_trigger:
                        force_ready = current_profit >= max(force_gate - force_tol, 0.0)
                        if not force_ready and current_profit <= lock_floor + force_tol:
                            force_ready = True
                        if force_ready and bars_since_hit is None:
                            bars_since_hit = 0
                    if force_trigger:
                        hold_gate = hold_gate or force_ready
                    if hold_gate and adds_done <= add_cap and not target_state.get("forced", False):
                        target_state["forced"] = True
                        return trigger("tp_small_target_forced", {
                            "peak_profit": peak_profit_effective,
                            "peak_profit_live": peak_profit_live,
                            "release_gate": release_gate,
                            "bars_since_hit": bars_since_hit,
                            "adds_done": adds_done,
                            "level": level,
                            "force_gate": force_gate,
                            "force_ready": force_ready,
                        })
                    if hold_timeout and not target_state.get("forced", False):
                        target_state["forced"] = True
                        return trigger("tp_small_target_timeout", {
                            "peak_profit": peak_profit_effective,
                            "peak_profit_live": peak_profit_live,
                            "release_gate": release_gate,
                            "lock_floor": lock_floor,
                            "hold_elapsed": hold_elapsed,
                            "max_hold_minutes": max_hold_minutes,
                            "force_gate": force_gate,
                            "timeout_reason": "small_target_timeout",
                        })
                    if relax_weaken and current_profit >= release_gate and (
                        momo_against or di_flip_against or struct_break_against
                    ):
                        info = {
                            "peak_profit": peak_profit_effective,
                            "peak_profit_live": peak_profit_live,
                            "level": level,
                            "lock_floor": lock_floor,
                            "use_peak": use_peak_scale,
                        }
                        score_level_cfg = str(getattr(self, "SMALL_TARGET_SCORE_LEVEL", "medium")) or "medium"
                        score_level = score_level_cfg
                        promote_major = float(getattr(self, "SMALL_TARGET_PROMOTE_TO_MAJOR", 0.0) or 0.0)
                        promote_medium = float(getattr(self, "SMALL_TARGET_PROMOTE_TO_MEDIUM", 0.0) or 0.0)
                        if np.isfinite(peak_profit_effective):
                            if promote_major > 0 and peak_profit_effective >= promote_major:
                                score_level = "major"
                            elif score_level_cfg == "minor" and promote_medium > 0 and peak_profit_effective >= promote_medium:
                                score_level = "medium"
                            elif score_level_cfg not in ("major",) and promote_medium > 0 and promote_major <= 0 and peak_profit_effective >= promote_medium:
                                score_level = "medium"
                        info["score_level_cfg"] = score_level_cfg
                        info["score_level_used"] = score_level
                        if promote_major > 0:
                            info["promote_major"] = promote_major
                        if promote_medium > 0:
                            info["promote_medium"] = promote_medium
                        ok, score_total, score_need, snap = self._elastic_exit_score(
                            pair,
                            trade_id,
                            side_txt,
                            make_exit_ctx(profit_floor=lock_floor, peak_profit=peak_profit_effective),
                            level=score_level,
                            tag="small_target_release",
                            info=info,
                        )
                        if ok:
                            extra = {
                                "peak_profit": peak_profit_effective,
                                "peak_profit_live": peak_profit_live,
                                "level": level,
                                "lock_floor": lock_floor,
                                "use_peak": use_peak_scale,
                                "score_level_cfg": score_level_cfg,
                                "score_level_used": score_level,
                                "elastic_score": round(score_total, 4),
                                "elastic_need": round(score_need, 4),
                            }
                            if promote_major > 0:
                                extra["promote_major"] = promote_major
                            if promote_medium > 0:
                                extra["promote_medium"] = promote_medium
                            events_log = snap.get("events") if isinstance(snap, dict) else None
                            if isinstance(events_log, list) and events_log:
                                extra["elastic_events"] = events_log[-3:]
                            return trigger("tp_small_target_release", extra)
                else:
                    st.pop("small_target_hit", None)
            else:
                st.pop("small_target_hit", None)

        if bool(getattr(self, "HIGH_TARGET_ENABLE", True)) and np.isfinite(entry_rate) and len(since_open_full) > 0:
            level_high = max(0.0, float(getattr(self, "HIGH_TARGET_THRESHOLD", 0.085)))
            if level_high > 0:
                if not is_short:
                    high_price = float(since_open_full["high"].max())
                    peak_high_live = (high_price / entry_rate) - 1.0 if entry_rate > 0 else float("nan")
                else:
                    low_price = float(since_open_full["low"].min())
                    peak_high_live = (entry_rate / low_price) - 1.0 if low_price > 0 else float("nan")

                state = high_map.setdefault(trade_id, {})
                stored_id = int(state.get("trade_id", 0) or 0)
                if stored_id and stored_id != trade_id:
                    state.clear()

                peak_effective_high = peak_high_live
                stored_peak_high = state.get("peak_profit")
                if stored_peak_high is not None:
                    try:
                        stored_peak_val = float(stored_peak_high)
                    except (TypeError, ValueError):
                        stored_peak_val = float("nan")
                    if np.isfinite(stored_peak_val):
                        if not np.isfinite(peak_effective_high):
                            peak_effective_high = stored_peak_val
                        else:
                            peak_effective_high = max(peak_effective_high, stored_peak_val)

                if np.isfinite(peak_effective_high) and peak_effective_high >= level_high:
                    state["trade_id"] = trade_id
                    state["threshold"] = level_high
                    state["peak_profit"] = peak_effective_high
                    if not is_short:
                        state["peak_rate"] = high_price
                    else:
                        state["peak_rate"] = float(since_open_full["low"].min())

                    ts_prev = state.get("ts")
                    if isinstance(ts_prev, datetime):
                        state["ts"] = ts_prev if ts_prev.tzinfo else ts_prev.replace(tzinfo=timezone.utc)
                    else:
                        state["ts"] = now_ctx

                    use_peak_scale = bool(getattr(self, "HIGH_TARGET_USE_PEAK", True))
                    base_for_floor = peak_effective_high if use_peak_scale else level_high
                    lock_ratio_high = float(getattr(self, "HIGH_TARGET_LOCK_RATIO", 0.62))
                    floor_min_high = max(0.0, float(getattr(self, "HIGH_TARGET_FLOOR_MIN", 0.048)))
                    lock_floor_high = max(floor_min_high, base_for_floor * lock_ratio_high)

                    lock_sens = self._lock_sensitivity_value()
                    drop_share_need = max(0.0, float(getattr(self, "HIGH_TARGET_DROP_SHARE", 0.32)) * lock_sens)
                    drop_abs_need = max(0.0, float(getattr(self, "HIGH_TARGET_DROP_ABS", 0.018)) * lock_sens)

                    if current_profit <= lock_floor_high:
                        return trigger("tp_high_target_floor", {
                            "peak_profit": peak_effective_high,
                            "current_profit": current_profit,
                            "lock_floor": lock_floor_high,
                            "threshold": level_high,
                        })

                    drop_val = max(0.0, peak_effective_high - current_profit)
                    drop_share = (drop_val / peak_effective_high) if peak_effective_high > 0 else 0.0
                    drop_trigger = (drop_val >= drop_abs_need) and (drop_share >= drop_share_need)

                    weaken_flag = momo_against or di_flip_against or struct_break_against or drop_trigger
                    if weaken_flag:
                        info = {
                            "peak_profit": peak_effective_high,
                            "current_profit": current_profit,
                            "lock_floor": lock_floor_high,
                            "drop": drop_val,
                            "drop_share": drop_share,
                            "drop_gate": int(drop_trigger),
                            "momo": int(momo_against),
                            "di_flip": int(di_flip_against),
                            "struct": int(struct_break_against),
                        }
                        level_tag = str(getattr(self, "HIGH_TARGET_SCORE_LEVEL", "major")) or "major"
                        ok, score_total, score_need, snap = self._elastic_exit_score(
                            pair,
                            trade_id,
                            side_txt,
                            make_exit_ctx(profit_floor=lock_floor_high, peak_profit=peak_effective_high),
                            level=level_tag,
                            tag="high_target_release",
                            info=info,
                        )
                        if ok:
                            extra = dict(info)
                            extra.update({
                                "elastic_score": round(score_total, 4),
                                "elastic_need": round(score_need, 4),
                            })
                            events_log = snap.get("events") if isinstance(snap, dict) else None
                            if isinstance(events_log, list) and events_log:
                                extra["elastic_events"] = events_log[-3:]
                            return trigger("tp_high_target_release", extra)
                else:
                    high_map.pop(trade_id, None)
        else:
            high_map.pop(trade_id, None)

        if self.PB_RELEASE_ENABLE and (current_profit < pb_min_gate):
            since_open = since_open_full
            atr = float(row.get("atr14", np.nan))
            if np.isfinite(atr) and len(since_open) > 0:
                atrk = float(self.PB_ATR_K)
                if self.PB_REQUIRE_MOMO:
                    momo_ok = ((not is_short and ((row.get("ema_12", 0.0) >= row.get("ema_26", 0.0)) or (row.get("macd", 0.0) >= row.get("macdsignal", 0.0)))))
                    momo_ok = momo_ok or (is_short and ((row.get("ema_12", 0.0) <= row.get("ema_26", 0.0)) or (row.get("macd", 0.0) <= row.get("macdsignal", 0.0))))
                else:
                    momo_ok = True
                if momo_ok:
                    if not is_short:
                        adverse_low = float(since_open["low"].min())
                        trig = adverse_low + atr * atrk
                        if np.isfinite(trig) and float(current_rate) >= trig:
                            info = {"trig": trig, "atrk": atrk}
                            ok, score_total, score_need, snap = self._elastic_exit_score(
                                pair,
                                trade_id,
                                side_txt,
                                make_exit_ctx(),
                                level="major",
                                tag="pb_small_release",
                                info=info,
                            )
                            if ok:
                                extra = {
                                    "trig": trig,
                                    "atrk": atrk,
                                    "elastic_score": round(score_total, 4),
                                    "elastic_need": round(score_need, 4),
                                }
                                events_log = snap.get("events") if isinstance(snap, dict) else None
                                if isinstance(events_log, list) and events_log:
                                    extra["elastic_events"] = events_log[-3:]
                                return trigger("tp_small_pullback_release", extra)
                    else:
                        adverse_high = float(since_open["high"].max())
                        trig = adverse_high - atr * atrk
                        if np.isfinite(trig) and float(current_rate) <= trig:
                            info = {"trig": trig, "atrk": atrk}
                            ok, score_total, score_need, snap = self._elastic_exit_score(
                                pair,
                                trade_id,
                                side_txt,
                                make_exit_ctx(),
                                level="major",
                                tag="pb_small_release",
                                info=info,
                            )
                            if ok:
                                extra = {
                                    "trig": trig,
                                    "atrk": atrk,
                                    "elastic_score": round(score_total, 4),
                                    "elastic_need": round(score_need, 4),
                                }
                                events_log = snap.get("events") if isinstance(snap, dict) else None
                                if isinstance(events_log, list) and events_log:
                                    extra["elastic_events"] = events_log[-3:]
                                return trigger("tp_small_pullback_release", extra)

        if bool(getattr(self, "PB_TRAIL_ENABLE", True)) and current_profit >= float(getattr(self, "PB_TRAIL_AFTER_GATE", 0.018)):
            atr = float(row.get("atr14", float("nan")))
            if np.isfinite(atr):
                since_open = since_open_full
                if len(since_open) > 0:
                    k_tr = float(getattr(self, "PB_TRAIL_ATR_K", 0.55))
                    if not is_short:
                        high_max = float(since_open["high"].max())
                        pb_trig = high_max - atr * k_tr
                        if np.isfinite(pb_trig) and float(current_rate) <= pb_trig:
                            info = {"trail": pb_trig, "atrk": k_tr}
                            ok, score_total, score_need, snap = self._elastic_exit_score(
                                pair,
                                trade_id,
                                side_txt,
                                make_exit_ctx(),
                                level="major",
                                tag="pb_trail_release",
                                info=info,
                            )
                            if ok:
                                extra = {
                                    "trail": pb_trig,
                                    "atrk": k_tr,
                                    "elastic_score": round(score_total, 4),
                                    "elastic_need": round(score_need, 4),
                                }
                                events_log = snap.get("events") if isinstance(snap, dict) else None
                                if isinstance(events_log, list) and events_log:
                                    extra["elastic_events"] = events_log[-3:]
                                return trigger("tp_pb_trail", extra)
                    else:
                        low_min = float(since_open["low"].min())
                        pb_trig = low_min + atr * k_tr
                        if np.isfinite(pb_trig) and float(current_rate) >= pb_trig:
                            info = {"trail": pb_trig, "atrk": k_tr}
                            ok, score_total, score_need, snap = self._elastic_exit_score(
                                pair,
                                trade_id,
                                side_txt,
                                make_exit_ctx(),
                                level="major",
                                tag="pb_trail_release",
                                info=info,
                            )
                            if ok:
                                extra = {
                                    "trail": pb_trig,
                                    "atrk": k_tr,
                                    "elastic_score": round(score_total, 4),
                                    "elastic_need": round(score_need, 4),
                                }
                                events_log = snap.get("events") if isinstance(snap, dict) else None
                                if isinstance(events_log, list) and events_log:
                                    extra["elastic_events"] = events_log[-3:]
                                return trigger("tp_pb_trail", extra)

        if self.MID_ADD_NEAR_RELEASE_ENABLE:
            near_gate2 = (current_profit >= min_profit_exit * near_exit_mult) or (current_profit >= near_exit_alt)
            if near_gate2:
                guard_info = self._expectation_guard_state(
                    pair,
                    trade,
                    float(current_profit),
                    now_ctx=now_ctx,
                    trade_profile=trade_profile,
                    risk_info=risk_info,
                    peak_profit=peak_for_guard,
                    measured_state=mm_state if isinstance(mm_state, dict) else None,
                    current_rate=current_rate,
                )
                weaken_ok2 = ( (not is_short and ((row.get("macd", 0.0) < row.get("macdsignal", 0.0)) or (row.get("close", np.nan) >= row.get("kel_up", np.nan)) or (row.get("wick_up_pct", 0.0) >= 0.35))) or
                               (is_short      and ((row.get("macd", 0.0) > row.get("macdsignal", 0.0)) or (row.get("close", np.nan) <= row.get("kel_dn", np.nan)) or (row.get("wick_dn_pct", 0.0) >= 0.35))) )
                log_guard = bool(guard_info)
                if guard_state is not None and log_guard:
                    log_due = True
                    cooldown = float(po.get("expectation_log_cooldown", getattr(self, "EXPECTATION_LOG_COOLDOWN_MIN", 10.0)) or 0.0)
                    last_log_dt = self._to_utc_datetime(guard_state.get("last_log")) if guard_state.get("last_log") else None
                    if last_log_dt is not None:
                        gap_minutes = max(0.0, (now_ctx - last_log_dt).total_seconds() / 60.0)
                        if cooldown > 0 and gap_minutes < cooldown:
                            log_due = False
                    if log_due:
                        guard_state["last_log"] = now_ctx
                    if log_due:
                        note_extra = {
                            "reason": guard_info.get("reason"),
                            "target_r": round(float(guard_info.get("target_r", 0.0) or 0.0), 3),
                            "current_r": round(float(guard_info.get("current_r", 0.0) or 0.0), 3),
                            "age_min": round(float(guard_info.get("age_minutes", 0.0) or 0.0), 2),
                        }
                        release_r_val = guard_info.get("release_r")
                        drawdown_r_val = guard_info.get("drawdown_r")
                        floor_r_val = guard_info.get("floor_r")
                        floor_profit_val = guard_info.get("floor_profit")
                        if release_r_val:
                            note_extra["release_r"] = round(float(release_r_val), 3)
                        if drawdown_r_val:
                            note_extra["drawdown_r"] = round(float(drawdown_r_val), 3)
                        if floor_r_val:
                            note_extra["floor_r"] = round(float(floor_r_val), 3)
                        if floor_profit_val:
                            note_extra["floor_profit"] = round(float(floor_profit_val), 5)
                        tag = "expectation_guard_hold"
                        if not weaken_ok2:
                            tag = "expectation_guard_hold_pending"
                        self._log_decision(stage, pair, side_txt, "观察", tag, note_extra)
                if weaken_ok2:
                    if not guard_info:
                        info = {
                            "near_exit_alt": near_exit_alt,
                            "macd_flip": int((row.get("macd", 0.0) < row.get("macdsignal", 0.0)) if not is_short else (row.get("macd", 0.0) > row.get("macdsignal", 0.0))),
                            "wick": float(row.get("wick_up_pct" if not is_short else "wick_dn_pct", 0.0)),
                        }
                        ok, score_total, score_need, snap = self._elastic_exit_score(
                            pair,
                            trade_id,
                            side_txt,
                            make_exit_ctx(),
                            level="medium",
                            tag="near_release",
                            info=info,
                        )
                        if ok:
                            extra = {
                                "near_exit_alt": near_exit_alt,
                                "elastic_score": round(score_total, 4),
                                "elastic_need": round(score_need, 4),
                            }
                            events_log = snap.get("events") if isinstance(snap, dict) else None
                            if isinstance(events_log, list) and events_log:
                                extra["elastic_events"] = events_log[-3:]
                            return trigger("tp_near_release", extra)

        if bool(getattr(self, "EMA_HARDLINE_EXIT", True)) and current_profit > 0:
            pad = float(getattr(self, "EMA_HARDLINE_PAD", 0.0010))
            ema200 = float(row.get("ema200_1h", np.nan))
            if np.isfinite(ema200):
                vol_gate = (int(row.get("vol_surge_any", 0)) == 1)
                di_flip = bool(((row.get("minus_di", 0) > row.get("plus_di", 0)) if not is_short else (row.get("plus_di", 0) > row.get("minus_di", 0))))
                if (not is_short and float(current_rate) + float(current_rate)*pad < ema200 and (vol_gate or di_flip)):
                    info = {"ema200": ema200, "pad": pad, "vol_gate": int(vol_gate), "di_flip": int(di_flip)}
                    ok, score_total, score_need, snap = self._elastic_exit_score(
                        pair,
                        trade_id,
                        side_txt,
                        make_exit_ctx(),
                        level="medium",
                        tag="ema_hardline",
                        info=info,
                    )
                    if ok:
                        extra = {
                            "ema200": ema200,
                            "pad": pad,
                            "elastic_score": round(score_total, 4),
                            "elastic_need": round(score_need, 4),
                        }
                        events_log = snap.get("events") if isinstance(snap, dict) else None
                        if isinstance(events_log, list) and events_log:
                            extra["elastic_events"] = events_log[-3:]
                        return trigger("tp_ema_hardline", extra)
                if (is_short and float(current_rate) - float(current_rate)*pad > ema200 and (vol_gate or di_flip)):
                    info = {"ema200": ema200, "pad": pad, "vol_gate": int(vol_gate), "di_flip": int(di_flip)}
                    ok, score_total, score_need, snap = self._elastic_exit_score(
                        pair,
                        trade_id,
                        side_txt,
                        make_exit_ctx(),
                        level="medium",
                        tag="ema_hardline",
                        info=info,
                    )
                    if ok:
                        extra = {
                            "ema200": ema200,
                            "pad": pad,
                            "elastic_score": round(score_total, 4),
                            "elastic_need": round(score_need, 4),
                        }
                        events_log = snap.get("events") if isinstance(snap, dict) else None
                        if isinstance(events_log, list) and events_log:
                            extra["elastic_events"] = events_log[-3:]
                        return trigger("tp_ema_hardline", extra)

        if bool(getattr(self, "VOL_EXHAUST_EXIT", True)) and current_profit >= min_profit_exit * 0.5:
            try:
                n = int(getattr(self, "VOL_EXH_DECAY_BARS", 4))
                recent = df.tail(max(2, n))
                ratio = (recent["vol_ma_fast"] / (recent["vol_ma_slow"] + 1e-12)).replace([np.inf, -np.inf], np.nan).fillna(0.0)
                drop_ok = (ratio.iloc[-1] <= ratio.max() * float(getattr(self, "VOL_EXH_DROP", 0.75)))
            except Exception:
                drop_ok = False
            if drop_ok and int(row.get("macdh_weak_cnt", 0)) >= 3:
                info = {
                    "vol_drop": int(drop_ok),
                    "macdh_weak": int(row.get("macdh_weak_cnt", 0)),
                }
                ok, score_total, score_need, snap = self._elastic_exit_score(
                    pair,
                    trade_id,
                    side_txt,
                    make_exit_ctx(),
                    level="medium",
                    tag="vol_exhaust",
                    info=info,
                )
                if ok:
                    extra = {
                        "vol_drop": int(drop_ok),
                        "macdh_weak": int(row.get("macdh_weak_cnt", 0)),
                        "elastic_score": round(score_total, 4),
                        "elastic_need": round(score_need, 4),
                    }
                    events_log = snap.get("events") if isinstance(snap, dict) else None
                    if isinstance(events_log, list) and events_log:
                        extra["elastic_events"] = events_log[-3:]
                    return trigger("tp_vol_exhaust", extra)

        try:
            last_ts = df.index[-1]
            open_ts = pd.Timestamp(trade.open_date_utc, tz=last_ts.tz if last_ts.tz is not None else None)
            since_open = df.loc[df.index >= open_ts]
        except Exception:
            since_open = df.tail(1)

        if self.STRUCT_STAIR_EXIT_ENABLED and len(since_open) > 0 and current_profit >= float(getattr(self, "STRUCT_EXIT_MIN_PROFIT", 0.0)):
            step_count = int((since_open["new_LL"].sum() if is_short else since_open["new_HH"].sum()))
            mode = str(getattr(self, "STRUCT_EXIT_MODE", "confirm")).lower()
            di_flip_against = int(((row.get("minus_di", 0) > row.get("plus_di", 0)) if not is_short else (row.get("plus_di", 0) > row.get("minus_di", 0))))
            if step_count >= int(self.STRUCT_STAIR_N):
                if (mode == "eager") or (mode == "confirm" and (int(row.get("macdh_weak_cnt", 0)) >= 2 or di_flip_against == 1)):
                    info = {
                        "stairs": step_count,
                        "mode": mode,
                        "macdh_weak": int(row.get("macdh_weak_cnt", 0)),
                        "di_flip": di_flip_against,
                    }
                    ok, score_total, score_need, snap = self._elastic_exit_score(
                        pair,
                        trade_id,
                        side_txt,
                        make_exit_ctx(),
                        level="medium",
                        tag="struct_stairs",
                        info=info,
                    )
                    if ok:
                        extra = {
                            "stairs": step_count,
                            "elastic_score": round(score_total, 4),
                            "elastic_need": round(score_need, 4),
                        }
                        events_log = snap.get("events") if isinstance(snap, dict) else None
                        if isinstance(events_log, list) and events_log:
                            extra["elastic_events"] = events_log[-3:]
                        return trigger("tp_struct_stairs_done", extra)

        # 峰值回撤/时效（兜底）
        tid = int(trade.id or 0)
        pk = self._peak.get(tid, -1e9)
        if current_profit > pk:
            self._peak[tid] = current_profit
            self._peak_time[tid] = current_time if current_time.tzinfo else current_time.replace(tzinfo=timezone.utc)
            pk = current_profit
        atr_pct_last = float(row.get("atr_pct", 0.006))
        if pk > 0:
            retr = pk - current_profit
            retr_need = max(0.003, min(0.5 * pk, 0.8 * (atr_pct_last if np.isfinite(atr_pct_last) else 0.006)))
            if retr >= retr_need:
                info = {"peak": pk, "retr": retr, "retr_need": retr_need}
                ok, score_total, score_need, snap = self._elastic_exit_score(
                    pair,
                    trade_id,
                    side_txt,
                    make_exit_ctx(peak_profit=pk),
                    level="major",
                    tag="peak_retrace",
                    info=info,
                )
                if ok:
                    extra = {
                        "peak": pk,
                        "retr": retr,
                        "retr_need": retr_need,
                        "elastic_score": round(score_total, 4),
                        "elastic_need": round(score_need, 4),
                    }
                    events_log = snap.get("events") if isinstance(snap, dict) else None
                    if isinstance(events_log, list) and events_log:
                        extra["elastic_events"] = events_log[-3:]
                    return trigger("tp_trail_retrace", extra)

        try:
            t0 = self._peak_time.get(tid, current_time)
            bars_age = int(((current_time if current_time.tzinfo else current_time.replace(tzinfo=timezone.utc)) - t0).total_seconds() // 60) // self._tf_minutes()
        except Exception:
            bars_age = 0
        if bars_age >= 6 and row.get("adx", 0.0) < 18:
            info = {"bars_age": bars_age, "adx": float(row.get("adx", 0.0))}
            ok, score_total, score_need, snap = self._elastic_exit_score(
                pair,
                trade_id,
                side_txt,
                make_exit_ctx(),
                level="minor",
                tag="time_decay",
                info=info,
            )
            if ok:
                extra = {
                    "bars_age": bars_age,
                    "adx": float(row.get("adx", 0.0)),
                    "elastic_score": round(score_total, 4),
                    "elastic_need": round(score_need, 4),
                }
                events_log = snap.get("events") if isinstance(snap, dict) else None
                if isinstance(events_log, list) and events_log:
                    extra["elastic_events"] = events_log[-3:]
                return trigger("tp_time_decay", extra)

        return None

    # -------------------- 分批（先减仓 → 浮盈腿 → 防守腿） --------------------
    def adjust_trade_position(self, trade: Trade, current_time: datetime,
                              current_rate: float, current_profit: float, **kwargs) -> Optional[float]:
        """教学提示：加减仓控制中心，先处理减仓，再判断浮盈腿/防守腿是否满足。"""
        pair = trade.pair
        df, _ = self.dp.get_analyzed_dataframe(pair, self.timeframe)
        if df is None or df.empty:
            return None
        row = df.iloc[-1]
        is_short = bool(trade.is_short)
        side_txt = "short" if is_short else "long"
        pos_amount = abs(float(getattr(trade, "amount", 0.0)) or 0.0)
        trade_id = int(getattr(trade, "id", 0) or 0)
        st = self._pair_state.setdefault(pair, {})  # 教学：持仓状态缓存（信号提示 / 冷却计时等）
        trade_profiles_obj = st.get("trade_profiles")
        trade_profiles = trade_profiles_obj if isinstance(trade_profiles_obj, dict) else {}
        trade_profile = trade_profiles.get(trade_id)
        iceberg_cfg = self._iceberg_config(pair)
        legs = tuple(iceberg_cfg.get("legs", ()))
        tier_label = iceberg_cfg.get("tier_label")
        if tier_label is not None:
            st.setdefault("position_tier_label", tier_label)
        if isinstance(trade_profile, dict):
            if tier_label is not None and not trade_profile.get("position_tier"):
                trade_profile.setdefault("position_tier", str(tier_label))
            if iceberg_cfg.get("balance_total") is not None and not trade_profile.get("position_tier_balance"):
                trade_profile.setdefault("position_tier_balance", float(iceberg_cfg.get("balance_total")))
            if legs and not trade_profile.get("iceberg_legs"):
                trade_profile.setdefault("iceberg_legs", [round(float(x), 6) for x in legs])
        quality_tier = str((trade_profile or {}).get("tier", "base") or "base").lower()
        fill_adjust = self._fill_slippage_adjustment(pair, trade_profile)
        signal_map = st.setdefault("position_signal_review", {})
        signal_hint = signal_map.get(trade_id)
        signal_hint_action: Optional[str] = None
        signal_hint_valid = False
        signal_hint_extra: Dict[str, Any] = {}
        if isinstance(signal_hint, dict):
            signal_hint_action = signal_hint.get("action")
            signal_hint_extra = dict(signal_hint.get("extra", {}))
            ts_hint = self._to_utc_datetime(signal_hint.get("ts"))
            max_age_min = float(getattr(self, "POSITION_SIGNAL_REVIEW_MAX_AGE", 15) or 15)
            if ts_hint:
                now_utc = current_time if current_time.tzinfo else current_time.replace(tzinfo=timezone.utc)
                age_minutes = max(0.0, (now_utc - ts_hint).total_seconds() / 60.0)
                if age_minutes <= max_age_min:
                    signal_hint_valid = True
                else:
                    signal_map.pop(trade_id, None)
                    signal_hint_action = None
            else:
                signal_hint_valid = True

        self._register_portfolio_trade(trade, pair, is_short, float(current_profit), float(current_rate), current_time)
        portfolio_guard = bool(getattr(self, "PORTFOLIO_CONTEXT_ENABLE", True))
        portfolio = self._portfolio_snapshot()
        port_net = float(portfolio.get("net_profit_pct", 0.0) if portfolio_guard else 0.0)
        port_losers = int(portfolio.get("loser_count", 0) if portfolio_guard else 0)
        port_loss_pressure = float(portfolio.get("loss_pressure_pct", 0.0) if portfolio_guard else 0.0)
        fragile_floor = float(getattr(self, "PORTFOLIO_FRAGILE_FLOOR", 0.022))
        loss_need = float(getattr(self, "PORTFOLIO_FRAGILE_LOSS_PRESSURE", 0.10))
        portfolio_fragile = portfolio_guard and (port_net <= fragile_floor) and (port_losers > 0) and (port_loss_pressure >= loss_need)
        pair_cfg = self._pair_cfg(pair)
        po = pair_cfg if isinstance(pair_cfg, dict) else {}
        try:
            scale_out_near_frac = float(
                (po or {}).get("scale_out_near_frac", getattr(self, "SCALE_OUT_NEAR_FRAC", 0.0)) or 0.0
            )
        except (TypeError, ValueError):
            scale_out_near_frac = float(getattr(self, "SCALE_OUT_NEAR_FRAC", 0.0) or 0.0)
        try:
            scale_out_exhaust_frac = float(
                (po or {}).get("scale_out_exhaust_frac", getattr(self, "SCALE_OUT_EXHAUST_FRAC", 0.0)) or 0.0
            )
        except (TypeError, ValueError):
            scale_out_exhaust_frac = float(getattr(self, "SCALE_OUT_EXHAUST_FRAC", 0.0) or 0.0)
        drain_limit = float(getattr(self, "PORTFOLIO_NET_DRAIN_LIMIT", -0.012))
        profile_limit = self._profile_val("portfolio_net_drain_limit", None)
        if profile_limit is not None:
            try:
                drain_limit = float(profile_limit)
            except (TypeError, ValueError):
                pass
        if isinstance(pair_cfg, dict) and pair_cfg.get("portfolio_net_drain_limit") is not None:
            try:
                drain_limit = float(pair_cfg.get("portfolio_net_drain_limit"))
            except (TypeError, ValueError):
                pass

        relax_limit = float(getattr(self, "PORTFOLIO_NET_DRAIN_RELAX_LIMIT", drain_limit))
        relax_limit = float(self._profile_val("portfolio_drain_relax_limit", relax_limit))
        if isinstance(pair_cfg, dict) and pair_cfg.get("portfolio_drain_relax_limit") is not None:
            try:
                relax_limit = float(pair_cfg.get("portfolio_drain_relax_limit"))
            except (TypeError, ValueError):
                pass
        if not np.isfinite(relax_limit):
            relax_limit = drain_limit
        if relax_limit > drain_limit:
            relax_limit = drain_limit

        relax_profit = float(getattr(self, "PORTFOLIO_NET_DRAIN_RELAX_PROFIT", 0.036))
        relax_profit = float(self._profile_val("portfolio_drain_relax_profit", relax_profit))
        if isinstance(pair_cfg, dict) and pair_cfg.get("portfolio_drain_relax_profit") is not None:
            try:
                relax_profit = float(pair_cfg.get("portfolio_drain_relax_profit"))
            except (TypeError, ValueError):
                pass

        relax_align_need = float(getattr(self, "PORTFOLIO_NET_DRAIN_RELAX_ALIGN", 0.22))
        relax_align_need = float(self._profile_val("portfolio_drain_relax_align", relax_align_need))
        if isinstance(pair_cfg, dict) and pair_cfg.get("portfolio_drain_relax_align") is not None:
            try:
                relax_align_need = float(pair_cfg.get("portfolio_drain_relax_align"))
            except (TypeError, ValueError):
                pass

        fast_lane_col = "fast_lane_short" if is_short else "fast_lane_long"
        slow_lane_col = "slow_lane_short" if is_short else "slow_lane_long"
        fast_lane_flag = bool(int(row.get(fast_lane_col, 0) or 0)) if pd.notna(row.get(fast_lane_col, 0)) and np.isfinite(row.get(fast_lane_col, 0)) else False
        slow_lane_flag = bool(int(row.get(slow_lane_col, 0) or 0)) if pd.notna(row.get(slow_lane_col, 0)) and np.isfinite(row.get(slow_lane_col, 0)) else False
        channel_narrow = bool(int(row.get("channel_mode_narrow_trend", 0) or 0))
        channel_wide = bool(int(row.get("channel_mode_wide_range", 0) or 0))
        channel_decay = bool(int(row.get("channel_mode_wide_decay", 0) or 0))
        htf_drive_lane = bool(int(row.get("channel_mode_htf_drive", 0) or 0))
        align_score = float(row.get("htf_alignment", 0.0) or 0.0)
        mania_lane = int(row.get("blowoff_tail_guard", 0) or 0) >= 1
        panic_lane = int(row.get("panic_tail_guard", 0) or 0) >= 1

        flash_ctx = self._flash_volatility_probe(df, is_short)
        flash_state = st.setdefault("flash_guard", {})
        if isinstance(flash_state, dict):
            if flash_ctx:
                try:
                    ts_now = current_time if current_time.tzinfo else current_time.replace(tzinfo=timezone.utc)
                except Exception:
                    ts_now = current_time
                flash_state["last_seen"] = ts_now.isoformat()
                flash_state["exit_bias"] = int(bool(flash_ctx.get("exit_bias")))
                flash_state["defend_bias"] = int(bool(flash_ctx.get("defend_bias")))
                flash_state["volume_ratio"] = float(flash_ctx.get("volume_ratio", 0.0) or 0.0)
                flash_state["wick_against"] = float(flash_ctx.get("wick_against", 0.0) or 0.0)
                flash_state["wick_support"] = float(flash_ctx.get("wick_support", 0.0) or 0.0)
            else:
                flash_state.setdefault("defend_bias", 0)
                flash_state["exit_bias"] = 0

        exit_ctx_obj = st.get("exit_score_ctx")
        if isinstance(exit_ctx_obj, dict):
            exit_score_ctx = exit_ctx_obj
        else:
            exit_score_ctx = {}
            st["exit_score_ctx"] = exit_score_ctx

        add_log_flags = st.setdefault("add_log_flags", {})
        trade_log_flags = add_log_flags.setdefault(trade_id, {}) if trade_id else {}
        cooldown_minutes = float(getattr(self, "ADD_LOG_COOLDOWN_MINUTES", 15.0) or 15.0)

        side_align = align_score if not is_short else -align_score
        lane_relax_ok = fast_lane_flag or (slow_lane_flag and not channel_decay)
        relax_allowed = (
            current_profit >= relax_profit
            and lane_relax_ok
            and not mania_lane
            and not panic_lane
            and side_align >= relax_align_need
        )

        if portfolio_guard and port_net <= drain_limit:
            relaxed_floor = relax_limit
            if relax_allowed and port_net > relaxed_floor:
                self._log_decision("加仓调度", pair, side_txt, "放宽", "组合回撤但浮盈腿仍获准加仓", {
                    "portfolio_net": port_net,
                    "limit": drain_limit,
                    "relax_limit": relaxed_floor,
                    "profit": current_profit,
                    "align": align_score,
                    "align_need": relax_align_need,
                })
            else:
                tag = "组合净值回撤超过放宽阈值暂停加仓" if relax_allowed else "组合净值回撤暂停加仓"
                info = {
                    "portfolio_net": port_net,
                    "limit": drain_limit,
                    "losers": port_losers,
                }
                if relax_allowed:
                    info["relax_limit"] = relaxed_floor
                    info["profit"] = current_profit
                    info["align"] = align_score
                self._log_decision("加仓调度", pair, side_txt, "拦截", tag, info)
                return None

        perf = self._performance_profile(pair)
        perf_guard = bool(perf.get("drawdown_guard", False))
        perf_hot = (perf.get("mode") == "hot")

        ct = current_time if current_time.tzinfo else current_time.replace(tzinfo=timezone.utc)

        def _log_once(key: str, verdict: str, tag: str, info: Dict[str, Any]) -> None:
            if trade_log_flags is None:
                return
            last = trade_log_flags.get(key)
            last_dt: Optional[datetime] = None
            if isinstance(last, datetime):
                last_dt = last if last.tzinfo else last.replace(tzinfo=timezone.utc)
            elif last is not None:
                try:
                    parsed = pd.to_datetime(last).to_pydatetime()
                except Exception:
                    parsed = None
                if isinstance(parsed, datetime):
                    last_dt = parsed if parsed.tzinfo else parsed.replace(tzinfo=timezone.utc)
            if last_dt is not None:
                if (ct - last_dt).total_seconds() < cooldown_minutes * 60.0:
                    return
            trade_log_flags[key] = ct
            self._log_decision("加仓调度", pair, side_txt, verdict, tag, info)
        session_ctx = self._session_context(ct)
        add_side = "short" if is_short else "long"
        event_guard = self._macro_event_guard(ct, pair, add_side, purpose="add")
        if event_guard.get("active") and event_guard.get("block_add", False):
            self._log_decision("加仓调度", pair, add_side, "拦截", "宏观事件窗口暂停加仓", {
                "event": event_guard.get("label", "event"),
                "phase": event_guard.get("phase", "live"),
            })
            return None

        session_block_add = bool(session_ctx.get("block_add") or session_ctx.get("block_adds"))
        session_add_mult = float(session_ctx.get("add_mult", 1.0))
        if session_block_add or session_add_mult == 0.0:
            self._log_decision("加仓调度", pair, add_side, "拦截", "交易时段宵禁暂停加仓", {
                "session": session_ctx.get("label", "session"),
                "session_bias": session_ctx.get("bias", "neutral"),
                "curfew_reason": "session_curfew",
                "block_add": int(session_block_add),
                "local_hour": session_ctx.get("local_hour"),
                "tz_offset_hours": session_ctx.get("offset_hours"),
                "window_local": session_ctx.get("window_local"),
            })
            return None

        if portfolio_fragile:
            align_need_base = float(getattr(self, "PORTFOLIO_FRAGILE_ALIGN", 0.28))
            align_need = self._fragile_align_need(
                align_need_base,
                add_side,
                fast_lane=fast_lane_flag,
                slow_lane=slow_lane_flag,
                htf_drive=htf_drive_lane,
                port_net=port_net,
                loss_pressure=port_loss_pressure,
                panic_lane=panic_lane,
                mania_lane=mania_lane,
            )
            if (not is_short and align_score < align_need) or (is_short and align_score > -align_need):
                self._log_decision("加仓调度", pair, side_txt, "拦截", "组合脆弱期需更强多周期对齐后再加仓", {
                    "portfolio_net": port_net,
                    "align": align_score,
                    "align_need": align_need,
                    "align_need_base": align_need_base,
                    "loss_pressure": port_loss_pressure,
                    "loss_need": loss_need,
                })
                return None

        profile = getattr(self, "_notional_profile", {}) or {}
        leverage = float(profile.get("leverage", self.DEFAULT_LEVERAGE) or self.DEFAULT_LEVERAGE)
        leverage = max(1.0, leverage)
        leverage_cap = getattr(self, "MAX_LEVERAGE_CAP", 0.0)
        if leverage_cap and np.isfinite(leverage_cap) and leverage_cap > 0:
            leverage = min(leverage, leverage_cap)
        cap = self._account_notional_cap(pair)

        live_price = _safe_float(current_rate)
        if live_price <= 0:
            try:
                live_price = _safe_float(row.get("close"))
            except Exception:
                live_price = 0.0

        stake_total = abs(float(getattr(trade, "stake_amount", 0.0)) or 0.0)
        stake_from_cap = False
        base_leg_ratio = float(legs[0]) if legs else 0.0
        if stake_total <= 0 and np.isfinite(cap) and cap > 0:
            if leverage > 0 and base_leg_ratio > 0:
                stake_total = (cap * base_leg_ratio) / leverage
            elif leverage > 0:
                stake_total = cap / leverage
            else:
                stake_total = cap
            stake_from_cap = True

        live_notional = pos_amount * live_price if pos_amount > 0 and live_price and live_price > 0 else 0.0
        fallback_notional = stake_total * leverage if stake_total > 0 else 0.0
        current_notional = live_notional if live_notional > 0 else fallback_notional
        if leverage > 0 and live_notional > 0:
            current_margin = live_notional / leverage
            current_size_basis = "live_position"
        elif stake_total > 0:
            current_margin = stake_total
            current_size_basis = "stake_amount"
        else:
            current_margin = 0.0
            current_size_basis = "empty"

        if not np.isfinite(cap) or cap <= 0:
            cap = current_notional
        cap = max(cap, current_notional)

        if current_size_basis == "empty" or (stake_from_cap and live_notional <= 0):
            info = {
                "live_price": round(float(live_price), 8) if live_price else 0.0,
                "pos_amount": round(float(pos_amount), 8),
                "stake_from_cap": bool(stake_from_cap),
                "cap": round(float(cap or 0.0), 4),
            }
            _log_once("add_size_basis_missing", "搁置", "add_size_basis_missing", info)
            return None

        leg_scale = float(fill_adjust.get("leg_scale", 1.0) or 1.0) if fill_adjust.get("active") else 1.0

        if isinstance(trade_profile, dict):
            try:
                entry_cap_usdt = float(trade_profile.get("entry_cap_usdt", 0.0) or 0.0)
            except (TypeError, ValueError):
                entry_cap_usdt = 0.0
            if entry_cap_usdt > 0 and np.isfinite(entry_cap_usdt):
                cap = max(cap, entry_cap_usdt)
            elif np.isfinite(cap) and cap > 0:
                trade_profile.setdefault("entry_cap_usdt", float(cap))
            try:
                entry_target_notional = float(trade_profile.get("entry_target_notional", 0.0) or 0.0)
            except (TypeError, ValueError):
                entry_target_notional = 0.0
        else:
            entry_cap_usdt = 0.0
            entry_target_notional = 0.0

        trim_min_profit = float(getattr(self, "POSITION_SIGNAL_TRIM_MIN_PROFIT", 0.0) or 0.0)

        # 先 Scale-out（与加仓窗无关）
        if bool(getattr(self, "SCALE_OUT_ENABLE", True)):
            po = pair_cfg if isinstance(pair_cfg, dict) else self._pair_cfg(pair)
            min_profit_exit = float(po.get("min_profit_exit", 0.02))
            near_exit_mult  = float(po.get("near_exit_mult", 0.90))
            near_exit_alt   = float(po.get("near_exit_alt",  0.017))
            if perf_guard:
                min_profit_exit *= 0.90
                near_exit_mult *= 0.95
                near_exit_alt *= 0.85
            elif perf_hot:
                min_profit_exit *= 1.08
                near_exit_mult *= 1.04
                near_exit_alt *= 1.08
            near_gate2 = (current_profit >= min_profit_exit * near_exit_mult) or (current_profit >= near_exit_alt)
            hint_trim_used = False
            trim_hint_ok = signal_hint_valid and signal_hint_action == "trim" and current_profit >= trim_min_profit
            if trim_hint_ok:
                near_gate2 = True
            if near_gate2:
                weaken_ok2 = ((not is_short and ((row.get("macd", 0.0) < row.get("macdsignal", 0.0)) or (row.get("close", np.nan) >= row.get("kel_up", np.nan)) or (row.get("wick_up_pct", 0.0) >= 0.35))) or
                              (is_short      and ((row.get("macd", 0.0) > row.get("macdsignal", 0.0)) or (row.get("close", np.nan) <= row.get("kel_dn", np.nan)) or (row.get("wick_dn_pct", 0.0) >= 0.35))))
                if trim_hint_ok:
                    weaken_ok2 = True
                    hint_trim_used = True
                if weaken_ok2:
                    if pos_amount > 0:
                        reduce_amt = pos_amount * max(0.0, scale_out_near_frac)
                        reduce_amt = min(reduce_amt, pos_amount)
                        if reduce_amt > 0:
                            raw_amount = (-reduce_amt if not is_short else reduce_amt)
                            exit_amount, meta = self._normalize_partial_exit(
                                pair, raw_amount, float(current_rate), pos_amount, tag="scale_out_near")
                            if exit_amount is not None:
                                signal_map.pop(trade_id, None)
                                if hint_trim_used:
                                    info = {**signal_hint_extra, "action": "trim", "source": "signal_review"}
                                    self._log_decision("加减仓", pair, side_txt, "执行", "signal_trim_scale_out", info)
                                return exit_amount
                            meta.update({"price": float(current_rate)})
                            self._log_decision("加减仓", pair, side_txt, "搁置", "scale_out_near_block", meta)

            # 量能衰竭先减
            try:
                n = int(self.VOL_EXH_DECAY_BARS)
                recent = df.tail(max(2, n))
                ratio = (recent["vol_ma_fast"] / (recent["vol_ma_slow"] + 1e-12)).replace([np.inf, -np.inf], np.nan).fillna(0.0)
                drop_ok = (ratio.iloc[-1] <= ratio.max() * float(self.VOL_EXH_DROP))
            except Exception:
                drop_ok = False
                if trim_hint_ok:
                    drop_ok = True
                    hint_trim_used = True
            if drop_ok and int(row.get("macdh_weak_cnt", 0)) >= 3:
                if pos_amount > 0:
                    reduce_amt = pos_amount * max(0.0, scale_out_exhaust_frac)
                    reduce_amt = min(reduce_amt, pos_amount)
                    if reduce_amt > 0:
                        raw_amount = (-reduce_amt if not is_short else reduce_amt)
                        exit_amount, meta = self._normalize_partial_exit(
                            pair, raw_amount, float(current_rate), pos_amount, tag="scale_out_vol")
                        if exit_amount is not None:
                            signal_map.pop(trade_id, None)
                            if trim_hint_ok:
                                info = {**signal_hint_extra, "action": "trim", "source": "signal_review"}
                                self._log_decision("加减仓", pair, side_txt, "执行", "signal_trim_scale_out_vol", info)
                            return exit_amount
                        meta.update({"price": float(current_rate)})
                        self._log_decision("加减仓", pair, side_txt, "搁置", "scale_out_vol_block", meta)

        if perf_guard:
            return None

        # --- 加仓治理 ---
        st = self._pair_state.setdefault(pair, {})
        hint_obj = st.get("fallback_review_hint")
        hint_mode = ""
        hint_age_bars = 0.0
        hint_align = 0.0
        hint_valid = False
        if hint_obj:
            hint_side = hint_obj.get("side")
            expect_side = "short" if is_short else "long"
            side_ok = (not hint_side) or (hint_side == expect_side)
            hint_ts = hint_obj.get("ts")
            hint_dt: Optional[datetime] = None
            if isinstance(hint_ts, datetime):
                hint_dt = hint_ts if hint_ts.tzinfo else hint_ts.replace(tzinfo=timezone.utc)
            elif isinstance(hint_ts, str):
                txt = hint_ts.strip()
                if txt.endswith("Z"):
                    txt = txt[:-1] + "+00:00"
                try:
                    hint_dt = datetime.fromisoformat(txt)
                except ValueError:
                    hint_dt = None
                if hint_dt and hint_dt.tzinfo is None:
                    hint_dt = hint_dt.replace(tzinfo=timezone.utc)
            if hint_dt:
                hint_age_minutes = max(0.0, (ct - hint_dt).total_seconds() / 60.0)
                hint_age_bars = hint_age_minutes / max(1, self._tf_minutes())
            max_age = float(getattr(self, "STOPLOSS_REVIEW_HINT_BARS", 4))
            if side_ok and hint_age_bars <= max_age:
                hint_valid = True
                hint_mode = str(hint_obj.get("mode", "observe"))
                try:
                    hint_align = float(hint_obj.get("align", 0.0) or 0.0)
                except (TypeError, ValueError):
                    hint_align = 0.0
            else:
                st.pop("fallback_review_hint", None)
                hint_obj = None
        defend_hint_active = hint_valid and hint_mode == "defend"
        tighten_hint_active = hint_valid and hint_mode == "tighten"

        adds_done = int(getattr(trade, "nr_of_successful_entries", 0))
        max_adds = int(iceberg_cfg.get("max_adds", int(getattr(self, "max_entry_position_adjustment", 0) or 0)))
        if isinstance(trade_profile, dict) and not trade_profile.get("iceberg_max_adds"):
            trade_profile.setdefault("iceberg_max_adds", max_adds)
        if adds_done >= max_adds:
            return None

        # 早期窗口
        try:
            open_ts = trade.open_date_utc if getattr(trade, "open_date_utc", None) else ct
            bars_open = int(((ct - open_ts).total_seconds() // 60) // self._tf_minutes())
        except Exception:
            bars_open = 0
        lifetime_cap = int(getattr(self, "ADDS_LIFETIME_MAX_BARS", self.ADDS_LIFETIME_MAX_BARS))
        lifetime_cap = max(0, lifetime_cap)
        if bars_open > lifetime_cap:
            extra_bars = int(getattr(self, "STOPLOSS_REVIEW_DEFEND_EXTRA_BARS", 0) or 0)
            if defend_hint_active:
                allow_until = lifetime_cap + max(0, extra_bars)
                if extra_bars == 0 or bars_open <= allow_until:
                    if hint_obj and not hint_obj.get("logged_lifetime_extend"):
                        self._log_decision("加仓调度", pair, side_txt, "放宽", "fallback_defend_extend_lifetime", {
                            "bars_open": bars_open,
                            "limit": lifetime_cap,
                            "extra": extra_bars,
                            "align": round(hint_align, 3),
                        })
                        hint_obj["logged_lifetime_extend"] = True
                else:
                    return None
            else:
                return None

        # 趋势/放量
        adx_val = float(row.get("adx", 0.0))
        vol_surge = int(row.get("vol_surge_any", 0)) == 1
        trend_ok = (adx_val >= float(self.ADX_TREND_STRONG)) or vol_surge
        allow_signal_hint_add = signal_hint_valid and signal_hint_action == "add"
        if bool(getattr(self, "ADD_REQUIRE_TREND_OR_VOL", True)):
            allow_skip = defend_hint_active and bool(getattr(self, "DEF_ADD_DEFEND_ALLOW_TREND_SKIP", True))
            if not trend_ok:
                if allow_skip or allow_signal_hint_add:
                    if hint_obj and not hint_obj.get("logged_trend_relax"):
                        self._log_decision("加仓调度", pair, side_txt, "放宽", "fallback_defend_relax_trend", {
                            "adx": round(adx_val, 3),
                            "vol_surge": int(vol_surge),
                        })
                        hint_obj["logged_trend_relax"] = True
                    if allow_signal_hint_add:
                        self._log_decision("加仓调度", pair, side_txt, "放宽", "signal_add_relax_trend", signal_hint_extra)
                else:
                    return None

        # 浮盈≥阈值后不加
        if current_profit >= float(getattr(self, "NO_ADD_AFTER_ROI", 0.10)):
            return None

        # 加仓冷却
        last_add_t = st.get("last_add_time", None)
        if last_add_t:
            fast_cool = int(iceberg_cfg.get("fastlane_cooloff", getattr(self, "ICEBERG_FASTLANE_COOLOFF", 0)) or 0)
            slow_cool = int(iceberg_cfg.get("slowlane_cooloff", getattr(self, "ICEBERG_SLOWLANE_COOLOFF", 0)) or 0)
            base_cool = int(iceberg_cfg.get("cooldown_bars", getattr(self, "ICEBERG_COOLDOWN_BARS", 0)) or 0)
            lane_cool = fast_cool if (int(row.get("fast_lane_short" if is_short else "fast_lane_long", 0)) == 1) else slow_cool
            cooldown_req = max(base_cool, lane_cool)
            bars_since = int((ct - last_add_t).total_seconds() // 60) // self._tf_minutes()
            if bars_since < cooldown_req:
                if defend_hint_active:
                    min_cd = max(0, int(getattr(self, "DEF_ADD_DEFEND_MIN_COOLDOWN", 1)))
                    if bars_since < min_cd:
                        return None
                    if hint_obj and not hint_obj.get("logged_cooldown_relax"):
                        self._log_decision("加仓调度", pair, side_txt, "放宽", "fallback_defend_relax_cooldown", {
                            "bars_since": bars_since,
                            "cooldown_req": cooldown_req,
                            "min_cd": min_cd,
                        })
                        hint_obj["logged_cooldown_relax"] = True
                else:
                    return None

        # 候选/反候选 + 三锚
        same_cand = int(row.get("sig_short_cand" if is_short else "sig_long_cand", 0)) == 1
        opp_cand = int(row.get("sig_long_cand" if is_short else "sig_short_cand", 0)) == 1
        if opp_cand:
            _log_once("opp_signal", "拦截", "float_add_opposite_signal", {
                "cand_side": ("long" if is_short else "short"),
                "profit": round(float(current_profit), 4),
            })
            return None
        if not same_cand:
            if defend_hint_active:
                if hint_obj and not hint_obj.get("logged_signal_relax"):
                    self._log_decision("加仓调度", pair, side_txt, "放宽", "fallback_defend_use_last_signal", {
                        "age_bars": round(hint_age_bars, 2),
                    })
                    hint_obj["logged_signal_relax"] = True
            elif allow_signal_hint_add:
                self._log_decision("加仓调度", pair, side_txt, "放宽", "signal_add_use_pending", signal_hint_extra)
            else:
                _log_once("same_signal", "搁置", "float_add_wait_signal", {
                    "profit": round(float(current_profit), 4),
                    "age_bars": round(hint_age_bars, 2),
                })
                return None
        tri_need = self._tri_need_threshold()
        tri_need *= float(session_ctx.get("tri_mult", 1.0))
        if event_guard.get("active"):
            tri_need *= float(event_guard.get("tri_mult", 1.0))
        if defend_hint_active:
            tri_need *= float(getattr(self, "DEF_ADD_DEFEND_TRI_RELAX", 1.0))
        tri_bias_val = float(row.get("tri_bias_short" if is_short else "tri_bias_long", 0.0))
        tri_ok = tri_bias_val >= tri_need
        if not tri_ok:
            if defend_hint_active and hint_obj and not hint_obj.get("logged_tri_relax_fail"):
                self._log_decision("加仓调度", pair, side_txt, "拦截", "fallback_defend_tri_gap", {
                    "tri_bias": round(tri_bias_val, 4),
                    "tri_need": round(tri_need, 4),
                })
                hint_obj["logged_tri_relax_fail"] = True
            else:
                _log_once("tri_gap", "搁置", "float_add_tri_gap", {
                    "tri_bias": round(tri_bias_val, 4),
                    "tri_need": round(tri_need, 4),
                })
            return None

        fadd_gate = float(getattr(self, "FADD_MIN_PROFIT_GATE", 0.03))
        if fast_lane_flag:
            fadd_gate *= float(getattr(self, "FADD_FASTLANE_MULT", 1.0))
        elif slow_lane_flag:
            fadd_gate *= float(getattr(self, "FADD_SLOWLANE_MULT", 1.0))
        fadd_gate *= float(session_ctx.get("add_mult", 1.0))
        if event_guard.get("active"):
            fadd_gate *= float(getattr(self, "FADD_EVENT_TIGHTEN", 1.0))
        if channel_narrow and ((not is_short and align_score >= 0.12) or (is_short and align_score <= -0.12)):
            fadd_gate *= 0.80
        if channel_wide and not channel_decay and abs(align_score) <= 0.15:
            fadd_gate *= 0.88
        if channel_wide and channel_decay:
            fadd_gate *= 1.12
        if (not is_short and panic_lane) or (is_short and mania_lane):
            fadd_gate *= 0.85
        if perf_hot:
            fadd_gate *= 0.88
        fadd_gate = fadd_gate * 1.12 if perf_guard else fadd_gate
        if quality_tier == "high":
            fadd_gate *= float(getattr(self, "HIGH_QUALITY_FADD_MULT", 1.0))
        elif quality_tier == "low":
            fadd_gate *= float(getattr(self, "LOW_QUALITY_FADD_MULT", 1.0))
        fadd_gate = max(0.005, fadd_gate)

        float_add_enabled = bool(getattr(self, "FLOAT_ADD_ENABLE", True))
        if not float_add_enabled:
            _log_once("float_add_disabled", "搁置", "float_add_disabled", {
                "profit": round(float(current_profit), 4),
            })
        profit_ready = bool(float_add_enabled and (current_profit >= fadd_gate))
        pre_event_gate: Optional[float] = None
        if event_guard.get("active") and event_guard.get("phase") == "pre":
            pre_event_gate = fadd_gate * 1.10

        # 反马丁
        atr = float(row.get("atr14", np.nan))
        if not np.isfinite(atr): return None
        am_reason = self._anti_martin_block(pair, ("short" if is_short else "long"), float(current_rate), float(atr))
        if am_reason and am_reason not in ("AM flip-flop window", "AM same-side cooldown"):
            return None

        # ATR 有利端回撤
        try:
            last_ts = df.index[-1]
            open_ts_df = pd.Timestamp(trade.open_date_utc, tz=last_ts.tz if last_ts.tz is not None else None)
            since_open = df.loc[df.index >= open_ts_df]
        except Exception:
            since_open = df.tail(1)
        if len(since_open) == 0: return None
        k_pull = float(iceberg_cfg.get("min_pullback_atr", getattr(self, "ICEBERG_MIN_PULLBACK_ATR", 0.0)) or 0.0)
        if channel_narrow and ((not is_short and align_score >= 0.18) or (is_short and align_score <= -0.18)):
            k_pull *= float(self.ICEBERG_PULLBACK_TREND_MULT)
        fast_lane_flag = int(row.get("fast_lane_short" if is_short else "fast_lane_long", 0) or 0) == 1
        slow_lane_flag = int(row.get("slow_lane_short" if is_short else "slow_lane_long", 0) or 0) == 1
        if fast_lane_flag:
            k_pull *= float(self.ICEBERG_PULLBACK_FAST_MULT)
        elif slow_lane_flag:
            k_pull *= float(self.ICEBERG_PULLBACK_DEF_RELAX)
        if defend_hint_active:
            k_pull *= float(self.ICEBERG_PULLBACK_DEF_RELAX)
        if channel_wide and channel_decay:
            k_pull *= float(self.ICEBERG_PULLBACK_DECAY_MULT)
        pull_mult = float(session_ctx.get("add_mult", 1.0))
        if event_guard.get("active"):
            pull_mult *= float(event_guard.get("add_mult", 1.0))
        k_pull *= pull_mult
        if quality_tier == "high":
            k_pull *= float(getattr(self, "HIGH_QUALITY_PULLBACK_MULT", 1.0))
        elif quality_tier == "low":
            k_pull *= float(getattr(self, "LOW_QUALITY_PULLBACK_MULT", 1.0))
        favorable = None
        try:
            open_rate_val = float(trade.open_rate or row.get("close", np.nan))
        except (TypeError, ValueError):
            open_rate_val = float("nan")

        if is_short:
            favorable = float(since_open["low"].min())
            pullback_ok = float(current_rate) >= (favorable + k_pull * atr)
        else:
            favorable = float(since_open["high"].max())
            pullback_ok = float(current_rate) <= (favorable - k_pull * atr)

        self._update_leg_n_shape_state(
            trade,
            trade_profile,
            open_rate=open_rate_val,
            favorable_price=favorable,
            current_rate=current_rate,
            atr=atr,
            pullback_need=k_pull,
            pullback_ok=bool(pullback_ok),
        )
        if not pullback_ok:
            allow_log = profit_ready
            if pre_event_gate is not None:
                allow_log = bool(float_add_enabled and (current_profit >= pre_event_gate))
            if allow_log:
                info = {
                    "profit": round(float(current_profit), 4),
                    "gate": round(float(pre_event_gate if pre_event_gate is not None else fadd_gate), 4),
                    "atr_pull": round(float(k_pull), 4),
                    "atr": round(float(atr), 4),
                    "rate": round(float(current_rate), 4),
                }
                if favorable is not None and np.isfinite(favorable):
                    info["favorable_extreme"] = round(float(favorable), 4)
                _log_once("pullback_wait", "搁置", "float_add_wait_pullback", info)
            return None

        # A) 浮盈金字塔 or B) 防守腿
        take_profit_add = bool(profit_ready)

        def_add_enable = bool(po.get("def_add_enable", getattr(self, "DEF_ADD_ENABLE", True)))
        def_add_max_profit = float(po.get("def_add_max_profit", getattr(self, "DEF_ADD_MAX_PROFIT", 0.005)))
        def_add_min_dd_atr = float(po.get(
            "def_add_min_dd_atr",
            iceberg_cfg.get("def_add_min_dd_atr", getattr(self, "DEF_ADD_MIN_DD_ATR", 0.60)),
        ))
        if flash_ctx and flash_ctx.get("defend_bias"):
            mult = float(getattr(self, "FLASH_VOL_GUARD_DEF_ADD_MULT", 1.0) or 1.0)
            if mult > 0:
                def_add_min_dd_atr *= mult
                exit_score_ctx.setdefault("flash_guard", {}).setdefault("def_add_mult", round(mult, 3))
        def_add_leg_frac = float(po.get(
            "def_add_leg_frac",
            iceberg_cfg.get("def_add_leg_frac", getattr(self, "DEF_ADD_LEG_FRAC", 0.10)),
        ))
        wick_ob = float(getattr(self, "DEF_ADD_WICK_OB", 0.45)); kel_tol = float(getattr(self, "DEF_ADD_KEL_TOL", 0.002))

        hint = hint_obj if hint_valid else None
        if hint:
            log_side = "short" if is_short else "long"
            if defend_hint_active:
                def_add_enable = bool(def_add_enable or True)
                def_add_min_dd_atr *= float(getattr(self, "STOPLOSS_REVIEW_DEF_ADD_RELAX", 0.88))
                def_add_max_profit = max(def_add_max_profit, float(getattr(self, "STOPLOSS_REVIEW_DEF_ADD_MAX_PROFIT", 0.008)))
                if not hint.get("logged_defend"):
                    self._log_decision("加仓治理", pair, log_side, "复核", "fallback_review_defend_hint", {
                        "align": hint.get("align", 0.0),
                        "age_bars": round(hint_age_bars, 2),
                    })
                    hint["logged_defend"] = True
            elif tighten_hint_active:
                def_add_enable = False
                take_profit_add = False
                if not hint.get("logged_tighten"):
                    self._log_decision("加仓治理", pair, log_side, "复核", "fallback_review_tighten_hint", {
                        "align": hint.get("align", 0.0),
                        "age_bars": round(hint_age_bars, 2),
                    })
                    hint["logged_tighten"] = True
            st["fallback_review_hint"] = hint

        if channel_wide and not channel_decay:
            def_add_min_dd_atr *= 0.92
        if channel_wide and channel_decay:
            def_add_enable = False
        if perf_guard:
            def_add_enable = False
        elif perf_hot:
            def_add_min_dd_atr *= 0.92
        if event_guard.get("active"):
            def_add_min_dd_atr *= float(getattr(self, "DEF_ADD_EVENT_TIGHTEN", 1.0))
        def_add_min_dd_atr *= float(session_ctx.get("add_mult", 1.0))
        if quality_tier == "high":
            if not bool(getattr(self, "HIGH_QUALITY_ALLOW_DEF_ADD", False)):
                def_add_enable = False
            else:
                def_add_min_dd_atr *= float(getattr(self, "HIGH_QUALITY_PULLBACK_MULT", 1.0))
        elif quality_tier == "low":
            def_add_min_dd_atr *= float(getattr(self, "LOW_QUALITY_DEF_ADD_MULT", 1.0))

        take_def_add = False
        take_def_add_reason: Optional[str] = None
        dd_atr: Optional[float] = None
        kel_hit = False
        wick_hit = False
        pos_ext = False
        stoprun_flag = False
        wick_extreme = False
        def_add_need_used = float(def_add_min_dd_atr)
        if def_add_enable and (current_profit <= def_add_max_profit):
            open_rate = float(open_rate_val)
            if (not np.isfinite(open_rate)) or open_rate <= 0:
                open_rate = float(trade.open_rate or row.get("close", np.nan))
            if np.isfinite(open_rate) and open_rate > 0:
                wick_col = "wick_up_pct" if is_short else "wick_dn_pct"
                wick_val = float(row.get(wick_col, 0.0) or 0.0)
                stoprun_col = "stoprun_short" if is_short else "stoprun_long"
                try:
                    stoprun_flag = bool(int(row.get(stoprun_col, 0) or 0))
                except (TypeError, ValueError):
                    stoprun_flag = False
                override_enable = bool(getattr(self, "DEF_ADD_WICK_OVERRIDE_ENABLE", True))
                override_share = max(float(getattr(self, "DEF_ADD_WICK_OB", 0.44)), float(getattr(self, "DEF_ADD_WICK_OVERRIDE_SHARE", 0.62)))
                wick_extreme = bool(override_enable and (wick_val >= override_share))
                if is_short:
                    dd_atr = max(0.0, (float(current_rate) - open_rate) / atr)
                    kel_hit = (np.isfinite(float(row.get("kel_up", np.nan))) and float(current_rate) >= float(row.get("kel_up", np.nan)) * (1.0 - kel_tol))
                    wick_hit = wick_val >= float(wick_ob)
                    pos_ext = float(row.get("price_position", 0.5)) >= 0.75
                else:
                    dd_atr = max(0.0, (open_rate - float(current_rate)) / atr)
                    kel_hit = (np.isfinite(float(row.get("kel_dn", np.nan))) and float(current_rate) <= float(row.get("kel_dn", np.nan)) * (1.0 + kel_tol))
                    wick_hit = wick_val >= float(wick_ob)
                    pos_ext = float(row.get("price_position", 0.5)) <= 0.25
                cond_hit = (kel_hit or wick_hit)
                take_def_add = (dd_atr >= def_add_min_dd_atr) and (cond_hit and pos_ext)
                if take_def_add:
                    take_def_add_reason = "base"
                    def_add_need_used = float(def_add_min_dd_atr)
                if channel_wide and not channel_decay and not take_def_add:
                    channel_need = float(def_add_min_dd_atr) * 0.9
                    take_def_add = (dd_atr >= channel_need) and cond_hit
                    if take_def_add:
                        take_def_add_reason = "channel_relax"
                        def_add_need_used = channel_need
                if (not take_def_add) and override_enable and dd_atr is not None and np.isfinite(dd_atr):
                    override_mult = float(getattr(self, "DEF_ADD_WICK_OVERRIDE_ATR_MULT", 0.74))
                    override_need = float(def_add_min_dd_atr) * max(0.0, override_mult)
                    override_need = min(float(def_add_min_dd_atr), override_need)
                    cond_extreme = wick_extreme or stoprun_flag
                    pos_relax_ok = bool(getattr(self, "DEF_ADD_STOPRUN_POS_RELAX", True))
                    cond_sources = cond_hit or cond_extreme
                    pos_ok = pos_ext or (pos_relax_ok and cond_extreme)
                    if cond_extreme and cond_sources and pos_ok and (dd_atr >= override_need):
                        take_def_add = True
                        def_add_need_used = override_need
                        if wick_extreme and not stoprun_flag:
                            take_def_add_reason = "wick_override"
                        elif stoprun_flag and not wick_extreme:
                            take_def_add_reason = "stoprun_override"
                        else:
                            take_def_add_reason = "extreme_override"
                if not take_def_add:
                    info = {
                        "dd_atr": round(float(dd_atr or 0.0), 4),
                        "need": round(float(def_add_min_dd_atr), 4),
                        "kel_hit": int(kel_hit),
                        "wick_hit": int(wick_hit),
                        "stoprun": int(stoprun_flag),
                        "wick_extreme": int(wick_extreme),
                        "pos_ext": int(pos_ext),
                    }
                    _log_once("def_add_wait", "搁置", "def_add_wait_pullback", info)
        elif def_add_enable and current_profit > def_add_max_profit:
            _log_once("def_add_profit", "搁置", "def_add_profit_exceeded", {
                "profit": round(float(current_profit), 4),
                "limit": round(float(def_add_max_profit), 4),
            })
        elif not def_add_enable:
            _log_once("def_add_disabled", "搁置", "def_add_disabled", {
                "profit": round(float(current_profit), 4),
                "quality_tier": quality_tier,
            })

        if event_guard.get("active") and (take_profit_add or take_def_add):
            if event_guard.get("phase") == "pre":
                gate_need = pre_event_gate if pre_event_gate is not None else fadd_gate * 1.10
                take_profit_add = bool(take_profit_add and current_profit >= gate_need)
                take_def_add = bool(take_def_add and dd_atr >= def_add_min_dd_atr * 1.05 if 'dd_atr' in locals() else take_def_add)

        if channel_wide and channel_decay:
            take_profit_add = False

        if not (take_profit_add or take_def_add):
            wait_info: Dict[str, Any] = {
                "profit": round(float(current_profit), 4),
                "profit_gate": round(float(pre_event_gate if pre_event_gate is not None else fadd_gate), 4),
                "def_add_need": round(float(def_add_min_dd_atr), 4),
            }
            if dd_atr is not None:
                wait_info["dd_atr"] = round(float(dd_atr), 4)
            _log_once("add_idle", "搁置", "float_add_wait_conditions", wait_info)
            return None

        if take_profit_add:
            leg_idx = adds_done + 1
            if leg_idx >= len(legs):
                return None
            leg_ratio = float(legs[leg_idx]) * leg_scale
            target_ratio = float(np.sum(legs[:leg_idx])) + leg_ratio
            desired_notional = cap * target_ratio
            add_notional = max(0.0, desired_notional - current_notional)
            stake_usdt = add_notional / leverage if leverage > 0 else 0.0
        else:
            leg_ratio = float(def_add_leg_frac) * leg_scale
            remaining_notional = max(0.0, cap - current_notional)
            add_notional = min(remaining_notional, cap * leg_ratio)
            stake_usdt = add_notional / leverage if leverage > 0 else 0.0

        if stake_usdt <= 0:
            if np.isfinite(cap) and cap > 0:
                cap_gap = max(0.0, float(cap) - float(current_notional))
                tol = max(float(cap) * 1e-4, 1e-6)
                if cap_gap <= tol:
                    info = {
                        "cap_usdt": round(float(cap), 4),
                        "current_notional": round(float(current_notional), 4),
                        "adds_done": adds_done,
                    }
                    if entry_cap_usdt > 0:
                        info["entry_cap_usdt"] = round(float(entry_cap_usdt), 4)
                    _log_once("cap_full", "搁置", "notional_cap_exhausted", info)
            return None

        # 限幅
        min_stake = float(kwargs.get("min_stake", 0.0) or 0.0)
        max_stake = float(kwargs.get("max_stake", stake_usdt) or stake_usdt)
        stake_usdt = max(min(stake_usdt, max_stake), min_stake)

        # 金字塔单次/总仓上限（默认关闭以兼容旧版）
        # 说明：这里用的是钱包余额（未乘杠杆）的可用/总额来约束 stake_usdt，本质限制的是实际占用保证金，而非名义仓位。
        pyr_add_abs = max(0.0, float(getattr(self, "PYRAMID_MAX_ADD_AMOUNT", 0.0) or 0.0))
        pyr_add_pct = max(0.0, float(getattr(self, "PYRAMID_MAX_ADD_PCT", 0.0) or 0.0))
        pyr_pos_pct = max(0.0, float(getattr(self, "PYRAMID_MAX_POSITION_PCT", 0.0) or 0.0))
        if stake_usdt > 0 and (pyr_add_abs > 0 or pyr_add_pct > 0 or pyr_pos_pct > 0):
            profile, free_balance, total_balance = self._resolve_notional_profile(pair)
            usable_free = self._usable_balance_amount(profile, free_balance) if profile else 0.0
            usable_total = self._usable_balance_amount(profile, total_balance) if profile else 0.0

            cap_candidates: List[Tuple[str, float]] = []
            if pyr_add_abs > 0:
                cap_candidates.append(("abs", pyr_add_abs))
            if pyr_add_pct > 0 and usable_free > 0:
                cap_candidates.append(("pct", usable_free * pyr_add_pct))

            if cap_candidates:
                cap_value = min(value for _, value in cap_candidates if value > 0)
                if cap_value > 0 and stake_usdt > cap_value:
                    stake_usdt = max(0.0, cap_value)
                    _log_once("pyramid_add_cap", "拦截", "pyramiding_add_cap", {
                        "cap_reason": "/".join([label for label, _ in cap_candidates]),
                        "cap_amount": round(cap_value, 6),
                        "req_stake": round(float(kwargs.get("stake_amount", stake_usdt)), 6),
                        "usable_free": round(usable_free, 6),
                        "cap_basis": "wallet_pre_leverage",
                        "size_basis": current_size_basis,
                    })

            if pyr_pos_pct > 0 and usable_total > 0:
                pos_cap = usable_total * pyr_pos_pct
                projected_margin = current_margin + stake_usdt
                if projected_margin > pos_cap:
                    allowed_margin = max(0.0, pos_cap - current_margin)
                    if stake_usdt > allowed_margin:
                        stake_usdt = allowed_margin
                        _log_once("pyramid_total_cap", "拦截", "pyramiding_position_cap", {
                            "cap_pct": round(pyr_pos_pct, 4),
                            "pos_cap": round(pos_cap, 6),
                            "projected_margin": round(projected_margin, 6),
                            "current_margin": round(current_margin, 6),
                            "cap_basis": "wallet_pre_leverage",
                            "size_basis": current_size_basis,
                        })

        if take_def_add and flash_ctx and flash_ctx.get("defend_bias") and not take_def_add_reason:
            take_def_add_reason = "flash_guard"
        if take_def_add:
            exec_reason = take_def_add_reason or "base"
            exec_extra = {
                "stake_usdt": round(float(stake_usdt), 4),
                "dd_atr": round(float(dd_atr or 0.0), 4),
                "need": round(float(def_add_need_used), 4),
                "kel_hit": int(kel_hit),
                "wick_hit": int(wick_hit),
                "wick_extreme": int(wick_extreme),
                "stoprun": int(stoprun_flag),
                "pos_ext": int(pos_ext),
            }
            self._log_decision("加仓调度", pair, side_txt, "执行", f"def_add_{exec_reason}", exec_extra)

        st["last_add_time"] = (current_time if current_time.tzinfo else current_time.replace(tzinfo=timezone.utc))
        if signal_hint_valid and signal_hint_action == "add":
            signal_map.pop(trade_id, None)
            exec_info = {**signal_hint_extra, "action": "add", "source": "signal_review"}
            self._log_decision("加仓调度", pair, side_txt, "执行", "signal_add_followup", exec_info)
        if isinstance(trade_log_flags, dict):
            trade_log_flags.pop("pullback_wait", None)
            trade_log_flags.pop("cap_full", None)
        return float(stake_usdt) if stake_usdt > 0 else None

    def custom_position_adjustment(self, trade: Trade, current_time: datetime,
                                   current_rate: float, current_profit: float, **kwargs) -> Optional[float]:
        """兼容 freqtrade 文档使用的 custom_position_adjustment 钩子名称。"""
        return self.adjust_trade_position(trade, current_time, current_rate, current_profit, **kwargs)

    # -------------------- 成交回调（亏损/方向/冷静期计数） --------------------
    def order_filled(self, pair: str, trade: Optional[Trade], order: Optional[Order], **kwargs) -> None:
        """教学提示：成交后更新冷静期、日内次数、最近亏损等状态，供其它闸门引用。"""
        try:
            if trade is None:
                return
            if not getattr(trade, "is_open", True):
                self._portfolio_forget(trade)
            st = self._pair_state.setdefault(pair, {})
            now = datetime.now(timezone.utc)
            trade_id = int(getattr(trade, "id", 0) or 0)

            # 冷静期 & 日内计数（新开仓计数，加仓不计）
            if trade.is_open:
                st["last_dir"] = ("short" if trade.is_short else "long")
                fill_ts = getattr(order, "order_fill_date_utc", None) or getattr(order, "order_date_utc", None) or now
                st["last_dir_time"] = fill_ts if isinstance(fill_ts, datetime) else now
                st["has_open_trade"] = True

                # 标记为 entry 的订单计为一次“新开仓”
                side_tag = getattr(order, "ft_order_side", "") or getattr(order, "order_type", "")
                if isinstance(side_tag, str) and "entry" in side_tag.lower():
                    st["last_entry_time"] = now
                    entries_count = int(getattr(trade, "nr_of_successful_entries", 0))
                    is_initial_entry = entries_count <= 1
                    if is_initial_entry:
                        day_key = f"entries_{_date.fromtimestamp(now.timestamp()).isoformat()}"
                        if st.get("day_key") != day_key:
                            st["day_key"] = day_key; st["entries_today"] = 0
                        st["entries_today"] = int(st.get("entries_today", 0)) + 1

                        pending_snap = st.pop("pending_entry_snapshot", None) or {}
                        entries_now = int(st.get("entries_today", 0))
                        limit_hint = self._normalize_daily_limit_value(
                            pending_snap.get("daily_limit", self._daily_entry_limit())
                        )
                        entries_left = max(0, limit_hint - entries_now) if limit_hint is not None else None
                        log_side = st.get("last_dir")
                        log_extra = {
                            "entries_today": entries_now,
                            "daily_limit": limit_hint if limit_hint is not None else 0,
                            "entries_left": entries_left,
                            "entry_tag": str(pending_snap.get("enter_tag", "") or ""),
                        }
                        self._log_decision("节奏计数", pair, log_side, "记录", "新仓计数更新", log_extra)

                        fill_price: Optional[float] = None
                        if order is not None:
                            for attr in (
                                "ft_order_filled_price",
                                "ft_order_price",
                                "average",
                                "price",
                                "order_price",
                            ):
                                price_candidate = getattr(order, attr, None)
                                price_val = self._safe_float(price_candidate)
                                if price_val is not None and price_val > 0:
                                    fill_price = price_val
                                    break
                        if fill_price is None:
                            fill_price = self._safe_float(getattr(trade, "open_rate", None))
                        fill_dt = fill_ts if isinstance(fill_ts, datetime) else now
                        self._entry_fill_slippage_log(pair, st.get("last_dir"), pending_snap, fill_price, fill_dt)

                        flash_reverse_state = st.get("flash_reverse")
                        if isinstance(flash_reverse_state, dict):
                            flash_reverse_state.pop("pending", None)
                            flash_reverse_state.pop("exhausted", None)
                            flash_reverse_state["last_fill_ts"] = now

                        if trade_id:
                            quality_score = float(pending_snap.get("entry_quality", 0.0) or 0.0)
                            quality_need = float(pending_snap.get("entry_quality_need", 0.0) or 0.0)
                            high_ratio = float(getattr(self, "ENTRY_QUALITY_HIGH_RATIO", 1.18))
                            low_ratio = float(getattr(self, "ENTRY_QUALITY_LOW_RATIO", 0.92))
                            ratio = quality_score
                            if quality_need > 1e-9:
                                ratio = quality_score / quality_need if quality_need > 0 else quality_score
                            ratio = float(np.clip(ratio, 0.0, 5.0))
                            tier = "base"
                            if quality_need > 0:
                                if ratio >= high_ratio:
                                    tier = "high"
                                elif ratio <= max(0.0, low_ratio):
                                    tier = "low"
                            else:
                                if quality_score >= min(1.0, high_ratio):
                                    tier = "high"
                                elif quality_score <= max(0.0, low_ratio):
                                    tier = "low"

                            trade_profiles = st.setdefault("trade_profiles", {})
                            entry_cap_snap = pending_snap.get("entry_cap_usdt") if isinstance(pending_snap, dict) else None
                            entry_target_snap = pending_snap.get("entry_target_notional") if isinstance(pending_snap, dict) else None
                            entry_ratio_snap = pending_snap.get("entry_frontload_ratio") if isinstance(pending_snap, dict) else None
                            try:
                                entry_cap_val = float(entry_cap_snap) if entry_cap_snap is not None else 0.0
                                if not np.isfinite(entry_cap_val) or entry_cap_val <= 0:
                                    entry_cap_val = 0.0
                            except (TypeError, ValueError):
                                entry_cap_val = 0.0
                            try:
                                entry_target_val = float(entry_target_snap) if entry_target_snap is not None else 0.0
                                if not np.isfinite(entry_target_val) or entry_target_val <= 0:
                                    entry_target_val = 0.0
                            except (TypeError, ValueError):
                                entry_target_val = 0.0
                            try:
                                entry_ratio_val = float(entry_ratio_snap) if entry_ratio_snap is not None else float(st.get("last_frontload_ratio", 0.0) or 0.0)
                            except (TypeError, ValueError):
                                entry_ratio_val = float(st.get("last_frontload_ratio", 0.0) or 0.0)

                            entry_notional = 0.0
                            try:
                                amt = abs(float(getattr(trade, "amount", 0.0)) or 0.0)
                                rate = float(getattr(trade, "open_rate", 0.0) or 0.0)
                                if amt > 0 and rate > 0:
                                    entry_notional = amt * rate
                            except (TypeError, ValueError):
                                entry_notional = 0.0

                            fill_ratio = 0.0
                            if entry_target_val > 0 and entry_notional > 0:
                                fill_ratio = entry_notional / entry_target_val
                                profile_entry["fill_slippage_ratio"] = fill_ratio
                                adjust_cfg = self._pair_cfg(pair).get("fill_slippage_adjust", {}) if isinstance(self._pair_cfg(pair), dict) else {}
                                threshold = float(adjust_cfg.get("threshold", getattr(self, "FILL_SLIPPAGE_THRESHOLD", 0.06)) or getattr(self, "FILL_SLIPPAGE_THRESHOLD", 0.06))
                                if abs(fill_ratio - 1.0) >= max(0.0, threshold) and fill_ratio > 1.0:
                                    lock_boost = float(adjust_cfg.get("lock_boost", getattr(self, "FILL_SLIPPAGE_LOCK_BOOST", 0.55)) or getattr(self, "FILL_SLIPPAGE_LOCK_BOOST", 0.55))
                                    lock_boost_max = float(adjust_cfg.get("lock_boost_max", getattr(self, "FILL_SLIPPAGE_LOCK_BOOST_MAX", 1.42)) or getattr(self, "FILL_SLIPPAGE_LOCK_BOOST_MAX", 1.42))
                                    target_penalty = float(adjust_cfg.get("target_penalty", getattr(self, "FILL_SLIPPAGE_TARGET_PENALTY", 0.42)) or getattr(self, "FILL_SLIPPAGE_TARGET_PENALTY", 0.42))
                                    leg_penalty = float(adjust_cfg.get("leg_penalty", getattr(self, "FILL_SLIPPAGE_LEG_PENALTY", 0.60)) or getattr(self, "FILL_SLIPPAGE_LEG_PENALTY", 0.60))
                                    leg_floor = float(adjust_cfg.get("leg_floor", getattr(self, "FILL_SLIPPAGE_LEG_FLOOR", 0.58)) or getattr(self, "FILL_SLIPPAGE_LEG_FLOOR", 0.58))
                                    dev = abs(fill_ratio - 1.0)
                                    profile_entry["fill_slippage_adjust"] = {
                                        "ratio": fill_ratio,
                                        "deviation": dev,
                                        "lock_scale": min(lock_boost_max, 1.0 + dev * lock_boost),
                                        "target_scale": max(0.5, 1.0 - dev * target_penalty),
                                        "leg_scale": max(leg_floor, 1.0 - dev * leg_penalty),
                                    }

                            stake_actual = 0.0
                            try:
                                stake_actual = float(getattr(trade, "stake_amount", 0.0) or 0.0)
                            except (TypeError, ValueError):
                                stake_actual = 0.0

                            account_profile: Dict[str, Any] = {}
                            try:
                                account_profile, _, _ = self._resolve_notional_profile(pair)
                            except Exception:
                                account_profile = {}

                            def _account_param(key: str, default: float = 0.0) -> float:
                                try:
                                    val = float(pending_snap.get(key, 0.0) if isinstance(pending_snap, dict) else 0.0)
                                except (TypeError, ValueError):
                                    val = 0.0
                                if (val is None or val <= 0) and account_profile:
                                    try:
                                        alt = float(account_profile.get(key, default) or default)
                                    except (TypeError, ValueError):
                                        alt = default
                                    if np.isfinite(alt) and alt > 0:
                                        val = alt
                                if val is None or not np.isfinite(val) or val <= 0:
                                    val = default
                                return float(val)

                            fee_rate = _account_param("fee_rate", 0.0)
                            funding_rate = _account_param("funding_rate", 0.0)
                            funding_hours = _account_param("funding_horizon_hours", 8.0)

                            profile_entry = {
                                "tier": tier,
                                "quality_score": quality_score,
                                "quality_need": quality_need,
                                "quality_ratio": ratio,
                                "fast_lane": int(pending_snap.get("fast_lane", 0)),
                                "slow_lane": int(pending_snap.get("slow_lane", 0)),
                                "enter_tag": str(pending_snap.get("enter_tag", "") or ""),
                                "opened": now,
                            }
                            priority_pref_val = pending_snap.get("priority_prefer")
                            if priority_pref_val is not None:
                                profile_entry["priority_prefer"] = priority_pref_val
                            priority_conf_val = pending_snap.get("priority_conf")
                            if priority_conf_val is not None:
                                try:
                                    profile_entry["priority_conf"] = float(priority_conf_val)
                                except (TypeError, ValueError):
                                    pass
                            for crowd_key in (
                                "cluster_same",
                                "cluster_opp",
                                "cluster_bias",
                                "cluster_bias_side",
                                "cluster_window_m",
                                "cluster_last_side",
                            ):
                                if crowd_key in pending_snap:
                                    profile_entry[crowd_key] = pending_snap[crowd_key]
                            if entry_cap_val > 0:
                                profile_entry["entry_cap_usdt"] = entry_cap_val
                            if entry_target_val > 0:
                                profile_entry["entry_target_notional"] = entry_target_val
                            if entry_ratio_val:
                                profile_entry["entry_frontload_ratio"] = entry_ratio_val
                            if entry_notional > 0:
                                profile_entry["entry_notional"] = entry_notional
                            if stake_actual > 0:
                                profile_entry["entry_margin_usdt"] = stake_actual
                                profile_entry["entry_margin_source"] = "trade_stake"
                            if fee_rate > 0:
                                profile_entry["fee_rate"] = fee_rate
                            if funding_rate > 0:
                                profile_entry["funding_rate"] = funding_rate
                            if funding_hours > 0:
                                profile_entry["funding_horizon_hours"] = funding_hours
                            entry_atr_snap = pending_snap.get("entry_atr_pct") if isinstance(pending_snap, dict) else None
                            if entry_atr_snap is not None:
                                try:
                                    entry_atr_val = float(entry_atr_snap)
                                except (TypeError, ValueError):
                                    entry_atr_val = float("nan")
                                if np.isfinite(entry_atr_val) and entry_atr_val > 0:
                                    profile_entry["entry_atr_pct"] = entry_atr_val
                            entry_risk_snap = pending_snap.get("initial_risk_pct") if isinstance(pending_snap, dict) else None
                            if entry_risk_snap is not None:
                                try:
                                    entry_risk_val = float(entry_risk_snap)
                                except (TypeError, ValueError):
                                    entry_risk_val = float("nan")
                                if np.isfinite(entry_risk_val) and entry_risk_val > 0:
                                    profile_entry["initial_risk_pct"] = entry_risk_val
                                    profile_entry.setdefault("risk_live_pct", entry_risk_val)
                                    profile_entry.setdefault("risk_actual_pct", entry_risk_val)
                                    profile_entry["risk_live_mode"] = "entry_snapshot"
                                    profile_entry["risk_live_ts"] = now

                            for rf_key, dest_key, as_float in (
                                ("risk_forecast_pct", "risk_forecast_pct", True),
                                ("risk_forecast_mode", "risk_forecast_mode", False),
                                ("risk_forecast_source", "risk_forecast_source", False),
                                ("risk_forecast_atr", "risk_forecast_atr", True),
                                ("risk_forecast_ewma", "risk_forecast_ewma", True),
                                ("risk_forecast_har", "risk_forecast_har", True),
                                ("risk_forecast_scale", "risk_forecast_scale", True),
                            ):
                                if rf_key not in pending_snap:
                                    continue
                                value = pending_snap.get(rf_key)
                                if as_float:
                                    try:
                                        value = float(value)
                                    except (TypeError, ValueError):
                                        continue
                                    if not np.isfinite(value):
                                        continue
                                profile_entry[dest_key] = value

                            profile_side = st.get("last_dir")
                            if profile_side not in ("long", "short"):
                                profile_side = "short" if bool(getattr(trade, "is_short", False)) else "long"
                            profile_entry["side"] = profile_side

                            trade_profiles[trade_id] = profile_entry

                            self._log_decision(
                                "建仓画像",
                                pair,
                                st.get("last_dir"),
                                "记录",
                                "entry_quality_profile",
                                {
                                    "tier": tier,
                                    "entry_quality": round(quality_score, 4),
                                    "need": round(quality_need, 4),
                                    "ratio": round(ratio, 4),
                                    "fast_lane": int(pending_snap.get("fast_lane", 0)),
                                    "slow_lane": int(pending_snap.get("slow_lane", 0)),
                                },
                            )

                        record = {
                            "time": now,
                            "side": st.get("last_dir"),
                            "fast_lane": int(pending_snap.get("fast_lane", 0)),
                            "slow_lane": int(pending_snap.get("slow_lane", 0)),
                            "align": float(pending_snap.get("align", 0.0) or 0.0),
                            "tri_bias": float(pending_snap.get("tri_bias", 0.0) or 0.0),
                            "tri_need": float(pending_snap.get("tri_need", 0.0) or 0.0),
                            "channel_narrow": int(pending_snap.get("channel_narrow", 0)),
                            "channel_wide": int(pending_snap.get("channel_wide", 0)),
                            "channel_decay": int(pending_snap.get("channel_decay", 0)),
                            "htf_drive": int(pending_snap.get("htf_drive", 0)),
                            "priority_prefer": pending_snap.get("priority_prefer"),
                            "priority_conf": float(pending_snap.get("priority_conf", 0.0) or 0.0),
                            "enter_tag": str(pending_snap.get("enter_tag", "") or ""),
                            "entry_quality": float(pending_snap.get("entry_quality", 0.0) or 0.0),
                            "entry_quality_need": float(pending_snap.get("entry_quality_need", 0.0) or 0.0),
                        }
                        hist = list(st.get("entry_cluster", []))
                        hist.append(record)
                        window_minutes = self._cluster_window_minutes()
                        window_delta = timedelta(minutes=window_minutes)
                        kept: List[Dict[str, Any]] = []
                        for rec in hist[::-1]:
                            when = rec.get("time")
                            if isinstance(when, str):
                                try:
                                    when = datetime.fromisoformat(when)
                                except ValueError:
                                    continue
                            if not isinstance(when, datetime):
                                continue
                            if when.tzinfo is None:
                                when = when.replace(tzinfo=timezone.utc)
                            if now - when <= window_delta:
                                rec = {**rec, "time": when}
                                kept.append(rec)
                        st["entry_cluster"] = list(reversed(kept))

                        pivot_state = st.get("channel_pivot")
                        if isinstance(pivot_state, dict):
                            pending_side = pivot_state.pop("pending_side", None)
                            pivot_state.pop("pending_time", None)
                            last_dir = st.get("last_dir")
                            if pending_side and pending_side == last_dir:
                                pivot_state["last_entry_side"] = pending_side
                                pivot_state["last_entry_ts"] = now
                                regime = pivot_state.get("regime")
                                if regime == "up_break" and pending_side == "short":
                                    pivot_state["pullback_taken"] = True
                                    pivot_state["pullback_ts"] = now
                                elif regime == "down_break" and pending_side == "long":
                                    pivot_state["pullback_taken"] = True
                                    pivot_state["pullback_ts"] = now
                                else:
                                    pivot_state.setdefault("pullback_taken", False)

                    # 记录已成交入场的蜡烛时间，供 WebUI 稳定标记
                    marker_side = "short" if bool(getattr(trade, "is_short", False)) else "long"
                    tf_alias = str(getattr(self, "timeframe", "")).strip().lower() or "5m"
                    tf_minutes = max(1, int(getattr(self, "_current_tf_minutes", self._tf_minutes())))
                    try:
                        fill_stamp = pd.Timestamp(fill_ts) if fill_ts is not None else pd.Timestamp(now)
                    except Exception:
                        fill_stamp = pd.Timestamp(now)
                    if fill_stamp.tzinfo is None:
                        fill_stamp = fill_stamp.tz_localize(timezone.utc)
                    else:
                        fill_stamp = fill_stamp.tz_convert(timezone.utc)
                    try:
                        candle_stamp = fill_stamp.floor(tf_alias)
                    except ValueError:
                        candle_stamp = fill_stamp.floor(f"{tf_minutes}T")
                    if candle_stamp.tzinfo is None:
                        candle_stamp = candle_stamp.tz_localize(timezone.utc)
                    else:
                        candle_stamp = candle_stamp.tz_convert(timezone.utc)
                    marker_cache = st.setdefault("entry_markers", [])
                    marker_cache.append({"ts": candle_stamp, "side": marker_side})
                    max_cache = int(getattr(self, "ENTRY_MARKER_CACHE_LIMIT", 480) or 0)
                    if max_cache > 0 and len(marker_cache) > max_cache:
                        del marker_cache[:-max_cache]
                    st["entry_markers"] = marker_cache
            else:
                st["has_open_trade"] = False
                close_pnl = float(trade.close_profit or 0.0)
                session_slot = self._session_slot(now)
                session_label = str(session_slot.get("label", "unknown") or "unknown")
                profile_ref = profiles.get(trade_id) if isinstance(profiles, dict) else None
                if profile_ref is None:
                    profile_ref = self._lookup_trade_profile(trade_id)
                basis_pct = self._profile_risk_basis_pct(profile_ref)
                if basis_pct <= 0:
                    basis_pct = float(getattr(self, "STOPLOSS_FALLBACK", 0.20))
                realized_r = None
                if basis_pct > 0 and np.isfinite(close_pnl):
                    realized_r = close_pnl / basis_pct
                realized_abs = None
                stake_amt = None
                try:
                    stake_amt = float(getattr(trade, "stake_amount", 0.0) or 0.0)
                except Exception:
                    stake_amt = None
                if stake_amt and np.isfinite(close_pnl):
                    realized_abs = stake_amt * float(close_pnl)
                self._update_session_profit_metrics(
                    now,
                    session_label,
                    realized_r=realized_r if (realized_r is not None and np.isfinite(realized_r)) else None,
                    realized_pct=close_pnl if np.isfinite(close_pnl) else None,
                )
                if realized_abs is not None and np.isfinite(realized_abs):
                    try:
                        self._daily_profit_cap_state(now, pair, realized_abs=realized_abs)
                    except Exception:
                        pass
                if close_pnl < 0:
                    st["last_loss_time"] = now
                    st["last_loss_side"] = ("short" if trade.is_short else "long")
                    st["last_loss_entry"] = float(trade.open_rate or 0.0)

                signal_map = st.get("position_signal_review")
                if isinstance(signal_map, dict):
                    signal_map.pop(int(getattr(trade, "id", 0) or 0), None)

                profiles = st.get("trade_profiles")
                if isinstance(profiles, dict) and trade_id:
                    profiles.pop(trade_id, None)

                add_logs = st.get("add_log_flags")
                if isinstance(add_logs, dict) and trade_id:
                    add_logs.pop(trade_id, None)

                window = max(1, int(getattr(self, "PERF_WINDOW", 6)))
                recents = list(st.get("recent_pnls", []))
                recents.append(close_pnl)
                if len(recents) > window:
                    recents = recents[-window:]
                st["recent_pnls"] = recents
                st["recent_avg"] = float(np.mean(recents)) if recents else 0.0

                if close_pnl < 0:
                    st["loss_streak"] = int(st.get("loss_streak", 0)) + 1
                    st["win_streak"] = 0
                    st["drawdown_acc"] = float(st.get("drawdown_acc", 0.0)) + close_pnl
                else:
                    st["win_streak"] = int(st.get("win_streak", 0)) + 1
                    st["loss_streak"] = 0
                    reset_thr = float(getattr(self, "PERF_RECOVERY_RESET", 0.018))
                    dd_prev = float(st.get("drawdown_acc", 0.0))
                    if close_pnl >= reset_thr:
                        st["drawdown_acc"] = 0.0
                    else:
                        st["drawdown_acc"] = min(0.0, dd_prev + close_pnl)
        except Exception:
            pass

    # -------------------- 资金抖动 & 杠杆 --------------------
    def custom_stake_amount(self, pair: str, current_time: datetime, current_rate: float,
                            proposed_stake: float, min_stake: float, max_stake: float,
                            entry_tag: Optional[str] = None, side: str = "long",
                            trade: Optional[Trade] = None, **kwargs) -> float:
        """教学提示：结合余额分层、手续费/资金费预留动态缩放名义资金 cap。"""
        profile, free_float, _ = self._resolve_notional_profile(pair)
        profile = profile or {}
        st = self._pair_state.setdefault(pair, {})
        iceberg_cfg = self._iceberg_config(pair)
        lev = max(1.0, float(profile.get("leverage", self.DEFAULT_LEVERAGE) or self.DEFAULT_LEVERAGE))
        leverage_cap = getattr(self, "MAX_LEVERAGE_CAP", 0.0)
        if leverage_cap and np.isfinite(leverage_cap) and leverage_cap > 0:
            lev = min(lev, leverage_cap)
        fee_rate = max(0.0, float(profile.get("fee_rate", 0.0) or 0.0))
        funding_rate = max(0.0, float(profile.get("funding_rate", 0.0) or 0.0))
        funding_hours = max(0.0, float(profile.get("funding_horizon_hours", 8.0) or 8.0))
        reserve_ratio = min(max(float(profile.get("reserve_ratio", 0.0) or 0.0), 0.0), 0.95)
        reserve_static = max(0.0, float(profile.get("reserve_static", 0.0) or 0.0))

        cap = self._account_notional_cap(pair)
        base_notional = max(0.0, min(proposed_stake * lev, cap))
        desired_notional = base_notional
        if trade is None:
            snapshot = st.get("pending_entry_snapshot")
            ratio = float(self._entry_frontload_ratio(pair, side, snapshot))
            st["last_frontload_ratio"] = ratio
            if np.isfinite(cap) and cap > 0:
                target_notional = max(0.0, min(cap, cap * ratio))
            else:
                target_notional = base_notional if np.isfinite(base_notional) else 0.0
            desired_notional = target_notional

            if isinstance(snapshot, dict):
                try:
                    if np.isfinite(cap) and cap > 0:
                        snapshot["entry_cap_usdt"] = float(cap)
                except Exception:
                    pass
                try:
                    if np.isfinite(target_notional) and target_notional > 0:
                        snapshot["entry_target_notional"] = float(target_notional)
                except Exception:
                    pass
                try:
                    snapshot["entry_frontload_ratio"] = float(ratio)
                except Exception:
                    snapshot["entry_frontload_ratio"] = ratio
                try:
                    snapshot["entry_leverage"] = float(lev)
                except Exception:
                    snapshot["entry_leverage"] = lev
                margin_hint = target_notional / lev if lev > 0 else 0.0
                if margin_hint > 0:
                    try:
                        snapshot["entry_margin_usdt"] = float(margin_hint)
                    except Exception:
                        snapshot["entry_margin_usdt"] = margin_hint

                tier_label = iceberg_cfg.get("tier_label")
                if tier_label and not snapshot.get("iceberg_tier"):
                    snapshot["iceberg_tier"] = str(tier_label)
                legs_for_snap = tuple(iceberg_cfg.get("legs", ()))
                if legs_for_snap and not snapshot.get("iceberg_legs"):
                    snapshot["iceberg_legs"] = ",".join(f"{x:.2f}" for x in legs_for_snap)

            legs = tuple(iceberg_cfg.get("legs", ()))
            base_ratio = float(legs[0]) if legs else ratio
            if isinstance(snapshot, dict) and snapshot and np.isfinite(cap) and cap > 0:
                diff = ratio - base_ratio
                if abs(diff) >= 1e-4:
                    info = {
                        "base_ratio": round(base_ratio, 4),
                        "frontload_ratio": round(ratio, 4),
                        "cap_usdt": round(float(cap), 3),
                        "fast_lane": int(snapshot.get("fast_lane", 0) or 0),
                        "slow_lane": int(snapshot.get("slow_lane", 0) or 0),
                        "align": round(float(snapshot.get("align", 0.0) or 0.0), 4),
                        "portfolio_fragile": int(snapshot.get("portfolio_fragile", 0) or 0),
                    }
                    verdict = "放宽" if diff > 0 else "收紧"
                    tag = "entry_frontload_expand" if diff > 0 else "entry_frontload_guard"
                    self._log_decision("建仓规模", pair, side, verdict, tag, info)

        stake = desired_notional / lev if lev > 0 else desired_notional
        if self.AF_ENABLE and float(self.AF_STAKE_JITTER or 0.0) > 0:
            j = float(self.AF_STAKE_JITTER)
            sign = -1.0 if np.random.rand() < 0.5 else 1.0
            stake = stake * (1.0 + sign * j)
        if max_stake is not None:
            stake = min(stake, max_stake)

        available_float: Optional[float] = free_float
        if available_float is None or not np.isfinite(available_float):
            wallets = getattr(self, "wallets", None)
            stake_currency = getattr(self, "stake_currency", "USDT")
            if wallets is not None:
                try:
                    available_val = wallets.get_free(stake_currency)
                except Exception:
                    available_val = None
                else:
                    try:
                        available_float = float(available_val) if available_val is not None else None
                        if available_float is not None and not np.isfinite(available_float):
                            available_float = None
                    except (TypeError, ValueError):
                        available_float = None

        usable_after_reserve: Optional[float] = None
        if available_float is not None and np.isfinite(available_float):
            reserve_amt = available_float * reserve_ratio + reserve_static
            usable_after_reserve = max(0.0, available_float - reserve_amt)
            if usable_after_reserve <= 0:
                logger.warning(
                    "%s 可用保证金 %.6f 在预留手续费/资金费后不足以开仓，本次信号将跳过以避免爆仓风险。",
                    pair, available_float,
                )
                return 0.0

            funding_scale = max(1.0, funding_hours / 8.0 if funding_hours > 0 else 0.0)
            cost_multiplier = 1.0 + fee_rate + funding_rate * funding_scale
            cost_multiplier = max(cost_multiplier, 1.0)
            stake = min(stake, usable_after_reserve / cost_multiplier)
            stake = min(stake, usable_after_reserve)
            stake = min(stake, available_float)

        if min_stake is not None:
            try:
                min_req = float(min_stake)
            except (TypeError, ValueError):
                min_req = 0.0
            if (
                available_float is not None
                and np.isfinite(available_float)
                and available_float < min_req - 1e-9
            ):
                logger.warning(
                    "%s 可用保证金 %.6f 低于交易所要求的最小下单量 %.6f，本次信号将跳过以避免反复告警。",
                    pair, available_float, min_req,
                )
                return 0.0
            stake = max(stake, min_req)

        return stake

    def leverage(self, pair: str, current_time: datetime, current_rate: float,
                 proposed_leverage: float, max_leverage: float, entry_tag: Optional[str], side: str,
                 trade: Optional[Trade] = None, **kwargs) -> float:
        """教学提示：统一限定杠杆不超过 5x，如需更高请在这里调整。"""
        cap = self.MAX_LEVERAGE_CAP if hasattr(self, "MAX_LEVERAGE_CAP") else 5.0
        default_max = cap if cap > 0 else 5.0
        return min(default_max, float(max_leverage or default_max))

    # -------------------- WebUI 绘图 --------------------
    @property
    def plot_config(self) -> dict:
        """教学提示：控制 WebUI 图层展示，方便对照护栏/信号质量。"""
        profile = str(self.WEBUI_PLOT_PROFILE or "balanced").strip().lower()
        if profile not in {"lite", "balanced", "full"}:
            profile = "balanced"

        cfg = {
            "main_plot": {
                "ema200_1h": {"color": "#888888"},
                "ema_12": {}, "ema_26": {},
                "kel_up": {}, "kel_mid": {}, "kel_dn": {},
                "struct_trail_long": {}, "struct_trail_short": {},
            },
            "subplots": {
                "ADX": {"adx": {}, "plus_di": {}, "minus_di": {}, "RFS": {}},
                "ATR%": {"atr_pct": {}},
                "MACD": {"macd": {}, "macdsignal": {}, "macdhist": {"type": "bar"}, "macdh_weak_cnt": {}},
                "Distance to 1h EMA200": {
                    "dist_ema200_1h": {},
                    "dist_need_used": {"color": "#ff9900"},
                    "dist_near_min_used": {"color": "#999999"},
                },
                "Stairs & Breaks": {
                    "new_HH": {"type": "bar"},
                    "new_LL": {"type": "bar"},
                    "breakL_conf": {"type": "bar"},
                    "breakS_conf": {"type": "bar"},
                    "wick_up_pct": {},
                    "wick_dn_pct": {},
                },
                "Volume": {
                    "volume": {},
                    "vol_ma_fast": {},
                    "vol_ma_slow": {},
                    "vol_accel": {"type": "bar"},
                    "vol_surge": {"type": "bar"},
                },
                "Entry & Exit Shadows": {
                    "sig_long_cand": {"type": "bar"},
                    "sig_short_cand": {"type": "bar"},
                    "entry_marker_long": {"type": "bar", "color": "#2ecc71"},
                    "entry_marker_short": {"type": "bar", "color": "#e74c3c"},
                    "entry_block_long": {"type": "bar", "color": "#f1c40f"},
                    "entry_block_short": {"type": "bar", "color": "#d35400"},
                    "exit_long": {"type": "bar"},
                    "exit_short": {"type": "bar"},
                },
                "Stop Floors (%)": {
                    "stop_floor_fallback_pct": {"color": "#7f8c8d"},
                    "stop_floor_dynamic_pct": {"color": "#f1c40f"},
                    "stop_floor_adaptive_pct": {"color": "#3498db"},
                    "stop_floor_expect_pct": {"color": "#1abc9c"},
                    "stop_floor_strict_pct": {"color": "#e74c3c"},
                    "stop_floor_final_pct": {"color": "#9b59b6"},
                },
                "Stop R Multiples": {
                    "stop_r_current": {"color": "#34495e"},
                    "stop_r_release": {"color": "#27ae60"},
                    "stop_r_expect": {"color": "#16a085"},
                    "stop_r_strict": {"color": "#c0392b"},
                    "stop_r_final": {"color": "#8e44ad"},
                },
                "Channel Regime": {
                    "kel_width_5m": {},
                    "kel_width_1h": {},
                    "channel_mode_narrow_trend": {"type": "bar"},
                    "channel_mode_wide_range": {"type": "bar"},
                    "channel_mode_wide_decay": {"type": "bar"},
                    "blowoff_tail_guard": {"type": "bar"},
                    "panic_slope_guard": {"type": "bar"},
                    "panic_tail_guard": {"type": "bar"},
                    "reflex_stop_long": {"type": "bar"},
                    "reflex_stop_short": {"type": "bar"},
                },
                "Tri-Anchor": {
                    "tri_dir": {},
                    "tri_breadth": {},
                    "tri_shock": {},
                },
                "Reflexive Energy": {
                    "reflex_feedback": {},
                    "reflex_feedback_ma": {},
                    "reflex_feedback_z": {},
                },
                "GATES": {
                    "gate_atr_ok": {"type": "bar"},
                    "gate_dist_ok_long": {"type": "bar"},
                    "gate_dist_ok_short": {"type": "bar"},
                    "entry_ok_long_shadow": {"type": "bar"},
                    "entry_ok_short_shadow": {"type": "bar"},
                    "gate_chop_trend": {"type": "bar"},
                    "gate_chop_range": {"type": "bar"},
                },
            }
        }

        if profile in {"lite", "balanced"}:
            # Lite/Balanced：默认隐藏结构跟踪线，专注价均与通道核心信息，减少主图残影。
            cfg["main_plot"].pop("struct_trail_long", None)
            cfg["main_plot"].pop("struct_trail_short", None)

        if profile == "lite":
            # Lite：仅保留关键节奏，显著减轻 WebUI 绘图负担。
            keep_subplots = {
                "ADX",
                "Volume",
                "Entry & Exit Shadows",
                "Channel Regime",
            }
            cfg["subplots"] = {k: v for k, v in cfg["subplots"].items() if k in keep_subplots}
        elif profile == "balanced":
            # Balanced：省略最重量级的结构/门控指标，保证信息充足且易于缩放拖动。
            for heavy in (
                "Stairs & Breaks",
                "GATES",
            ):
                cfg["subplots"].pop(heavy, None)

        # Full 档保留全部图层，方便深度审计；无需额外处理。
        return cfg


# ---------------------------------------------------------------------------
"""
新策略完整架构总览（复习用）
--------------------------------------------------------------------
◎ 核心流程十步（v2025.11.07-r08）：
  1) **多周期输入** —— 5m 为主驱动，1h/4h/日线提供偏置、宽度与宏观偏好，channel pivot 将行情拆成突破、回踩与震荡节奏。
  2) **三锚骨架** —— EMA/MACD 方向锚 + 市场广度锚 + 微观冲击锚组装 `tri_bias`，由 `_side_priority_bias` 统一排序多空优先级。
  3) **极端守护 & 探针** —— panic/mania/瀑布护栏与反身性能量联动；暗面评分达标时首腿压成探针仓并输出 `[暗面]` 日志。
  4) **节奏稀疏化** —— QuietMode 融合 CI/ER、冷静期、日内限次与 channel pivot 冷却，避免同节奏反复反手。
  5) **候选闸门** —— ATR、EMA 距离、通道模式、宏观守护与优先级需求过滤噪声，确保高潜力行情才进入终审。
  6) **终审质量分** —— `_entry_quality_score` 汇总对齐、三锚、动能、价格位置与优先级；未达阈值直接拒单并输出扣分项。
  7) **仓位调度** —— 账户画像 cap、首腿前置倍率、浮盈金字塔、防守腿与风格自动驾驶协同，并根据余额 tier 自动重配首腿与 martingale。
  8) **离场治理** —— 弹性止盈计分板整合小目标、停滞、动能衰退、EMA 硬阈、风险守护；动态止损地板结合 ATR、严格回吐与测距期望。
  9) **组合 & 风险守护** —— 组合净值、亏损压力、赢家分布与会话偏置决定是否允许再入或加仓，动态风险基线同步推送名义敞口与杠杆。
 10) **数据闭环** —— `_log_decision`、多档 WebUI 图层与日更复盘报告串联每一次判定，支持教学式复盘与异常追溯。

◎ 调参路线图（建议顺序）：
  - **护栏优先**：按目标币种波动校准 panic/mania、channel pivot、价格极值阈值，确认极端行情守护适配。
  - **仓位其次**：结合资金体量调整 `ACCOUNT_NOTIONAL_PROFILE`、首腿倍率、`POSITION_TIER_SCHEDULE` 与加仓窗口，让名义风险与杠杆匹配账户承受力。
  - **离场最后**：根据胜率/走势微调风格自动驾驶、弹性止盈阈值、严格回吐守卫与动态止损放宽，确保趋势单能拿稳、逆风单快速收敛。
"""
"""
新策略功能与因子审计总结（部署前快速复核）
--------------------------------------------------------------------
◎ 功能全景巡检：
  - **进场链路**：候选影子需先通过对齐/通道/宏观/暗面评分；终审由 `_entry_quality_score`、ATR/距离硬闸与价格极值守护共同决定放行。
  - **仓位调度**：`custom_position_adjustment` 管理浮盈金字塔、防守腿、锁盈减仓，结合 `POSITION_TIER_SCHEDULE` 自动分配首腿/尾腿并记录风格模式、组合回撤与 ATR 条件。
  - **离场治理**：弹性止盈计分板（大/中/小事件）+ 严格回吐守卫 + `_calc_dynamic_loss_floor` 协作，涵盖停滞、震荡、EMA 硬阈、风险守护等场景；Measured Move 与期望守卫共享实时 R 倍数。
  - **宏观守护**：`_session_context`、`_macro_event_guard`、动态热榜与反身性能量按事件窗口自动升阈或暂停信号。
  - **组合治理**：`_portfolio_snapshot`、风格自动驾驶、回撤阈值与日内限次共同限制新仓与加仓，并把名义敞口/杠杆/风险单位写入交易档案。
  - **复盘链路**：`_review_capture_event` 写入机器人标签、事件分数、优先级、中文理由与 UTC/北京时间；`_review_write_report` 输出教学级 Markdown 日报，新增名义敞口与守卫状态回放。
  - **工程守护**：`_audit_feature_conflicts`、`_audit_directional_parity` 现已结构化写入 `_review_state` 与 `_preflight_disaster_guard`，一目了然查看启用状态、冲突/警告与优先级缺口；绘图/日志快照仍为复盘主流程，`tools/*` 脚本用于可选回归辅助。

◎ 因子结构备忘：
  - **趋势/偏置**：`tri_dir` / `tri_breadth` / `tri_shock`、HTF EMA/Keltner、`channel_mode_*` 与风格模式决定多空优先级和首腿倍率。
  - **波动/空间**：`kel_width_*`、`atr_k`、`ema_distance`、价格极值阈值控制追单/防守和止损放宽程度。
  - **动能/节奏**：`rfs`、`vol_accel`、`ci`、`er`、冷静期统计刻画动量衰竭与震荡停滞，驱动离场事件分数。
  - **绩效/组合**：`recent_pnls`、`drawdown_acc`、`portfolio_net`、`loss_streak` 触发风格切换、组合锁盈与再入限制。
  - **极端保护**：panic/blowoff/mania 旗帜、暗面评分、反身性能量、channel pivot 冷却阻断灾难性追单。
  - **优先级权重**：`_side_priority_bias`、`_entry_quality_score` 与弹性止盈事件等级确保进出场都可追溯。

◎ 审计检查清单：
  1) **入场** —— 对照候选/终审日志确认暗面评分、质量分、距离闸门与优先级符合预期；必要时调权重或阈值。
  2) **仓位** —— 复盘首腿倍率、加仓触发与组合回撤；检查风格模式、ATR 窗口、冷静期是否按设定生效。
  3) **离场** —— 检视弹性止盈事件日志与严格回吐守卫记录，确认趋势单未被单一事件提前驱逐、逆风单能及时止损或锁盈；复核 `current_r / target_r` 是否贴合实际杠杆，并确认期望守卫日志出现 `release_stop_r≈0.338` 且 `< current_r` 的“floor clamp”记录（代表旧版 0.5R 止损已落地）。
  4) **数据（可选审计）** —— 有余力时可运行 `tools/strategy_feature_sanity.py`、`tools/future_leak_scan.py`、`tools/preflight_guard_matrix.py` 与逻辑一致性审计，帮助发现潜在代码回归；常规部署不运行也不影响机器人功能。必要时导出名义敞口/杠杆快照交叉核验。
  5) **配置（可选审计）** —— 需要批量检查模板时再执行 `python tools/validate_freqtrade_templates.py`，确认 stake/保证金模式/仓位调整开关/守卫阈值符合最新 freqtrade 规范；若不运行该脚本也可直接用模板配合策略上线，但建议手动复核 `pair_overrides` 中 0.5R 守卫、scale-out、杠杆上限等关键参数覆盖情况。

整体结论：版本 v2025.11.07-r08 在极端守护、进场质量、动态仓位治理、严格回吐锁盈、Measured Move 期望与复盘链路上形成闭环，并新增“≥1R 即把止损抬至 0.5R” 的自动保护；新增全景冲突巡检会把开关状态、冲突与优先级体检写入复盘总控，默认参数即可满足“日内 1–2 单、轻仓试探、顺势放大”节奏，若需个性化调参可按以上步骤逐层审计与覆写。
"""